{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embedding for pdf file using OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import openai  # for generating embeddings\n",
    "import pandas as pd \n",
    "import tiktoken\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting text from the manual pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script described below is engineered to meticulously extract and organize text from PDF documents into a more accessible and structured format. It achieves this by discerning section headers and the associated content, ensuring a coherent representation of the information originally laid out in the PDF.\n",
    "\n",
    "Here's an in-depth overview of how the script functions:\n",
    "\n",
    "1. **Header Identification Function (`is_header`)**: Central to the organization process is the ability to recognize section headers within the document. The `is_header` function executes this by applying a heuristic that deems a text line as a header if it adheres to certain formatting rules, such as being in uppercase or title case. Given the variability in document formatting, this criterion may require customization to suit the particular style and structure of different PDFs.\n",
    "\n",
    "2. **Text Extraction and Sectioning (`extract_sections`)**: This function serves as the workhorse of the script, delving into the PDF specified by `pdf_path` and orchestrating the text into an organized ensemble of sections, each marked by a distinct header:\n",
    "   - The function employs `pdfplumber` for its capability to sift through the PDF and draw out the textual content, offering a raw yet comprehensive look at the document's contents.\n",
    "   - It systematically categorizes the text into headers and their subsequent content. The advent of a new header signals the commencement of a fresh section, thereby ensuring the text is partitioned accurately under the relevant headers.\n",
    "   - Upon the culmination of this processing stage, the function compiles the discrete lines of text into unified strings representative of individual sections. The output materializes as a list of dictionaries, with each dictionary encapsulating a unique section derived from the PDF.\n",
    "\n",
    "3. **Post-Processing for Cohesive Content Representation**: After the initial segmentation and content aggregation, the script performs an additional step of post-processing. This stage involves merging the list of text lines within each section into a singular, coherent string. This transformation is crucial for preserving the narrative flow and original context of the content, making the extracted information more readable and primed for subsequent analysis or processing tasks.\n",
    "\n",
    "4. **Resultant Data Structure**: The final product of the script is a cleanly structured list, where each element is a dictionary that contains a distinct section of the original PDF file. These dictionaries consist of two key components: the 'header' detailing the section's title, and the 'content' representing the amalgamated text pertinent to that section. \n",
    "\n",
    "This methodical approach not only ensures the integrity and continuity of the information extracted from the PDFs but also paves the way for more efficient and organized data handling, whether for analytical, archival, or content management purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_header(text):\n",
    "    # Simple heuristic to determine if a line of text is a header.\n",
    "    # This could be improved with more complex logic, analyzing font size, or using machine learning models.\n",
    "    return text.isupper() or text.istitle()  # Modify this condition based on your specific criteria for headers\n",
    "\n",
    "def extract_sections(pdf_path):\n",
    "    sections = []\n",
    "    current_section = {\"header\": \"\", \"content\": []}\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                for line in text.split('\\n'):\n",
    "                    # Check if the line seems like a header\n",
    "                    if is_header(line):\n",
    "                        # If we were already filling a section, store it and start a new one\n",
    "                        if current_section[\"content\"]:\n",
    "                            sections.append(current_section)\n",
    "                            current_section = {\"header\": \"\", \"content\": []}\n",
    "                        current_section[\"header\"] += line + ' ' \n",
    "                    else:\n",
    "                        # Otherwise, it's normal content, add it to the current section\n",
    "                        current_section[\"content\"].append(line)\n",
    "\n",
    "        if current_section[\"content\"]:\n",
    "            sections.append(current_section)\n",
    "\n",
    "    for section in sections:\n",
    "        section[\"content\"] = '\\n'.join(section[\"content\"])  # Join the list of content lines into a single string\n",
    "\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function on your PDF\n",
    "pdf_path = r\"path_to_your_pdf.pdf\"  # Update this path\n",
    "sections = extract_sections(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'header': 'Petrel Exploration Geophysics ',\n",
       " 'content': 'Interpret regional 2D and 3D projects at your desktop. Make use of high-performance computing\\nfor improved regional understanding.\\nPetrel Geology and Geological Modeling\\nObtain accurate, high-resolution geological models of reservoir structure and stratigraphy.\\nClassification and Estimation | Petrel Facies Modeling | Petrel Well Correlation | Petrel Surface'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'header': '',\n",
       "  'content': 'WWeellccoommee ttoo tthhee PPeettrreell** hheellpp mmaannuuaall\\nPPeettrreell SSeeiissmmiicc ttoo SSiimmuullaattiioonn SSooffttwwaarree\\nOOppttiimmiizzee eexxpplloorraattiioonn aanndd ddeevveellooppmmeenntt ooppeerraattiioonnss\\nPPeettrreell sseeiissmmiicc ttoo ssiimmuullaattiioonn ssooffttwwaarree hheellppss iinnccrreeaassee rreesseerrvvooiirr ppeerrffoorrmmaannccee bbyy iimmpprroovviinngg aasssseett\\ntteeaamm pprroodduuccttiivviittyy.. GGeeoopphhyyssiicciissttss,, ggeeoollooggiissttss,, aanndd rreesseerrvvooiirr eennggiinneeeerrss ccaann ddeevveelloopp ccoollllaabboorraattiivvee\\nwwoorrkkfflloowwss aanndd iinntteeggrraattee ooppeerraattiioonnss ttoo ssttrreeaammlliinnee pprroocceesssseess..\\nBBeenneeffiittss\\nUUnniiffyy wwoorrkkfflloowwss ffoorr EE&&PP tteeaammss-- EElliimmiinnaattee tthhee ggaappss iinn ttrraaddiittiioonnaall ssyysstteemmss tthhaatt rreeqquuiirree\\nhhaannddooffffss ffrroomm oonnee tteecchhnniiccaall ddoommaaiinn ttoo tthhee nneexxtt uussiinngg PPeettrreell mmooddeell--cceennttrriicc wwoorrkkfflloowwss iinn aa\\nsshhaarreedd eeaarrtthh mmooddeell..\\nMMaannaaggee rriisskk aanndd uunncceerrttaaiinnttyy-- EEaassiillyy tteesstt mmuullttiippllee sscceennaarriiooss,, aannaallyyzzee rriisskk aanndd uunncceerrttaaiinnttyy,,\\nccaappttuurree ddaattaa rreellaattiioonnsshhiippss aanndd ppaarraammeetteerrss ttoo ppeerrffoorrmm rraappiidd uuppddaatteess aass nneeww ddaattaa aarrrriivveess,,\\naanndd ppeerrffoorrmm ddeettaaiilleedd ssiimmuullaattiioonn hhiissttoorryy mmaattcchhiinngg..\\nEEnnaabbllee kknnoowwlleeddggee mmaannaaggeemmeenntt aanndd bbeesstt pprraaccttiicceess-- RReedduuccee wwoorrkkffllooww lleeaarrnniinngg ccuurrvveess bbyy\\nccaappttuurriinngg bbeesstt pprraaccttiicceess vviiaa tthhee WWoorrkkffllooww EEddiittoorr,, pprroovviiddiinngg qquuiicckk aacccceessss ttoo pprreeffeerrrreedd\\nwwoorrkkfflloowwss,, aanndd iinnccrreeaassiinngg eeaassee ooff uussee tthhrroouugghh iinnttuuiittiivvee aanndd rreeppeeaattaabbllee wwoorrkkfflloowwss..\\nOOppeenn ffrraammeewwoorrkk-- SSeeaammlleessssllyy iinntteeggrraattee yyoouurr iinntteelllleeccttuuaall pprrooppeerrttyy iinnttoo tthhee PPeettrreell wwoorrkkffllooww\\ntthhrroouugghh tthhee ooppeenn OOcceeaann.. TThhiiss eennvviirroonnmmeenntt lleevveerraaggeess ..NNEETT ttoooollss aanndd ooffffeerrss ssttaabbllee,, uusseerr--\\nffrriieennddllyy iinntteerrffaacceess ffoorr eeffffiicciieenntt ddeevveellooppmmeenntt aalllloowwiinngg ffooccuuss oonn iinnnnoovvaattiioonn rraatthheerr tthhaann\\ninfrastructure.'},\n",
       " {'header': 'Petrel Exploration Geophysics ',\n",
       "  'content': 'Interpret regional 2D and 3D projects at your desktop. Make use of high-performance computing\\nfor improved regional understanding.\\nPetrel Geology and Geological Modeling\\nObtain accurate, high-resolution geological models of reservoir structure and stratigraphy.\\nClassification and Estimation | Petrel Facies Modeling | Petrel Well Correlation | Petrel Surface'},\n",
       " {'header': 'Imaging | Petrel Fault Analysis | Petrel Well Path Design | Data Analysis | Petrel Discrete Fracture ',\n",
       "  'content': 'Modeling | Petrel Workflow Editor and Uncertainty Analysis | Ocean Application Development'},\n",
       " {'header': 'Framework ',\n",
       "  'content': 'Plug-ins for Petrel\\nLeverage predesigned plug-in extensions to add more powerful functonality to standard Petrel\\nseismic to simulation workflows.'},\n",
       " {'header': 'Petrel Geophysics ',\n",
       "  'content': 'Perform rapid 2D and 3D seismic interpretation, fully integrated with geological and engineering\\ntools.\\nClassification and Estimation | Ocean Application Development Framework | Petrel Well Path'},\n",
       " {'header': 'Design | Petrel Seismic Interpretation | Petrel Seismic Attribute Analysis | Petrel Seismic Sampling | Petrel Seismic Volume Rendering & Geobody Extraction | Petrel Domain Conversion Petrel Reservoir Engineering Software ',\n",
       "  'content': 'Integrate dynamic data with geological models to generate reservoir simulation cases, calibrate\\nmodels to observed production data, and forecast reservoir performance for alternative field\\ndevelopment scenarios and multiple geological model realizations to quantify risk and assist in\\nmaking field development decisions'},\n",
       " {'header': '| Ocean Application Development Framework | Petrel Well Path Design | Petrel Advanced Gridding ',\n",
       "  'content': 'and Upscaling | FrontSim | Petrel History Match Analysis | Petrel Reservoir Engineering Core |'},\n",
       " {'header': 'Optimization Tasks|Sensitivity Tasks Petrel Drilling Workflows ',\n",
       "  'content': 'Well path design, drilling visualization, and real-time model updates\\nPetrel Well Path Design | Drilling Event Visualization for Petrel | Real-Time Data Link'},\n",
       " {'header': 'Petrel Support Portal ',\n",
       "  'content': 'For further assistance, see also https://support.slb.com/\\nThis online help was updated on: 22-April-2010'},\n",
       " {'header': 'Petrel Geophysics ',\n",
       "  'content': 'Unified 2D and 3D seismic interpretation software\\nFully integrated with the geological and engineering tools, Petrel geophysical software allows for\\nrapid 2D and 3D seismic interpretation. Sample your seismic data directly into a 3D reservoir\\nmodel to predict pay and bias reservoir property distribution using a geostatistical approach. An\\nextensive library of seismic attributes and volume rendering techniques can help identify\\nhydrocarbon indicators and fracture patterns. A fully scalable solution, Petrel takes you\\nseamlessly from regional exploration to reservoir development.\\nClassification and Estimation\\nEstimate well logs, surfaces, seismic volumes, and 3D property models using neutral network\\ntechnology.'},\n",
       " {'header': 'Petrel Domain Conversion ',\n",
       "  'content': 'Quickly perform domain conversion backwards and forwards between time and depth. Create\\nyour velocity models directly in Petrel or import from any third party application.'},\n",
       " {'header': 'Petrel Seismic Interpretation ',\n",
       "  'content': 'Visualize and interpret regional 2D and 3D seismic data manually or use advanced auto-tracking\\ntechniques. Interactively create attribute maps of horizons or intervals.'},\n",
       " {'header': 'Petrel Seismic Attribute Analysis ',\n",
       "  'content': 'Generate and analyze seismic attributes to enhance information that might be subtle in traditional\\nseismic, leading to a better interpretation of the data.'},\n",
       " {'header': 'Petrel Seismic Sampling ',\n",
       "  'content': 'Convert your seismic data to depth and resample the seismic attribute into the 3D structural grid\\nas a property.'},\n",
       " {'header': 'Petrel Seismic Volume Rendering & Geobody Extraction ',\n",
       "  'content': 'Interactively blend multiple seismic volumes, isolate areas of interest, and then instantly extract\\nwhat is visualized into a 3D object called a geobody.'},\n",
       " {'header': 'Petrel Synthetic Seismograms ',\n",
       "  'content': 'Bridge the gap between your time and depth domains.'},\n",
       " {'header': 'Petrel Exploration Geophysics ',\n",
       "  'content': 'Unprecedented access to extremely large seismic datasets\\nIt is increasingly important to have an accurate regional understanding of the geology and\\nregional structure of your basin. Petrel seismic software is specifically designed to take advantage\\nof the latest advances in PC compute technology, providing unprecedented access to extremely\\nlarge seismic datasets while offering a remarkably interactive user experience.\\nScalable interpretation at your desktop\\nThrough smart disk roaming technology and bricked seismic rendering it is possible to visualize\\nand interpret regional exploration datasets in both 2D and 3D at your desktop without the need to\\ninvest in huge amounts of RAM. Users are able to visualize and interpret data directly from the\\ndisk file with a performance quality traditionally associated with applications where data is loaded\\ninto memory.\\nParallel processing enables rapid analysis\\nParallel processing of geophysical workflows from volume visualization to attribute analysis is\\ndesigned to take full advantage of the rapid development of multiprocessor desktop workstations\\nand provide massive performance enhancements-freeing up the machine and allowing the user to\\nbecome more productive.\\n64-bit for improved performance\\nCombine the power of advanced disk roaming with 64-bit extending memory for the ultimate\\nperformance when working with large seismic datasets. This improves seismic scalability\\nespecially with networked storage seismic. Single seismic data format for line and volume\\ninterpretation removes the need for multiple geophysical applications.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': '3D surveys and thousands of 2D seismic lines can be visualized together to improve\\nunderstanding of regional geology.\\nPerformance and image quality improves with faster hardware and will continue to improve\\nas hardware develops.\\nFull integration with reservoir modeling and reservoir engineering domains provides a\\ncomplete understanding of your basin.\\nExploration scale mapping support.\\nAutomatic fault polygon generation for improved exploration mapping and volumetric\\ncalculations.\\nPetrel Classification and Estimation\\nHandle data estimation and forward modeling problems\\nNeural networks have emerged as proven technology to handle data estimation and forward\\nmodeling problems. The Classification and Estimation module provides an alternative to the\\ndeterministic and stochastic 3D property estimation techniques currently found within Petrel. It\\nalso introduces new workflows for log estimation, property mapping and seismic classification.\\nClassification and estimation process-how it works\\nThis module gives you access to tools for neural network analysis, enabling you to train and then\\ncreate the estimation model object. Data types available for use as input to the estimation and\\nclassification process include:\\nWell logs\\nSurfaces with attributes, including seismic attribute maps\\nProperties, both discrete and continuous\\nPoints with attributes (attributes can be sampled from maps or seismic volumes, points\\ncould also be well tops or point well data)\\nPredictive modeling\\nOnce the nonlinear functions have been created, the estimation model can be used for predictive\\nmodeling on a wide variety of data types via the appropriate Petrel process for that data type.\\nThe relevant Petrel processes are:\\nMake well logs - well logs\\nMulti-trace attribute generation - seismic attribute cubes\\nFacies modeling - discrete property generation\\nPetrophysical modeling - continuous property generation\\nMake surface - surface attributes (including seismic attribute maps)'},\n",
       " {'header': 'Advantages ',\n",
       "  'content': 'Generalized neural network implementation for the estimation of well logs, surfaces, seismic\\nvolumes and 3D property models. An alternative to geostatistics when there exists a non-linear\\nrelationship between a set of input data and a given output, or when there is no single or set of\\ntwo variables that provides an adequate correlation.'},\n",
       " {'header': 'Petrel Seismic Interpretation ',\n",
       "  'content': 'Combine 2D and 3D seismic interpretations in a unified environment\\nPetrel seismic interpretation software seamlessly combines the rigorous workflows of interpreting\\nin 2D with the visual and performance benefits that only 3D volume interpretation can provide.\\nYou also gain the unique advantage of an interpretation environment unified with geology,\\nreservoir modeling, and reservoir engineering domains, giving the ability to rapidly interpret\\nseismic data and compare the results with other data in your project. Effortlessly moving from\\ninterpretation to structural model building to property modeling and back eliminates the gaps and\\ninevitable knowledge and data loss of traditional systems that require handoffs from one technical\\ndomain to the next.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': \"Combines visual and performance advantages of 3D seismic interpretation with the\\ntraditional 2D views for accuracy and detailed event picking, enabling advanced 3D\\nvisualization at every desktop\\nEnables rapid, detailed event interpretation using accurate manual and powerful automated\\ntracking with a wide range of control and editing options\\nOffers the unique advantage of interpreting seismic in a truly unified environment\\nProvides scalable desktop interpretation from regional basin study workflows down to\\nreservoir detail\\n2D seismic interpretation\\nLoad SEG-Y format data together with the corresponding UKOOA navigation data into the Petrel\\napplication for comprehensive 2D workflows. Interpret horizons and faults across 2D data with a\\nfull set of interpretation tools and grid directly from within the Petrel application for improved\\nunderstanding and mapping.\\n3D seismic interpretation\\nVisualize and interpret massive amounts of 3D data directly from your Windows PC without\\nhaving to load all the data to RAM. A full range of tools allows you to take a traditional line-by-line\\napproach combined with the latest algorithms and tools, including amplitude and waveform based\\ntracking for best-in-class 3D volume interpretation, allowing you to achieve rapid results while\\ngiving you control in more complex areas of weaker signal strength.\\n2D/3D multi-volume interpretation\\nIt is often necessary to work with multiple vintages and surveys of both 2D and 3D data. Petrel\\nsoftware makes it easy to interpret across multiple 3D and 2D surveys, either in the interpretation\\nor in 3D windows, to gain the best understanding in the shortest time. Interpret the same event\\nacross multiple surveys and grid, contour, and map either the whole event or just a part for\\nindividual surveys.\\nData management\\nToday's interpretation projects demand a flexible and dynamic project data management\\nstructure to cope with the amount of data involved. Current projects may cover large regional\\nareas, thousands of 2D lines with tens of thousands of traces covering hundreds of kilometers,\\nand multiple 3D vintages and surveys. The Seismic Survey Manager allows you to effectively\\nmanage the 2D and 3D seismic data within your Petrel project, improving the user experience\\nwhen working with large amounts of data.\\nAdditional interpretation highlights\\nBasemap selection of seismic lines, including 2D lines, for display in the interpretation and\\n3D windows\\nMis-tie analysis for correction of gain-, phase-, and vertical mis-ties of 2D data\\nGhost curve analysis, allowing you to correlate your seismic section across faults\\nComposite lines across multiple 2D and 3D surveys for improved regional interpretation\\nSmart cropping of both 2D and 3D data for interpretation or export\\nUnified interpretation windows, 3D windows, and base maps with continuous cursor tracking\\nfor improved interpretation and fully flexible interpretation workflows\\nIntelligent autotracking, including amplitude and waveform based tracking\\nTracking constrained by faults, horizons, polygons, dip, and strike\\nInteractive parameter testing for improved results\\nStored parent-child relationship for easy editing and correction of interpretation\"},\n",
       " {'header': 'Petrel Seismic Attribute Analysis ',\n",
       "  'content': \"Enhance traditional seismic information for improved data interpretation\\nThe attribute generation process contains a library of different single and multi-trace seismic\\nattributes for display and use within the seismic interpretation workflow. Seismic attribute\\nanalysis helps to enhance information that might be subtle in traditional seismic, leading to a\\nbetter interpretation of the data.\\nMultiprocessor capability for rapid attribute calculations\\nTake advantage of multiprocessor desktop workstations to run attributes faster and in the\\nbackground, freeing up the machine and allowing the user to be more productive. Optionally,\\ngenerate attributes remotely on a Linux cluster and instantly review and use the results back in\\nPetrel, reducing the time taken from hours to minutes and allowing more informed decisions to be\\nmade quicker.\\nGenetic inversion\\nSeismic reflection data is the primary input for resolving structural and stratigraphic variations\\nbetween points of well control in the majority of the world's sedimentary basins for the\\nexploitation of hydrocarbon resources. Petrel brings a step change to this process with the fully\\nintegrated genetic inversion algorithm allowing geophysicists and geologists to more accurately\\npredict inter-well properties from seismic inside of Petrel. Horizon autotracking options allow you\\nto pick directly on the impedance volume, or it can be used as an input in the enhanced geobody\\nisolation and extraction process for improved reservoir characterization.\\nSurface attribute library for rapid prospect identification\\nA new attribute library gives the user access to over 40 attributes that can be instantly calculated\\ndirectly at interpreted events, on nearby uninterpreted events, or between events. This allows the\\ninterpreter to extract the maximum value from seismic data by providing more detail on the\\nsubtle lithological variations of your reservoir without having to generate new seismic attribute\\nvolumes, speeding up the prospect identification and mapping workflows.\\nCapture and repeat attributes to share knowledge\\nAttribute calculations can be built into the Workflow Manager and repeated across different events\\nor fields to share knowledge between teams and capture parameters for best practices.\"},\n",
       " {'header': 'Benefits ',\n",
       "  'content': \"Structural attributes can help accelerate the task of picking horizons and faults.\\nSeismic attributes related directly to log and rock properties in the model can take\\nadvantage of the integrated petrophysical and facies modeling in the Petrel application, thus\\ndefining a better model and reducing uncertainty.\\nA wide range of attributes and combinations of different attributes can be used to identify\\nstratigraphical and structural events.\\nParameters can be optimized using a real-time probe or slice. You can then calculate the\\nentire volume or set up a series of calculations using the workflow editor.\\nInstant surface attributes can be generated without having to generate seismic attribute\\nvolumes, increasing understanding, saving time, and enhancing the mapping workflow.\\nMultithreaded and background processing increase performance and speeds up the\\ncalculations, enabling the user to be more productive.\\nRemote attribute generation on a Linux cluster reduces the time, from hours to minutes,\\nand allows attribute volumes to be shared among multiple users.\\nEnhancing seismic workflows\\nA variety of new workflows can be derived using attributes to\\nprecondition the data for better horizon autotracking\\nenhance the fault signature of the data by calculating variance or chaos, or by filtering\\nstructural smoothing with the edge enhancement option\\nprecondition the data for seismic facies extraction using relative acoustic impedance or the\\nchaos attribute to isolate salt bodies\\ncombine attributes and generate users' own attributes using the seismic calculator.\"},\n",
       " {'header': 'Petrel Seismic Sampling ',\n",
       "  'content': 'Generate seismic attribute maps on any 2D surface or average seismic properties within a time or\\ndepth interval.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': 'Display any seismic data with a 3D depth converted model.\\nImport a simulation model into Petrel and quality check it with the seismic data.\\nCondition your reservoir model with depth converted seismic attributes sampled into the\\ngrid.\\nSeismic depth conversion\\nWith a simple click, your seismic volume is depth converted according to the velocity functions for\\nthe horizons in a 3D grid. When a seismic volume is depth converted, Petrel will locate the time\\nhorizons and the corresponding depth horizon in the two 3D grids and adjust the Z-position of\\neach seismic trace. The resulting depth converted seismic will be restricted to the boundaries of\\nthe 3D depth grid.\\nThe depth converted seismic allows the same options as original seismic, including 3D auto\\ntracking and manual interpretation. You can display the volume in the interpretation window and\\ncreate attributes from the depth data.\\nQuality control\\nDisplay the depth converted seismic with property grids or results from simulation to ensure\\nthe quality of the modeling.\\nDifferent disciplines can work together on the same interface.\\nSample depth converted seismic amplitudes or attributes into an existing 3D grid.'},\n",
       " {'header': 'Sampling ',\n",
       "  'content': 'Sampling is the process whereby Petrel investigates the attribute values within a grid cell and\\npopulates the grid cells with one attribute value. The algorithms that can be used in this process\\nare: closest, interpolate, intersection, and exact.\\nTo obtain a realistic and accurate model, the sampled seismic attributes can be used to guide or\\ncondition the property modeling.'},\n",
       " {'header': 'Petrel Seismic Volume Rendering & Geobody Extraction ',\n",
       "  'content': 'Improve reservoir understanding, detect anomalies, and define facies\\nVisualization and extraction of 3D objects from seismic is critical for improving reservoir\\nunderstanding, detecting anomalies, and defining facies. Petrel software now allows users to\\ninteractively blend multiple seismic volumes, isolate areas of interest, and then instantly extract\\nwhat is visualized into a 3D object called a geobody. In essence, \"what you see is what you pick\",\\nmaking this approach to volume interpretation fast, intuitive, and accurate. After the geobody has\\nbeen extracted, it can be included directly in the 3D geological model, providing an efficient\\nworkflow from seismic to geological modeling.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': 'Interactive volume rendering of regional 3D volumes\\nRapid identification and isolation of areas of interest\\nBlending of up to 3 volumes for improved interactive reservoir characterization\\nRGB blending available\\nWYSIWYG-extraction of geobodies based on visualized results\\nInclusion or exclusion of extracted geobody in future settings to allow improved facies\\ndetection\\nSingle-click import into geological model\\nPetrophysical model conditioning with geobody in the geological model\\nCan be used as hard data in multipoint geostatistics workflow\\nSeismic volume rendering\\nInteractively apply transparency on regional 3D seismic volumes to rapidly identify areas of\\ninterest. The ability to set free volumes independent of inline x-lines and time slices and the\\noption to set volumes on or between horizons allow you to take a more geological approach to\\nvisualization. Multiple attribute cubes can be applied and combined in a number of ways to help\\nfurther classify the reservoir.\\nGeobody extraction\\nAfter you have visualized the 3D object, a series of tools allows you to further isolate the body\\nand then interactively extract it. Once extracted, volumetrics can be calculated or the body can be\\ndirectly sampled into a geological model as a discrete object to condition the petrophysical\\nmodeling. Existing geobodies can be included or excluded from further volume extraction for\\nimproved classification of facies. The resulting property can then be used in much the same way\\nas a facies model to condition petrophysical property models. By filtering on this property,\\noperations such as data analysis, property modeling, and volume calculations can be performed\\non the grid cells within the bodies.'},\n",
       " {'header': 'Petrel Domain Conversion ',\n",
       "  'content': 'Geophysicists typically work in the time domain while geologists work with depth data. Petrel\\nDomain Conversion reconciles these differences by helping you make depth data the rule rather\\nthan the exception.\\nPetrel allows you to quickly perform domain conversion backwards and forwards between time\\nand depth. All the necessary steps are performed directly in your project, so there is no need to\\never leave the friendly Petrel interface.\\nPetrel Domain Conversion involves two simple steps. First you create a velocity model and\\ncalibrate it to the available well markers. Next select the data you wish to domain convert,\\nwhether it is surfaces, horizon and fault interpretations, points, well data, 2D and 3D seismic, or\\n3D grids.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': 'Domain conversion runs directly in Petrel, saving you time by avoiding unnecessary input\\nand output of information.\\nPerform domain conversion at any stage in your workflow. Build 3D models in either time or\\ndepth, and convert when it is convenient for you.\\nBuild multiple velocity models to test different velocity parameter scenarios and obtain a\\nbetter understanding of structural uncertainty.\\nUse a 3D grid property for depth conversion, useful for conversion of complex structures\\nsuch as reversely faulted environments.'},\n",
       " {'header': 'Features ',\n",
       "  'content': 'Domain conversion of 2D and 3D seismic, surfaces, horizon and fault interpretations, points,\\nwells and logs, well tops, and 3D grids.\\nUses a standard layer cake approach for domain conversion, giving you the freedom to\\nselect velocity variations for each layer, while preserving the relationships between faults\\nand horizons.\\nVelocity modeling and depth conversion can be run in the Petrel Workflow Editor, allowing\\nyou to generate a single workflow that spans both time and depth domains.\\nSupported velocity methods include linear functions V=Vo, V=Vo+kZ, V=Vo+k(Z-Zo).\\nConstants or surfaces can be used as variables.\\nCan utilize externally generated velocity cubes to create velocity models.\\nSupports conversion within the same domain (Time to Time and Depth to Depth), enabling\\nAVO and 4D seismic workflows and the calibration of PreStack Depth Migration to well\\nmarkers.'},\n",
       " {'header': 'Petrel Geology ',\n",
       "  'content': 'Obtain accurate, high-resolution geological models of reservoir structure\\nand stratigraphy.\\nUnify geology, geophysics, and reservoir engineering\\nIdentifying and recovering hydrocarbons requires an accurate, high-resolution geological model of\\nthe reservoir structure and stratigraphy. The Petrel geology capabilities, all seamlessly unified\\nwith the geophysical and reservoir engineering tools, enable an integrated study by providing an\\naccurate static reservoir description that evolves with the reservoir.\\nClassification and Estimation\\nEstimate well logs, surfaces, seismic volumes, and 3D property models using neutral network\\ntechnology.'},\n",
       " {'header': 'Petrel Surface Imaging ',\n",
       "  'content': 'Display images such as scanned maps, attribute maps, seismic time-slices, or satellite images\\ndraped over structural models.'},\n",
       " {'header': 'Petrel Facies Modeling ',\n",
       "  'content': 'Estimate your facies distributions using a variety of pixel- and object-based stochastic and\\ndeterministic methods.'},\n",
       " {'header': 'Petrel Fault Analysis ',\n",
       "  'content': 'Calculate fluid flow properties and sealing potential for faults in a Petrel model.'},\n",
       " {'header': 'Petrel Fracture Network Modeling ',\n",
       "  'content': 'Create discrete fracture networks or make a combined model with both discrete and continous\\nfracture values, for fracture reservoirs based on well log interpretation and/or seismic data in 3D.\\nWorkflow Editor and the Uncertainty and Optimization processes\\nEvaluate the risk and understand the uncertainty of your reservoir , or create and modify your\\nown workflow to achieve maximum understanding of your field.'},\n",
       " {'header': 'Petrel Petrophysical Modeling ',\n",
       "  'content': 'Assign petrophysical values to cells in a 3D grid; use a number of different deterministic and\\nstochastic modeling techniques.'},\n",
       " {'header': 'Petrel Well Correlation ',\n",
       "  'content': 'Display and organize your logs in a flexible 2D visualization environment.\\nPetrel Classification and Estimation | Petrel Facies Modeling | Petrel Well Correlation | Petrel'},\n",
       " {'header': 'Surface Imaging | Petrel Fault Analysis | Petrel Well Path Design | Data Analysis | Petrel Discrete ',\n",
       "  'content': 'Fracture Modeling | Workflow editor | Petrel OpenSpirit Plug-In | Ocean Application Development'},\n",
       " {'header': 'Framework Petrel Facies Modeling ',\n",
       "  'content': 'New methods to model complex, geological features and connectivity\\nModel your pixel- or object-based stochastic facies using deterministic techniques. Condition the\\nfacies to a seismic property or trend surfaces with the data analysis process, or use objects\\nsampled directly from seismic with the volume extraction tool.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': 'Use a facies 3D model to incorporate your lithological information when modeling reservoir\\nproperties, such as porosity.\\nGuide your algorithms with a range of trends.\\nMultipoint geostatistics\\nTraditional reservoir modeling techniques use simplified, two-point statistics to represent\\ngeological phenomena that have complex geometrical configurations. The use of multipoint\\nstatistics has improved in recent years, reducing the limitations. The Petrel 2010 software release\\nreintroduces multipoint geostatistics, providing users with new methods to model complex\\ngeological features and connectivity. These workflows work efficiently in multimillion cell models\\nand honor well, seismic, and probability data. The workflows are much faster than before and use\\nless than five percent of the memory needed to run MPS in the model, improving performance\\nwhen using training images.\\nIndicator kriging\\nPetrel Facies Modeling features indicator kriging, a deterministic, pixel-based method for\\nproducing krieged facies models.\\nSequential indicator simulation\\nA stochastic, pixel based method for facies modeling lets you\\nindividually set variograms and volume fractions for each facies\\nuse object modeling to distribute facies objects\\ndistribute channels in your model by using fluvial modeling.\\nInteractive editing\\nUse the intuitive drawing tools, such as pencil, brush, and airbrush, as a standard drawing\\npackage. Edit your facies models and use them as a background in object and fluvial modeling.\\nOther features\\nUse the Data Analysis process to investigate and edit trends in the data, condition the\\nmodel to a seismic cube, or build a variogram.\\nUse the scientific calculator for calculations.\\nFilter by index, zone, segment, value, and upscaled cells.\\nGenerate synthetic logs for well trajectories.\\nGenerate connected volumes.\\nVisualize facies in the mapping module for printing scaled maps and intersections in\\ncombination with any other filtered or unfiltered data.\\nView facies in 3D using simbox mode.'},\n",
       " {'header': 'Petrel Well Correlation ',\n",
       "  'content': 'Integrate G&G with reservoir engineering\\nConstruct a consistent geological model that honors the relationships between faults and horizons\\nin 3D space.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': 'Gain a better understanding of your well distribution by viewing well trajectories and log\\ndata in 3D space.\\nDisplay dip and azimuth information as tadpole diagrams.\\nAccess well data from industry standard databases.\\nDisplay well picks in time directly on seismic data.\\nDisplay synthetic seismograms.\\nData import\\nImport well trajectories, well headers, deviations, and logs separately or combined.\\nUse the OpenSpirit plug-in to access and update well data in GeoFrame or OpenWorks\\ndatabases.\\nEdit existing logs or generate new ones from any number of curves using the powerful well\\nlog calculator.\\nInterpret discrete properties interactively.\\nSample data from a property model along well trajectories.\\nImport FMI interpretation.\\nWorking with well picks\\nPick horizon tops in the well panel and see the effects directly in 3D, or vice versa. You can also\\nedit tops manually in a spreadsheet style editor.'},\n",
       " {'header': 'Petrel Surface Imaging ',\n",
       "  'content': 'With the Surface Imaging utility you can drape a surface with any image, including aerial or\\nsatellite images, scanned maps, seismic time-slices, or property maps. For example, in hill\\nterrain, you can drape a satellite image over the model to check access to proposed drilling sites.\\nYou can also drape maps or property surfaces over models.\\nBuild 3D models when only paper data is available. Paper maps can be scanned and then\\nimported as images, from which digital maps can be created by digitizing over the contours.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': 'Drape satellite images over the topographic surface to precisely locate surface features.\\nImport scanned maps or drawings, orientated correctly in 3D space and draped over a\\nsurface.\\nDrape property maps, isochore maps and maps of any seismic attribute over time or depth\\nsurfaces.'},\n",
       " {'header': 'Workflow ',\n",
       "  'content': 'Import images in a range of formats and drape (project) over surfaces in the Petrel model.\\nSet corner coordinates\\nImages can be gridded where the pixel intensity is used as elevation. This is an excellent\\nway to display images together with your Petrel models.'},\n",
       " {'header': 'Petrel Fault Analysis ',\n",
       "  'content': 'Calculate fluid flow properties and sealing potential for faults\\nThe Fault Analysis module lets you calculate fluid flow properties and sealing potential for faults in\\na Petrel model. The module uses geologic parameters, such as fault displacements and adjacent\\nrock types, to estimate fault zone thickness, permeability, and sealing potential. From the fault\\nzone permeability and thickness estimations, transmissibility multipliers are calculated for each\\ncell that lies adjacent to a fault.\\nYou can also assign basic properties to a fault, such as a uniform transmissibility multiplier and\\nthreshold pressure. Fault properties can then be visualized in the viewers and used as keywords\\nin the ECLIPSE simulators.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': 'Calculate the sealing potential of faults with user-defined equations.\\nGenerate detailed Allen diagrams for visual analysis.\\nUse the calculated transmissibility multiplier directly in simulation, without leaving Petrel.'},\n",
       " {'header': 'Petrel Well Path Design ',\n",
       "  'content': 'Design well paths in 3D\\nDesign wells interactively by digitizing the path directly in the 3D window-on any type of data,\\nincluding raw seismic, property models or simulation results. Edit well nodes in the 3D window or\\nthe spreadsheet editor, or copy and paste into Excel for editing. Share data points describing the\\nnew well with Osprey Risk.\\nMinimize the total cost of your drilling program\\nAutomatically generate well trajectories and platform locations for a set of reservoir targets to\\nminimize the total cost of your drilling program, using the Petrel Well Cost Optimizer (part of the\\nWell Path Design module). Targets defined as \"must hit\" data points for the optimized well paths\\nmust can be locked to platforms, and target-platform sets can be constrained by closed\\nboundaries. Automatically computed well trajectories are constrained by a user-defined dogleg\\nseverity. The output is a set of optimized trajectories based on geometrical drilling constraints\\nextending from the reservoir back to the surface. The Drilling Difficulty Index (DDI) provides a\\nfirst-pass evaluation of the relative difficulty encountered in drilling a well.\\nCreate a well that fits into a region\\nThe Create best fit well option of the Well path design process allows you to create a well based\\non a discrete 3D grid property. To use the option you need to define a target region as a discrete\\ngrid property. Then supply this region along with a point set that specifies the well header as\\ninput, and Petrel generates a well, possibly multi-lateral, that fits the region.\\nComplex well placement and optimization\\nPetrel 2010.1 introduces a new feature that allows placing wells and/or laterals automatically\\ninside arbitrary volumes of interest in the model without the need for manual digitizing. An\\nadditional Lateral design process allows automatic design of a system of laterals connected to\\nexisting wells using pre-defined templates (fork, fish-bone) to produce complex wells. This\\napproach where Petrel computes the placement of the wells/laterals based on given inputs makes\\nthe process repeatable in a workflow and hence amenable to optimization using the uncertainty\\nand optimization module.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': 'Automatically generate well trajectories and platform locations that minimize the total\\ndrilling program cost\\nManually design wells quickly in 3D, directly on seismic lines, property models, STOIIP maps\\nand even simulation results\\nDisplay well path segments that exceed your specified dogleg severity\\nCreate instant well reports and synthetic property logs\\nExport generated well paths for use in drilling and reservoir simulation packages'},\n",
       " {'header': 'Petrel Data Analysis ',\n",
       "  'content': 'The Data Analysis utility lets you analyze data interactively to gain a better understanding of the\\ntrends within your data. You also benefit from an understanding of the relationships across all\\nyour data types.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': 'Gain better control of the modeling process through trend analysis and transformations\\nPerform interactive and intuitive variogram analysis\\nRapidly generate presentation-ready cross plots and histograms\\nCalculate and save regression curves and cumulative distribution functions\\nContinuous properties\\nUse simple transformations such as input and output truncations, scale shifts, logarithmic and\\nbox-cox operations. More complex data transformation functions allow you to edit the property\\ndistribution directly on the histogram.'},\n",
       " {'header': 'Discrete Properties ',\n",
       "  'content': 'Perform facies thickness analysis, investigate and edit vertical facies distributions and correlate\\nfacies type to seismic attributes.'},\n",
       " {'header': 'Variograms ',\n",
       "  'content': 'Simplify the whole data analysis process by using the intuitive, interactive variogram analysis\\ntool.\\nDefine the search criteria for the analysis and see the resultant search cone plotted\\ntogether with the input data in the map window\\nEdit the variogram models either graphically, on the histograms or by typing numbers\\ndirectly as input\\nGenerate variogram maps from your input data to determine major and minor directions'},\n",
       " {'header': 'Data Management ',\n",
       "  'content': 'Save all the detailed analysis for each property for use later in the modeling process or when you\\nare updating your models at some later time.'},\n",
       " {'header': 'Petrel Fracture Modeling ',\n",
       "  'content': 'Visualize and analyze fractured reservoirs\\nModeling flow in fractured reservoirs is difficult. The challenge requires a software solution that\\nsupports tight integration between the static and dynamic reservoir modeling disciplines and\\nprovides a way to visualize and analyze many data types that may be direct or indirect indicators\\nof fractures.\\nOne of the difficulties with a traditional discrete fracture modeling workflow is that the number of\\nfractures to be modeled in the field can be extremely large. Trying to represent all of them\\nexplicitly in the model is often hampered by system memory limitations. Even if this is achieved,\\ncalibration of fracture modeling parameters to flow simulation results demand iterative steps in a\\nworkflow, and then computational performance becomes a limiting factor.\\nPetrel 2010.1 proposes an original numerical representation of the fracture networks so that an\\naccurate calculation of the contribution to the fluid flow of all the fracture sets are present in the\\nreservoir model. You can now create a hybrid model where the bigger and more important\\nfractures are modeled explicitly as discrete patches (Discrete Fracture Network - DFN), and the\\nresidual part of the distribution (smaller fractures) is statistically represented as grid properties\\n(implicit fracture model - IFM).'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': 'Comprehensive and easy-to-use tool to model discrete and/or continous fracture networks\\nWorks directly in Petrel and uses all tools available in the software (i.e., train estimation and\\nmodel, workflow editor, property calculators, etc.)\\nProvides a direct input for ECLIPSE dual-porosity models\\nPetrel Workflow Editor & Uncertainty and'},\n",
       " {'header': 'Optimization ',\n",
       "  'content': 'Rapidly update reservoir models, better manage risk, and easily share\\nknowledge\\nThe Workflow Editor, an integral part of Petrel software, captures data parameters and\\nrelationships that enable rapid updating of reservoir models as information from new wells\\narrives.\\nGeoscientists and engineers can create multiple model realizations to assess the impact on\\nreserve volumetrics or to cost well placement. Engineers can run all the possible scenarios in\\nECLIPSE directly, without leaving Petrel.\\nIn addition to understanding uncertainty and risk management, the Workflow Editor empowers\\nknowledge sharing, allowing best practices and workflows to be easily shared across your\\norganization.\\nWith Petrel, asset teams can reduce project cycle time and maximize productivity.\\nUncertainty and Optimization\\nThe Uncertainty and Optimization process allows you to to sensitivity analysis. You can create\\nproxies for volumetric or simulation cases using experimental designs for faster evaluation of\\nuncertainty in volumetric and recovery. Proxy models can also be used for screening to evaluate\\nwhich parameters the model is most sensitive to.\\nUse the process to optimize your simulation forcasts, and consider uncertain parameters during\\noptimization.'},\n",
       " {'header': 'Petrel Reservoir Engineering ',\n",
       "  'content': 'Integrate dynamic data into geological models to create reservoir simulation models, calibrate\\nmodels to observed production data, and forecast reservoir performance for alternative field\\ndevelopment scenarios and multiple geological model realizations to quantify risk and assist in\\nmaking field development decisions.'},\n",
       " {'header': 'Petrel Reservoir Engineering Core ',\n",
       "  'content': 'Build and run ECLIPSE simulation models and analyze results directly from within Petrel.\\nPetrel Advanced Gridding and Upscaling\\nResample and re-grid fine-scale geological models to coarser-scale simulation models using a\\nwide range of upscaling techniques.'},\n",
       " {'header': 'Petrel History Match Analysis ',\n",
       "  'content': 'Analyse history matching studies by computing and visualizing statistics, comparing simulated\\nwith actual history.\\nFrontSim Locked\\nECLIPSE FrontSim streamline reservoir simulation software is a three-phase, 3D simulator that\\nmodels multiphase flow of fluids along streamlines.'},\n",
       " {'header': 'Petrel Well Path Design ',\n",
       "  'content': 'Design well paths, identify surface locations, pick targets, and adjust trajectories dynamically in a\\n3D canvas to find the optimal solution.'},\n",
       " {'header': 'Petrel Sensitivity Analysis ',\n",
       "  'content': 'Create proxies for volumetric or simulation cases using experimental designs for faster and\\nstatistically significant evaluation of volumetric uncertainty, recovery and screening of most\\nsensitive model parameters.'},\n",
       " {'header': 'Petrel Optimization ',\n",
       "  'content': 'Optimize reservoir simulation forecasts using a selection of optimization algorithms. Optimize\\nwhile considering uncertain parameters. Use proxies created through the Petrel Sensitivity\\nAnalysis module for faster processing.'},\n",
       " {'header': 'Ocean Application Development Framework ',\n",
       "  'content': \"The Ocean framework enables seamless integration of your application or intellectual property\\ninside the Petrel application. It's not just data integration; it makes new capabilities available as\\nan integral part of a Petrel workflow .\"},\n",
       " {'header': 'Petrel Reservoir Engineering Core ',\n",
       "  'content': 'Your entry point for detailed ECLIPSE simulation and pre- & post-\\nprocessing\\nThe Petrel Reservoir Engineering Core lets you select and launch the appropriate ECLIPSE\\nsimulator and analyze your results-all within Petrel.\\nBuild efficient simulation models. Use this tool to build ECLIPSE simulation models directly from\\nyour geological models, adding fluid properties, well completions, production history, and event\\nscheduling. Organize geological realizations and develop scenarios into cases.'},\n",
       " {'header': 'Advantages ',\n",
       "  'content': 'Integration and improved communication between Geophysics to Reservoir Engineering\\nAccess to the workflow editor allows for rapid model updates and simulation based\\nuncertainty quantification\\nPetrel usability for the petroleum engineers'},\n",
       " {'header': 'Features ',\n",
       "  'content': 'Well completion design - import tubing and completion data; interactively create completion\\nstring specifications alongside the log view of the well; intersect the completion description\\nwith the grid and calculate connections to grid cells for the simulator; specify completions\\nrelative to horizons and copy them from well to well\\nFlow controls - import historical production rates and average them up into simulation\\ncontrol time steps; set prediction controls and economic limits\\nFluids - import or create from correlations the pressure, volume, temperature (PVT)\\nproperties for oil, water and gas\\nCase definition - select which realization of each grid, property, and engineering data is to\\nbe used in a simulation run; copy cases, make modifications; and run them directly in'},\n",
       " {'header': 'ECLIPSE ',\n",
       "  'content': 'Results and case trees - manage cases in folders and analyze the results in the new results\\ntree\\nPetrel Advanced Gridding and Upscaling\\nUse a wide range of gridding and upscaling techniques\\nResample fine-scaled geological models to coarser-scale simulation while still preserving\\nimportant details in the geologic model. An assortment of averaging methods includes a flexible\\ntensor upscaling function for determining effective permeability in each simulation cell.\\nAdvanced gridding techniques include:\\nLocal grid refinement (LGR) - to create small cells around wells, surface, or polygons for\\nimproved resolution\\nLocal grid coarsening (LGC) - define coarse cells (ECLIPSE only) that aggregate selected\\ncells\\nStair step (IJK) gridding - to ensure grid orthogonality when faults are highly inclined'},\n",
       " {'header': 'Advantages ',\n",
       "  'content': 'Preserve geologic knowledge scale-construct a simulation grid from the same 3D model as\\nyour fine-scale geological grid\\nGet an accurate upscaled representation of your modeled properties-from standard\\naveraging or flow-based tensor techniques\\nCapture complex structural or near-wellbore effects-using advanced gridding techniques\\nJudicious coarsening, e.g. around aquifers, can reduce number of grid cells thereby\\nimproving simulation performance\\nFlow-based tensor upscaling-how it works\\nWhen upscaling permeability from a fine geological grid to a coarser simulation grid, a block of\\ngrid cells from the fine grid will have direction-dependant permeability. This is modeled using a\\npermeability tensor.\\nThe default output is permeability properties for X, Y, and Z. You can also request coupling terms\\nXY, XZ, and YZ. In situations where there are only a few cells in each coarser cell, you can define\\na skin zone that includes additional cells outside the coarse cell to calculate the upscaled\\npermeability. The larger zone improves the pressure field calculations and the accuracy of the\\nflow relative to directional permeability differences'},\n",
       " {'header': 'Petrel History Match Analysis ',\n",
       "  'content': 'Simplify the history matching process and arrive at best history match sooner. The efficient, easy-\\nto-use Petrel History Match Analysis module lets you quickly and easily analyze hundreds of\\nECLIPSE reservoir simulation runs to isolate the most likely geological realization.'},\n",
       " {'header': 'Advantages ',\n",
       "  'content': 'Quantify history match quality to identify the best-possible realization\\nIdentify history match problems in the field from immediate graphical results\\nManage hundreds of runs and cases with simple case management tools\\nChange properties and rerun all cases from any ECLIPSE family of simulators thanks to\\ncomplete integration with Petrel\\nHistory match analysis-How it works\\nThe tool calculates statistics on the quality of a history match across many realizations and\\nhighlights the best matches for further study. Results are calculated on every well and for every\\ndata type (oil rate, water rate, bhp, water cut, etc.)\\nBy combining different matches into scenarios, you can move from a case view to a field view and\\ndown to the specific details in any well. The results are then displayed in a map window with color\\ncodes indicating good and bad history matches. Instead of looking at hundreds of line plots and\\ntrying to find the best case, the cases are ranked according to your choices.\\nFrontSim Locked Used in Petrel Software\\nRank and screen reservoir models in a dynamic environment by combining industry-standard\\nstreamline technology with intuitive and interactive 3D modeling. FrontSim streamline reservoir\\nsimulation software is a three-phase, 3D simulator that models multiphase flow of fluids along\\nstreamlines. FrontSim enables you to construct enhanced reservoir models quickly, paving the\\nway for more accurate production forecasting and better decisions.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': 'Efficiently rank, screen and visualize multiple sensitivity runs, combining static and dynamic\\ninformation to create more reliable models in less time.\\nOptimize well placements by combining streamline analysis with the detailed static model to\\nenhance sweep efficiency.\\nValidate upscaled reservoir models with dynamic data by understanding grid orientation\\nissues, thereby improving the quality of the model used for reservoir simulation.\\nIdentify flow patterns\\nWhen heterogeneity and reservoir uncertainties are dominating the fluid flow behavior in your\\nreservoir, stochastic modeling techniques are used to create multiple views of your fine scale\\ngeological model. With FrontSim, you can dynamically identify the tortuous flow paths by visually\\ndepicting the injector-to-producer streamline bundles and make ranking decisions based on\\nproduction history, not static methods alone.\\nImprove your reservoir management\\nIdentifying optimal drilling locations is not only based on engineering constraints, but also on\\nreservoir heterogeneity. Running FrontSim on your fine scale geological model lets you identify\\ninjectors not contributing to production, or producers that are cycling injected water. Such\\nanalysis lets you make development and field management decisions to optimize sweep, improve\\nultimate recovery and minimize injection costs.\\nBuild better quality models\\nIdentifying the representative model from stochastic analysis is challenging enough. Fine scale\\ngeological models must then be upscaled to reduce the number of cells for practical full-field\\nsimulation. The knowledge gained using FrontSim can directly impact ECLIPSE reservoir\\nsimulation models, resulting in more reliable models with better predictive forecasting.'},\n",
       " {'header': 'Ocean Application Development Framework ',\n",
       "  'content': \"The Ocean application development framework is an open, extensible, and productive\\nenvironment that accelerates the development and deployment of innovative software solutions\\nto solve today's oil and gas challenges. The Ocean environment allows energy companies the\\nfreedom to create specialized workflows to solve complex problems, profit from technology\\ndifferentiation, deploy plug-ins on top of existing tools, and reduce their technology adoption cycle\\n all without disrupting to current business processes.\\nThe Ocean framework enables seamless integration of your application or intellectual property\\ninside the Petrel application. It's not just data integration; it makes new capabilities available as\\nan integral part of a Petrel workflow. Geoscientists can immediately focus on new workflows to\\nsolve today's oil and gas challenges, while developers focus on innovation rather than\\ninfrastructure.\"},\n",
       " {'header': 'Petrel Drilling Workflows ',\n",
       "  'content': 'Well path design, drilling visualization, and real-time model updates\\nPetrel workflows improve operational efficiency by setting an environment to visualize and\\nunderstand relationships between the drilling processes in the earth context.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': 'Maximize reservoir exposure by designing a well trajectory, understanding at initial stages\\nthe potential risks the well might be exposed to\\nUnderstand the relationship between actual undesired drilling events (well control, mud\\nlosses, wellbore stability, stuck pipe, etc.) in geological context\\nMonitor execution in a proactive manner in real time to ensure optimum well position and\\nforesee potential risks when the actual well path trajectory is approaching a risk zone,\\ndeviations from planned well trajectory, and variations in the prognosis.'},\n",
       " {'header': 'Petrel Well Path Design ',\n",
       "  'content': 'Design well paths, identify surface locations, pick targets, and adjust trajectories dynamically in a\\n3D canvas to find the optimal solution.\\nDrilling Event Visualization for Petrel\\nVisualize undesired drilling events in geological context to enhance both the well design and the\\nexecution of drilling operations through a proactive risk management approach.'},\n",
       " {'header': 'Real-Time Data Link ',\n",
       "  'content': 'The Petrel Real-Time Data Link can connect to streaming real-time data from InterACT wellsite\\nmonitoring and data delivery system.\\nDrilling Event Visualization for Petrel\\nVisualize and correlate drilling risks\\nDrilling events such as lessons learned, best practices, and risks encountered on offset wells (such\\nas kicks, losses, high/low pressure zones, and other difficult drilling conditions) can be easily\\nimported into the Petrel application. Geologists can improve well proposals by visualizing and\\ncorrelating the events on the 3D and well section windows. Better collaboration while drilling\\nproduces more feasible well proposals.\\nDrillers proactively reduce risk\\nRisks and events can also be entered directly and edited as needed. They can be migrated to a\\nplanned well, reclassified and correlated to geology. Importing the Osprey Risk drilling risk\\nprediction model allows a comprehensive view of simulated drilling risks alongside the event-\\ndriven drilling knowledge.\\nThe entire operations team makes better decisions\\nVisualizing these risks and events in the overburden shared earth model enables the entire team\\nto monitor the impact of geology interpretation changes on the drilling process, minimizing\\ngeologically driven risk.\\nReal-time risk is effectively managed\\nRisks can also be exported in WITSML format for proactive use in other tools, used in Real-time\\nDrilling, such as PERFORM Toolkit real-time and postdrilling data optimization and analysis\\nsoftware and PERFORMView real-time drilling monitoring and visualization software.'},\n",
       " {'header': 'Benefits ',\n",
       "  'content': 'Enhance well planning with knowledge correlation and create better well proposals.\\nCollaborate while drilling.\\nReduce risk by dynamically updating a common earth model with real-time drilling data.'},\n",
       " {'header': 'Real-Time Data Link ',\n",
       "  'content': 'The Petrel Real-Time Data Link can connect to streaming real-time data from InterACT wellsite\\nmonitoring and data delivery system. This gives you a secure, real-time data link directly from the\\nwellsite to the desktop.\\nThe Petrel Real-Time Data Link can also connect WITSML data sources, from any vendor, to wells\\nin Petrel, allowing you to load trajectory and log data. This data is saved with your Petrel project\\nfor later use.\\nNow, the Petrel shared earth model can be driven by real-time data, allowing you to understand\\nthe full impact of new geologic knowledge on the well while it is being drilled. Surveillance in a\\nshared earth model while drilling allows effective cross-discipline collaboration in real time.\\nPlug-ins for Petrel\\nAdd more functionality to Petrel workflows with plug-in extensions\\nThrough the power of the Ocean application development framework, many extensions have been\\ncreated for the Petrel seismic-to-simulation workflow. These plug-ins provide additional\\nfunctionality to the standard Petrel workflow and are provided as an executable that simply adds\\nthe module to your existing Petrel install.\\nDrilling event visualization for Petrel\\nThe visualization of drilling knowledge in the overburden shared earth model enhances well\\nplanning and real-time drilling operations workflows with proactive drilling risk management.\\nOpenSpirit plug-in\\nSeamlessly integrate your logs, markers, seismic volumes, and interpretations in OpenWorks,\\nGeoFrame, and Finder with Petrel.\\nIP plug-in\\nThe Interactive Petrophysics (IP) plug-in for Petrel allows you to import and export wells, well\\nlogs, and well tops between the IP database and Petrel. The users do not need to have the IP\\nsoftware installed to make use of the interface, as the IP plug-in includes its own database\\nengine.\\nProSource plug-ins\\nThe ProSource plug-ins consist of the ProSource Petrel Extensions and the ArcGIS Plug-in for'},\n",
       " {'header': 'Petrel. ',\n",
       "  'content': \"The ProSource Petrel Extensions bring Information Management workflows for managing multiple\\nPetrel projects, using Ocean plug-ins to read the data from Petrel projects. Once the Petrel\\nproject data is in a database, a tool like ProSource can be used to\\naccomplish IM workflows, such as data QA/QC\\nmake comparisons with other data\\nview data in a map view\\nexport data for further analysis.\\nThe ArcGIS Plug-in enables the import and export process for Shapefiles and ESRI grids.\\nPetrel OFM plug-in\\nWell configuration data (location, deviation surveys, tubing configurations) and production\\nvolumes are vital for efficient Petrel modeling. In many cases, these data are available in OFM\\nprojects with live links to the client's production data management system. The OFM plug-in for\\nPetrel eliminates the need for the Petrel user to laboriously pass this data to his or her earth\\nmodel. It also eliminates the errors introduced by re-keying or copy/paste.\\nFind out which companies are developing plug-ins for Petrel using the Ocean framework at\\nwww.ocean.slb.com\"},\n",
       " {'header': 'Key Information Overview Petrel Workflow Tools ',\n",
       "  'content': 'Petrel is a PC-based workflow application for subsurface interpretation and modeling. It allows\\nusers to perform various workflows, from seismic interpretation to reservoir simulation.\\nGeophysicists, geologists and reservoir engineers can move across domains, rather than\\napplications, through the Petrel integrated toolkit.\\nKey benefits\\nAll tools from seismic interpretation to simulation are integrated in one application, eliminating\\nimport and export problems and promoting collaboration.\\nStrong visualization capabilities give you instant QC of all data in 3D.\\nModels can be updated instantly when new data arrives, allowing the user to make quick and\\nreliable decisions.\\nMost results can be copied and pasted to any Windows application, making it quick and easy to\\nreport and present your latest results.\\nPetrel has a familiar Windows user interface, undo/redo functionality, and stores modeling history,\\nmaking it easy to use and learn.\\nThe wide range of functionality in Petrel covers:\\n3D visualization\\nWell correlation\\nClassification and Estimation (Artificial Neural Net)\\nCreation of synthetic seismograms\\nSeismic attributes'},\n",
       " {'header': 'Geobody Interpretation ',\n",
       "  'content': '2D & 3D seismic interpretation and modeling\\nSeismic volume rendering and extraction\\n3D mapping\\n3D grid modeling for geology and reservoir simulation'},\n",
       " {'header': 'Velocity Modeling (Domain Conversion) ',\n",
       "  'content': 'Well log upscaling'},\n",
       " {'header': 'Facies Modeling Petrophysical Modeling Data Analysis Uncertainty Analysis Optimization ',\n",
       "  'content': 'Workflow editor'},\n",
       " {'header': 'Fracture Modeling Volume Calculation ',\n",
       "  'content': '3D well design\\nStreamline simulation\\nECLIPSE Simulation\\nSimulation post-processing\\nRemote Simulation Run submission'},\n",
       " {'header': 'Plotting ', 'content': 'To contact Petrel see Support.'},\n",
       " {'header': 'Online Help ',\n",
       "  'content': 'This document describes the use of the Petrel software and helps new users to get started and\\nadvanced users to improve their existing skills.'},\n",
       " {'header': 'Hard Copy ',\n",
       "  'content': 'To get a hardcopy of the Online Help manual, please go to the Contents tab and use the print\\nfunction. You may print the selected topic only or all the topics in the selected heading.'},\n",
       " {'header': 'Petrel ',\n",
       "  'content': 'The use of Petrel is controlled through a license and may be used only in accordance with a\\nlicense agreement.\\nPetrel is a registered trademark.\\nThird party\\nTornado plots are generated using third party software Chart FX which is a registered trademark\\nfor Software FX, Inc.'},\n",
       " {'header': 'Help System Information ',\n",
       "  'content': 'Information on how to use Petrel may be found in the following resources:\\nRelease notes . Read this document for a detailed description of updates and new features\\ncoming with the new release. It is provided through your Petrel installation; Help menu,\\nRelease notes.\\nGetting Started manual is a printed introduction manual to Petrel, that takes you through\\ntypical steps in a workflow. It is not designed as a training course but as a tool for the\\nbeginner to get started and running on Petrel. Contact your local Schlumberger SIS account\\nfor information on how to get hold of the manual.\\nThe Online Help System . Consists of two parts: This Online Manual and Hypertexts (Tips\\nbuttons) that shows a short description of items selected by the cursor.\\nTraining : For specialized or in-depth information about Petrel, contact your nearest\\nSchlumberger office to sign up for an advanced training course. Schlumberger also arranges\\ntraining courses upon client request.\\nTo get access to the complete worldwide classroom training offering and registration for\\nPetrel, please see http://www.slb.com/services/software/training/standard_courses.aspx\\nClassroom course offerings for Petrel are the following:'},\n",
       " {'header': 'Petrel Introduction Petrel Data Management ',\n",
       "  'content': 'Petrel Seismic Visualization and Interpretation\\nPetrel Play to Prospect Identification'},\n",
       " {'header': 'Petrel Structural Modeling Petrel Property Modeling ',\n",
       "  'content': 'Petrel Advanced Property modeling\\nPetrel Mapping and Geological workflows'},\n",
       " {'header': 'Petrel Applied Well Correlation Petrel Fracture Modeling ',\n",
       "  'content': 'Petrel Workflow Editor and Uncertainty Analysis'},\n",
       " {'header': 'Petrel Velocity Modeling ',\n",
       "  'content': 'Petrel for Reservoir Engineers\\nPetrel RE Advanced topics\\nPetrel Upscaling and Simulation Gridding\\ne-Learning courses area also available at\\nhttp://www.slb.com/content/services/software/training/elearning.asp :\\nSupport With a manintenance agreement you will recieve support from your nearest\\nSchlumberger SIS support site.\\nSupport portal: A complete Login service https://support.slb.com/default.aspx\\ndelivering online resources such as a knowledge base, support request submissions,\\ndiscussion forums, software news etc.\\nConsultant Services: For help on specific projects, contact your nearest Schlumberger\\nSIS office for a quote on consultant services. Also have a look at our general site offering on\\nthe web http://www.slb.com//content/services/software/services/consulting_services.asp?\\nGetting Help in Petrel\\nAdditional help in Petrel is provided via the:\\nButton tips - Short description of objects in the user interface. The description appears\\nwhen the cursor is placed on an object.\\nStatus bar - Information on selected objects and processes found at the bottom of the\\nuser interface.\\nTool tips - Help located within dialog boxes. Hold the mouse over the button to see the\\ntext.'},\n",
       " {'header': 'Support ',\n",
       "  'content': 'Contact Petrel support via your local Schlumberger office. For more information on Training and\\nSupport, see Help System Information\\nSupport portal: Login to the\\nhttp://support.slb.com/New_home/New_Petrel/tabid/156/Default.aspx for access to Petrel\\nresources such as a knowledge base, support request submissions, discussion forums, software\\nnews, software downloads etc.\\nInformation required for Prompt Support\\nIn order to be able to address your request in the most efficient manner, we ask that you provide\\nthe following information whenever you contact your local Schlumberger support center:'},\n",
       " {'header': 'Petrel Installation Issues & Application Errors Computer Manufacturer & Model ',\n",
       "  'content': 'Processor (CPU) Manufacturer, Model & Speed\\nComputer Memory (RAM)\\nGraphics Card Manufacturer, Model, Driver Versions and Onboard Memory (DDR RAM)\\nOperating System and Version\\nPetrel Version and Build Date\\nOther applications running Simultaneously with Petrel\\nDetailed description of the problem\\nEmbedded image(s) of application errors (if present)'},\n",
       " {'header': 'Introduction ',\n",
       "  'content': 'Petrel is a Windows based software for 3D visualization, 3D mapping and 3D reservoir modeling\\nand Simulation. The user interface is based on the Microsoft Windows standards on buttons,\\ndialogs and help systems. This makes Petrel familiar to the majority of geoscientists today and\\nensures efficient usage of the application.\\nPetrel is a system for\\nSeismic visualization and interpretation by using SEG-Y and ZGY data cubes in 2D and 3D\\nwindows.\\nA seismic Calculator can be used for advanced operations on several cubes.\\nAutomatic Fault Extraction with the Ant tracker attribute.\\nSeismic Volume Rendering, which allows the seismic volume to be more or less transparent.\\nThe new Petrel Geobody interpretation module employs state-of-the-art volumeblending\\ntechnology to quickly isolate, extract, and integrate a body directly into a property model\\nfor true 3D volume interpretation.\\nBuilding faulted 3D grids for reservoir modeling and flow simulation. A new approach for\\nbuilding faulted 3D grids is introduced which makes the grid generation process significantly\\nfaster while producing high quality results. There are few restrictions to the complexity of\\nthe fault pattern or fault types in Petrel.\\nGridding of 2D structural surfaces honoring inter-surface relationships (erosion, onlap, etc.)\\nand the generated 3D fault model. This method of gridding structural surfaces (3D\\nmapping) is a true 3D approach and is unique to Petrel.\\n3D visualization of geophysical, geological, petrophysical and production data. Petrel has an\\noption to use 3D glasses for obtaining a true 3D effect (Virtual Reality).\\nFlattening of the 3D grid using a horizon as datum.\\nThe 3D grid can be depth converted node by node by using different velocity models.\\nMaking an improved zonation of the reservoir by using the Well Correlation facility.\\nAnalysis of well data, upscaled wells and properties, including data transformations and a\\ncomprehensive variogram analysis package.\\n3D property modeling based on well logs and trend data (stochastic, deterministic). This\\nincludes a calculator for solving complex mathematical equations involving one or several\\n3D property models; i.e. Sw transforms based on porosity and permeability 3D models.\\nFacies Modeling using stochastic and deterministic methods.\\nFracture network modeling using for creating fracture properties as direct input to dual\\nPorosity/Dual Permeability simulation.\\nVolume calculations, data analysis and plotting.\\nUpscaling of geometric grids and properties.\\nStreamline simulation using FrontSim.\\nRun ECLIPSE from Petrel. Set up an ECLIPSE Run in Petrel using Petrel grid and properties.\\nE100 can be used for Black Oil simulation, and E300 for Compositional Simulation. There is\\nalso a library of more advanced Keywords which can be used in addition to the standard\\nsetup in Petrel.\\nPost-processing of simulation result data.'},\n",
       " {'header': 'History Matching. ',\n",
       "  'content': 'Well design in 3D. Digitizing, editing and visualizing of well trajectories based on the\\ngenerated geological models. Output spread sheets with detailed well report and synthetic\\nwell logs.\\nWell Optimizer to create a series of cost-dependant realizations based on Target points and\\ncost model.\\nImproved documentation and reporting of the project work through tight integration with\\ndesktop tools like PowerPoint, Word and Excel.'},\n",
       " {'header': 'Petrel Workflow ',\n",
       "  'content': 'Petrel is a software package that allows the user to build a reservoir model all the way from\\nSeismic cubes to upscaled grids with properties, ready for export to a simulator or for being\\nsimulated in Petrel.\\nThe Processes pane, shown in the lower left corner of the user interface, gives the user an\\noverview of the suggested workflow in Petrel. Export and plotting are not a part of the workflow\\nsince that can be done at any stage of the workflow process.'},\n",
       " {'header': 'Seismic (Petrel Workflow) ',\n",
       "  'content': '3D seismic data sets can be imported as SEG-Y or ZGY and can be used for interpreting horizons\\nand faults in 3D. Seismic volumes can also be depth converted and sampled into a structural 3D\\ngrid as seismic property. This can be the starting point for your structural model. It is also a\\nvisual quality control tool where imported interpretations can be checked together with high\\nresolution seismic.\\nAdvanced multi trace seismic attributes enhance the important aspects of your seismic data and\\nprepare the seismic for use in picking fault planes or preparing pseudo property cubes for steering\\nproperty modeling.\\nThe Petrel user has the possibility of doing seismic volume rendering. A sub-volume of the seismic\\nvolume (ZGY) can be generated and given a transparency. This sub-volume can be moved freely\\ninside the larger seismic volume. By giving frequencies within a specific interval (e.g. non-\\nreservoir) some degree of transparency, the user can look at those frequencies that represent\\nreservoir. The bodies which now stand out could represent certain facies bodies, e.g. a turbidite\\nbody. Volume extraction can create a solid body from the seismic using isosurfaces which can be\\nmeasured and used to help to determine input when modeling facies later on. Geobody\\ninterpretatation can capture entire bodies with various amplitude values; these bodies can be\\nconverted directly into 3D grid properties.\\nSee Seismic Interpretation and Seismic Modeling for further details.'},\n",
       " {'header': 'Well Correlation (Petrel Workflow) ',\n",
       "  'content': 'Petrel includes a tool for making rapid on-screen correlation, with the possibility to bring up\\nmultiple wells in a well section, make marker-picks (well tops), re-datum and then bring up new\\nwells to compare with already correlated wells. Well Tops can be edited by dragging them to their\\nnew location and a depth track can give an instant depth reading of the new pick depth in, for\\nexample, MD (measured depth) ,TVDSS (true vertical depth sub-sea) or TWT (two-way-travel\\ntime). Ghost curves can be used for correlation.\\nDetails of well correlation can be found in Well correlation.'},\n",
       " {'header': 'Structural Modeling (Petrel Workflow) ',\n",
       "  'content': 'Structural modeling in Petrel can be performed in two different ways. There are two separate\\nprocess folders available to facilitate this.\\nStructural framework modeling'},\n",
       " {'header': 'Corner Point Gridding ',\n",
       "  'content': 'Structural Framework modeling\\nA Structural Framework is a 3D model consisting of horizons, faults and salt bodies. Each are\\nmodeled as individual surfaces from their interpretations, then assembled into a volumetric model\\nof Zones. There are three main process steps involved; defining a geometry, making a fault\\nframework and horizon modeling. SM_Structural_Modeling_sailfish.xml\\nCorner point gridding\\nCorner point gridding in Petrel consists of fault modeling, pillar gridding and vertical layering. All\\nthree operations are tied together into one single data model - a three dimensional grid.\\nThe resulting grid is a full corner point 3D grid. Corner_point_gridding.xml The procedure of\\nbuilding the 3D grid is divided into 3 main steps:'},\n",
       " {'header': 'Fault Modeling ',\n",
       "  'content': 'Generation of fault pillars, known as Key Pillars, are lines defining the slope and shape of the\\nfault. There are up to five so called Shape Points along each of these lines to adjust the shape of\\nthe fault to match your input data. The Key Pillars are generated based on input data such as\\nfault surfaces, fault sticks, fault lines, fault polygons, structural maps, interpreted seismic lines,\\netc. This step involves manual work in the 3D window. See Fault Modeling for further details.'},\n",
       " {'header': 'Pillar Gridding ',\n",
       "  'content': 'Pillar Gridding generates the 3D framework. The grid is represented by pillars (coordinate lines)\\nthat define the possible position for grid block corner points. The user can define directions along\\nfaults and borders to guide the gridding process.\\nThis process step involves user settings for an automatic Pillar Gridding algorithm. See Pillar\\nGridding for further details.'},\n",
       " {'header': 'Vertical Layering ',\n",
       "  'content': 'When defining the vertical layering, the layers are inserted into the set of pillars generated in step\\n1 and 2. Where each pillar intersects each layer, a node in the 3D grid is defined. Faulted areas\\nare treated separately to ensure proper fault implementation.\\nInput for the vertical layering can be lines, seismic interpretation, points and surfaces. By using\\nany of these input types, Petrel will perform a 2D gridding. The resulting 2D grid is an integral\\npart of the 3D grid and can be extracted and exported as a regular 2D surface grid. See Make\\nHorizons and Make Zones and Layering for further details.'},\n",
       " {'header': 'Depth Conversion (Petrel Workflow) ',\n",
       "  'content': 'It is possible to build the structural model directly in time, based on the seismic data. You can\\nthen use your original seismic interpretation prior to any depth conversion and create a full 3D\\ncorner point grid in time. This will reduce the uncertainty of the geophysical work.\\nAfter creating the initial Velocity Model, the depth conversion process converts the corner point\\ngrid on a node-by-node basis. The model is converted, including all the grid pillars and faults. This\\nprocess facilitates the possibility to analyze the uncertainty in the velocities by using different\\nvelocity setups. By reversing the process, a time grid can be built from a depth model.\\nFor more details on creating a Velocity model, see Make velocity model process\\nFor more details on Depth converting a grid, see Depth Conversion Process'},\n",
       " {'header': 'Data Analysis (Petrel Workflow) ',\n",
       "  'content': 'Continuous and discrete properties can be analyzed. For discrete properties, analysis of facies\\ndistribution, body thickness and correlation with seismic attributes are all available. For\\ncontinuous properties a number of powerful tools are available for investigating and dealing with\\ntrends (1, 2 or 3D) in the data and transforming the data prior to modeling.\\nAn interactive variogram package can be used with either type of data with an option to\\nautomatically use the results in Facies and Petrophysical modeling processes. See Data Analysis\\nfor more details.'},\n",
       " {'header': 'Facies Modeling (Petrel Workflow) ',\n",
       "  'content': \"You can perform general stochastic object modeling such as, 'Sequential Indicator Simulation',\\n'Object modeling' (including fluvial channels and adaptive channels), 'Truncated Gaussian\\nSimulation' or 'users own algorithm' to assign values. In addition a more complex facies model\\ncan be built using the 'Multi-Point Facies Simulation' method. The petrophysical properties can be\\nconditioned later on to the facies model. You can also condition a facies model to a previously\\ngenerated facies model (hierarchical modeling). Petrel also supports the ability to manually draw\\nand edit facies shapes using standard drawing tools. This makes it easy to put your ideas into a\\n3D model. Details of stochastic and deterministic modeling can be found in Facies Modeling and\"},\n",
       " {'header': 'Petrophysical Modeling. Petrophysical Property Modeling (Petrel Workflow) ',\n",
       "  'content': 'Petrophysical property modeling is the process of assigning petrophysical property values\\n(porosity, permeability, etc.) to each cell of the 3D grid. See Petrophysical Modeling for details.\\nPetrel has several algorithms for deterministic petrophysical property modeling. These\\ntechniques use well logs and trend data for input.\\nPetrel also offers stochastic petrophysical modeling. Sequential Gaussian Simulation can be\\nused in both univariant and bivariant distribution methods.\\nAlternatively, you can use Neural Network models generated in the Train Estimation Process\\nto create a new property.\\nMaps showing properties, such as average porosity or net sand thickness, can be output from\\nfiltered property models.'},\n",
       " {'header': 'Scale Up Property Data (Petrel Workflow) ',\n",
       "  'content': 'Fine-scaled models are usually upscaled into a coarser simulation grid. This is due to the fact that\\nreservoir simulations commonly handle models with less than 1 000 000 grid cells. Petrel honors\\nthe structures in the fine grid when scaling up to a coarser grid. In addition, the most common\\nupscaling techniques for homogenization of properties are available including full flow tensor\\nmethods. See Upscaling for details.'},\n",
       " {'header': 'Volumetrics (Petrel Workflow) ',\n",
       "  'content': 'Petrel comprises an advanced volume calculation process where constraints, such as different\\ncontacts, zones, fault compartments, polygons and well influence radii, are used. The result is\\npresented in an Output sheet as a spreadsheet giving an extensive hydrocarbon volume report.\\nThis report can be used directly in commercially available spreadsheets (MS Excel) for editing and\\nprinting. Batch runs can be performed with multiple selections of properties, stochastic re-\\nsampling and output distribution functions. See Volume Calculations for further details.'},\n",
       " {'header': 'Streamline Simulation (Petrel Workflow) ',\n",
       "  'content': 'Streamline simulation in Petrel uses FrontSim to run black oil simulations with rapid results in\\nrelatively large grids. The module includes processes for creating PVT tables, saturation curves\\nbased on standard tables and includes a number of default values making it easy to get a\\nsimulation up and running, see Overview of how to set up a simulation case for details.'},\n",
       " {'header': 'Workflow Editor ',\n",
       "  'content': \"The Workflow editor has several functions. Two of the most important to allow rapid updates of\\nmodels and to perform batch operations on input data. A workflow for rebuilding the model can be\\ngenerated at the push of a button and edited as required before running, recreating the model in\\na single operation. Any changes in the input data will be taken into account. Batch operations on\\ninput data are created intuitively using an object orientated programming language based on\\nPetrel's user interface. See Workflow editor for details.\"},\n",
       " {'header': 'Data Export (Petrel Workflow) ',\n",
       "  'content': 'Petrel has a strong focus on the need to transfer data to and from other applications. Being able\\nto move data from one application to another is of vital importance in an exploration or reservoir\\nmodeling study.\\n2D data (maps, lines and points) can be imported and exported to a range of different mapping\\nsystems (Zmap+, CPS-3, EarthVision, IRAP Classic, etc.). 3D grids and 3D property models can\\nbe exported in ECLIPSE, CMG and VIP formats. For details on export, see Export Data. A range of\\nnew links will be added in future Petrel releases. Remember that feedback from Petrel users helps\\nguide our development. Petrel also uses OpenSpirit to transfer data to and from common\\ndatabases like OpenWorks, GeoFrame, etc.\\nReporting and Plotting (Petrel Workflow)\\nA generated Output sheet with, for example, statistics, volume reports, etc., can be copied\\ndirectly into a spreadsheet or printed directly from Petrel.\\nMaking images for reporting is easy. Petrel is a Windows based application and, as a result, is\\ntightly integrated with the Microsoft Office suite. The Copy/Paste functionality of 3D graphics from\\nPetrel to, for example, PowerPoint or Word is an example of the ease-of-use and speed in making\\nfigures and reports. See Reporting and Graphical Output for details.\\nPlotting of maps, well sections and cross sections is also an important part of reporting. When a\\nplotting window is opened, new tools become available in the toolbar. The user can select almost\\nany kind of data for plotting and designing the layout of the plot according to personal preference.\\nSeveral different Plot windows with different settings can be saved for further use.'},\n",
       " {'header': 'Terminology ',\n",
       "  'content': 'Petrel introduces a few new terms and expressions. They are briefly explained below.\\n3D Grid - A network of horizontal and vertical lines used to describe a three dimensional\\ngeological model. Petrel uses the \"Corner Point 3D Grid\" technique.\\nArtificial method - Terminology used in the Make Surface process for creating a surface without\\nusing any input data.\\nAttribute map - A map based on a seismic attribute. Created by extracting data across a surface\\n(a map of the average attribute within a certain offset from a surface or between two surfaces\\ncan also be extracted) from a seismic volume. The map can then be draped across this surface.\\nAutomatic legend - A predefined template displaying the color table legend of a visualized\\nobject.\\nBitmap image - An imported bitmap, e.g. a BMP or a JPG file. If given UTM coordinates, it can\\nbe draped over a surface.\\nBulk Volume - Total rock volume.\\nCell Volume - The volume of a single cell in a Petrel grid.\\nConnected Volume - The process of calculating connected volumes in a discrete 3D property.\\nCan be used to search for e.g. connected channels.\\nContact Level - The level of a Gas-Oil contact or an Oil-Water contact, normally at a constant\\ndepth but a tilted contact can be represented by a surface.\\nContact Set - A set of contacts defined by the user, to be used as input for volume calculation\\nand/or for visualization.\\nCropping - Used for 2D and 3D seismic data. Creating a virtual volume by defining inline-,\\ncrossline-, and time-range.\\nCrossline intersection - Vertical seismic section perpendicular to the inline direction.\\nCross plot - Two or more data sets plotted against each other in a Function Window (also called\\nscatter plot).\\nDatum - A constant depth/time or surface used as a reference in measuring elevation.\\nDepth Contours - Contours for a horizon, representing equal depth or time values.\\nDepth Conversion - Converting Z-values, from time domain to depth domain.\\nDisplay Window - Window used for display of Petrel models. Two types of display windows are\\navailable: 2D and 3D.\\nDongle - The same as a hardware key - Also called \"software protection key\". It controls the\\naccess and expiration dates of software modules.\\nDrainage Area - The area from which it is possible to produce hydrocarbons.\\nErosion Line - Line defining truncation of one horizon against another.\\nFault Center Line - Line connecting the midpoints of faulted pillars in a 3D grid.\\nFault Modeling - The process of modeling fault planes in a three dimensional framework. The\\nfirst step in fault modeling is creating key pillars.\\nFault Polygon - An intersection line between a fault plane and a surface.\\nFault Stick (fault dip line) - Lines describing the fault, usually from top to bottom.\\nFluid Constants - Formation Volume Factors Bo for oil and Bg for gas. GOR: Gas-Oil-Ratio.\\nStrictly speaking the Recovery Factor is not a fluid constant, but it is found in the Fluid Constants\\nmenu of the Volume Calculations menu.\\nFormation Volume Factor - The ratio between hydrocarbon volumes at surface conditions and\\nthe volumes at reservoir conditions (Bo and Bg for oil and gas, respectively).\\nFunction Bar - Also called toolbar (in Microsoft terminology). Group of icons on a horizontal or\\nvertical bar. These icons change as different processes are selected in the Process Diagram.\\nFunction window - Plot window used for display of functions, cross plots, sample variograms\\nand variogram models.\\nGas Saturation - Gas fraction in a given fluid volume.\\nGeological grid - The finer 3D grid modeled in detail to represent the geology as accurately as\\npossible. Commonly upscaled to a coarser grid for simulation.\\nGIIP - Gas initially in place.\\nGOC - Gas-oil-contact.\\nGOR - Gas-oil-ratio: the ratio of gas to oil in a volume.\\nGross rock volume - Total rock volume.\\nGSLIB - Geostatistical Software Library (http://www.gslib.com).\\nGuided Autotracking - Automatic seismic interpretation. Is initiated by giving two points on a\\nseismic intersection. The program will interpret between the two points according to user defined'},\n",
       " {'header': 'Autotracking Settings. ',\n",
       "  'content': 'GWC - Gas-water-contact.\\nHardware Key - The same as a \"dongle\" - also called \"software protection key\". Together with\\nthe license file It controls the access and expiration dates of software modules.\\nHCPV - Hydrocarbon pore volume.\\nHistogram - Display of frequency distribution of a data set.\\nHistogram window - Plot window used for display of histograms and cumulative distribution\\nfunctions.\\nHorizon - The equivalent of a surface, except that a horizon is a surface in a 3D grid and an\\nintegrated part of the 3D model. Petrel\\'s 3D grid means that a horizon can have multiple Z values\\nat a single XY value whereas a surface can not. Horizons can be exported from a 3D grid, in which\\ncase they become 2D surfaces (regular 2D grids).\\nInline intersection - An intersection parallel to the inline direction, i.e. the direction of seismic\\ndata acquisition.\\nIntersection - A cut through a three dimensional model (3D grid). Intersections can be plane\\nsurfaces with arbitrary direction and dip, but can also be cross sections along one of the main\\ndirections of a 3D grid (I, J, K directions).\\nIntersection window - Plot window used for generation of scaled plots of cross sections.\\nIsochore - A line connecting points of equal true vertical thickness. Similar to an isopach, but\\nonly equivalent when the rock layer is horizontal.\\nIsopach - A line connecting points of equal true stratigraphic thickness. Similar to an isochore,\\nbut only equivalent when the rock layer is horizontal.\\nIsopleth - A general term for a line on a map connecting points of equal value - a contour.\\nK factor - Increase or decrease of velocity with depth.\\nKey Pillars - The \"building blocks\" for creating fault planes in a three-dimensional model. Are\\ncreated in the first step of fault modeling. Key Pillars have four basic shapes: vertical, linear, listric\\n(3 shape points), and curved (5 shape points).\\nKriging - Local estimation based upon an empirical solution.\\nLine Data - Input data with X, Y, Z values. Displayed as lines. Several import and export data\\nformats are supported.\\nLinvel - Linvel describes the velocity at depth Z as a linear function: V = V0 + K*Z.\\nMap window - Plot window used for generation of scaled plots (2D maps), and for display of\\nvariogram maps created in Petrel.\\nMaps - 2D grids (imported or generated in Petrel).\\nMenu Bar - The Menu bar is a special Tool bar at the top of the screen that contains menus such\\nas File, Edit, and View.\\nMetafile - Format used for copying or saving the view of the Plot window.\\nModel - The complete set of data needed to describe a three dimensional geological model. This\\nincludes the 3D grid structure with faults and horizons, well data, all cells with different\\nproperties, depth conversion model and volume calculations models.\\nModules - Any of the self-contained software segments in Petrel, each designed for particular\\ntasks.\\nMonte Carlo Simulation - Used for uncertainty evaluation; Distributions can be used for the\\ndifferent types of input data. By applying Monte Carlo simulation, it is possible to draw a random\\nnumber from each of the distributions to get a value for the result. By running several\\nrealizations, it is possible to come up with a distribution of the result. In Petrel, the method is\\nused to take care of the uncertainty range for the contact level, when calculating volumes.\\nNet Volume - The volume of rock that can produce hydrocarbons. Net Volume = Bulk Volume *'},\n",
       " {'header': 'Net/Gross. ',\n",
       "  'content': \"Net/Gross - The fraction of the bulk rock volume representing porous and permeable rock\\nformation\\nNodes - In a 3D grid, nodes are corner points of the grid cell. In a 2D grid they are intersection\\npoints between grid lines.\\nNugget - The discontinuity/error at the origin of a Variogram model (i.e. the vertical distance\\nbetween 0 and where the variogram model crosses the Y-axis).\\nOil Saturation - Fraction of oil in a given fluid volume.\\nOWC - Oil-water-contact.\\nPick Mode - Same as Select mode.\\nPillar Geometry - Pillar shape geometry. One of four types: vertical, linear, listric, and curved.\\nPillar Gridding - The process of creating the initial three-dimensional (3D) grid. This is done by\\nusing a combination of key pillars, trend lines and boundaries. The result is a three dimensional\\nframework called a skeleton grid.\\nPillars - There are two basic types of pillars in a 3D grid: faulted and non-faulted. The shape can\\nbe any of the four standards: vertical, straight, listric or curved. After the pillar gridding process,\\nthe key pillars are replaced with faulted pillars. Non-faulted pillars are inserted in the non-faulted\\narea of the 3D grid.\\nPlot window - 2D viewers that can be used for intersections, diagrams, functions, plots, maps,\\n2D interpretation, etc.\\nPore Volume - The porous volume of rock containing hydrocarbons.\\nProcesses pane - Workflow scheme with different Process steps for modeling. For each Process\\nstep a new set of tools are available in the Function bar.\\nProject File - All model data is saved to a project file with the extension *.pet. This file contains\\nlinks to all related objects in a saved project. An associated project directory *.ptd, containing all\\nthe data object files is also created, along with the project file. If simulation is performed, an\\nassociated *.sim file is created.\\nProperty Models - 3D models of petrophysical/facies/geometrical properties generated in Petrel.\\nRandom line - A user defined cross section through a seismic data set.\\nRange - Describes where the variogram model reaches its plateau of the Variogram model (i.e.\\nthe separation distance where there is no correlation anymore between pairs of data values).\\nRecoverable Gas - Volume of gas, at surface conditions, that can be produced.\\nRecoverable Oil - Volume of oil, at surface conditions, that can be produced.\\nRecovery Factor - The fraction of the hydrocarbon volume that is possible to produce.\\nReservoir Modeling - General term for a digital representation of reservoir characteristics in 3D.\\nSample variogram - Variogram calculated for a sample data set using a direction and a search\\ndistance.\\nSEG-Y - A data exchange format developed by the SEG (Society of Exploration Geophysicists) for\\nstoring vast amounts of seismic data on magnetic tape. Seismic data stored in this format can be\\nread on many different types of computers and geophysical processing systems.\\nSeismic Attribute - A property derived from the seismic amplitude.\\nSeismic Cube - Three-dimensional volume of seismic data (SEG-Y or ZGY).\\nSelect Mode - Functionality for selecting objects in 3D and 2D. Used for quality control and\\nediting.\\nShape Point - Control points defining the shape of a key pillar or a pillar. Vertical and linear\\n(key) pillars have 2 shape points, listric (key) pillars have 3 shape points and curved (key) pillars\\nhave 5 shape points.\\nSimulation grid - The 3D grid that will be used for flow simulation in Petrel or exorted to other\\nsimulation packages. This grid is usually a coarser, upscaled version of the geological grid.\\nSill - The variogram value at the plateau of the Variogram model (i.e. the semi-variance value\\nwhere there is no correlation anymore between pairs of data values).\\nSkeleton - The skeleton is made up of the three grids created during Pillar Gridding. These three\\nso-called skeleton grids are associated with Top-, Mid- and Base-Shape Points, but not related to\\nthe layering of the 3D grid.\\nStatus Bar - Information on processes, coordinates, etc. in the user interface.\\nStereo Graphics - True 3D effect is obtained by using the 3D glasses' option.\\nStochastic Modeling - Randomly distributed properties generated in Petrel based on well data\\nand/or trends.\\nSTOOIP - Stock Tank Oil Originally In Place. Also called STOIIP (Stock Tank Oil Initially In Place).\\nVolume of hydrocarbons at surface conditions.\\nStructural Modeling - Consists of Fault Modeling, Pillar Gridding and generation of 3D grids. All\\nthree operations are tied together into one single data model: a three dimensional grid.\\nSummary files - Files containing the result data of a simulation run for a simulation package.\\nSurfaces - 2D grids (imported or generated in Petrel). A surface is a simpler version of a horizon\\nin Petrel, the major difference being that horizons are held in 3D grids (as opposed to 2D grids)\\nand can therefore have multiple Z values at each XY point. Surfaces are stored in the Input pane,\\nwhile horizons are stored in the Models pane.\\nTabs - Some panels and diagrams have tabs that can be selected to open new pages for that\\npanel.\\nTemplates - Are linked to objects in Petrel and control globally their settings for color, units,\\nmeasurements etc. Petrel comes with several predefined templates: depth and thickness color\\ntables, property templates and seismic color tables.\\nThickness Contours - Contours representing equal isochores in depth or time.\\nTime slices - Horizontal slice through the seismic cube.\\nTitle Bar - The file name (project name) and location is displayed in the Title bar on top of the\\nuser interface.\\nTool Bar - Icons for commonly accessed commands in the user interface. These tools are useful\\nshortcuts for items that also can be found by accessing the Menu bar.\\nTools - Icons for commonly accessed commands in the user interface.\\nTrends - User defined directions of grid cells (I- and J-directions) to be used as an aid in the Pillar\\nGridding process.\\nV Start value for Linvel function V +K*Z at Z=0.\\n0 - 0\\nVariogram - Measure of the variance between sample data pairs separated by a given distance\\nin a given direction. Used for modeling the spatial correlation of a data set.\\nVariogram map - A contour map (2D plot) of the sample variogram surface.\\nVariogram model - Mathematical model used to describe the sample variogram.\\nVelocity - Velocity of P-wave (compression wave).\\nVelocity model - A model that describes the complete sequence of velocities and corrections in a\\ngeological section.\\nVertical Layering - Sub-zonation of a 3D grid. Fine scale layering reflecting the depositional\\nsetting of specific zones.\\nViewing Mode - In this mode, objects can be moved around in the Display windows.\\nViewport - A limited rectangular area in the 2D viewer (Plot window) where the data objects are\\ndisplayed.\\nVolume Rendering - Seismic Volume Rendering is the process of visualizing and extracting\\nseismic volumes in 3D space.\\nWell Correction - Correction of surfaces at well entry points. Often used in depth conversion.\\nWell Section window - Plot window used for display of well sections used in the well correlation\\nprocess.\\nWell Trajectories - Lines in space representing well paths.\\nZero line - Line defining zero values for thickness or property data.\\nZGY - It is possible to create a new brick representation of a seismic volume. Using the bricked\\nformat (ZGY), the seismic is stored in bricks rather then the traditional trace format. When\\nseismic is displayed only the bricks needed are loaded into memory. Big bricks with low resolution\\nare loaded into memory first, after which the program will start loading smaller bricks with high\\nresolution.\\nZones - A zone is defined by the volume between a top and a bottom horizon.\"},\n",
       " {'header': 'System Requirements ',\n",
       "  'content': 'This document outlines the hardware (HW) and operating system (OS) requirements for Petrel.\\nTo ensure that Petrel functions and performs as expected, we are constantly testing the latest\\nhardware available from major suppliers, as well as optimizing it for maximum performance. In\\nour attempt to minimize unexpected problems and cost, we tend to use branded solutions, such\\nas those offered by HP, Dell, Intel, AMD/ATI and nVidia. However, we do not exclude hardware\\nfrom other vendors.\\nThe following table lists minimum and recommended system requirements.'},\n",
       " {'header': 'Operating Systems ',\n",
       "  'content': 'The following table shows the supported operating systems:\\nVisualization settings recommended for Vista 64\\nTo get the most efficent settings for Petrel with Vista 64, use the following settings:\\n1. Go to: Control panel -> Appearance and Personalization -> Personalization ->\\nWindow Color and Appearance -> Apperance Settings\\n2. Set Color scheme to Windows Vista Basic. It is not recommended to use the Windows'},\n",
       " {'header': 'Aero. Processor ',\n",
       "  'content': 'Processor speed is a determining factor when it comes to large calculation tasks, such as volume\\nsize, property modeling, and upscaling. The processor also has the function of feeding information\\nto the graphics board. The minimum requirement for a processor might be adequate for simple\\nPetrel usage; however, to achieve the highest performance we recommend opting for the best PC\\nconfiguration available. Although Petrel currently utilizes most efficiently only one processor, a\\nmulti processors/multi core system offers many advantages to geophysics and geological\\nalgorithms. These are multithreaded in Petrel 2010. For more information, please see the \"Petrel\\nGeophysics recommendations\" section. Running Petrel on a multi core system will also enable you\\nto start ECLIPSE batch jobs in an efficient manner since ECLIPSE can take advantage of multiple\\nCPUs as well. Newer core technologies will be tested as soon as they become available.\\nA 64-bit processor is needed to run Windows XP 64-bit and Vista 64-bit operating systems. The\\nlatest Intel Xeon 5500 chip, AMD Opteron and Phenom processors are suitable candidates for a\\n64-bit system.\\nThe Front-side bus (FSB) speed should be considered when buying a multiple core processor. FSB\\ntransfer rates have a large impact on main memory transfers. This impacts overall system\\nperformance.'},\n",
       " {'header': 'Internal Memory ',\n",
       "  'content': 'With a 32-bit application (like Petrel ) running on a 32-bit OS (for example, Windows XP) only 2\\nGB of memory per application can be addressed.\\nHowever, a Windows 64-bit operating system (XP 64 or Vista 64) gives each 32-bit application\\naccess to an additional 2 GB of memory, increasing the available memory to 4 GB. The total\\nsystem memory is recommended to be higher than the memory used by the application. This is to\\nensure that your operating system has dedicated RAM and so you do not have to use your page\\nfile (disk). In the event that the amount of RAM cannot be increased, it is recommended to use\\nfaster media such as SDHC cards to achieve better performance\\nTo estimate the size of your system, the following rule of thumb could be applied:\\nFor small data sets (~1 GB), the 32-bit version of Petrel on a Windows XP 32-bit with 2-3 GB of\\ninternal memory is sufficient to run Petrel. A medium sized data set (~5 GB) will run successfully\\nwith Petrel 32-bit on a Windows XP 64-bit system with 4 GB+ of RAM. Petrel projects with large\\ndata sets, that is, large 3D seismic volumes, regional seismic models or large simulation\\n(ECLIPSE) runs, will require Petrel 64-bit running on a Windows Vista 64 or XP 64 systems with\\n32-128 GB of RAM.\\nPetrel Reference Project (RPT) storage\\nrecommendation\\nReference projects are usually stored on a network drive on a central server. Often, access to\\nthese projects becomes a performance issue due to network traffic. This is especially true when\\nmultiple users access a single reference project and multiple data items are transferred back and\\nforth between the local project and the reference project. Windows Vista offers a new remote file\\nsystem protocol called SMB2. The SMB2 system has been adopted by several File Server vendors\\nand it has been deployed on their new platforms. The combination of Windows Vista 64 and the\\nSMB2 protocol can significantly enhance and promote the use of Reference project tool\\nworkflows'},\n",
       " {'header': 'Graphics Cards ',\n",
       "  'content': 'Choosing the right graphics card for your computer is important to optimize Petrel visualization\\nperformance. There is a substantial difference in performance between low and high-end graphics\\ncards when using large 3D grids, or when performing seismic volume rendering.\\nGraphics card performance depends on several factors outside of our control; such as, Corporate\\nOperating System images, drivers and board manufacturers are some of the factors which can\\nimpact graphics performance. nVidia\\'s SLI offering does not currently add any benefit to Petrel;\\nhowever, it might be helpful with large high-resolution monitors, such as the new 30 inch LCD\\nrecently introduced to the market. Integrated graphics cards with no dedicated RAM are not\\nrecommended, as they will reduce the amount of memory available for Petrel and the Operating\\nSystem. For maximum Petrel user experience, we recommend investing in a good monitor, such\\nas a 30 inch LCD monitor, without forgetting a high-end graphics card.\\nPetrel Modeling recommendations\\nSeveral modeling algorithms (see \"Release notes\" on the support web site for details) in this\\nPetrel release take advantage of multiple core processing. Therefore, increasing the number of\\nprocessors will improve the run time of these algorithms. This current trend of converting\\nalgorithms to run in parallel will continue based on algorithm runtime.\\nPetrel Geophysics recommendations\\nWhen using the geophysics module to view large 2D lines and 3D surveys, and when using the\\nvolume rendering feature, we recommend using a graphics card with at least 512 MB memory. In\\naddition, a fast hard drive (such as a SCSI drive or solid state) will increase the speed at which\\nseismic volumes are interpreted. It is also advisable to install as much memory as your operating\\nsystem permits.\\nAs a general memory setup recommendation, the sum of the \"Graphics card memory setting\" and\\nthe \"Geobody render cache\" should be equal to the available GPU memory.\\nSerial Attached SCSI (SAS) disks are common with high-end HW systems. This will have a great\\nimpact on performance for bulk seismic loadings. (SAS 15000 rpm hard disks are recommended.)\\nSolid State disks (SSD) have recently also hit the market. They have an extremely low search\\ntime and quite high sustained read/write speeds.\\nIn Petrel several seismic workflows (e.g. seismic display, attribute generation and realize) utilize\\nmulti-threading, thus enabling higher usage of any extra processors.\\nPetrel Geophysics setup scenarios\\n1) 32-bit Petrel users should be careful to increase this limit. Petrel may become unstable.\\n2) Users with a 64-bit OS can try to increase this limit, however system instabilities may occur\\n3) Users with a 64-bit OS can try to increase this limit, however system instabilities may occur\\nGeneral setup tips\\n64-bit Petrel - Geobody interpretation on Windows Vista 64\\nX GB of RAM, Y GB of GPU RAM the seismic cache (S) equals:'},\n",
       " {'header': 'S=X-2*Y-4 ',\n",
       "  'content': 'where 4 is deducted for the Operating system\\n64-bit Petrel - Seismic interpretation on Windows Vista 64\\nX GB of RAM, the seismic cache (S) equals:'},\n",
       " {'header': 'S=X-4 ',\n",
       "  'content': 'where 4 is deducted for the Operating system\\nPetrel Geobody interpretation\\nPetrel 2010.1 recommended requirements are considered minimum requirements for the\\nGeobody interpretation functionality. Vista 64-bit or Windows XP 64-bit and Petrel 64-\\nbit is the recommended system configuration.\\nSchlumberger has tested various cards in the nVidia Quadro FX card series and the newest ATI\\nFirePro series. See the \"Graphics card\" section for detailed information about what graphics cards\\nyou should select.\\nYour graphics card needs to have:\\nPixel shader 2 or later.\\nOpenGL 2 compatible.\\nIntegrated graphics cards are not supported. In addition, we have noticed some problems with\\nthe nVidia Quadro FX 350M on the Dell M65 model.\\nDue to a limitation in HueSpace ( High End Volume visualization API used by Petrel ), only 2 GB of\\nGPU in a graphics card are fully exploited by this module.\\nPetrel Reservoir Engineering considerations\\nIf a user wants to run FrontSim or ECLIPSE on the same PC as Petrel, then a multi-core machine\\nwould be recommended. Windows Vista 64-bit would be the preferred OS.\\nRecommended tested hardware solutions\\nWe regularly test hardware from different vendors; the tables shown below list some of the\\nhardware used in the Petrel commercialization cycle. Although we have tested the hardware, we\\ncannot certify it. Problems outside of SIS control, such as driver and BIOS bugs and operating\\nsystem limitations may affect the user experience.\\nRecommended laptops\\nNote: For 64-bit Windows to run on a Laptop select a 64-bit capable Intel Core 2 Duo processor or\\nsimilar\\nRecommended workstations\\nRecommended graphics card\\nThe latest official nVidia drivers that have been tested are 186.18 (Workstation) and 185.85\\n(Laptop). The latest official ATI driver tested is Catalyst 8.603. We suggest that you always\\nupgrade to the latest official drivers from your PC vendor\\'s home page, this is particularly\\nimportant when upgrading your laptop display driver.\\nYou should use the \"Schlumberger Petrel\" profile of the graphics card for optimized performance.\\nThis option is typically found in the 3D settings tab of the NVIDIA control panel.\\nExamples of Graphic errors\\nHow can you determine whether or not the graphics card is causing trouble when trying to use it\\nwith Petrel?\\nErrors can show up in a number of different ways, from system crashes to displaying dotted\\ninstead of solid lines. If you experience problems with your particular graphics card, it is usually\\nassociated with the driver you are using. The evolution of new chips and graphic accelerators is\\nvery fast, and upgrades of graphic card drivers are constantly available on the web sites of the\\ndifferent graphic card manufacturers.\\nIt is important to have a card that fully supports OpenGL. Unfortunately, this is not always the\\ncase as some cards designed specifically for the gaming industry and often have poor OpenGL\\nsupport. Purchase a card designed for professional use. Some of the common graphic display\\nerrors are listed below:\\nDark shadows on filled polygons.\\nSpikes originating from one point.\\nIrregular color pattern.\\nDisplay windows are limited to a smaller area than the fully extended window.\\nArbitrary colors on displayed surface.\\nSolid lines are displayed irregularly dotted.\\nPetrel puts a high demand on the quality of graphic cards. The types of errors listed above may\\nimply that the cards are not fully compliant with OpenGL. Please contact your local Schlumberger\\nsupport representative for more information.\\nStarting with Petrel\\nA data set from the Gullfaks field in the North Sea is provided with the Petrel installation CD. This\\nis to provide our new users with sample data for initial training. Use it to get acquainted with the\\nsoftware - The sample data set includes most of the elements needed to become familiar with the\\nfunctionality in Petrel. It is strongly recommended that users learn the basics of Petrel before\\nstarting on a complex data set. This will save time in the long run.\\nIn addition it is recommened to take one or several Petrel Training courses to get up to speed\\nwith Petrel and use the max of its capabilities.\\nFor available courses in Petrel, please see Help System Information\\nData Set used in the Petrel Training and Help'},\n",
       " {'header': 'Systems ',\n",
       "  'content': 'The Gullfaks data set has been released for commercial use by the Norwegian oil company Statoil.\\nGullfaks is one of the major oil fields in the North Sea and one of the largest oil producing fields\\non the Norwegian continental shelf. Some of the explainations in this Online help manual are\\nbased on Gullfaks as an example\\nGullfaks location map\\nThe data set consists of:\\n3D seismic survey in time\\nSurfaces in time\\nFault polygons in time\\nIsochore maps\\nSixteen wells with eight logs (Density, Sonic, Gamma, Perm., Por., Water Sat. and Facies).\\nWell tops tying the horizons to the wells.\\nProperty Maps (Perm, N/G, Water Saturation and Por).\\nVelocity data for depth conversion.\\nFor further details, see the Read Me file in the Demo folder in the Petrel installation folder.\\nImage of the top reservoir surface\\nStarting up Petrel the first time\\nPetrel 2010.1 will install separately from any previous versions installed on your system. This\\nmeans you can keep your old version, for example, Petrel 2008.1, and run it in parallel with Petrel\\n2010.1. The installation of Petrel 2010.1 will not perform an upgrade of your current installation.\\nIt is highly recommended that you look at the System Requirements before proceeding with the\\ninstallation.\\nPetrel 2010.1 can be installed either as a standalone application on your local computer, or you\\ncan run your Petrel license on a license server. It is also possible to run the Petrel application from\\na file server.\\nPetrel needs the address of a valid license server to be able to start. If you have configured a\\nlicense on your local computer using Schlumberger licensing, you can proceed with launching\\nPetrel using the option Petrel 2010.1 from this menu.\\nLicense files\\nAll Petrel license files issued from 2010.1 onwards should contain the dongle number as part of\\nthe Feature line and comment lines with a module features summary as part of the body text.\\nThe version number for Petrel 2010.1 is 2010.1. (For Petrel 2007.1 the version number is 1024\\nand for Petrel 2008.1 the version number is 1034). In the Petrel Help menu; License Status\\ndialogue - more information about the dongle and license in current use is listed.\\nDefine Licence Server environment\\nIf Petrel 2007.1/2008.1 has not been run on this system, or if you need to use a different license\\nserver other than Petrel 2010.1:\\n1. You should select the option Petrel Select License, the first time you start Petrel 2010.1.\\nThis opens the Define license server environment window.\\n2. Access the Start menu on your computer, go to Programs >Schlumberger >Petrel\\n2009. Use the Petrel Select licenseoption\\n3. Enter the address of the license server here.\\nThe address must be of the form port@servername. Please contact your System/License\\nAdministrator for this address. If you use a local license with a dongle,@localhost will\\nnormally do.\\nNote that changing the License server environment variable can affect other applications. If\\nyou try to change it, a warning message will appear. Overwriting the existing license servers in\\nthe environment will affect other applications running with the same environment variables\\n(SLBSLS_LICENSE_FILE or LM_LICENSE_FILE).'},\n",
       " {'header': 'Select License Package ',\n",
       "  'content': 'To change the name of a Package, type the name in the Name box above the Packages and\\npress the Refresh button. Observe that the name changes in the list. This name is stored in the\\nuser environment for each user, but if you want to change these names so that all users see the\\nsame name, it can be distributed in a Global Configuration File.\\nYou can select a Favorite package to speed up the startup time of Petrel. To do this, select the\\npackage and toggle on Favorite. A star bitmap symbol indicates your favorite package. If you\\nselect only one Favorite package, Petrel will launch directly, bypassing any licensing dialogs. This\\nwill speed up the launch time if you only use one package.\\nIf you have correctly configured license access, Petrel opens the Package Selection window. If you\\nplace the cursor over one of the elements of this window, a description will pop up to help you.\\nThe license packages available to the user on the selected license server(s) are listed on the left\\nside of the window, while the modules available within this predefined package of modules are\\nlisted on the right. Click on the Package name in this list and click OK to proceed with starting up'},\n",
       " {'header': 'Petrel. ',\n",
       "  'content': 'If a Package has multiple licences, the package can be selected and the current users can be\\nidentified by pressing the List users...button (top left in the dialog).\\nYou can also launch the Select license package window from within Petrel. Go to: Help >\\nLicense packages \\nNote: It is possible to avoid showing available licenses/packages, see Number of licenses\\navilable\\nChange Licence Server environment\\nIf the Select license package dialog is open and you have problems starting Petrel due to the\\nServer selection:\\n1. Press the Set button.\\nThis opens the Define license server environment selection box again.\\n2. Type in the new server or localhost, but be aware of the warning message described above.\\nSchlumberger Licensing for stand-alone license\\ndongles offers the following usability improvements\\nAbility to refer to a folder with multiple license files\\nAbility to use Windows processes in addition to a Windows service as a license server\\nAdditional flexibility in managing Schlumberger Licensing configuration'},\n",
       " {'header': 'Licensing ',\n",
       "  'content': \"A hardware key, a so-called dongle, controls the Petrel license. The dongle is plugged into the\\nparallel port on the local machine, or into the server if a Flex LM net license has been purchased.\\nThe hardware key controls the expiry date and available modules.\\nTo run Petrel you need a valid license configured. You can either connect to an already existing\\nlicense server, or you can configure the license on your local machine, either as Standalone or as\\na license server. Petrel uses FLEXnet 11.4 in combination with CodeMeter dongles to provide a\\nsecure licensing solution called 'Schlumberger licensing'. Petrel uses the WIBU CodeMeter dongle\\nfor license authentication.\\nIt is only required to install the CodeMeter dongle on machines that act as a license server.\\nTo make sure that the dongle has been recognized by the system, you can check that the\\nCodeMeter icon is in the notification area of the taskbar. Double-click this icon to bring up the\\nCodeMeter Control Center. If the dongle is recognized, the ID number (CM-Stick) of the dongle(s)\\nshould be listed in this Window.\\nIf the hardware key is missing on the local PC when starting Petrel, the program will search\\nfor a net license, and if it is absent, the user will be given an error message.\\nSchlumberger controls the licensing and hardware key shipments, and all license inquiries must\\nbe made to Schlumberger Petrel support.\\nPetrel is a modular system where the hardware key controls the available modules. The following\\nmodules exist:\\n1.\\n1. Geoscience Core system:- Online help system, 2D and 3D visualization, data import,\\nhistogram and calculator for well logs, creating & editing well tops, digitizing & editing\\npolygons, fault modeling with 3D editing, 3D pillar gridding, make horizons, zonation\\nbuilding (isochores) and fine-scaled sub-zonation in 3D grid, filtering functions, Allen\\ndiagrams, editing 3D grid, generation of flow simulation grids (geometric scale-up from fine\\ngrid), advanced volume calculations, grid and line operations, general 2D gridding, stereo\\nimaging, general and well intersections, spreadsheet reports output as text files, Workflow\\neditor for automated model updates and mapping processes. Scaled map & cross section\\nplotting.\\n2. Reservoir Engineering Core system:- From the new Reservoir Engineering Core\\nmodule, you can build ECLIPSE simulation models directly from your geological models; add\\nfluid properties, well completions, production history and event scheduling. Organize your\\ngeological realizations and development scenarios into cases and select and launch the\\nappropriate ECLIPSE and Frontsim simulator and analyze your results.\\n3. Combined Core system:- The Combined Core module includes the functionality of both\\nthe Geoscience Core and the Reservoir Engineering Core\\n4. Data and Results Viewer:- The Data and Results Viewer provides easy access for viewing\\nwell and seismic data, reservoir interpretations and simulation results. An ideal tool for\\nsimulation engineers, managers, stakeholders and even shareholders, the viewer provides\\nviewing access to all Petrel data items found in a project, without the necessity of learning\\nindividual Petrel modules.\"},\n",
       " {'header': 'Petrel Geophysics ',\n",
       "  'content': 'Fully integrated with the geological and engineering tools, the Petrel seismic toolkit allows for\\nrapid 2D & 3D interpretation. Sample your seismic data directly into your 3D reservoir model to\\npredict pay and bias reservoir property distribution using a geo-statistical approach. An extensive\\nlibrary of attributes and volume rendering techniques can help identify hydrocarbon indicators and\\nfracture patterns.\\n1. Seismic interpretation:- Import of 2D & 3D SEG-Y or ZGY data, 3D visualization of\\nseismic inlines, crosslines, timeslices and random lines. Generation of simple seismic\\nattributes, digitizing fault pillars/fault sticks, guided-, 2D & 3D seeded auto-tracking and\\nmanual interpretation of reflectors on vertical seismic intersections, digitizing fault planes\\non timeslices, QC and re-interpretation of imported line data, seismic color table including\\ndiscrete color ranges, advanced filtering options on value ranges including transparency,\\nresampling of imported data (cropping). Traditional 2D interpretation window with bitmap,\\nand/or wiggle display.\\n2. Multi-trace seismic attributes:- Generation of advanced seismic attributes from\\nimported seismic volumes (e.g. graphic equalizer, structural smoothing, variance, Iso-\\nfrequency, iso frequency, t*attenuation, Ant-tracking).\\n3. Seismic volume rendering and extraction:- Any 3D seismic attribute volume can be\\nextracted from a SEG-Y/ZGY cube. Different degrees of transparency can be applied. The\\nseismic volume can be rendered in 3D and visualized together with any other data available\\nin Petrel. State-of-the-art volumeblending technology is used in Geobody interpretation to\\nquickly isolate, extract, and integrate a body directly into a property model for true 3D\\nvolume interpretation. This allows users to interactively blend multiple seismic volumes,\\nisolate areas of interest, and then instantly extract those areas into a 3D object called a\\ngeobody.\\n4. Seismic sampling:- Display of seismic data (using intersections) and QC of the seismic\\ndata within a 3D grid, depth conversion of a seismic volume (requires the Domain\\nConversion module), creating a seismic property by sampling any seismic attribute into a\\n3D grid, extract seismic data to an attribute map that can be draped over a surface.\\n5. Domain conversion:- Node by node depth conversion of the structural 3D grid, average\\n5.\\nvelocity for selected zones are used based on constants, linear velocity functions, velocity\\nmaps or a combination of these, depth conversion along pillars or vertically, spreadsheet\\nreport.\\n6. Automated structural interpretation:- An automated fault interpretation workflow\\nallowing interpreters to spend time understanding the trends of fault surfaces and to make\\ncorrelations from automatically extracted fault patches from Petrel-generated Ant tracking\\ncubes.'},\n",
       " {'header': 'Petrel Geology ',\n",
       "  'content': \"A full suite of reservoir characterization modules include the ability to generate well correlation\\npanels, perform traditional mapping and plotting techniques and 3D reservoir modeling,\\nseamlessly integrated with the simulation environment. The Workflow editor tool allows for rapid\\nmodel updates reducing project cycle time and maximizing efficiency.\\n1. Well Correlation:- 2D well correlation display, correlation of formation and facies tops,\\ndynamic link in all displays; 2D, 3D and Spreadsheet, extensive display options, various\\nsubdivisions of tops and facies with legends.\\n2. Facies modeling:- Scale up of well logs, sequential indicator simulation, stochastic fluvial\\nobject modeling, adaptive channel modeling with well conditioning, Multipoint Facies\\nmodeling, deterministic interactive facies modeling permits editing and adding facies\\nobjects by using interactive drawing tools, zone by zone modeling with options to model\\nseveral zones together.\\n3. Petrophysical modeling:- Scale up of well logs, deterministic petrophysical property\\nmodeling, stochastic property modeling using algorithms from GSLib and improved inhouse\\nversions of Kriging, histograms of well data & generated model, geometrical property\\nmodeling, 4D property player, geometric and property value filter, interactive editing of\\nproperty values, generation of average and net maps, display properties directly in a well\\nsection, scale up of properties, export of 3D property models (filter sensitive).\\n4. Data analysis:- Perform transformations and analyze 1,2 and 3D trends in continuous\\ndata, analyze and edit vertical distribution of discrete data and correlate with sampled\\nseismic or property cubes. Interactive modeling of variograms for both discrete and\\ncontinuous data. Generate histograms and cross plots of log data, model input and final\\nproperties, insert regression curves. Interactive editing of functions from cross plots, CDF,\\noptional logarithmic scales.\\n5. Fault Analysis:- Extraction of fault cell faces along fault surfaces in the 3D grid.\\nCalculation of permeability, thickness and shale gouge ratio along the fault. Calculation of\\ntransmissibility multipliers based on fault properties and grid permeabilities. Export of\\ntransmissibility multipliers in ECLIPSE format.\\n6. Discrete fracture Modeling:- Discrete Fracture Networks (DFN's) can be generated and\\nvisualized in Petrel, fracture attributes can be assigned to each fracture plane and the\\nfracture attributes can be upscaled using Golder algorithms to grid properties\\n(Permeabilities, Porosity and Sigma Factor), fracture grid properties can be used directly in\\nDefine simulation case in Petrel for Dual Porosity/Dual Permeability simulation.\"},\n",
       " {'header': 'Petrel Reservoir Engineering ',\n",
       "  'content': \"With your reservoir model in place, use the Petrel simulation workflows to perform ECLIPSE\\nsimulation, reduce uncertainty and assist in future well planning. Advanced up-scaling techniques\\nallow you to recreate geologically accurate models for full reservoir simulation.\\n1. Advanced Gridding and Upscaling:- The Advanced Upscaling module has now been\\nplaced on maintenance mode. A new module, Advanced Upscaling and Gridding, contains\\nnew simulation gridding technology supporting Local Grid Refinements (LGR's) and IJK\\n1.\\nstair-step gridding, as well as the upscaling functionality of the Advanced Upscaling module.\\nFeatures include a wide range of upscaling techniques for sampling fine scale grids into\\ncoarser simulation grids. Includes full tensor upscaling for permeability, which runs simple\\nsimulation in each of the coarse cells to calculate effective permeability in each direction.\\nFlexible options for the solver used, skin cell definition, output orientations and the\\nconsideration of porosity and N/G properties.\\n2. Frontsim Locked:- Inclusion of the ECLIPSE FrontSim streamline simulation technology\\nenables better workflows for ranking geological models. It is an important step in the\\niterative workflows in Petrel for estimating uncertainties and to better understand which\\nmodels to base decisions on. The module and the user interface is adjusted and conformed\\nto fit with the 3D modeling workflows in Petrel.\\n3. History Match Analysis:- Perform history-matching studies on multiple ECLIPSE reservoir\\nsimulation runs in an effort to isolate the best or most likely geological realization.\\n4. Sensitivity Analysis: -Create proxies for volumetric or simulation cases using\\nexperimental designs for faster and statistically significant evaluation of volumetric\\nuncertainty, recovery and screening of most sensitive model parameters. Module provides\\naccess to four sampling algorithms - Plackett-Burman, Fractional Factorial, Central\\ncomposite, Box-Behnken - and a user defined list in a CSV format text file. In addition the\\nmodule provides access to a Tornado chart window and the Objective function definition\\nprocess.\\n5. Optimization: -Optimize reservoir simulation forecasts using a selection of optimization\\nalgorithms. Optimize while considering uncertain parameters. Use proxies created through\\nthe Petrel Sensitivity Analysis module for faster processing. The module offers three\\nvariants of a local optimization (simplex) algorithm with ability to handle linear and non-\\nlinear constraints on the control and response variables. Tornado chart window and\\nobjective function definition process are available with this module.\"},\n",
       " {'header': 'Petrel Utilities ',\n",
       "  'content': '1. Well design:- Digitizing and editing of well trajectories in 3D, sampling of modeled\\nproperties from a 3D model along any well trajectory, intersection report of well trajectories\\nand Horizons, make synthetic logs for well trajectories, export well trajectory to file.\\n2. Surface imaging:- Option to drape a surface with a bitmap, e.g. aerial- or satellite\\npictures, coordinates can be added to imported bitmaps.\\n3. Classification & Estimation:- Neural network technology for the estimation and\\nclassification of well logs, surfaces, seismic volumes and 3D property models.\\n4. API Developers Kit:- Allows access to the Ocean API development environment for\\ndeveloping Petrel plug-ins. Running a Petrel plug-in requires one of the Core systems.\\n3rd Party plug-ins\\nTransparent access to project and corporate databases like GeoFrame, Finder and OpenWorks\\nlets you create your ideal seismic-to-simulation workflow.\\n1. OpenSpirit plug-in for Petrel:- Access model data held in a remote database across\\nplatforms through the OpenSpirit link.\\n2. Ocean plug-ins:- Any plug-in generated through the Ocean API development environment\\ncan now be directly linked and used in Petrel.'},\n",
       " {'header': 'Petrel Performance ',\n",
       "  'content': 'To be able to use Petrel with optimal performance, there are a few things that should be checked to\\nensure that the computer hardware is optimized for working with Petrel.\\nOpen the System Info under the Help menu for more information on your hardware.'},\n",
       " {'header': 'Hardware ',\n",
       "  'content': 'For best graphical performance and speed, use an OpenGL supported graphics card. If the\\ngraphics are slow and \"jumpy\", check the installed card. Schlumberger has tested the\\nperformance of some cards, see Hardware Recommendations.'},\n",
       " {'header': 'Virtual Memory ',\n",
       "  'content': \"When loading large data sets, the Windows operating system may give an error message, stating\\nthat the machine is low on Virtual Memory. This happens when the physical RAM is (almost) used\\nup and the system tries to swap some data to the hard drive.\\nThis can be avoided by increasing the Total paging file size, which is found in the Control Panel\\n- System - Advanced - Performance and Virtual Memory.\\nVirtual Memory = 2xphysical RAM is standard when Windows is installed. It could help to\\nincrease this to:\\nVirtual Memory = 3xphysical RAM, but probably not more as the operating system might\\nstall. This can occur when 99 % of the resources are used for swapping.\\nIf you have several disks on your PC, it is recommended to place the page file on the fastest disk.\\nOptimizing Memory usage\\nThere are three things you can do to ensure that you are using the installed memory efficiently:\\n1. Petrel allows you to work with several Display windows open simultaneously. Keep in mind\\nthat all open Display windows will be updated continuously as you work and that this\\nprocess uses a lot of RAM as well as CPU time. To optimize RAM usage, close Display\\nwindows you are not using at the time or switch off data objects from displays.\\n2. Petrel will store temporary data in memory to optimize graphics rendering. This may\\nhowever slow down the program after a prolonged work period. To free the memory used\\nby this process, go to the Tools pull-down menu on the Menu bar and select Free\\nmemory.\\n3. In the Uncertainty and Optimization process there is also a checkbox to free memory every\\nn'th run. This can also be manually input in the Workflow editor.\\n4. In the Display window, it is possible to change the Display resolution to optimize the speed\\nof the graphics. These options are listed on a menu in the Display window, opened with the\\nright mouse button. Under Draw Style different move options are listed. Move same as\\nstill is high resolution and is default in Petrel, but can be slow. Move low res is the fastest\\noption.\\nTo check the performance status, open the Task Manager in Windows; position the cursor on the\\nMenu bar at the bottom of the Windows interface and click with the right mouse button. The Task\\nManager will, under the Applications tab, give the status of the program as Not responding\\nwhen Petrel is making calculations (for example, performing the Pillar Gridding process). This only\\nmeans that the program is busy with calculations. The Petrel process can be closed, by clicking\\nthe End Task button.\\nLimiting Petrel's multi-threading ability\\nSeveral of the processes in Petrel offers multithreading, taking advantage of new multi core\\nsystems. But this functionality could also lead to conflicts when several applications run on the\\nsame system.\"},\n",
       " {'header': 'Scenario: ',\n",
       "  'content': 'Petrel and ECLIPSE parallel running on the same Windows 8-core system. ECLIPSE running\\n4 way parallel, but Petrel detects the 8 cores and runs petrophysical modeling using all 8\\ncores, bringing ECLIPSE to its knees.\\nTo limit the number of cores Petrel will use, the user can set an environment variable (from a dos\\nprompt), like:\\nset OMP_NUM_THREADS=4\\nPetrel uses the OpenMP lib, that honours this, for all its various parallel algorithms.'},\n",
       " {'header': 'User Interface ',\n",
       "  'content': 'The user interface is designed to give the average PC user a familiar look and feel. The Petrel\\nwindow consists of two main parts:\\nThe Petrel Explorers - The Explorer panes have the same look and feel as the Windows\\nExplorer. Each piece of data has an associated icon and these can be organized into folders and\\nsub-folders as required. There are eight panes on the explorers:\\nInput for input data such as wells, seismic, surfaces etc.\\nModels for the generated 3D models, velocity models, fracture models and simulation\\nmodels\\nResults for the results from volume calculations and simulations\\nTemplates for the color tables used to display the data\\nProcesses contains a list of all the processes in Petrel. Activating a particular process will\\ncause the tools associated with that process to appear on the Function bar. Double clicking\\na process will open the process dialog.\\nCases gives access to all cases defined for simulation and volume calculation\\nWorkflows provides access to the workflow manager and any workflows which have been\\ncreated in the current project.\\nWindows provides access to the windows and plots that have been created in the open\\nproject. Files or folders can be activated by clicking them within the Petrel Explorer.\\nFor more details on the different explorer panes: Details of the Petrel Explorer.\\nThe Display window - Displays selected items from the Petrel panes. A number of windows are\\navailable for displaying data, 3D, 2D, Well Section, Interpretation, Intersection, Map, Plot,\\nHistogram, Function and Stereonet window although some of these can only display certain types\\nof data. For information on the various windows available in Petrel see Windows and Plotting.\\nUser interface details\\nTitle bar - The file name (project name) and location is displayed in the Title bar. Press and\\ndrag the Title bar to move the Petrel screen on your desktop.\\nMenu bar - (Top) Click on any of the Menu bar headings to access a list of dialog boxes,\\npop-up menus, commands and features.\\nToolbar - (Top) Tools for commonly accessed commands. These tools are useful shortcuts\\nfor items that can also be found by accessing the Menu bar.\\nFunction bar - (Right) Process specific functionality. These tools change as different\\nprocesses are selected in the Process diagram. Note that there can be two Function bars -\\none on the right hand side and one below the Display window.\\nPetrel Explorer panes - (Left) A file manager for optimizing all related model data.\\nConsists of eight panes; Input, Models, Results, Templates, Processes (access to the\\nprocess in petrel), Cases, Workflow (automate processes) and windows pane (control the\\nplots and windows in the project).\\nDisplay window - Checked items in Petrel Explorer panes will be displayed in the active\\nDisplay window.\\nStatus bar (message) - (bottom left) Information on processes will be displayed here.\\nStatus bar (Info) - (bottom right) Shows information of the selected item in the active\\nwindow.\\nThe \"Spin animation\" in the 3D display window can be turned off from the Tools Menu,\\nSystem Settings. Under the Effects tab there is an option to turn on or off the spin animation. This\\nwill now work for all windows. If the user wants to turn off the spin effect only in particular\\nwindows, it\\'s possible to right click inside the display window, choose Preferences and then click\\nSpin animation (a small checkbox by the text in the menu indicates if the spin animation is on\\nor off).\\nLayout of the Interface\\nThe User Interface gives the possibility to customize the setup of windows and panels. The Petrel\\nExplorer panes can be turned off or moved around in the window. The different panes can be\\ndocked, pinned, shown as floating panes and can be hidden. There is free placement and\\ngrouping. It is recommended to always maximize the window. As in some process steps,\\nmore function buttons are added on the Tool bar and these are not visible unless the window is\\nmaximized\\nMoving panes\\nBy default Petrel opens the eight panes divided into two areas with four panes in each.\\nThe left part of the user interface, where the Petrel Explorer panes are placed, can be made larger\\nor smaller by clicking the left mouse button on the border between these windows and the Display\\nwindow. In the same way, the area for upper and lower division of the explorer panes can be\\nchanged, by clicking and dragging the border between these areas.\\nTo move one of the panes, left click the top border and drag. Use the navigator (as shown above)\\nto pin the panes in different locations of the Petrel window. The pane can be pinned to the top,\\nleft, bottom, or right of the explorer windows or the display window. Hold the left mouse button\\ndown, and hover the marker inside the navigator to indicate where to place the pane. To dock the\\npane back into one of the explorer windows, select the upper or lower part of the navigator.\\nManipulating panes\\nThe Petrel Explorer panes can be moved from the left side of the window to a separate window\\nfloating in the Display area.\\nRight click one of the panes in the header and choose floating from the menu to make that pane\\nmove into the display area. To move the pane back, click with the right mouse button on the\\nheader again, and deselect the floating option.\\nAll panes can be closed and opened. This can be done in the View pull-down menu on the Menu\\nbar. Select View> Panes >.\\nThe objects are marked if they are visible. All panes can also be closed by right clicking the\\nheader and pressing Hide. To make the panes visible again, there are shortcuts to be used:\\nInput pane - Ctrl+T\\nModels pane - Ctrl+L\\nProcesses pane - Ctrl+R\\nIf the display window is maximized, and all the panes are opened in the View pull-down menu,\\nthose will not be visible as they are hidden behind the maximized Display window. To be able to\\nuse these windows, reduce the size of the Display window.\\nNote that the Toolbars can be un-docked and moved to become floating toolbars. There are\\nfree placements. Right click the toolbars to customize or lock them.\\nSystem settings\\nIt is possible to reset the layout to default settings:\\nGo to Tools> System settings> Effects tab and click the Reset layout button. Also within the same\\ntab it\\'s possible to toggle on the possibility to rename node directly, using the mouse.\\nIn the same tab you can choose to \\'Rename node directly (mouse)\\'. This allows you to directly\\nrename an object in the Input pane without'},\n",
       " {'header': 'Menu Bar ',\n",
       "  'content': 'The pull-down menus are listed on the Menu bar at the top of the Petrel interface. To open a pull-\\ndown menu, click on the menu with the left mouse button. To perform any of the commands in\\nthe menu, click on it.\\nFile pull-down menu\\nThe most commonly used functions can be found in the Toolbar.\\nNew Project (CTRL and N) will start a new project.\\nOpen Project (CTRL and O) will open an existing project.\\nImport File (CTRL and I) will import a selected data file and place it at the bottom of Petrel'},\n",
       " {'header': 'Explorer ',\n",
       "  'content': \"Reference project tool (CTRL and M) will launch Petrels data sharing tool where it's possible to\\ncopy data between projects.\\nSave Project (CTRL and S) will save the current project.\\nSave Project as allows the user to save the current project under a user specified name.\\nAutomatic save will launch a dialog box where the user can alter settings for an automatic\\nsave of projects in Petrel.\\nExport to save the selected item on file.\\nExport Graphics to save the graphical display in the current Display window as a bitmap.\\nPrint (CTRL and P) to print what is being displayed in the Display Window.\\nPage setup allows the user to change the settings for the printouts (e.g. maps).\\nExit will quit the application with a prompt to save the project.\\nEdit pull-down menu\\nThe most commonly used functions can be found in the Toolbar.\\nUndo (CTRL and Z) will undo the last editing action in process steps such as Fault Modeling,\\nMake/Edit Polygons, etc.\\nRedo (CTRL and Y) will redo the last editing action in process steps such as Fault Modeling,\\nMake/Edit Polygons, etc.\\nCut (CTRL and X) will cut the active (selected) item in Petrel Explorer.\\nCopy (CTRL and C) will copy the active (selected) item in Petrel Explorer.\\nPaste (CTRL and V) will paste a previously Cut or Copied item in the active (selected) folder\\nin Petrel Explorer. If a folder is not selected, the item will be pasted at the bottom of Petrel\"},\n",
       " {'header': 'Explorer. ',\n",
       "  'content': 'Delete (DEL) will delete a selected object.\\nFind (CTRL and F) will search for items within the local project\\nCopy Bitmap will take a copy of the graphics in the active Display window and place it on the\\nclipboard.\\nCopy Metafile will take a copy from the graphics in the active Plot window place it on the\\nclipboard - the output is a vector file (wmf).\\nPaste Bitmap will paste a bitmap from the clipboard into the project or the selected folder.\\nSelect All (CTRL and A) will select all items in the Display window, e.g. all polygons if a file\\nwith polygons is displayed.\\nView pull-down menu\\nView contains options on how to organize the Petrel windows. The most commonly used functions\\ncan be found in the Toolbar.\\nPanes contains a list of all the panes that can be visualized in Petrels display window.\\nTime player toolbar - toggle for the time player toolbar which will appear below the Display\\nwindow.\\nFlight Simulator toolbar - toggle for the flight simulator. The flight simulator toolbar will also\\nappear below the Display window.\\nStatus bar - toggle for the Status bar.\\nMessage log - opens the message log used by various processes in Petrel.\\nFull screen (F11) displays current Petrel window as full screen.\\nShow active workflow (CTRL and W) will open the active workflow ready for use.\\nColor table toolbar allows the user to, on the fly, change color templates for the selected\\nseismic specified in the toolbar, rotate and compress the colors. Also, an opacity histogram can be\\nbrought up for the colorbar by right-clicking on the colorbar itself.\\nCollapse all icons in project will collapse all icons in the project recursively.\\nNext pane (F6) will select and set the focus on the next pane in the Petrel explorer.\\nPrevious pane (Shift and F6) will select and set the focus on the previous pane in the Petrel\\nexplorer.\\nSet focus to Input pane (CTRL and T) will select and set focus on the Input pane.\\nSet focus to Processes pane (CTRL and R) will select and set focus on the Processes pane.\\nSet focus to Models pane (CTRL and L) will select and set focus on the Models pane.\\nSet focus to Work area (F3) will set focus on the Work area.\\nSettings will open the Settings window of the active object in Petrel Explorer.\\nProcess dialog will open the process dialog of the active process step in the Process diagram.\\nView all will zoom out and view all items in the active window.\\nOverview all will set the camera above the visual items to get a map view.\\nHome will set the camera to home position for the active window\\nSet home will set the current camera position to home.\\nHeadlight will toggle headlight on or off.\\nOrthogonal camera will toggle orthogonal perspective on or off.\\nSome viewing icons are listed in this pull-down menu as well. They can also be found in the Tool\\nbar.\\nInsert pull-down menu\\nThe Insert menu gives the possibility to insert new objects into an already open Petrel project.\\nImport (on selection) allows the user to import data on the selected item on file.\\nGraphic allows the user to insert a graphic file to a project.\\nNew annotations allows the user to insert new annotation object in the Input pane.\\nNew checkshots will insert checkshots into the project.\\nNew intersection plane inserts a new General Intersection into the active 3D Display\\nwindow.\\nNew point well data insert point well data in the Input pane.\\nNew well will create a new vertical well in the project.\\nNew well tops will insert a new well tops folder in the Input pane.\\nNew workflow will insert a new workflow and make it active.\\nNew geobody will insert a Geobody folder for geobody interpretation\\nNew fault patches folder will insert a new fault patches folder in the Input pane.\\nNew fluid folder will insert a new fluid folder in the Input pane.\\nNew folder / model creates a new folder in the Input pane or a new model in the Models\\npane.\\nNew interpretation folder will insert a new interpretation folder in the Input pane for\\ncontaining interpreted objects.\\nNew rock physics folder will insert a new rock physics folder in the Input pane for containing\\nsaturation and compaction functions.\\nNew seismic main folder will insert a seismic main folder in the Input pane.\\nNew seismic survey folder will insert a seismic survey folder in the Input pane.\\nNew variogram folder will insert a variogram folder in the Input pane for containing\\nvariogram objects.\\nNew well folder will insert a well folder in the Input pane.\\nNew aquifer folder will insert a new aquifers folde to the active 3D grid\\nNew thermal boundary folder will insert a new Thermal boundary conditions folder to the\\nactive 3D grid\\nProject pull-down menu\\nThe Project menu gives the options to set project settings.\\nProject Settings: this Settings window contains some settings for the current project.\\nInfo - details of the project such as history of users and location of field.\\nStatistics - statistical overview of the project, e.g. max. min. X, Y, Z and time spent\\nworking on the project.\\nWell settings - Set default date for well events and select to decimate the well section\\nwhen scrolling.\\nUnits and coordinates - details of project units and projection, with possibility to alter\\nthese options.\\n3D settings - Settings for transparency, decimation, anti-aliasing, and 3D editing.\\nMisc settings 1 - options for how to save the project, time settings for the players and\\nglobal surface filter. Project Settings.\\nMisc settings 2 - index axis swap options and project expert settings of Minimum'},\n",
       " {'header': 'Curvature. Project Settings. ',\n",
       "  'content': \"Reset all draw styles will set all drawing styles to default.\\nReset all default draw styles will remove all user given defaults of draw styles.\\nSave project templates will save the project templates in this project.\\nLoad project templates will load project templates from a project and insert them into the\\ncurrent project.\\nOpen project folder will open the .ptd data folder associated to the project .pet file\\nClean project directory - removes orphaned reservoir simulation files from the project\\ndirectory.\\nFlush dead icons will remove all icons with no data in the entire project.\\nECLIPSE export settings - allows the user to specify settings for export in ECLIPSE format.\\nCMG export settings - allows the user to specify settings for export in CMG format.\\nVIP export settings - allows the user to specify settings for export in ECLIPSE format.\\nGslib export settings - allows the user to specify settings for export in ECLIPSE format.\\nECLIPSE import settings - allows the user to specify settings for import in ECLIPSE format. For\\ndetails of these settings, go to Grid and Properties.\\nCMG import settings - allows the user to specify settings for import in CMG format. For details\\nof these settings, go to Grid and Properties.\\nVIP import settings - allows the user to specify settings for import in ECLIPSE format. For\\ndetails of these settings, go to Grid and Properties.\\nGslib import settings - allows the user to specify settings for import in ECLIPSE format. For\\ndetails of these settings, go to Grid and Properties.\\nReal Time settings - allows the user to specify settings for Real Time Data Link for\\nwellbores.\\nTools pull-down menu\\nSystem Settings include options for troubleshooting, effects, Company profiles on wells and\\noil coloring, VR, Licensing and Queue definition for remote submission jobs.\\nFree Memory can be used if visualization slows down. It will clear the memory (temporary or\\nredundant) and speed up visualization, although it may take some more time to re-display\\nobjects.\\nLaunch Reservoir Engineering Legacy applications:\\nLaunch FloGrid will launch FloGrid with licensing from Petrel.\\nLaunch FloViz will launch FloViz with licensing from Petrel.\\nLaunch ECLIPSE Office will launch ECLIPSE Office with licensing from Petrel.\\nLaunch Schedule will launch Schedule with licensing from Petrel.\\nLaunch GRAF will launch GRAF with licensing from Petrel.\\nExtensions - plug-in related\\nSecurity settings - Set security level (Very high, high, medium or low), in addition to adding\\nTrusted publishers.\\nFree framework model memory will clear cached memory related to the structural framework\\nmodel.\\nLaunch Seismic and Virtual reality tools:\\nLaunch SEG-Y Utility - Launches the 2D seismic UKOOA Navigation to SEG-Y header utility.\\nLaunch VR hybrid wand - Virtual Reality navigator tool application\\nLaunch VR Site manager - Virtual reality set up tool application\\nLaunch VR On-screen keyboard - opens a keyboard to be used for Virtual Reality.\\nWindow pull-down menu\\nIn the Window pull-down menu on the Menu bar, different options for arranging the Display\\nwindows are listed.\\nNew 2D window will open a new 2D window.\\nNew 3D window will open a new 3D window.\\nNew function window will open a new Function window.\\nNew histogram window will open a new Histogram window.\\nNew interpretation window will open a new interpretation window.\\nNew intersection Window will open a new Intersection window.\\nNew map window will open a new Map window.\\nNew plot window inserts an empty plot window. Should be used together with the New\\nObject in Window and New Object on Viewport icons in the top toolbar.\\nNew stereonet window inserts a stereonet window for dip/azimuth related data.\\nNew well section window will open a new Well Section window.\\nNew tornado plot window will open a Tornado plot related to Case and Result data generated\\nthrough Volumetrics or Uncertainty runs.\\nClear all visualizations will clear the active window.\\nClose window will close the currently active window.\\nNext and Previous options give the possibility to move from one active Display window to\\nthe next.\\nCascade arranges the windows on top of each other but with all Display windows visible.\\nTile Horizontal places all Display windows over each other horizontally.\\nTile Vertical places them next to each other vertically.\\nArrange Icons will arrange iconized Display windows at the bottom of the Display window area.\\nIt is not recommended to have many windows with objects visualized open at the same time. This\\ncan slow down the 3D visualization as they are dynamic. Display windows that are not in use\\nshould be closed for optimal use of Petrel.\\nHelp pull-down menu\\nManual (HTML help) opens the Online manual in a compiled HTML format. You need a recent\\nversion of MS Internet Explorer to run this. The shortcut key is F1.\\nRelease notes opens the Release Notes for the current Petrel version in a compiled HTML\\nformat.\\nPetrel Workflow Tools home page opens the home page in an Internet browser (if\\navailable).\\nSystem info opens the Microsoft System Information.\\nLicense status gives information about the license status and available modules.\\nLicense packages opens a window where it's possible to choose different license packages.\\nCheck for Software Updates takes you to the Petrel download site.\\nList of available Formats list all formats in Petrel; and whether they can be imported and/or\\nexported.\\nAbout Petrel gives information about the currently active version and build date of Petrel.\"},\n",
       " {'header': 'The Explorer Panes ',\n",
       "  'content': 'The Explorer panes consist of eight panes for different types of data,\\nInput - imported data such as lines, points, gridded surfaces and SEG-Y data is stored\\nhere. Output data of the same kind is put here as well, for example, if a set of internally\\nmodeled faults are converted to polygons, the generated polygons will automatically be put\\nhere.\\nModels - internally created data connected with a 3D model (such as faults, trends and 3D\\ngrids) is stored here. Imported grids (3D models or parts of models) and properties will also\\nbe put here. Velocity models and Discrete fracture network models are also stored here.\\nResults - the numerical results of volume calculations and simulations are stored in this\\npane, such that they can be browsed and any reports made.\\nTemplates - color tables for continuous, discrete and seismic property templates, in\\naddition to datums and well section templates are stored under this pane.\\nProcesses - show the list of available processes in Petrel.\\nCases - shows the actual cases related to simulation and volumetrics results.\\nWorkflows - stores results from the Workflow editor and Uncertainty and optimization\\nprocess in Petrel. In addition it holds a folder with predefined variables.\\nWindows - stores all opened and active plots and windows used in the Petrel project. In\\naddition it holds the Light sources and the Cursor tracker.\\nSelecting data in the panes\\nTo select a folder or file in the Petrel Explorer, click on it. The item will be surrounded by a blue\\nbox. Objects that can be edited (for example, well tops, faults, horizons) also become bold when\\nthey are selected.\\nExample: If a fault is bold, in the faults folder in a model, and new Key Pillars are digitized,\\nthese Key Pillars will be added to the fault that is selected.\\nExample: If one 3D Model (of several) is bold in the Models pane, this selected model is the\\none that will be affected if, for example, the Make Horizon process is run.\\nCustomize toolbars and menus\\nCustomize a toolbar\\nIt is possible to customize the toolbar, menu bar and menus by right-clicking on the grey area\\nwithin the toolbar or the Menu bar. A right-click menu becomes available. Here the user can\\nchoose to lock all toolbars so they cannot be moved around within Petrels interface, or the user\\ncan choose the option to Customize :\\nA new dialog window opens:\\nIn the Toolbars tab, click new and a small dialog window opens:\\nNew Toolbar: Here the user can set a user defined name for the new toolbar and in the lower\\npull-down menu, the user can specify the location of the new toolbar. There are 5 options:\\nDocked top\\nDocked bottom'},\n",
       " {'header': 'Docked Left ', 'content': 'Docked right'},\n",
       " {'header': 'Floating ',\n",
       "  'content': 'Click OK . The new user defined tool bar will now be located as a floating toolbar in the display\\nwindow, but it is empty and contains no tools. right-click the new empty toolbar and choose\\nCustomize . Go to the Commands tab within the dialog window and click the button named'},\n",
       " {'header': 'Rearrange Commands . ',\n",
       "  'content': 'A new window opens for adding commands to the empty toolbar. Make sure Toolbar is toggled\\non, and then choose the correct toolbar (in this example: Ultra Toolbar1). Click the Add button. A\\nwindow called Add command opens. Here you can choose which tools to include from the menu\\nand then click OK . Close the dialog windows and find the new toolbar with the new tool located\\nfloating in the display window. This toolbar can be edited by right-clicking it and choosing\\nCustomize . The toolbar can be dragged and dropped to new locations in the menu bar, function\\nbar and the lower bar of the Petrel interface. The new user defined toolbar will not be saved with\\nthe project, and must be recreated during the next launch of Petrel.\\nCustomize a menu\\nIt is possible to edit the different menus of Petrel. Right-click on the grey field of the function bar\\nor the menu bar and choose Customize :\\nGo to the Commands tab in the Customize dialog window. Click the Rearrange commands\\nbutton. A new window opens:\\nWithin the Rearrange Commands window, toggle on Menu Bar and from the pull-down menu,\\nselect which menu to edit (in this case the Edit menu). The dialog window shows how this menu\\nlooks at the moment. By clicking Add, the user can add Petrel tools from a pull-down menu and\\nadd this into the current Edit menu (or other menus). As default, newly added tools are located at\\nthe top of the menu. By using the Move up and the Move down buttons the new tools can be\\nmoved within the menu by the user. When the user closes the dialog windows for customizing the\\nmenus, the new tools can be found by going into the menu that was customized.\\nThe customized menu now has the original tools within the menu, but also user defined tools\\nlocated at the top of the menu. The new user defined menus will not be saved with the project,\\nand must be recreated during the next launch of Petrel.\\nMouse button functions\\nThe command Click that is frequently referred to throughout the documentation, generally\\nmeans one click with the left mouse button. The mouse buttons are assigned different functions in\\nthe specific windows.\\nWhen the pointer is in Select/Pick mode in the Display window, it can be toggled temporarily\\nto View mode by holding down the Alt key. The Esc key functions as a switch between the\\ntwo.\\nIf a tool is selected from the Function bar, the toggle will be between this tool and the View'},\n",
       " {'header': 'Mode. ',\n",
       "  'content': 'Display window 3D (pointer in View mode)\\nLeft mouse button to rotate the view.\\nLeft mouse button and the Ctrl key to pan the view.\\nLeft mouse button and the Ctrl+Shift keys for zooming.\\nRight mouse button to open a menu for graphical settings.\\nDisplay window 2D (pointer in View mode)\\nLeft mouse button for zooming.\\nLeft mouse button and the Ctrl key to pan the view.\\nLeft mouse button and the Ctrl+Shift keys for rotating the view around the center point.\\nRight mouse button to open a menu for graphical settings.\\nPlot windows - except for Well Section window\\n(pointer in View mode) & Viewport (except for\\nHistogram window)\\nLeft mouse button to pan the view.\\nLeft mouse button and the Ctrl+Shift keys to zoom. Zoom in X by moving up and down;\\nzoom in Y by moving left and right.\\nViewport edges (only if axis is displayed)\\nLeft mouse button to move the edge.\\nLeft mouse button and the Ctrl key to pan the viewport.\\nLeft mouse button to move the corner.\\nLeft mouse button and the Ctrl key to move the corner without changing the width/height\\nrelationship.\\nVisual objects\\nLeft mouse button to move the object.\\nWell Section window (pointer in View mode)\\nLeft mouse button to select.\\nExplorer panes\\nSimilar functionality to Windows Explorer. Data is stored in folders and sub folders.\\nLeft mouse button to open/close folders and to drag icons into a new folder. Also to switch\\non displays of data objects in the active Display window.\\nRight mouse button to open a menu for settings and operations on the selected data icon.\\nThe Processes pane\\nLeft mouse button to select a process step. Note that for the selected process step, a row of\\nicons will appear in Function bar with functionality only relevant for that specific process.\\nRight mouse button to access a pull-down menu with hide, floating and Auto hide in Main\\nWindow option.\\nDisplay window pointer\\nThe user can change between Viewing Mode and Select/Pick Mode in the display\\nwindow by clicking on the two icons. The Select/Pick Mode is generally used for all types of editing\\noperations in the display window, while the Viewing Mode allows the user to rotate and move\\nobjects around in the display window.\\nHowever, the easiest way to change between the two modes is to press the Esc key. This will\\nchange the selection to the previously selected tool.\\nShortcut Keys in Petrel\\nThere are a number of shortcut keys in Petrel. The shortcut keys allow the user to increase speed\\nand efficiency in their daily work. Some of them are process restricted and will be available only\\nwhen certain process steps are active.\\nShortcut keys related to Microsoft Windows:\\nF3 sets focus to Work area\\nPress ALT and TAB to switch between applications open in Windows.\\nCTRL and ESC will open the Windows Start menu.\\nTAB will move between edit boxes in an open menu.\\nArrow keys\\nThe arrow keys on the keyboard can be used to move data around in the Display window. If\\nnothing has been selected in the Display window, the arrow keys will move the camera, i.e. the\\nposition from which you are moving the data.\\nIf you select a point, a Shape Point in the Display window, the arrow keys and the Page Up and\\nDown will move the selected point. Go to the Project pull-down menu (in the Menu bar), select\\nProject Settings and go to the Settings 1 tab - here the translation increment can be changed.\\nShortcut keys in the Menu bar\\nThe different menus can be opened by clicking on them or by using ALT and the underlined letter\\nin the name, for example, ALT and F to open the File menu.\\nTo select something from an open menu, either click on it, or type the letter underscored in the\\nselection you want, e.g. O for opening a project from the File menu.\\nOpening a Project:\\nCTRL and N will start a new project.\\nCTRL and O will open an existing project.\\nCTRL and open project from project link will open a project with no windows.\\nCTRL and open project will open a project with no windows.\\nCTRL and double-click on project in file browser will open a project with no windows.\\nCTRL and single-click on project in file browser + Open will open a project with no\\nwindows.\\nOther shortcuts:\\nCTRL and I will import a selected data file and place it at the bottom of the Input pane.\\nCTRL and M will open the Reference project tool.\\nCTRL and S will save the current project.\\nCTRL and E to export selected files (files selected in the Explorer panes).\\nCTRL and P to print what is displayed in the Display Window.\\nCTRL and Z will undo the last editing action in process steps such as Fault Modeling,\\nSeismic interpretation, etc.\\nCTRL and Y will redo the last editing action in process steps such as Seismic interpretation,\\netc.\\nCTRL and X will cut the active (selected) item in the Explorer panes.\\nCTRL and C will copy the active (selected) item in the Explorer panes.\\nCTRL and V will paste a previously Cut or Copied item in the active (selected) folder in the\\nExplorer panes. If a folder is not selected, the item will be pasted at the bottom of the\\nExplorer pane.\\nDelete will delete an object selected in Petrel Explorer or in the Display window.\\nCTRL and A will select all items in the Display window, e.g. all polygons if a file with\\npolygons is displayed (in Select/Pick Mode).\\nF1 opens the Online manual in windows format for explanation and examples.\\nF11 View full screen (of the active window in Petrel).\\nShortcut keys related to the Explorer panes\\nMinus key or Left arrow key collapses the selected icon\\nPlus key or the Right arrow key expand the selected icon\\nCTRL and Up selects previous sibling\\nCTRL and Down selects next sibling\\nSpace bar toggles selected icon (visualize)\\nEnter activates objects and folders\\nALT and Enter opens Settings dialog for highlighted object or item\\nMenu key opens context menu of the activated object or folder. To close, hit Esc\\nF2 (or two single mouse clicks) for renaming active object or folder\\nCTRL and T activates the Input pane\\nCTRL and L activates the Models pane\\nCTRL and R activates the Processes pane\\nShortcut keys related to the Display window\\nSee also the shortcut keys related to the Menu bar.\\nV switches to Viewing Mode\\nZ activates the Magnify tool (only in orthogonal 3D view and in a 2D window.\\nP activates the Select/Pick Mode .\\nEsc toggles between Viewing Mode and last selected action in 2D and 3D windows.\\nSHIFT and Esc toggles between Viewing Mode and Select/Pick Mode in 2D and\\n3D windows.\\nArrows on the keyboard will scroll the view of an item in the Display window (in Viewing'},\n",
       " {'header': 'Mode). ',\n",
       "  'content': 'Home will bring the displayed item back to home position if the Set Home Position\\ntool has been used.\\nS activates the Target Zoom tool (works in Viewing Mode in a 3D window).\\nCTRL and U activates the View all option; centers all data in the middle of the display\\nwindow.\\nCTRL and J activates the selected Map view position.\\nCTRL and Tab opens a short cut menu for panes and open display windows in Petrel.\\nShortcut keys related to the Intersection\\nThere are some additional shortcut keys for the General Intersection. The plane must be active\\n(bold), displayed, the Manipulate Plane icon must be active and the cursor must be in'},\n",
       " {'header': 'Select/Pick Mode . ',\n",
       "  'content': 'M activates the Manipulate Plane tool.\\nD activates the Measure Distance tool.\\nCTRL and B toggles the Toggle Visualization on Plane tool.\\nArrows left and right will turn the plane around vertically with a constant tilt. Note that\\nthe plane cannot move if it is aligned North to South or East to West.\\nArrows up and down will change the tilt of the plane. The alignment will be kept constant.\\nNote that the plane cannot be tilted if it is aligned vertically or horizontally.\\nPage Up and Down will move the plane along its normal.\\nShortcut Keys related to Make/Edit Polygons\\nN to start a New Polygon .\\nSHIFT and P to Show Points in polygons\\nP activates the Select/Pick Mode .\\nE to Select and Edit/Add Points\\nB to activate the Bounding Box Select tool (2D window only).\\nShortcut Keys related to Well Correlation\\nA to activate the Paint discrete log class .\\nF to activate the Flood discrete log class .\\nSHIFT and S to Pick up discrete log class .\\nL to activate Create/Edit continuous logs .\\nSHIFT and C to activate Create/Edit Comment log .\\nShortcut Keys related to Make/Edit Well Tops\\nT to activate Create/Edit Well Tops tool.\\nN to Add New Well Tops Surface .\\nShortcut keys related to Seismic Interpretation\\nSince the seismic interpretation is performed on an intersection, the shortcut keys for General\\nIntersection will also function in the Seismic Interpretation process step.\\nB - to activate the Bounding Box Select tool.\\nSHIFT and B - to activate the Selection Paintbrush tool (All windows)\\nDel - to delete selection.\\nP - activates the Select/Pick Mode .\\nX - to activate eraser mode.\\n(+) / (-) - increase / decrease the size of the eraser (when active)\\nPgUp / PgDn - Move the active seismic section by a given increment (All windows)\\nSHIFT and S - Activates fault or horizon (All windows)\\nF - Fault interpretation (All windows)\\nN - New Fault stick/interpretation (All windows)\\nH - Horizon Interpretation (All windows)\\nU - to set manual drawing mode .\\nA - to set 2D seeded autotracking mode .\\nSHIFT and A - to set 3D seeded autotracking mode .\\nG - to set 2D guided autotracking mode .\\nR - to set paintbrush autotracking mode (2D window only).\\nSHIFT and R - to set active box autotracking mode (2D window only).\\nY - select parent points (3D window).\\nSHIFT and Y - select child points (3d window).\\nZ - Zoom (Interpretation window).\\nCTRL and Z will undo the last editing action.\\nCTRL and Y will redo the last editing action.\\nSHIFT and Z will unmagnify (only if magnifier has been used in the Interpretation\\nwindow.\\n(+) / (-) - Zoom in/out (Interpretation window).\\nL - Select Inline Intersection (Base map and 3D windows).\\nSHIFT and L - Select Crossline Intersection (Base map and 3D windows).\\nK - Select any visible line, i.e. inline, crossline, general vertical intersection or 2d line\\n(Base map and 3D windows) or redisplay previous intersection (Interpretation window).\\nSHIFT and K - redisplay next intersection (Interpretation window).\\nC - Create Arbitrary Polyline Intersection (Base map and 3D windows).\\nSHIFT and C - Create Seismic Aligned Polyline Intersection (Base map and 3D\\nwindows).\\nO - select composite selection (Base map and 3D windows) or compose with intersecting\\nline (Interpretation window).\\nW - draw arbitrary composite intersections (Base map and 3D windows).\\nSHIFT and W - draw aligned composite sections (Base map and 3D windows).\\nI - compose with inline (Interpretation window).\\nSHIFT and I - compose with crossline (Interpretation window).\\nQ - clip and extend composite (Interpretation window).\\nShortcut Keys related to Pillar Gridding\\nSHIFT and A activates the Set Arbitrary Direction tool.\\nSHIFT and B activates the Set Part of Grid Boundary tool.\\nSHIFT and I activates the Set I-Direction tool.\\nSHIFT and J activates the Set J-Direction tool.\\nN activates the Set Number of Cells for the Selected Connection tool.\\nB activates the Create External Grid Boundary tool.\\nI activates the New I-Trend tool.\\nJ activates the New J-Trend tool.\\nSHIFT and P activates the Show Points in Polygons tool.\\nShortcut Keys related to Facies Modeling\\nL activates Pencil tool .\\nB activates 3D Brush tool .\\nA activates Airbrush tool .\\nF activates Fill Selected Facies Code tool .\\nSHIFT and S activates Adapt facies code from Image tool .\\nShortcut Keys related to Workflow editor\\nCTRL and W will open the active workflow.\\nMulti selection\\nMulti-selection is enabled in the Petrel Explorer.\\nHold the Ctrl key while clicking an icon to add that single icon to the selection. Press SHIFT while\\nclicking an icon to select all icons between the two selections. With an icon selected, press SHIFT\\nand use the up and down arrow keys to extend the selection.\\nThe following operations can be performed on a multi selection:'},\n",
       " {'header': 'Delete ',\n",
       "  'content': 'Cut, Copy and Paste\\nDrag and Drop (be sure to drag the last icon added to the selection!)\\nVisualization toggle (press SHIFT to toggle the clicked icon only)\\nNote: A warning will be issued if a Cut or Copy operation will overwrite data that is already\\non the Petrel clipboard.'},\n",
       " {'header': 'Project Administration ',\n",
       "  'content': 'The file menu contains several options of administrating your projects (import, export, open,\\nmake a new project, database options, save, clean project directory, print) :\\nHow to merge/copy projects\\nData can be copied between Petrel projects, see Reference Project Tool.\\nSaving a project\\nWhen the project is saved, the data is stored in a project file. Use the option File> Save Project\\nAs from the Menu bar the first time you save a project. The default project file extension is *.pet.\\nA Petrel project contains all imported and generated data, as well as all dialog settings and\\ngraphical settings. Opening a Petrel project will bring back the exact status of the project as it\\nwas last saved.\\nThere is no default automatic save in Petrel, so all users are recommended to save their project\\nregularly when working with it. Use File: Save Project from the Menu bar, Ctrl+S or click on the\\nSave Project icon to do this.\\nWhen saving a project, a file and a folder are created. The file is called <project name>.pet and\\ncontains a list of pointers to all the data. The folder is called <project name>.ptd and contains the\\ndata. This organization ensures an optimal performance of the memory handling which is\\nimportant when working with large data sets.'},\n",
       " {'header': 'Automatic Save ',\n",
       "  'content': 'The automatic save option in Petrel is available under the project settings (choose Project,\\nProject settings from the main toolbar); a shortcut to this can be found under File, Automatic\\nSave on the main toolbar. AutoSave can be turned on by checking the Auto-save every option\\nand setting the Minutes to the desired period. At the requested interval a dialog will appear\\nasking the user if they wish to save. Checking Silent auto-save will save the project without\\nasking the user.\\nNote: Automatic Save will save the project overwriting the current saved version. You\\nwill not be able to revert to your original saved version in the event of incorporating errors in the\\nmodel. Automatic Save must be used with caution.'},\n",
       " {'header': 'Clean Project Directory ',\n",
       "  'content': 'In the Project menu pull-down list, there is an option called Clean Project Directory.\\nClean Project Directory will prompt the user to delete any orphaned data sets that are detected.\\nOrphaned data sets are data sets on disk that are not referenced by any simulation case in the\\nCases pane. They can arise from runs/exports of cases, or case renames where the project is not\\nsubsequently saved. For each simulation case in the Cases pane the status of, and path to, the\\n\".DATA\" file is shown in the simulation Settings dialog, Info tab.\\nGlobally Unique Identifiable objects in Petrel'},\n",
       " {'header': '(GUID) ',\n",
       "  'content': 'Objects in a Petrel project are uniquely identifiable across projects. The GUID will be preserved\\nwhen using the Save Project As option in the File menu. An object copied from a reference\\nproject to the primary project will also retain its unique ID. If the object already exists in the\\nprimary project,the transferred object will replace the existing object. When making a copy of\\nobjects, a new unique ID will be generated.\\nRunning Petrel from a command line\\nPetrel can be launched (and shut down) from the command line and can be incorporated into\\nbatch workflows. You can specify a workflow to run and set values for the variables in that\\nworkflow. The results can be exported from the workflow by saving the workflow output sheet to\\ndisk. It is also possible to specify a custom method to execute tasks that do not require user\\ninteraction, for instance fetching data from Petrel, performing computation, and storing data back\\nto Petrel. Ocean plug-ins can specify their own command line variables but need to follow the\\n[s/n]option syntax below.\\nIt may be desirable to set up a default project environment for a set of Petrel users or a user\\ncommunity. For example, an asset team or department may like to share a project template that\\nall Petrel users can share. This can include projection system information, color templates and\\nfolder administration.\\nCommand line syntax\\npetrel [/exec assemblyName methodName] [/runWorkflow myworkflowname|/runAllWorkflows]\\n[/exit] [/quiet] [/[s|n]parm myvar1=9,myvar2=3] [-[s|n]option mymodule.myvar=2,\\ntheirmodule.myvar=3] /nosplashscreen /SelectLicense /licensePackage package\\nd:\\\\work\\\\myprojectfile.pet\\n/exec - will run the named method of the named assembly\\n/runWorkflow - will run the named workflow in the named project\\n/runAllWorkflows - will run all workflows in the named project\\n/[s|n]parm - pass variables to the workflow (s for string, n for numerical)\\n/[s|n]option \"assembly=var=parm\" - Syntax for variables handled by Ocean plug-in\\'s. Note the\\nuse of quotes to allow spaces.\\n/exit - terminates Petrel after running workflow\\n/quiet - runs the workflows without launching the workflow window\\n/nosplashscreen - disable splash screen on startup only\\n/SelectLicense - show the licensing dialogs on startup.\\n/licensePackage package - name of the license package that you want to check out without being\\nasked\\nHow to generate and share a project template\\n1. Open a new Petrel project and set the projection system information, color templates,\\nfolder structures, window setups, variable values, etc. desired for the target Petrel user\\ncommunity\\n2. Save the project to a shared area.\\n3. Make a batch file that launches the application with the new default project parameters.\\nExample text: \"C:\\\\Program Files\\\\Schlumberger\\\\Petrel 2007\\\\Petrel 2007.exe\"\\n\"D:\\\\Petrel\\\\Template.pet\"\\n4. Save the batch file and distribute it to the target user community.'},\n",
       " {'header': 'Basics Overview ',\n",
       "  'content': 'This chapter contains generic information about the use of Petrel. It cover general information\\nabout Visualization of objects, windows and settings in addition to data processing.\\nTools related to data management like import, export and reference project tool is also covered.\\nSpatial enablement'},\n",
       " {'header': 'Introduction ',\n",
       "  'content': 'Petrel 2010.1 is the first release from the Petrel Spatial project. This first release will enable\\ncartographic transforms and conversion of data on import, export, and through the Reference\\nproject tool. It will not support all data items, mainly lattice data such surfaces and 3D seismic,\\nwhich is planned to come in future releases. It is not mandatory to use this new functionality, it\\nwill be still possible to select a Null CRS which will disable this functionality and Petrel will\\nperform like pre-Petrel 2010.1.\\nThe following data items will be supported in Petrel 2010.1 for coordinate conversion:\\nPoints (Points with attributes)'},\n",
       " {'header': 'Polygons ',\n",
       "  'content': '2D seismic lines\\n2D seismic interpretation'},\n",
       " {'header': 'Faults ',\n",
       "  'content': \"Well data (Well head, Deviation surveys (Grid, True north), Markers, Well point data)\\nSurface images (for RPT)\\nPetrel will be using the ESRI cartographic engine to perform these conversion. Petrel will only\\nsupport Early bound coordinate reference systems. Petrel will also provide an external\\napplication to manage the catalog. This tool is will use Well Known Text (WKT) to define the\\ncoordinate system.\\nSpatial enablement also introduces latitude and longitude support for read-outs, statistics, and\\nalso maps with latitude and longitude lines.\\nProject upgrades\\nPrior to upgrading to Petrel 2010.1, it is advisable to check your current Petrel projects for data\\nconsistency and create your company's spatial infrastructure. The spatial infrastructure includes\\ncustomizing the spatial catalog and designing spatial workflows.\\nThings to consider before upgrading your projects to Petrel 2010.1:\\nThere are seven Petrel project CRS states in previous version of Petrel. Most of them will be\\nautomatically upgraded with no user intervention; however, some require you to select a valid\\nCRS or connect to OSP to complete the project upgrade process. Details can be found in the\\nfollowing table:\\nImporting data\\nIt is possible to perform a coordinate conversion of supported data items on import. You must\\nhave the project CRS set to a valid CRS (not Null) to enable the coordinate selection section of\\nthe import dialog. You also need to know the CRS of the file you choose to import.\\nExample 1 - Importing a polygon in a project with a CRS set\\n1. Right-click and select Import on selection .\\n2. Select the file and file format.\\n3. The import dialog opens. Select the File CRS .\\n4. Select the CRS from the drop-down list (if the CRS has been used in the project before) or\\nselect Other CRS to launch the Coordinate Catalog .\\n4.\\n5. Select the CRS from the catalog. It will now appear in the File CRS drop-down list.\\n5.\\n6. Click OK to import the file and perform the CRS transform.\\nOnce the data has been imported into Petrel, the History of the conversion will be captured and\\nthe data item will be stamped with the original CRS in the Info tab of the item.\\nExample 2 - Importing a well Deviation survey\\n1. Right-click on the well and select Import on selection . Select Well path/deviation and the\\nfile.\\n2. Select input as MD, INCL, AZI and specify the input columns.\\n3. Click on the Coordinates and units tab.\\n4. Specify the deviation CRS from the drop-down or by selecting one from the catalog.\\n5. Also select the azimuth reference, either True north or Grid north .\\n6. Click OK to import the deviation survey.\"},\n",
       " {'header': 'Reference Project Tool ',\n",
       "  'content': 'The Reference project tool will support coordinate conversion of supported data items. This\\nopens the door for companies to minimize data duplication by creating a set of spatial aware\\nmaster project where the user transfers data into their working project in a different CRS.\\nWhen there is a CRS mismatch between the working project and the background project, the RPT\\ndata trees are filtered so the user can only transfer and coordinate convert supported data.\\nWhen there is a CRS mismatch, the following warning will open up warning the user that only\\nspatially supported data items will displayed in the RPT.\\nExport of data\\nYou can coordinate convert data on export.\\nExample of exporting a fault:\\n1. Right-click on the fault and select Export.\\n2. Select the format and the file name.\\n3. Specify the coordinate system you want to export to and click OK.\\nThe file will be exported to the selected CRS.\\nLatitude and longitude support\\nIn a spatially aware project this will enable the latitude and longitude support for:\\nCustomize the datum from the project settings window to WGS 84 and select between\\nDegrees-minutes-seconds (DMS) or Decimal degrees (DD) for the display of latitude\\nand longitude data'},\n",
       " {'header': 'Readouts ',\n",
       "  'content': 'When you are in Pick mode , it is possible to have latitude and longitude readouts.\\nExample of a readout:\\nStatistics will now have latitude and longitude readouts:\\nMap gridlines\\nPrinciples of Geomodeling\\nGeological models are created for different purposes, but common to all of them is the desire to\\nbuild a representation of the subsurface. Depending on the purpose, different aspects of the\\nmodel can be important.\\nIn the case of a regional exploration model, the shape of the structures may be the most\\nimportant aspect. Geological models can be used to achieve accurate volume calculations or to\\ntest the effect of different depositional regimes against observed data. With simulation models,\\nthe size and complexity can be the limiting factor for achieving a model that has a good history\\nmatch.\\nPetrel uses a 3D grid to supply the building blocks for the user to create representations of reality.'},\n",
       " {'header': '3D Grid Concept ',\n",
       "  'content': \"In simple terms, a 3D grid divides a model into boxes. Each box is called a grid cell and will have a\\nsingle rock type, one value of porosity, one value of water saturation, etc. These are referred to\\nas the cell's properties. This is a simplification of the true case, but allows us to generate a\\nrepresentation of reality that can be used in calculations, etc.\\nGrid resolution\\nThe resolution of the grid will be a key decision when building the model. A high resolution grid\\n(many cells) will allow the modeler to create great spatial complexity, but will result in a model\\nwhich has many cells and might be cumbersome to use with each process taking a long time. A\\nlower resolution grid will have less scope for complexity, but will be quick to work with and will\\nallow the user to test many possibilities quickly.\\nThe decision will depend on the purpose of the model, the detail and amount of data available.\\nThere is little point in creating a model with higher resolution horizontally or vertically than the\\ndata available for modeling. It is often wise to begin with a coarse model, testing the effects of\\nchanges and then increase the resolution as parameters become more certain.\"},\n",
       " {'header': 'Grid Structure ',\n",
       "  'content': 'The inclusion or exclusion of faults is another key decision in the model building process. When\\ndealing with simulation, the faults may be critical as flow barriers or conduits and could be the key\\ncontrol on results. For volume calculations they may also be important in defining the geometry of\\nthe reservoir, however, including faults requires a number of decisions to be made regarding their\\ninclusion in the grid and will increase the time taken to create the model.\\nOnce faults are included there is also the question of where to stop. Including every discontinuity\\nin the model would make it unmanageable, and at some point fractures are better modeled as\\nmodified properties as opposed to breaks in structure.\\n3D Grids in Petrel\\n3D grids are created in the Corner point gridding or Structural framework modeling processes and\\nappear on the Models tab. A 3D grid represents one version of the reservoir geometry but it can\\ncontain as many different properties as required. For example, it may have 5 different porosity\\nproperty models, each representing a different interpretation of the reservoir quality.'},\n",
       " {'header': 'Case Concept ',\n",
       "  'content': 'A case is a single, consistent representation of reality.\\nDuring the process of modeling the reservoir, several 3D grids may be created with different\\ntreatments of the faults and horizons. Within those grids there may be several versions of a\\nproperty model and contacts, and there may be several representations of the fluids within the\\nmodel.\\nWhen a volume calculation or a simulation is performed on the grid, a single set of parameters\\nmust be chosen; one 3D grid with a single set of consistent horizons, a set of properties (like\\nporosity), and an analysis method (a specific simulator, or Volumetric analysis). This is considered\\nto be a case.\\nA single case is either a volume calculation or a simulation using any of the supported simulators.\\nCreating a volume calculation which uses 2 different porosities will require two different\\nVolumetric cases.\\nOnce a case has been created, it will appear on the Cases pane and this will act as a filter for\\nviewing volume and simulation results. The type of results available will be displayed on the\\nResults pane.\\nCases in practice\\nEach case appears as an item on the Cases pane. Whenever a new simulation or volume\\ncalculation is run, a new item is created on the Cases pane.\\nCases are created using the \"Volume calculation\" process or the \"Define simulation case\" process;\\nsee Volume Calculation Process dialog and Define simulation case.\\nCases pane\\nThe Cases pane shows the simulation cases produced when running simulation cases as set up in\\nDefining a simulation case. Each simulation case represents a different experiment based on a\\nunique set of inputs.\\nSimulation cases that have been defined with no specified keywords are shown in bold.\\nWithin the Cases pane you can:\\nExpand a case folder.\\nCollapse a case folder.\\nInsert a new case.\\nView settings for a case.\\nDelete a case.\\nInsert simulator keywords.\\nImport an existing deck.\\nOpen the keyword editor.\\nView simulator messages.\\nRun a simulation.\\nExport simulation keywords.\\nDelete a simulation case.\\nHow to expand a case folder\\nYou can use any of three methods to expand a collapsed case folder:\\nClick the + icon to the left of the case folder.\\nRight-click the folder and select the Expand (Recursive) option.\\nDouble-click the case folder.\\nHow to collapse a case folder\\nYou can use any of three methods to collapse an expanded case folder:\\nClick the - icon to the left of the case folder.\\nRight-click the folder and select the Collapse (Recursive) option.\\nDouble-click the case folder.\\nHow to insert a new case\\nTo insert a new case:\\nMake a new case in the Volume calculation process.\\nMake a new case in the Define simulation case process.\\nTo rename the case folder, right-click the case folder and select Settings. Enter the new\\nname into the Name field under Info tab and click OK. Alternatively, rename directly by\\nchecking Rename node directly (mouse) in Tools > System Settings > Effects tab.\\nHow to rename a case\\nTo rename a case, right-click the case node and select Settings. Enter the new name into\\nthe Name field in the Info tab and click OK.\\nIf the case is a simulation case and has been exported, there will be an underlying project\\nfolder on the disk.\\nThe new case name is not yet propagated to the underlying folder, So, after the rename,\\nthe name of the project folder might not be the same as the name of the case.\\nWhen this happens, the name of the case will be decorated with the name of the project\\nfolder and displayed in RED.\\nCases that have been renamed cannot be used as base cases for restart or sector modelling\\ncases until the project has been saved.\\nWhen the Petrel project is saved, the underlying folder names are synchronized with the\\nproject names, and the name is then displayed in the usual BLACK text.\\nFigure 1. Rename from \\'Case\\' to \\'Base-case\\', showing the new case name and the underlying\\nsimulation project folder name\\nHow to view settings for a case\\nTo view the settings of a case, right-click the case folder and select the Settings option. This\\ndisplays the Settings dialog, which has two tabs labeled Info and Definition.\\nThe Info tab shows the name of the case and has a field into which you can enter comments as\\nfree text. The Definition tab shows all the parameters entered when the simulation case was\\ndefined. You cannot change the parameters in this dialog.\\nHow to delete a case\\nTo delete a case folder:\\n1. Right-click the case folder.\\n2. Select the Delete option.\\n3. Click Yes button.\\nHow to make a new simulation in an existing Case\\n1. Double-click on the Define Simulation Case.\\n2. Select Edit existing case and choose the Case you want to edit from the drop-down menu.\\n3. Now you can select Simulator type and 3D Grid type.\\n4. Right-click anywhere in the Cases pane.\\nHow to import an existing deck\\n1. Select the Import (on tree) option. This will open the Import File dialog.\\n2. Select the data file to be imported and the related format.\\n3. In the next dialog, specify the target simulator of the selected data file. If other related files\\n(such as .GRID, .INIT, .SMSPEC, etc) are found, these will also be shown in the dialog and\\nwill be selected for loading. Deselect the corresponding check box in order to request that a\\nfile not be loaded.\\nHow to open the keyword editor\\n1. Right-click the simulation under a Case for which you want to edit the keywords.\\n2. Select the Editor option. This will open the keyword editor. For more information refer to\\nthe help for the appropriate simulator keywords.\\nHow to view simulator messages\\nYou can view messages generated by the simulator when the simulation is run:\\n1. Right-click the simulator type under a case in Cases pane.\\n2. Select \\'Show Simulation log...\\' for comments, warnings and messages reported during the\\nsimulation.\\n3. Select \\'Show print file...\\' to view everything reported in the DOS console during the\\nsimulation.\\nHow to run a simulation\\nIf you have defined a new Case, click the run button to run the simulation.\\nIf you have already run a simulation, but want to re-run it, right-click the simulation and select\\neither the Simulation Run Only or Simulation Export and Run option. The consistency of the\\ncase will be checked before the simulation runs.\\nHow to export simulation keywords\\nRight-click the simulation and select the Simulation Export Only or Simulation Export and\\nRun option. The consistency of the case will be checked before the keywords are exported.\\nHow to delete a simulation\\nTo delete a simulation:\\n1. Right-click the simulation.\\n2. Select the Delete option. This will display a message asking you to confirm the deletion.\\n3. Click the Yes button to delete the simulation.\\nWindows and Plotting\\nAll the available windows in Petrel can be opened and closed through the Window pull-down\\nmenu in the Menu bar. Once opened, the windows will appear in the Windows pane on the\\nprocess diagram and can be reopened at any time by checking the tickbox and ensuring that the\\nwindow is bold. Unchecking the tickbox will release the windows from memory, but the data will\\nstill be stored.\\nThe Map, Histogram, Function, Intersection, Stereonet and Well Section windows are also called\\nviewports and can be arranged in a plot window for WYSIWYG (what you see is what you get)\\nstyle printing. The well section and interpretation windows are also referred to as plot windows\\nwhile the 2D and 3D windows are called Graphic windows.\\nAt the top of each of the \"real world\" windows is a toggle to switch between the time and\\ndepth domains. Objects in the wrong domain cannot be displayed, and will instead show a grey\\ntick mark in the project explorer. Use if you wish to ensure that all objects are displayed.\\nGeneral window information\\nWhen starting Petrel, a 3D graphics window is opened. More graphical and plotting windows can\\nbe opened from the Window drop-down menu.\\nIt is recommended to minimize the number of open windows, with objects displayed, at any one\\ntime as they might slow the display. This can be done by removing the check box besides the\\nwindow in the Windows pane of the process diagram.\\nAs with all programs using the Windows interface, the active window can be maximized by clicking\\nthe icon in the upper right corner, while clicking the icon will restore your window to the\\nprevious scaling. The window can be minimized by clicking the icon. Open windows can be\\narranged by selecting the appropriate arrangement within the Window drop-down menu (tiled\\nvertically, tiled horizontally, or cascading).\\nCommon tools for all window types\\nAdjust color table on selected - Sets the depth color table, with maximum range, of a\\nselected object in the Petrel Explorer. If a folder with several objects is selected, the range will be\\nfrom maximum to minimum Z-values of all the objects within the folder.\\nNew Window - Opens a pull-down menu from which the user can select which type of new\\nwindow to open.\\nShow/Hide Auto Legend - Displays a color legend of the visible object(s). Click the arrow\\nnext to the legend to open the overall legend Settings window. Define the layout of the legends\\nhere. Depth and thickness color tables can also be defined here.\\nShow/Hide Axis - Toggle a box with axis in X-, Y-, and Z-direction. Click the arrow next to\\nthe legend to edit the axis Settings.\\nFind - Opens a new dialog box. Type in a text string to search for a match in the current Pane\\nor in the entire project.\\nDetails of the 2D and 3D Windows\\nThe 2D window and the 3D window represent the Graphic windows. In these windows, objects\\nimported or created can be visualized in 2D and 3D respectively. The user can switch between\\nView Mode and Select/Pick Mode in the graphic windows by pressing Escape.\\nThe user can also select the domain of the window TWT (Two way time), TVD (True vertical\\ndepth) or Any. If an object is not in the correct domain and has not been depth converted, then it\\nwill not be displayed and will have a grey tick mark. By choosing the Any option, all objects can\\nbe displayed.\\nWhen clicking the right mouse button on the cursor in a graphic window, a pull down menu\\nwill open. Here you can change the way objects are drawn in the Display window. If you have\\nproblems moving large objects in the window (i.e. they jump rather than moving smoothly),\\nselect the move low res option from the Draw style option. Note that the Spin Animation has\\nto be toggled on or off from the System Settings menu. It will then work for all windows. For\\nmore information about the System settings see System Settings.\\nTools for the 2 and 3D windows\\nHome Position - Move to the default view.\\nSet Home Position - Set the current view as the Home position.\\nView All - View the whole data set.\\nMap View Position - Positions the data set so that it is seen from the selected angle. The\\ndefault position is from above with North upwards. Select your preference from the pull-down list\\n(click on the arrow). The Keep focus icon (if selected) keeps the point of focus the same\\nwhen the data set is repositioned. Without this option checked, Petrel will zoom to fit all of the\\nvisible data to the screen.\\nTarget zoom - Click on the icon, and then click on the spot to zoom in on (in the Display\\nwindow). Note that multiple clicks before the selected point will be set as the new center of the\\nview. Zoom also by clicking the shortcut key S. The cursor must be in View mode and the\\nOrthogonal On/Off must be turned off to use this tool.\\nOrthogonal On/Off - Toggles the view of objects in the Display window between perspective\\nand orthogonal projections. Orthogonal projection will display objects with no vanishing points.\\nAnti Roll - Prevents the camera from rolling i.e. keeps the horizon horizontal when the data is\\nbeing moved around in the Display window.\\nCamera linking on/off - It is possible to create a group of 3D windows with shared camera\\nposition. Viewing settings inside the group will be synchronized: each change of camera position\\n(rotation, zooming, view all) in any \"linked\" window will be repeated for all windows in the group.\\nSet Z-scale - Changing this parameter gives a higher/lower relief on the data set. It is\\nunit sensitive, i.e. if XY are in meters and Z is in feet, a distance of 100 units will be approximately\\na third in Z to what it is in X or Y.\\nSet Z domain - Switches between time and depth.\\nShow/Hide Compass - Toggle for a compass arrow indicating viewing orientation of the data\\nset. Click on the arrow to open the Settings window where position and size of the compass may\\nbe defined. The arrow points towards North, and has a green top and a red base (e.g. a red arrow\\nindicates you are looking up from the base. The compass type can be changed to a different icon\\n(from the Settings window).\\nOpen windows settings for color/name - This is used to change the background color of\\nthe Display window. Use the Toggle background color and black to switch color.\\nToggle background color and black - This will toggle between the selected color and black\\nwhich is default.\\nThe Function bar on the right hand side of the Display window contains the important icons during\\nmost process steps:\\nViewing Mode - When this tool is active the cursor will be displayed as a hand in the Display\\nwindow. Press the left mouse button to rotate the view, holding the Ctrl key pans the view,\\nholding both Ctrl+Shift keys will zoom in and out.\\nMagnify (shortcut key Z) - Works in a 2D window and when orthogonal view is on in the 3D\\nwindow. Click on the icon, then click and drag in the Display window.\\nMeasure Distance (shortcut key D) - Will measure the 2D and the 3D distance between\\ntwo different points in the Display window. Click on the icon, and then click on a point (on an\\nobject) in the Display window. When dragging the cursor from that point, the distance is\\nmeasured and displayed interactively. The distance and direction will be given in project units.\\nSelect/Pick Mode - The cursor will become an arrow or a cross when this tool is active\\n(depending on process step active). It allows the user to select/edit objects in the Display\\nwindow. Press the Shift key to select more than one object.\\nArtificial Horizon - When this option is checked, an artificial horizon will be displayed\\nsomewhere in the Display window (depending on where the user sets it to be). The artificial\\nhorizon may help the user to get oriented when working in a 3D view.\\nThe Show/Hide Axis, Compass and Auto Legend options are also available in the Petrel\\nExplorer under the Windows pane. A more detailed description of the Settings windows of the\\ntools available in the Windows pane can be found in Settings for objects in the Windows pane.'},\n",
       " {'header': 'Plotting ',\n",
       "  'content': \"The plotting functionality in Petrel allows you to print to any plotter/printer with Windows drivers.\\nThe data is output as a Windows Metafile and can be fitted to any paper size supported by the\\nprinter/plotter. Plots appear on the screen exactly as they appear on the finished plot.\\nA plot window in Petrel can contain one or more viewports. There are several types of these 2D\\nviewers:\\nMap viewport: Used for generation of scaled plots (2D maps), and for display of\\nvariogram maps created in Petrel.\\nIntersection viewport: Used for generation of scaled plots of cross sections.\\nHistogram viewport: Used for display of histograms and cumulative distribution functions.\\nFunction viewport: Used for display of functions, cross plots, sample variograms and\\nvariogram models.\\nStereonet viewport: Used to display dip and strike data.\\nWell Section viewport: Used for display of well sections used in the well correlation\\nprocess.\\nWith plotters supporting multiple paper sizes (e.g. plotters), the paper size should be set\\nthrough printer setup before the plot is composed.\\nPlot windows\\nEach plot window can contain several viewports and each of these may have associated objects\\nsuch as a scale or a legend. The active viewport is indicated by a red border and can be switched\\nby clicking on a different viewport, or inserting a new viewport which will then become active.\\nDifferent types of viewports will have different tools available, and when switching between these,\\nthe toolbar will change. When a viewport is active, the items that can be displayed in the viewport\\nwill have a check box next to them in the Petrel explorer and checking it by clicking the box once\\nwill display the item in the viewport.\\nCreating plot windows\\nStandard plot windows can be created by choosing one of the options under Window in the main\\nmenu. These will have a single viewport and are scaled and positioned for immediate printing.\\nBlank plot windows can also be created with no viewports. In both cases, additional viewports can\\nbe added to the plots via the New Object in window button\\nClick on the required viewport from the list and draw the outline of the frame in the plot window.\\nThe new viewport will be inserted and appear as a new icon under the plot window in the Windows\\npane on the process diagram.\\nAnnotation in the form of labels, lines and rectangles, independent of the viewports, can be added\\nin the same way.\\nCreating multiple viewports\\nMultiple viewports can be managed and created via the Setup multiple viewports tab on the\\nplot window's settings dialog or via Create/align multiple viewports beneath the New Object\\nicon.\\nChoose the number of viewports to create and the number of columns and rows in the plot. If the\\nnumber of viewports exceeds the number of existing viewports, then the user has the option to\\nchoose the type of viewports to be added.\\nHow to create multiple viewports\\n1. Select New plot window from the window menu.\\n2. Select Create/Align Multiple Viewports from the new object menu.\\n3. Choose the number and type of viewports to insert.\\n4. Choose the number of rows and columns to align the viewports in.\\n5. Choose the separation between viewports and their measurement system, percentage or\\nmm.\"},\n",
       " {'header': '6. Press Setup Viewports. ',\n",
       "  'content': '7. Select each viewport in turn and choose the data to display.\\nHow to arrange existing viewports\\n1. Open the settings for the active plot window.\\n2. Choose the number of rows and columns for the viewports\\n3. Choose the separation between viewports and their measurement system, percentage or\\nmm.'},\n",
       " {'header': '4. Press Setup Viewports. ',\n",
       "  'content': 'Managing plot windows\\nPlot windows, as with any other window in Petrel, will appear on the Windows pane of the process\\ndiagram where the active window will appear in bold. The window frame and any viewports in the\\nplot window will appear as child icons beneath the window, which in turn will have scales and\\nlegends as their own child icons.\\nViewports can be copied and pasted within and between plot windows using the standard copy\\npaste operations.\\nClosing a window will remove it from view, however the window will remain defined and can be\\nredrawn at any time by simply rechecking it. To permanently remove a window, select it on the\\nWindows pane and press delete.\\nManipulating viewports\\nThe size and position of each viewport can be altered interactively or via the viewports settings.'},\n",
       " {'header': 'Interactively ',\n",
       "  'content': \"Use the selection tool and place the mouse over the viewport's edge. The position of the cursor on\\nthe axis will decide the type of movement allowed. This will be shown by the cursor.\\nCenter of each side - move the axis in or out.\\nCorner points - drag the corner of the axis to a new position. By pressing Shift during this\\noperation the ratio between the two axes will remain constant.\\nBetween corner and center of the axis - drag the whole viewport intact. By pressing Ctrl,\\ndrag mode will be selected irrespective of the position of the cursor.\\nDuring interactive editing of the viewport, the scale will remain constant and the center of\\nthe viewport will remain static relative to the four axes.\"},\n",
       " {'header': 'Via Settings ',\n",
       "  'content': 'Access the settings for the active viewport by pressing or by double-clicking on the viewport in\\nthe Windows pane. Type in the desired margins at each side of the viewport, either in mm or in\\npercentage points of the total paper size.\\nLinking viewports\\nViewports can be linked by three different methods:\\nCoordinate Groups - Similar windows can share scaling and positioning information such\\nthat panning or zooming the view in one window will pan and zoom the view in the other\\nwindow.\\nVisual Groups - Any windows can share display events so that displaying an object in one\\nwindow will automatically try to display it in all other windows in the group.\\nLinked Selections - Selections in one viewport will be automatically displayed in another\\nviewport in the same plot window (Function window only).'},\n",
       " {'header': 'Coordinate Viewport Groups ',\n",
       "  'content': 'Viewports with similar coordinate systems and those of the same type (two maps or two\\nintersections, etc) can be linked together enabling synchronized scrolling and panning of objects\\nin the same plot. Several viewport groups can be generated in the same plot. Linked viewports\\ncan be generated manually or automatically during Setup multiple viewports.\\nHow link viewports together manually\\n1. Select New Empty Plot Window from the window menu.\\n2. Drag the number and type of viewports to insert.\\n3. From the settings menu for each of the viewports you wish to link set Linked viewport\\ngroup to First.\\n4. Display a data item with similar coordinate systems in each of the viewports.\\n5. Scrolling and panning actions for each linked viewport will now be synchronized.\\n4.\\n5.'},\n",
       " {'header': 'Visual Viewport Groups ',\n",
       "  'content': 'Any windows can be linked to share display events. Once the windows are linked, then any object\\ndisplayed in one window will automatically also be displayed in the other, as long as that object is\\ncompatible with the second window.\\nThis is particularly useful when using a 2D view as a base map in seismic interpretation, but can\\njust as easily be used to tie a stereonet together with a 3D view for viewing borehole fracture\\ndata.\\nViewports are grouped via the visual group option on their settings panels. The default buttons\\nmake it easy to apply the settings to all the viewports in the project or all the viewports in a\\nparticular folder.\\nThe user have to distinguish between the option \"Linked to visual group: inherit\" and \"Linked to\\nvisual group: First, second e.g.\". If one or more existing viewports have been linked using the\\ninherit option and a new viewport not linked to any groups are inserted, any data displayed in the\\nnew unlinked viewport will appear in the existing old viewports. This since they inherit the settings\\nfrom the active viewport (the new one). To avoid this behavior the old viewports could be linked\\nusing First, second e.g. group.'},\n",
       " {'header': 'Linked Selections ',\n",
       "  'content': \"If multiple function viewports are displayed in the same window and common objects are\\ndisplayed in both, then selections can be linked between them by toggling on linking on the\\ntoolbar.\\nFor linking to work, the objects must have a common point, this is currently supported for:\\nPoints with Attributes - Linked via the common point.\\nWell tops - Linked via the well top.\\nProperties - These are linked via the cells of the 3D grid. Selection of data from one cell on\\none cross plot will trigger the selection of the same cells in the other function viewport. If\\nthe original well logs are displayed then all the log points from that cell will be displayed in\\nboth viewports.\\nIf the number of points has been reduced, then the precise points that are being selected in\\none viewport may not appear on the second viewport. Toggle off reduction on the Objects\\nAnalysis tab.\\nObjects linked to plot windows\\nEach plot window can have a number of child objects, such as a frame and unlimited text,\\nrectangles andarrows for annotating data independently of the viewports drawn on the window.\\nSettings for Labels\\nThe area covered by a label is defined by a rectangle drawn by the user in the plot window. It's\\nsettings can be accessed via it's icon in the Windows pane on the process dialog or by double\\nclicking on the label itself.\\nThe user can define the style of the text, its rotation, the rectangle's line style and the fill color for\\nthe rectangle. By checking on Autosize from label, the rectangle will be automatically sized to\\nthe text. Insert autotext can be used to insert dynamic labels linked to the project settings or\\nthe data on display, e.g. horizon name.\\nSettings for Arrows\\nEach arrow's settings can be accessed via it's icon in the Windows pane on the process dialog or\\nby double clicking on it in the viewport.\\nThe user can specify it's name, it's line style, the arrow styles and whether or not arrowheads will\\nbe drawn. Either end of the arrow can also be dynamically linked to a point with real coordinates\\nwithin the viewport. This means that as the viewport is panned and zoomed the arrow still points\\nto the same point in space.\\nHow to tie an arrow to real coordinates\\n1. Display the viewport to be used.\\n2.\\n3.\\n1.\\n2. Press and choose New arrow.\\n3. Click once where you want the arrow line to end, hold the mouse button down and release\\nwhere you want the arrow's head (inside the viewport).\\n4. Double click the arrow to open its settings.\\n5. Check on the Link option next to the arrowhead, the X and Y coordinates will automatically\\nbe set to the arrows current position on the viewport.\\nThe viewport can now be panned, etc. and the arrow's position will remain tied to the original\\npoint in space.\\nSettings for Rectangles\\nRectangles are identical to labels however, as a default, the text option is off. See Settings for\\nlabels.\\nSettings for Frame\\nThe Frame settings window is accessed by pressing the arrow next to the show hide frame button\\n. The settings dialog has the following options:\\nLogo: Gives the user the option of displaying a logo from an image file (*.png) inside the\\nFrame. The size of the logo can be adjusted within the dialog.\\nFrame Text: Gives the user the option to enter a multiline text string inside the Frame. To\\ninsert a line shift press Ctrl+Enter. When several lines are present the alignment (center,\\nleft or right) of the lines can be specified. The longest line controls the alignment. Insert\\nautotext can be used to insert dynamic labels linked to the project settings or the data on\\ndisplay, e.g. horizon name.\\nPositions and Margins: Allows the user to manipulate the positioning of the text and the\\nlogo as well as to set the distance from the paper margin to the Frame.\\nColors/Lines: Allows the user to manipulate the colors for the foreground (borders and\\ntext) and background, as well as the line width. If the background is turned off, the area\\ninside the Frame will be transparent, otherwise it will cover underlying objects.\\nObjects linked to viewports\\nIn addition to the data in the Viewport, other visual objects can be part of the output. Legend, Axis,\\nInfo box, Scale bar, Symbol legend, Frame and Header can be toggled on/off and manipulated\\ninteractively by the user.\\nThe layout and placement of the objects can be set in their respective Settings dialog. The\\nplacement of the objects can also be manipulated manually by dragging the objects to new\\npositions.\\nFrame (child icon to the window)\"},\n",
       " {'header': 'Legend Axis ', 'content': 'Info box\\nScale bar\\nSymbol legend'},\n",
       " {'header': 'Header North Arrow ',\n",
       "  'content': 'Settings for Legend\\nThe legend settings window is accessed by pressing the arrow next to the show hide legend button\\n. The settings dialog has the following options.\\nShow : Allows the user to manipulate the layout of the legend (frames and header text).\\nLayout : Allows the user to make discrete color tables and to manipulate the layout (size,\\nannotation interval, offset to corresponding viewport and font).\\nColors/Lines : Allows the user to manipulate the colors for the foreground (frame, text and\\nannotations) and background and the line width. If the background is turned off, the legend\\nwill be transparent, otherwise it will cover underlying objects.\\nSettings for Axis\\nThe Axis Settings window is accessed by pressing the arrow next to the show hide axis button .\\nThe settings dialog has four Sub tabs:\\nGeneral : Allows the user to choose which sides should have a frame and set the color and\\nline with of the frame.\\nTicks : The tab where the placing and appearance of the ticks is defined. The spacing of the\\nticks will be automatically estimated based on the project settings XY unit and the size of the\\nplot. This can be overridden and the units for the ticks changed.\\nAnnotation : Allows the user to specify the annotation fonts and to set the density of the\\nannotations (every n\\'th tick mark) and whether the annotations should be aligned horizontally\\nor vertically. As a default, labels are created automatically from the names of the data being\\ndisplayed or the coordinate system and these can be overwritten with user defined texts.\\nGrid : Allows the user to turn on/off gridlines (Vertical and Horizontal or Crosses only) and to\\nchange the color and line width. Crosses only will display a cross at each gridline intersection.\\nInfo box settings - viewports\\nSettings for Info box\\nThe info box settings window is accessed by pressing the arrow next to the show hide info box\\nbutton . The settings dialog has three sub tabs: Style, Info and Settings\\nInfo Box; Style tab\\nInfoBox: Option to use a predefined or user defined xml template for the Info Box\\nHeader: Option to toggle header text on/off and to implement a logo from an image file\\n(*.png).\\nFonts: Allows the user to change the style and size of the text for Header, Lead text and\\nVariable text.\\nColors/Lines: Allows the user to manipulate colors for the foreground (borders and text)\\nand background, as well as the line width. If the background is turned off, the Info box will\\nbe transparent, otherwise it will cover underlying objects.\\nNumber of columns: Specifies the number of columns used for the items in the Info box\\nand the width of each column.\\nLayout: Specify the distance to the viewport.\\nPosition: Allows the user to manipulate the placement of the Info box.\\nInfo Box; Info tab\\nName: Specify the name for the Info Box object.\\nComments: Add any comments for the object.\\nInfo Box; Settings tab\\nProject Settings: This button will open the Project Settings dialog where information used\\nin the Info box can be entered.\\nReset: Resets all settings to default settings.\\nHeader: User defined text string for the Info box.\\nThe items in the Info box can either contain user-defined or pre-defined text. The user can\\nmanipulate the layout of the Info box by adding and deleting items in the table. By selecting a\\ncode in the list of codes, Petrel writes the appropriate lead text and picks up the corresponding\\nvariable text from the computer, visualized objects or the viewport. This is valid for all codes\\nexcept for \"User input\", which gives the user the possibility to generate user specified lead and\\nvariable text. For some of the codes the variable text will be picked up from the Project Settings\\n(see Pull-Down Menus).\\nExamples on codes to insert into the different cells of the info box:\\nUser defined lead and variable text:\\n- User input\\nFrom the computer:\\n- User name\\n- Date (DD/MM/YYYY)\\nFrom viewport:'},\n",
       " {'header': '- Scale - Xmin, Ymin ', 'content': '- Z-scale - Xmax, Ymax'},\n",
       " {'header': '- Xmin, Xmax - Xmin, Ymin, Xmax, Ymax - Ymin, Ymax ',\n",
       "  'content': 'From visualization of 3D grid, surface or property:\\n- # rows and columns - Xinc, Yinc\\n- # grid nodes (nI, nJ, nK) - Contour inc\\n- # grid cells (nI, nJ, nK) - Layer\\nFrom data object visualized:\\n- Points name - Model name\\n- Surface name - Property name\\n- Horizon name - Skeleton name\\n- 3D.Grid name\\nFrom Project settings:\\n- Project name - Country\\n- Project file - Area'},\n",
       " {'header': '- Projection - Block ', 'content': '- UTM zone - License'},\n",
       " {'header': '- Datum ',\n",
       "  'content': 'By selecting the box for Cover row the item will expand across the following columns.\\nFrom the 2007.1 release of Petrel, the user may define a list of variables to be used in the info\\nbox. For example, a company might have a list of classifications for plots such as Public, Private,\\nSecret, and so forth.\\nThis list can now be created in a configuration file; consequently, the user can select it from the\\nlist, rather than entering it as free text. The control for this utility can be found in the\\n\"InfoBoxItems.xml\" file, located in the Petrel install directory, under the\\nPetrel(version)/Resources/InfoBox folder.For more information see User customized Info Box.\\nUser customized Info Box\\nTo better meet the needs of individual users or companies, Petrel allows the user to customize the\\ndesign of the Info box by altering certain XML files in the normal Petrel installation. Before\\nmodifying files, it is suggested to make a backup of files for QC and data restore options. See\\nAppendix 7- User Editable Resources for more information.\\nTo use the predefined design, tick the Use Predefined box. This will give you access to a\\ndropdown list containing a basic Petrel Infobox and the user defined Infobox Style.\\nTo alter the user defined design you have to alter an xml file called UserInfoBoxes.xml. This file is\\nlocated in the subfolder resources/InfoBox/UserInfoBoxes.xml placed under your Petrel\\ninstallation. You then need to open this file in notepad or any other text editor of your choice. This\\nis an example on how the file may look:\\nEach <TR> command will insert a new row, while the <TD command will insert cells into the row.\\nThe width of the cells is controlled by the rowspan tag. The user has freedom to insert bitmaps\\nand text strings into any of the cells in the table.\\nNote! The XML file defining the User defined textbox will only be loaded when Petrel starts.\\nIf you have done any adjustments to the file while Petrel is running, you have to restart Petrel to\\nmake the changes take affect.\\nOther settings for viewports\\nSettings for Scale bar\\nThe Scale bar settings window is accessed by pressing the arrow next to the show hide scale bar\\nbutton . The settings dialog has the following options:\\nLayout: Allows the user to manipulate the layout for the scale bar (show scale/unit, color,\\nfont, type etc.)\\nData: Allows the user to set the tick unit and the increment for the tick marks. Pressing the\\nChange-button accesses the Project settings where the units for the whole project can be\\nchanged.\\nSettings for Symbol Legend\\nThe Symbol legend settings window is accessed by pressing the arrow next to the show hide\\nsymbol legend button . The settings dialog has the following options:\\nShow: Allows the user to toggle outer and inner frame on/off and set the offset to the\\ncorresponding viewport.\\nLayout: Allows the user to specify the height and width of the Symbol Legend and number\\nof columns/rows in the legend.\\nFont: Allows the user to change the style and size of the text.\\nColor/Lines: Allows the user to manipulate the colors for the foreground (borders and\\ntext) and background as well as the line width. If the background is turned off, the area\\ninside the Symbol Legend will be transparent, otherwise it will cover underlying objects.\\nNote that if no symbols are represented in the view, only a symbol legend frame appears in\\nthe window.\\nSettings for Header\\nThe Header settings window is accessed by pressing the arrow next to the show hide header\\nbutton . The user can set the color, font size and font style, as well as the position of the\\nheader and the offset to the viewport. The label input box allows the user to type in a heading.\\nInsert autotext can be used to insert dynamic labels linked to the project settings or the data on\\ndisplay, e.g. horizon name.\\nSettings for North Arrow\\nThe setting for the North Arrow is accessed by clicking on the show/hide north arrow icon . The\\nuser may change the style, height, color and position of the north arrow.\\nHow to change settings for the visual objects\\nThe settings dialog can be opened by use of the shortcut icons in the toolbar.\\n1. Click on the arrow on the right side of the shortcut icon (e.g. the page header icon ).\\n2. Change the settings.\\n3. Press OK.\\nThe settings dialog for all of these objects can also be opened from the Windows pane.\\n1. Go to the Windows pane of the process dialog.\\n2. Open the Settings dialog for the specific object, by double clicking on the name or clicking\\nwith the right mouse button on the name and selecting the Settings option.\\n3. Change the settings.\\n4. Press OK.\\nPaper settings for viewports\\nPaper settings\\nPaper margins, paper size and paper orientation can be set by use of standard page setup\\ndialogs. This will affect the size of the paper displayed in the plot window and needs to be set\\ncorrectly before designing the plot window.\\nHow to change Page Setup\\nClick on the icon Edit paper and margin settings for this page in the toolbar.\\n1. Adjust the settings in the Page Setup dialog.\\n2. Press OK.'},\n",
       " {'header': 'Or ',\n",
       "  'content': '1. Open the File pull-down menu from the Menu bar.'},\n",
       " {'header': '2. Select Page Setup. ',\n",
       "  'content': '3. Adjust the settings in the dialog.\\n4. Press OK.\\nThere are two print methods. The standard windows print functionality or the new APS print\\nfuctionality. APS offers improved options for page scaling (e.g. fit to page), orientation (e.g.\\nportrait & landscape), roll plotter support and improvements to quality, memory handling and\\nperformance. The Print dialogue has new options for direct generation of CGMs.'},\n",
       " {'header': 'Output ',\n",
       "  'content': 'The active view can be sent to a printer/plotter for printing, \\'copied and pasted\\' into other\\napplications, or saved as a printer file (*.prn) or an Enhanced Windows Metafile (*.emf).\\nThird party applications are available for exporting plot windows in a CMG format. These appear\\nas a printer when installed and printing will write a file out to the specified location.\\nHow to print the display\\nPress the Print shortcut icon or select the Print option from the pull-down menu under Files\\nin the menu bar.\\n1. Make the settings.\\n2. Select if you want to print directly or as a CGM file.\\n3. Press OK.\\nPlotting canvasses incorporating transparent polygon fill to hardcopy is dependent on\\nwhether the selected printer supports blending. If your plotter does not support this feature,\\ntransparent polygon fill will be drawn solid. The window may be exported to another Windows\\napplication (see How to export graphics as Enhanced Windows Metafile (*.emf) for details) and\\nplotted from there.\\nHow to configure the printer for each plot window\\nEach plot window may have independent print settings, giving the user the flexibility to, for\\nexample, set up some plot windows to a standard A4 printer, while other plot windows will print\\non a large plotter.\\n1. Select the \"Show Paper and Margin Settings\" in the active viewport.\\n2. Select paper size and decide on landscape or portrait.\\n3. Click on the print button and choose the printer on your network.\\nHow to copy images into other applications\\n1. Press Copy Bitmap or Copy Metafile in the tool bar.\\n2. Open the other application.\\n3. Paste the copied display.\\nWhen using Copy Metafile the picture must be pasted as an Enhanced Metafile. To\\nmake sure that this is done, use the Paste Special option from the Edit pull-down menu and\\nselect Picture (Enhanced Metafile) from the list.\\nPasting the image into another application.\\n1. Open the application, e.g. PowerPoint\\n2. Open the Control toolbox (View>Toolbars>Control Toolbox).\\n3. Click on .\\n4. Specify location, name and file type.'},\n",
       " {'header': '5. Press Save. ',\n",
       "  'content': 'Exporting plotting canvasses incorporating transparent polygon fill to emf may be dependent\\non graphics driver version. Older graphics drivers may draw the transparent fill in white, instead\\nof the color selected in Petrel.\\nHow to import an Enhanced Windows Metafile (*.emf) into for example\\nPowerPoint\\n1. Open PowerPoint.\\n2. Open the Insert pull-down menu.\\n3. Select Picture - From file.\\n4. Select the file and specify the correct file format (*.emf)'},\n",
       " {'header': '5. Press Insert. ',\n",
       "  'content': 'Some drawing applications have problems reading *.emf files correctly.\\nCommon tools for plot windows\\nWhen one of the Plot windows is active, specific shortcut icons (associated with the window) will\\nbe visible in the Tool bar.'},\n",
       " {'header': 'Paper Actions: ',\n",
       "  'content': 'Edit paper and margins settings for this page: Will open the Page Setup dialog, where\\npaper settings and printer options can be set.\\nZoom Factor : Will reduce or enlarge the display of the Map view to an entered\\nmagnification.\\nZoom : Will zoom the display by the zoom factor.\\nFit Window By Paper Width : Will zoom the Map view to show the whole paper width.\\nFit Window By Paper Height : Will zoom the Map view to show the whole paper height.\\nUse Dynamic Size : Will adjust the size and shape of the map view to fit the Display window.\\nIn this state, it is not possible to print the page because the relationship between width and\\nheight of the screen is not the same as for the selected paper size. This state can be used for\\nworking with the plot.'},\n",
       " {'header': 'Mapping Actions: ',\n",
       "  'content': 'Show window settings : Opens the settings for the active viewport.\\nNew objects in plot window : Provides a drop down list of new objects that can be added to\\nthe active plot window (viewports and annotation).\\nNew objects in viewport : Provides a drop down list of new objects that can be added to the\\nactive viewport (scales and legends).\\nShow/Hide Auto Legend : Toggles the automatic color legend on/off. The arrow to the right\\nwill open the settings dialog.\\nShow/Hide Axis : Toggles the axis on/off. The arrow to the right will open the settings dialog.\\nShow/Hide Info box : Toggles the Info box on/off. The arrow to the right will open the\\nsettings dialog.\\nShow/Hide Scale bar : Toggles the Scale bar on/off. The arrow to the right will open the\\nsettings dialog.\\nShow/Hide Symbol Legend : Toggles the Symbol legend on/off. The arrow to the right will\\nopen the settings dialog.\\nShow/Hide Frame : Toggles the Frame on/off. The arrow to the right will open the settings\\ndialog.\\nShow/Hide Header : Toggles the Header on/off. The arrow to the right will open the settings\\ndialog.\\nTools associated with the Map and Intersection\\nviewports\\nShow Viewport Settings : Will open a dialog for specifying settings for the Viewport.\\nView all : Will adjust the scaling of the visualized objects to view all.\\nFit Viewport to Height : Will adjust the scaling of the visualized objects to fit to the height of\\nthe Viewport.\\nFit Viewport to Width : Will adjust the scaling of the visualized objects to fit to the width of\\nthe Viewport.\\nPan Viewport to Center : Will pan the visualized object to the center of the Viewport.\\nSet Home Scale to Viewport Scale : Sets the viewport scale to the Home scale.\\nSet Current Viewport to Home Scale : Resets the Home scale of the viewport to the current\\nscale.\\nSet Origin To (0, 0) : Sets the origin of the X- and Y-axis to zero.'},\n",
       " {'header': 'Map Viewport ',\n",
       "  'content': 'When the Map window is active, only items suitable for XY-mapping will be active in the Petrel\\nExplorer and these items can be toggled on/off interactively. The data will then be displayed in\\nthe Viewport (see Settings for the Map Viewport). The display of the data objects can be\\nmanipulated manually or by using the mapping action tools in the function bar. The scaling will be\\nset automatically by the use of the tools in the function bar, but can interactively be changed by\\nzooming with the mouse or by entering a scaling factor in the settings dialog for the Viewport.\\nWhen displaying several data objects at the same time Petrel uses a layer hierarchy. The layers\\nwill depend on visual style and these are:'},\n",
       " {'header': 'Point ', 'content': 'For data objects drawn as points.'},\n",
       " {'header': 'Line ', 'content': 'For data objects drawn as lines.'},\n",
       " {'header': 'Solid ',\n",
       "  'content': \"For data objects drawn with solid style on.\\nPoints will be drawn on top of lines, which will be drawn on top of solid objects.\\nIf more than one object from the same layer (visual style) is displayed, the views will be\\nvisualized in the order they are represented in the project tree.\\nAlmost any kind of data stored in the Input pane of the Petrel Explorer can be visualized in the\\nmap view and plotted.\\nThe same applies for data in the Model pane of Petrel. The only objects that cannot be used are\\nthe Fault Model (Key Pillars) and the I- and J-intersections.\\nWhen plotting properties in the map view window, only one layer is visible at any one time.\\nChange the layer under the Properties Settings tab, see Properties Settings.\\nHow to display data in the Map viewport\\n1. Create a new Map window, by clicking on New window in the tool bar and selecting\\nNew Map Window in the list.\\n2. Select data to display in the Petrel Explorer.\\nHow to display Annotations in the Map window\\nThe Annotations folder can be inserted from the Insert menu and will be placed under the\\nInput pane of the Petrel Explorer. Multiple objects can be entered into the settings window in\\norder to get them displayed.\\n1. Open the settings window by right-clicking on Annotations and selecting Settings. Under the\\nAnnotations tab, insert a new item by first adding a new row. Use the Add item in table\\nicon to insert a new row.\\n2. Select an item in the Petrel Explorer. E.g.: Segments, Faults, Horizons.\\n3. Click on the blue arrow in order to add the item to the list.\\n4. Change the text of the object if required.\\n5. Change the angle of the text if it should be aligned different from 0. Zero angle is as the\\n6.\\n3.\\n4.\\n5.\\nfigure shows:\\n6. Tick Show if the object text should only be displayed when the object itself is shown. Tick\\nShow always if the text should be shown always, even if the object is not visible.\\n7. Change the text size if desired (default, small or large). User-defined settings are possible\\n(defined under the Style tab, 2D settings: size, bold/italic, color, background and frame).\\n8. Press OK.\\nTo see the changes, open a Map window and make sure the Annotations icon is checked. Any\\nobject can be displayed together with the annotations.\\nThe Annotation table supports copy and paste with Microsoft Excel. This is a quick and easy way\\nto import and display external information. The Excel sheet will need the correct columns.\\nBy clicking and dragging the mouse on an item in Map view, the positions can be changed.\\nBy pressing the shift key and the left mouse button, each annotation can be rotated interactively.\\nSettings for the Map Viewport\\nLinked to coordinate group: Viewports with similar co-ordinate systems and of the same\\ntype (two maps or two intersections etc) can be linked together enabling synchronized\\nscrolling and panning of objects in the same plot. See How link viewports together manually\\nfor more information.\\nLinked to visual group: Any windows can be linked to share display events. Once the\\nwindows are linked then any object displayed in one window will automatically also be\\ndisplayed in the other as long as that object is compatible with the second window.\\nScale: Here the scale for the map viewport can be specified. The user has an option to lock\\nthe scale by checking the fixed tick box.\\nCoordinates: Options to specify the max or min coordinates for the X-and Y-axis.\\nMargins: Here the margins outside the Viewport can be manipulated. Values can be\\nentered either as a distance in millimeters or as a percentage of the printing area (within\\npaper margins).\\nSettings for points and lines (polygons)\\nPoints and lines are displayed in a similar way to those in the 3D and 2D, and the settings are\\nlargely similar. Exceptions are that transparency can not be used and the display material can not\\nbe changed for points.\\nFor point data the available symbols are different from the 2D/3D view. Symbols available in Map\\nview are:\\nIt's possible to have color fill inside a polygon and the user can specify transparency.\\nSettings for wells and well tops\\nThe settings are the same as for 3D/2D view, except that well tracks/annotation cannot be used.\\nThe well filter can be used in any of the views, for example, to filter the well trace and log only\\ninside the reservoir interval.\\nFor wells the settings are the same as for 3D/2D view, except that transparency cannot be used\\nand the display material cannot be changed. See Well Tops.\\nThe available point types are different from the 2D/3D view. The point types available in Map view\\nare:\\nThe well point types can be set separately for each well and each point in the Well Tops Editor\\n(see Well Tops Spreadsheet ).\\nSettings for surfaces (2D maps)\\nWhen displaying surfaces in the map view, one color is applied for each contour interval.\\nThe settings are the same as for 3D/2D view, except that transparency cannot be used and\\nmaterial cannot be changed. See Gridded surfaces.\\nSome features are only active in the map view and these are:\"},\n",
       " {'header': 'Contour ',\n",
       "  'content': 'Spline: Will smooth the contour lines using a spline function .\\nNote that this function will not affect the data, merely smooth the display of the contour\\nlines.\\nOn bold levels only: Only displays contour labels on bold contours.\\nFont size in world coord: Uses the unit scale to set the size of the text.'},\n",
       " {'header': 'Solid ',\n",
       "  'content': 'Change color at contour level: Each contour interval will have a single solid color\\nChange color at bold levels only: The solid color will only change at bold contour lines.\\nSmooth: The color will change smoothly and take no account of the contours.\\nSettings for intersections\\nIntersections can be displayed as lines in the map view. If displaying a non-vertical intersection\\nplane there is an option for specifying the depth of the display. The settings for the intersections\\n(see General Intersection ) are:\\nMap/intersection line settings: The depth value for the display of non-vertical\\nintersection planes can be set here.\\nColor: Type of color for the display of the line.\\nLine width: Width of the displayed line.\\nSettings for skeleton (Corner point grids)\\nThe settings are the same as for 3D/2D view, except that transparency cannot be used and\\nmaterial cannot be changed. See Skeleton Settings .\\nWhen displaying the skeleton grid as solid and using the depth color table, one color is used for\\neach contour interval.\\nSome features are only active in the map view and these are:'},\n",
       " {'header': 'Contour ',\n",
       "  'content': 'Spline: Will smooth the contour lines using a spline function.\\nNote that this function will not affect the data, merely smooth the display of the contour\\nlines.\\nOn bold levels only: Only displays contour labels on bold contours.\\nFont size in world coord: Uses the unit scale to set the size of the text.'},\n",
       " {'header': 'Solid ',\n",
       "  'content': 'Change color at contour level: Each contour interval will have a single solid color\\nChange color at bold levels only: The solid color will only change at bold contour lines.\\nSmooth: The color will change smoothly and take no account of the contours.\\nSettings for faults (Corner point grids)\\nThe settings are the same as for 3D/2D view, except that transparency cannot be used and\\nmaterial cannot be changed. Pillars, and lines between pillars, cannot be displayed in the fault\\nplanes. See Faults Settings .\\nYou have two color options, gray or any other color. This makes it easier to display fault polygons\\nor faults with different colors for their outline and for their color-fill. The fault planes will be\\ndisplayed on top of any other \"solid\" object (e.g. horizon). To display fault planes corresponding\\nto a specific horizon only, the Fault filter must be used (i.e. filter away all other horizons).\\nTo display fault planes as a part of the horizon, the color can be set to \"depth\" and contour lines\\nin the fault planes can be toggled on/off in the settings for Horizons (see Horizons Settings).\\nSettings for horizons (Corner point grids)\\nWhen displaying horizons in the map view, the same color is applied for each contour interval.\\nThe settings are the same as for 3D/2D view, except that transparency cannot be used and\\nmaterial cannot be changed. See Horizons Settings.\\nSome features are only active in the map view and these are:'},\n",
       " {'header': 'Contour ',\n",
       "  'content': 'Spline: Will smooth the contour lines using a spline function.\\nNote that this function will not affect the horizon i.e. the color table will not follow the\\ncontour lines exactly.\\nShow in faults: Will show contour lines in the fault planes.\\nOn bold levels only: Only displays contour labels on bold contours.\\nFont size in world coord: Uses the unit scale to set the size of the text.'},\n",
       " {'header': 'Solid ',\n",
       "  'content': 'Change color at contour level: Each contour interval will have a single solid color\\nChange color at bold levels only: The solid color will only change at bold contour lines.\\nSmooth: The color will change smoothly and take no account of the contours.\\nSettings for edges (Corner point grids)\\nThe display of edges will only show segment edges as lines sorted by horizon. To display segment\\nedges corresponding to a specific horizon only, the Fault filter must be used (i.e. filter away all\\nother horizons).\\nSettings for properties\\nThe settings are the same for both 3D and 2D view, except that transparency cannot be used and\\nmaterial cannot be changed. See Properties settings .\\nProperties can only be displayed for one K-index of the 3D grid at a time when using the K-filter.\\nThe Property player is not available in the Map window.\\nProperties in Map view\\nBy using the following tools in the Settings > Style tab for Properties, shifting between K-index\\ncan be done.\\nK - index of property layer:\\n: Typing in a number, or scrolling by using the arrows, can enter a specific K-index to\\nbe displayed. To update the plot press Apply/OK.\\n: By using these arrows, the display will jump to the next/previous K-index and the plot\\nwill be updated automatically.\\nJump to Top/Jump to Base:\\n: All zones in the model are listed here with the associated K-indexes.\\nWhen selecting a zone from the list, the display will jump to the top or base K-index layer of that\\nzone. To update the plot press Apply/OK.'},\n",
       " {'header': 'Intersection Viewport ',\n",
       "  'content': 'Only data suitable for display on an intersection will be activated in the Petrel Explorer. The\\nsettings for the display of the data are in the Settings dialog for the intersection (see General'},\n",
       " {'header': 'Intersection). ',\n",
       "  'content': \"When displaying well intersection fences, vertical well intersections, or vertical intersections from\\npolygons, the intersection will be unfolded and displayed as a plane.\\nWells and surfaces (depth) in the Input pane can be displayed on the intersection, and well\\ntrajectories can be projected on the intersections as lines. The line will be drawn as solid if it is in\\nfront of the intersection and as dotted lines if located behind. Surfaces (i.e. 2D regular grids) can\\nbe displayed as lines on the intersection. To be able to display the surfaces, the category of the\\nsurfaces has to be set to 'Z-values' not 'depth'.\\nHorizons, fault planes, zones and properties from the 3D model can be displayed on the\\nintersection. Horizons and fault planes will be displayed as lines and zones/properties will be\\ndisplayed as solid.\\nHow to display data in an Intersection window\\n1. Create an intersection and align it as desired in the 3D space.\\n2. Create a new intersection window by clicking on the New window button in the Tool\\nbar and selecting New intersection window in the menu.\\n3. Select the intersection in the Petrel Explorer.\\n4. Select data to display on the intersection in the Petrel Explorer.\\nSettings for the Viewport\\nLinked to coordinate group: Viewports with similar coordinate systems and those of the\\nsame type (two maps or two intersections, etc), can be linked together enabling\\nsynchronized scrolling and panning of objects in the same plot. See How link viewports\\ntogether manually for more information.\\nLinked to visual group: Any windows can be linked to share display events. Once the\\nwindows are linked, any object displayed in one window will automatically also be displayed\\nin the other as long as that object is compatible with the second window.\\nScale: Here the scale for the intersection viewport can be specified. The user has an option\\nto lock the scale by checking the fixed tick box. Coordinates: Options to specify the max\\nor min coordinates for the X-and Y-axis.\\nMargins: Here the margins outside of the Viewport can be manipulated. Values can be\\nentered either as a distance in millimeters or as a percentage of the printing area (exclusive\\npaper margins).\\nSettings for intersections\\nThe settings for the display of data objects in the Intersection window are in the Settings\\ndialog for the intersection (see General Intersection ). The settings are:\"},\n",
       " {'header': 'Input Wells: ',\n",
       "  'content': 'Color and Width: Defines the color and line width for the display of the well trajectory.\\nDistance limit: This is the maximum offset used for the projection. Only wells or parts of\\nwells within the distance will be displayed.\\nShow name: Shows the name as a text label at the top of the well trajectory.\\nShow symbol: Shows the well symbol at the top of the well trajectory.\\nName/symbol color: Sets the color for the display of the well name and symbol.'},\n",
       " {'header': 'Surfaces: ',\n",
       "  'content': 'Color and Width: Defines the color and line width for the display of the surface.\\n3D model\\nColor and Width: Defines the color and line width for the display of the horizons and the\\nfault planes, as well as color and material for display of zones.\\nApply property filter (If property is visualized): Allows the property filter to be used.\\nGrid Lines: Shows the gridlines from the 3D grid on the intersection.\\nHistogram viewport\\nAny data can be displayed as a histogram, where the user has the option to set number of bins\\nand to standardize the histogram (i.e. display the frequency as a percentage of the total.).\\nThe distribution can be displayed as:\\nHistogram drawn as a bar chart\\nHistogram drawn as a line\\nCumulative distribution function\\nHistograms can be shown for imported data (well logs, points and surfaces) and generated 3D\\nproperty models. For well logs the user can show a histogram for the global well logs or a single\\nwell independently. For properties, the user has the option to show histogram for property,\\nupscaled well logs and raw well log curves used in upscaling.\\nThe data object used in the histogram can interactively be toggled on/off in the Petrel explorer\\nand the layout can be manipulated in the Settings dialog for the specific object or for the wells\\nand properties folder.\\nThe histogram with its functions will be displayed in a histogram window. For more information\\nabout the viewport see Viewport.\\nHow to display a histogram\\n1. Open a Histogram window by clicking on New Window in the toolbar, and selecting New\\nHistogram Window from the list.\\n2. Toggle the data objects in Petrel Explorer to be displayed.\\n3. Colors and symbols can be set in the Settings dialogs for the respective objects (see\\nSettings for objects in the Input pane and Settings for objects in the Models pane ).'},\n",
       " {'header': 'Displaying Volume Calculation Results ',\n",
       "  'content': \"Volume Calculation results are displayed in a histogram. Exactly what is displayed is controlled by\\n3 sets of selections, the case, the property and the filter. See The Results pane for more\\ninformation.\\nWhen multiple cases are chosen, the histogram will display the percentage of the selected cases\\nin each volume bin. A cumulative distribution function (cdf) can be displayed based on the\\nhistogram-intervals shown in the histogram window. Use the Show cdf curve icon. The cdf\\ncurve is drawn based on the mid-point in each bin. The P10, P50 and P90 levels will be shown in\\nthe histogram window when displaying a distribution function. The cumulative distribution gives\\nthe probability of Z(x)<z for all z.\\nWhen multiple filters are chosen, the numbers displayed will be the sum of the volumes in all of\\nthe selected filters for the cases chosen.\\nFilters must be included in the volume calculation process. They can't be used on the results\\nif they were not included in the original volume calculation, and filters will only affect the cases\\nthey were included in.\\nFigure 1. An example of a distribution function with a 10% probability of getting a volume lower\\nthan 4509.\\nHow to view the results of a volume calculation as a histogram\\n1. Create and run a volume calculation, see How to calculate the volume of oil in a 3D grid.\\n2. Select New Histogram Window from the Window menu.\\n3. Select the cases to be viewed from the Cases pane.\\n4. Select the properties to be viewed from the Results pane.\\n5. Select any required zone or segment filters.\\nPress to see a CDF curve of the results.\\nViewport settings (histogram)\\nLinked to coordinate group: Viewports with similar coordinate systems and of the same\\ntype (two maps or two intersections etc) can be linked together enabling synchronized\\nscrolling and panning of objects in the same plot. See How link viewports together manually\\nfor more information.\\nLinked to visual group: Any windows can be linked to share display events. Once the\\nwindows are linked then any object displayed in one window will automatically also be\\ndisplayed in the other as long as that object is compatible with the second window.\\nIntervals - the data range will be split into this number of intervals.\\nIncrement - the data range will be split using the chosen increment.\\nDiscrete - this will use integer values for the histogram.\\nMin - the minimum value on the x-axis.\\nMax - the maximum value on the x-axis.\\nMax percent - the maximum percentage shown on the y axis when the toggle is on.\\n- will use a log scale for the x axis.\\nMargins: Here the margins outside of the Viewport can be manipulated. Values can be\\nentered either as a distance in millimeters or as a percentage of the printing area (exclusive\\npaper margins). The axis can be set to be included inside the margins to prevent the axis\\nlabels ending up outside the paper margins.\\nSettings for wells (Histogram)\\nTo have access to the settings to set color type, color and pattern for the histograms, the user\\nmust have a histogram viewport active.\\nOpen the settings for the wells folder and go to the Style > Histogram tab.\\nSettings for Points and Surfaces (Histogram)\\nOpen the settings for the point/surface object and go to the Style tab. (You need to have a\\nhistogram open to acces the histogram settings.) Here you can set color type, color and point\\ntype/size for the cross plot. There is also an option where you can specify if points are allowed to\\nbe removed from the plot.\"},\n",
       " {'header': 'Settings Properties (Histogram) ',\n",
       "  'content': 'Open the settings for the property folder and go to the Style tab.\\nTools associated with the Histogram viewport\\nShow Viewport settings: Opens the Settings window for the viewport.\\nShow Histogram: Displays the distribution as a bar chart.\\nShow Lines Between the Columns: Displays the distribution as a line chart.\\nShow Cdf Curve: Displays the distribution as a cumulative distribution function.\\nScale Cdf: Scales the Cdf to the maximum value in the histogram.\\nUse volume weighting for the values (percentage display only)\\nUse Percentage: If activated the histogram will show the distribution in percentage, otherwise\\nin number of data points for each interval.\\nShow Property: Displays the distribution for the entire 3D property model.\\nShow Upscaled Well Log: Displays only the distribution for the upscaled well logs.\\nShow Well Log Used in Upscaling: Displays only the distribution for the well logs used in the\\nupscaling.'},\n",
       " {'header': 'Function Viewport ',\n",
       "  'content': 'The function viewport has two modes:\\nLine plot mode - data is displayed as lines, multiple selections will result in additional axis\\non the plot. This is used by functions, fluid models, saturation functions and simulation\\nresults.\\nCross plot mode - data is displayed as points plotted against each other. The first point\\nchosen will be the X axis, the second the Y axis and subsequent points will determine the\\npoint color. This is used by well logs, well top and point attributes, surface attributes and\\nproperty models.\\nThe mode will be determined automatically by the data type selected.'},\n",
       " {'header': 'Displaying Crossplots ',\n",
       "  'content': 'Only data of the same type can be plotted together as a crossplot. This means that a property of\\none grid cannot be plotted against a property of another grid. Similarly, a well log of one well may\\nnot be plotted against a well log of another well, although different crossplots can be displayed at\\nthe same time in the same Function window.\\nThe variables used in the crossplot can be interactively toggled on/off in the Petrel explorer. The\\nletter x, y and z, written in the check box when the user makes the selections, will give the order\\nof the axis.\\nLinear regression function can be generated if only one crossplot is drawn and this function can be\\nmanipulated manually. The functions can then be printed or saved as a \"Function\" to be used in\\nthe calculator. For more information about functions see Functions. When generating the linear\\nregression function, correlation statistics will be given in the dialog.\\nThe linear regression function will have information about the scaling of the axis. If for example\\nthe X-axis is logarithmic, the X-direction in the function will be interpolated logarithmic. The same\\nis applied for the Y-axis.\\nThe crossplot with its function will be displayed in a function viewport, that is a limited rectangular\\narea of the view. For more information about the viewport see Viewport\\nNote that discrete logs are sampled at 0.5 units intervals in the crossplot. This applies to\\nthose discrete logs that can be edited in the well correlation process. The resampling avoids\\nskewing of the population distribution due to possible irregularity of sampling intervals.\\nHints for crossplot of properties\\nThe colors of the points are dependant on the value of the third variable (z). In order to look for\\n\"hidden\" relations, properties listed below can be used as the third variable.\\nProperty with the zone index.\\nProperty with the segment index.\\nOther geometric properties (volume, depth etc.)\\nThese properties can be made in the Geometrical Property Modeling, see Geometrical modeling.\\nHow to generate a crossplot\\n1. Create a new Function window by clicking on New Window in the toolbar, and selecting\\n2.\\n1.\\nNew Function Window from the list.\\n2. Toggle the data objects in Petrel Explorer to be displayed. Note that the letters x, y and z in\\nthe checkboxes will give the order of the axis.\\n3. Colors and symbols can be set in the Settings dialogs for the respective objects (see\\nSettings for objects in the Input pane and Settings for objects in the Models pane ).\\nViewport settings (Function Viewport)\\nLinked to coordinate group: Viewports with similar co-ordinate systems and of the same\\ntype (two maps or two intersections etc) can be linked together enabling synchronized\\nscrolling and panning of objects in the same plot. See How link viewports together manually\\nfor more information.\\nLinked to visual group: Any windows can be linked to share display events. Once the\\nwindows are linked, then any object displayed in one window will automatically also be\\ndisplayed in the other, as long as that object is compatible with the second window.\\nMargins: Here the margins outside of the Viewport can be manipulated. Values can be\\nentered either as a distance in millimeters or as a percentage of the printing area (exclusive\\npaper margins).\\nReduce points in cross plot: Option to specify maximum number of points in one single\\ncross plot. The removal of points only affects the display, and this means that statistics and\\nthe generation of linear regression function always will represent the entire data set.\\nSettings for Wells (Cross Plot)\\nOpen the settings for the wells folder and go to the Styles tab->Crossplot. Options to set color\\ntype, color and point type/size for the cross plot. There are also options for specifying if points are\\nallowed to be removed from the plot and to set different point types for each well.\\nSettings for Surfaces (Cross Plot)\\nOpen the settings for the surface object and go to the Style tab. Here you will find options to set\\ncolor type, color and point type/size for the cross plot. There is also an option for specifying if\\npoints are allowed to be removed from the plot.\\nSettings for Properties (Cross Plot)\\nHere you will find options to set color type, color and point type/size for the cross plot. There is\\nalso an option for specifying if points are allowed to be removed from the plot.\\nIt is recommended to always allow the reduction of points when displaying properties,\\nbecause no reducing will produce one point for each cell in the model.\\nTools associated with the Function Viewport\\nEdit Function Points: Allows the user to manipulate the function points.\\nEdit Function Line: Allows the user to manipulate the entire function parallel to the Y-axis.\\nShow Viewport settings: Opens the settings dialog for the viewport.\\nView All: Adjusts the display to view all data.\\nFit Viewport to Height: Adjusts the display to fit the height of the viewport.\\nFit Viewport to Width: Adjusts the display to fit the width of the viewport.\\nPan Viewport to Center: Centers the data in the viewport.\\nLogarithmic X-axis: Applies logarithmic scale on the X-axis.\\nLogarithmic Y-axis: Applies logarithmic scale on the Y-axis.\\nShow Property: Displays the entire 3D property model in the cross-plot.\\nShow Upscaled Well Log: Displays only the upscaled well logs in the cross plot.\\nShow Well Log Used in Upscaling: Displays only the well logs used in the upscaling in the cross\\nplot.\\nMake Linear Function from Cross plot: Opens the settings dialog for generation of a linear\\nregression function, based on the visualized cross plot.\\nMake Variogram for Sample Variogram: Opens the settings dialog for generation of a\\nvariogram model based on the visualized sample variogram.\\nCreate New Variogram: Opens the settings dialog for generation of a new variogram model.\\nSelect data points using freehand draw.\\nSelect data points using a 2D rectangle.\\nSelect data points using 1D range on the x axis.\\nSelect data points using 1D range on the y axis.'},\n",
       " {'header': 'Stereonet Viewport ',\n",
       "  'content': \"The stereonet viewport allows users to display dip and azimuth data in a standard stereonet\\ndisplay. The azimuth of the point controls which radial line the point is plotted on, while the dip\\ncontrols the point's distance from the center of the stereonet.\\nDips are plotted as a pole to the dip plane, so, points with zero dip are plotted in the center, and\\npoints with 90 degree dips are plotted at the perimeter of the diagram. The plot uses a Schmidt\\nprojection and on the settings panel the user can choose between upper and lower hemisphere\\nprojections.\\nData which can be displayed include:\\nPoints with attributes\\nPoint well data\\nWell tops\\nFigure 1. Point well data plotted in a stereonet\\nSelecting data in the Stereonet\\nBy choosing the freehand draw selection tool , the user can draw freely on the stereonet to\\nencompass points and select them. The freehand drawing option will be active as long as the\\nmouse is depressed, and the polygon will be automatically closed when the mouse button is\\nreleased.\\nThe selection is global, so any points selected in one stereonet will automatically be selected in\\nany other stereonet and in any other window.\\nObjects and settings\\nIn Petrel, all objects will have settings controlling the behavior, appearance and possible\\noperations. The settings available are determent by the type of object and are also sometimes\\ndepending on the type of window the user has active. All objects have a statistic tab and a info\\ntab. Most will also have a style tab controlling the way the object (s) are displayed.\\nA standard pattern has been followed for all settings dialogs for the objects in Petrel. This is aimed\\nat making navigation through the program as simple as possible. The following options are\\ncommon to many of the settings dialogs.\\nStyle tab\\nStyle settings under the settings dialog for an object allows the user to control how an object is\\ndisplayed.\\nAs a default, the changes made will usually only affect the object being edited (except when\\nediting templates and color tables),however, this behavior can be overridden. There are a number\\nof options for controlling how changes in the style settings are applied:\\nReset option will apply the default settings.\\nApply the settings to all similar objects in the project. Will copy these settings and paste\\nthem to all other objects which are like gridded surfaces in the entire project.\\nApply the settings to all similar objects in the folder. Will copy and paste the settings\\nonly to similar objects in the same folder.\\nSet the settings as default will set the current settings as the project default for all\\nobjects subsequently added to the project. All objects (with the same template) whose style\\nsettings have not been changed manually will be given the same settings as the current\\nobject.\\nInfo tab\\nThe Info tab exists on every object in Petrel and looks very similar for each of these objects. A\\ntypical Info tab contains the following elements:\\nName - this is the name of the object as it appears in the various panes and can normally\\nbe edited. For a few automatically created objects, the name may be grayed out, indicating\\nit can not be edited. If the name is in italics in the pane, it cannot be edited and will be\\ngrayed out once opening the Info tab. Pressing the reset button will revert the object name\\nto the default name of its template.\\nColor - If the object can be displayed in any window then there will often be a specified\\noption. In this case the specified option will refer to this color. In some cases the color of\\nthe objects icon in the project explorer will also be changed to match this color.\\nType - this entry is non-editable and describes the type of data for the specific object.\\nTemplate* - The template that the data is attached to. The template will determine the\\nway that data is displayed in the various windows, the color of the points, the number\\nformat used for writing out values, the units, etc. In many cases it will also define the\\ndomain of the data and control what is displayed. See Templates and Color tables for more\\ninformation.\\nCategory/object type* - some objects such as surfaces and polygons can have a sub\\ntype to describe the data, e.g. boundary or fault stick. Others, such as wells, have a well\\nsymbol which describes the sub type, e.g. injector or producer.\\nDate* - Certain objects such as simulation results will have an associated date. This is\\nusually editable.\\n(* items with an asterisk are not present for all objects)\\nThere are two sub tabs on the Info tab which provide a means for users to keep track of edits to\\nobjects and decisions made during the project:\\nComments: The user can add any information to the Comment tab, such as the source of the\\ndata that was imported and its reliability. Beneath this section is the name of Petrel's data file for\\nthe object and the name of the file that was imported (if applicable).\\nHistory*: The history of the object is stored within the data structure, including information\\nabout edits and operations performed on the object. By right clicking in this field, the user can\\nadd their own date stamped comments or clear the history completely.\\nFigure 1. The info tab for a surface stored in the Input pane.\\nStatistics tab\\nAvailable statistics for each data object are listed on the Statistics tab. The max and min values\\nfor the XYZ-axis of the object are listed under Axis. Additional statistics are listed under\\nDescription. The description comprises different information depending on object.\\nThe Statistics for the object can be copied with the Copy to output sheet icon at the bottom.\\nCheck the list(s) (List 1 = Axis and List 2 = Description etc.) you want to copy to the Output\\nsheet. By checking the Reset button, the Output sheet will be reset before the statistics are\\ncopied into it. From the output sheet it is possible to copy the statistics to other applications.\\nSettings for objects in the Input pane\\nAll data types or objects have a Settings dialog which can be opened by double-clicking the object\\nin the various explorer panes where they are stored. Some data types also have special menu\\nselections available when clicking on the object with the right mouse button.\\nThe Settings dialog consists of different tabs that can be selected. These tabs can be selected for\\ndisplaying the different Settings options, which depend on the data type you have selected. The\\ntype of Settings also depends on whether you select a single object or a category (folder) of\\nobjects.\\nNote that the Settings window is resizable (click and drag in the lower right corner of the\\nwindow).\\nRight mouse button menus in the Input tab\\nSome right mouse button options are common for several different data types and some are\\nspecific for a data type.\\nGeneral objects (Right Mouse Menus)\\nSettings will open the Settings window for the object.\\nShow color table settings will open the color table based on the template attached to the\\nchosen object.\\nDelete will delete the object permanently.\\nExport will open the export dialog for the selected object. A template and name can be given.\\nView object will zoom the 2 or 3D view to fit the selected object (only available in active display\\nwindows). This is useful for finding an object that may not be immediately obvious.\"},\n",
       " {'header': 'General Folders (Right Mouse Menus) ',\n",
       "  'content': 'User created folders for general data organization (open) (closed) have a specified set of\\nmenu choices on the right mouse button.\\nSettings will open the Settings window for the folder.\\nImport (on selection) and Export options give the possibility to export or import data to or\\nfrom this folder.\\nDelete will delete the folder and its contents, while Delete content only deletes the content of\\nthe folder and not the folder itself.\\nSort by names / templates / depth will sort the files in the folder by names or by depth.\\nSorting by depth will give the correct vertical order of the objects.\\nSet colors for all will automatically put colors on the objects within the folder. A pop-up window\\nwill ask whether the color selection is OK. If you answer no, another suggestion will come up.\\nSet names for all will automatically rename the objects within the folder and give the content\\nnames with consecutive numbers, e.g. Lines 1, Lines 2, Lines 3, etc... (Note: this is not\\nreversible!)\\nInsert Folder inserts a sub-folder.\\nView object will pan/zoom the 2 or 3D view to fit all the selected objects in the folder (only\\navailable in active display windows). This is useful for finding objects that may not be immediately\\nobvious.\\nInsert General Intersection inserts a General Intersection into the folder. The General\\nIntersection can be used to view any data in Petrel, independent on which folder it was created in.\\nThe use of the General Intersection is described in General Intersection .'},\n",
       " {'header': 'Gridded Surfaces (Right Mouse Menus) ',\n",
       "  'content': \"The menu options will change depending on whether the surface is structured or regulra, and\\nwheter it has attributes associated with it. Surface attribute grids have a subset of these options.\\nApart from the general options there are a few object related options:\\nCalculator - Opens the surface calculator.\\nCopy as Surface attribute - Copies the surface to the clipboard. The surface can be pasted to\\nany other surface as an attribute. Note that the Paste as Surface Attribute is only available\\nwhen there is data on the clipboard.\\nCopy structured/regular surface (data only) - copies only data related to the surface. This\\ncan be pasted on anothe rsurface of same type/geometry.\\nInsert New Attribute - Will insert a new surface attribute. Select from discrete or continuous.\\nCreate surface edge - creates a polygon around the outside of the surface.\\nCreate/update Dip angle and azimuth - If Dip and Azimuth do not exist as attributes then\\nnew ones will be generated.\\nConvert to points - This operation will make a point file and append the file to the bottom of\\nInput pane. Every node in the gridded surface will be represented by a point.\\nConvert to polygons - This operation will make a line data set of the gridded surface. The new\\nline data set will be appended to the bottom of Input pane. The lines will either be created from\\nnode to node in I-direction or in J-direction. After selecting the menu option, a pop-up window\\nappears where the selection between I- and J-direction has to be taken. Yesin the pop-up window\\nwill make lines in I-direction, No in the pop-up window will make lines in the J-direction.\\nDomain Convert by Active velocity model -This operation will add a new attribute to the\\nsurface using the active velocity model. If the surface is in time (determined by the object\\ntemplate) the calculated attribute will be given a depth icon. If the surface is in depth the\\ncalculated attribute will be given a time symbol.\\nUse as visual vertical position -Need to right-click the attribute itself for this option to appear.\\nThis will use the selected attribute as the vertical position for the 3D display and drawing of\\ncontours. The attribute will then appear with pink text in the Explorer pane.\\nLine data (Right Mouse Menus)\\nSpreadsheet- Will open the text editor showing all x,y,z coordinates associated with the polygon.\\nAttribute spreadsheet - will open a spreadsheet containing Label X,Y and Z, Label angle and\\nany inserted attribute. An option to Show the each polygon point is also available.\\nConvert to points- Option to convert the line data to points. The operation extracts all the\\npoints of the line data set and creates a new data object placed in the Petrel Explorer as a point\\ndata set.\\nInsert new attribute - any continous, discrete, boolean, string or date attribute can be inserted.\\nConvert to interpretation- converts a copy of the polygons to a seismic interpretation object.\\nThe objects will be assigned as horizon or fault interpretation depending upon the template they\\nare attached to.\\nCut by faults in active 3D grid- This operation will prepare a line data set to the faults modeled\\nin the active (selected) 3G grid in the Models pane. The function is used for preparing a line data\\nset before it is used in the Make Horizons process step. All the line segments in the line data set\\nwill be cut where they intersect the modeled faults in the active model.\\nSplit- creates a copy of the polygon object with one object for each unconnected polygon (rather\\nthan several polygons in a single object).\\nCreate Vertical Intersection- A vertical Intersection for the polygon line will be created and\\nstored at the bottom of the Input pane. More information regarding the Intersection can be found\\nin Vertical Intersections.\\nFlight simulator toolbar- Activates the flight simulator function for this polygon. A menu for the\\nflight simulator will be displayed below the Display window. Details on the flight simulator can be\\nfound in Flight Simulator.\\nCut by faults in active 3D grid - cuts the polygons by faults\\nDomain convert...-Will use the active velocity model to domain convert the polygons\\nCreate simulation (grid) fault - will generate a fault in the Faults folder of the active 3D grid\\nPoint data (Right Mouse Menus)\\nCalculator - Opens the point attribute calculator.\\nSpreadsheet - This menu option will open the point editor. The point editor lists all the points in\\nthe data set with a column for X-, Y-, and Z-coordinates. The editor is ideal for editing the\\ncoordinates of points or for removing or adding points to the data set. By adding/computing new\\nattributes, their values will be listed in separate columns.\\nThere is a limit of 3000 points in the editor. If the file contains more than that, the editor cannot\\nbe opened. For more information on how to use the point editor, see Point Editor.\\nCopy points (data only) - will copy data froma point set to be able to paste it on another\\nexoisting point data set.\\nConvert to polygons - This menu option will convert the point data set to a line data set. The\\nnew file will be added in the bottom of the Input pane. The lines will be drawn from one point to\\nanother as the points are organized in the point editor. If the points need to alter order before\\nconverting them to lines, do this in the point editor before converting the lines to points.\\nInsert new attribute - will insert a new attribute, a template and name must be given. The new\\nattribute can be computed or values can be typed in the spreadsheet.\\nDomain convert... - will convert teh points by using the active velocity model.\\nAdd to active Well Tops as horizons - This menu option on point data will convert the selected\\npoint data set to well tops, and add a copy of the data to the well top folder. The data set will be\\nsorted as a horizon under Stratigraphy, with the name equal to the name of the point data set.\\nUnder the Well filter folder, the data set will not be assigned to any well trace.\\nAdd to active Well Tops as fault - This menu option on point data will convert the selected\\npoint data set to well tops, by adding a copy of the data set to the well tops folder. The data set\\nwill be placed under the Faults, with the same name as the original data set.\\nAdd to Well Tops as well - In this menu option, the point data are converted to well top data\\nand copied into the well tops folder. A well with the same filename as the point data set is added\\nto the Well Filter folder.\\nConvert to interpretation - This menu option will convert the point data to seismic\\ninterpretation. It will be limited to the active seismic cube extent; the interpretation will be split\\ninto interpretation (converted) and points (not converted).\\nWell data (Right Mouse Menus)\\nEach of the data options under the wells folder has a different set of right mouse button menus.\\nWell folder (Right Mouse Menus)\\nView Calculator -For information on how to use the calculator, see Well Log Calculator.\\nLaunch Well Manager- will launch a separate dialog containing all relevant data for wells,\\nattributes, logs and other parameters. All well data can be sorted from here; into separate folders\\netc. See (Well Manager).\\nMove Wells inside Boundary...- Moves well(s) inside the active closed polygon.\\nNew well- inserts a new well into the folder see Create new well.\\nCreate vertical wells intersection- creates a combined vertical well intersection for all the\\nwells in the folder see How to create a Vertical Wells Intersection from a well path.\\nExport- will export all the well header info for all wells.\\nExport all wells in a folder- will export all of the wells deviation surveys in a standard ASCII\\nformat to a specified location.\\nExport all logs in folder- will export all the well logs from the wells in the chosen folder in a\\nstandard ASCII format to a specified location. The logs for each of the well will have the same\\nsampling as that of the first continuous log in the folder.\\nAdd Empty 'active global log' to all wells- Select (make bold) a log from the Global Well log\\nfolder and then select this option from the Wells folder menu. An empty log with the selected\\ntemplate will be created for each well.\\nSorting- option to sort wells and well logs (all lists) by name, property template or property\\ntemplate/name.\\nConvert to polygon- Creates a polygon of the well trace. This polygon will be found at the\\nbottom of the Petrel Explorer Input tab.\\nSet colors for all- Replace the current colors for all the wells in the folder with randomly\\ngenerated colors.\\nSet names for all- Replace the existing names of wells in the folder with a new, automatically\\ngenerated name.\\nGlobal Well logs folder (Right Mouse Menus)\\nView Calculator -For information on how to use the calculator, see Well Log Calculator.\\nInsert Global Well Log- The option inserts a new global well log into the global well log list. The\\nnew log can be of either continuous (cont.) or discrete (disc.) type. The new global well log will\\nnot contain any data, nor have any members in any of the wells, however well logs stored under\\neach well can be attached to this new global well log. For further information on how to use this\\noption, see Global well logs vs. local well logs.\\nInsert global comment log- Creates a new comment log, see Comment logs.\\nInsert global combined log- Creates a new combined log, see Combined Well Logs.\\nInsert estimated global log- See Log estimator.\\nMake log(s) static or dynamic- Logs can be locked (made static) to prevent updating when\\nthe synthetic process chain is re-run. A typical workflow would be to lock the folder after\\ngenerating the final synthetic for a well, to avoid accidentally overwriting it. By right-clicking on\\nany derived log (see below), this log can be changed from Static (padlock icon will appear in\\nattached to template name) or Dynamic (default).\\nInsert new time folder- will insert a Production log folder.\\nInsert new synthetics folder- will insert a new empty Synthetics folder.\\nInsert new derived log (continuous/discrete/seismic)- The Derived logs process allows\\nusers to create a hierarchical log, which can be used in the synthetic process. It also enables the\\nfundamental inputs used in synthetics to appear inside the synthetics folder and to be present\\noutside it. By inserting a continuous/discrete derived log, the topmost continuous/discrete global\\nlog will be generated with a derived suffix in parentheses.\\nGlobal Well logs (Right Mouse Menus)\\nView Calculator -For information on how to use the calculator, see Well Log Calculator.\\nSynchronize colors and labels- If a discrete log is available for one or more of the wells, this\\nmenu option is available on the discrete log under the Global Well Logs folder. When importing\\ndiscrete well logs to Petrel, the different codes of each log are listed as separate objects under the\\ndiscrete log for each well.\\nLocal Well logs (Right Mouse Menus)\\nView Calculator -For information on how to use the calculator, see Well Log Calculator.\\nView Spreadsheet -Open the spreadsheet for the chosen well log.\\nShow global well log settings -show the settings for the global well log that the chosen well\\nlog is attached to.\\nSeismic data (Right Mouse Menus)\\nCreate well seismic - will create a well seismic icon under the global well logs icon. Seismic will\\nbe extracted along a 2D line (in traces) or as radial or orbital extraction (in distance project units)\\nfrom a selected seismic volume. There should be a time-depth relationship for the wells if the\\nseismic is in time.\\nCreate interpretation window - will open an interpretation window displaying the seismic\\nintersection from which the selection was made.\\nSurvey manager - will open a spreadsheet containing information about the survey(s) in this\\nfolder and its sub-folders.\\nInterpretation manager - will open a spreadsheet containing information about the\\ninterpretations contained in this folder and its sub-folders.\\nInsert inline intersection - this option will insert an Inline Intersection plane, on which seismic\\ndata will be displayed. By using the available options in the intersection Tool bar the intersection\\nplane can be moved to wanted positions. For information about the settings for the intersection\\nplane, see Seismic Intersections.\\nInsert crossline intersection - this option will insert a crossline intersection plane, on which\\nseismic data will be displayed. By using the available options in the intersection Tool bar the\\nintersection plane can be moved to wanted positions. For information about the settings for the\\nintersection plane, see Seismic Intersections.\\nInsert time slice intersection - this option will insert a Time slice Intersection plane and is\\navailable directly from a seismic cube. By using the available options in the intersection Tool bar,\\nthe intersection plane can be moved to wanted positions. For information about the settings for\\nthe intersection plane, see General Intersection.\\nCreate well seismic - will create a well seismic icon under the global well logs icon. Seismic will\\nbe extracted along a 2D line (in traces) or as radial or orbital extraction (in distance project units)\\nfrom a selected seismic volume. There should be a time-depth relationship for the wells if the\\nseismic is in time.\\nInsert seismic intersection - this option will insert a crandom intersection plane through the\\ncube, on which seismic data will be displayed.\\nInsert virtual cropped volume - this option will insert a virtual cropped volume that will be a\\nshortcut to a portion of the source volume. It can be cropped to a desired size. See Cropping.\\nPrefetch to cache- will load the seismic data at full resolution into the computers RAM (memory)\\nif the size of the seismic is less then the Seismic cache size.\\nVolume attributes... - this option will run the attribute generation process. Pick the attribute\\nyou wish to create from the list (this may be limited if you do not have the advanced attributes\\nlicenses) insert a seismic attribute volume. See Attribute generation.\\nAttach seismic volume to active grid - will use the active 3D grid in the model pane and\\nstretch the data to fit inside the grid (provided the grid and seismic is in the same domain of time\\nor depth).\\nRealize- will open the Settings window of the seismic object and display the Realize tab of the\\nOperations tab. All volumes will be realized to ZGY format.\\nGenerate cube layout- will create a polygon with the XY values of the bin cells of a 3D cube.\"},\n",
       " {'header': 'Gridded Surfaces Settings ',\n",
       "  'content': 'Surfaces are regular 2D grids and are one of the most common used data types in Petrel. They\\ncan be created using the Make/Edit Surfaceprocess or imported from other data stores and can be\\nedited interactively or manipulated using operations (seeOperations tab) or the surface calculator\\n(seeCalculator).\\nEach surface may have many associated attributes which appear as children to the original\\nsurface in the project explorer pane. These are essentially additional surfaces at the same\\nresolution as the initial surface but representing different attributes. The settings available for\\nsurface attributes are a logical subset of those available for the original surface.\\nOne of the attributes will have pink text in the project explorer indicating that it will be used for\\nthe vertical position of the surface; to change this, ensure the window is set to the appropriate\\ndomain (TWT or TVD in a 3D window). If the Any domain is used, right click on a new attribute\\nand choose as Use as visual vertical position. This will now turn pink.\\nSee Statistics tab and Info tabs for information on these tabs.'},\n",
       " {'header': 'Displaying Large Surfaces ',\n",
       "  'content': 'With very large surfaces, performance at full resolution can be a problem with respect to\\nmanipulating the view in 3D. To solve this Petrel has the option to reduce the resolution of the\\nsurface in the areas away from the center of the view based on the camera position and the\\ndistance to the nodes.\\nThere are 3 options available for the resolution settings, found on the style tab of the surface\\nsettings:\\nHigh - No sub sampling of the surface will be done, but areas of the surface outside the\\nview are not loaded into memory and resolution beyond individual pixels on the screen id\\nnot drawn.\\nMed - (Default) Only 160,000 nodes of the surface will be drawn. The whole surface is\\ndrawn at a low resolution with higher resolution in the center of the view and close to the\\ncamera. As the user zooms in and areas of the surface are obscured, the resolution in the\\ncenter will increase accordingly.\\nLow - As above but only 50,000 nodes will be drawn. This option will give the best\\nperformance for very large surfaces.\\nTo see the effects of these settings, right click in the 3D view and choose Draw style,\\nWireframe. Note that Resolution only changes the display, not the surface itself.\\nFigure 1. A surface displayed as wireframe showing the high resolution in the center of the view\\nand the lower resolution for the surrounding area.\\nStyle tab (Gridded Surfaces)\\nThese settings control how the surface will be displayed in the active window.'},\n",
       " {'header': 'Resolution ',\n",
       "  'content': 'Gives the possibility to reduce the resolution of the surface for increasing the speed of rotation\\nand visualization of the surface. See Displaying Large Surfaces, Note that Resolution only\\nchanges the display, not the surface itself.\\nGrid lines\\nOptions for displaying the grid lines of the selected surface. The grid lines can be displayed with\\ndifferent colors, different line types and thickness.\\nContour lines (tab)\\nOptions for displaying the contour lines of the selected surface. The selected increment annotates\\nthe spacing of the contour lines. The grid lines can be displayed with different colors, different line\\ntypes and thickness. There is an option button of iconizing contours. Set the desired contour\\nincrement and press the button. The iconized contours will be found in the very bottom of the\\nInput pane, as lines, which can be edited in the Make/Edit Polygons Process.'},\n",
       " {'header': 'Contour Annotation ',\n",
       "  'content': 'Show determines whether or not contour lines will be displayed at all. On bold levels only is only\\navailable when the surface is viewed in a Map window. If checked, the annotation will only be\\nshown for the bold levels.\\nStart This controls the distance along a contour before a label will be inserted. The next label will\\nbe controlled by the Interval settings. The result is more contours getting labels but without\\nrepetition on a given contour.\\nCheck Show and define the label settings according to preference. Interval defines the distance\\nbetween labels, Font the size of the labels. Font size world (relative to scale) is also only available\\nwhen the surface is viewed in a Map window. The font size in this case will change with the scale\\nof the output map.'},\n",
       " {'header': 'Solid ',\n",
       "  'content': \"Options for how a selected surface will be filled with color, its material and transparency in the\\ndisplay window. Choice of material will change the reflectivity of the surface. In a 3D window,\\nShow contours in the solid, performs a similar function to contours and allows for rapid redrawing\\nwhile editing surfaces. Choosing texture as the surface color allows the surface to be colored by a\\nbitmap, See Texture mapping for more information. Clicking on a surface attribute in the Input\\npane will automatically display that attribute as the color of the parent surface. In the map\\nwindow there are 3 options:\\nContours  will only change the color of the fill at the contours\\nBold  will only change the colors at the bold contours.\\nSmooth  Colors will change gradually across the surface.\\nContouring method\\nOnly available in map window. It controls the method for creating the contours:\\nClassic  Traditional Petrel algorithm. Good for fast screen quality visualization. Compatible with\\nolder Petrel version objects. Enhanced  newer method that supports more detail and faulted 2D\\ngrids. A Refinement can be specified and a Fault polygon set can be dropped in; will refine the\\ncells of the underlying grid (1= no refinement; 2=divides the cell in 2x2). Note: A large number\\nwill slow down Petrel performance.\\nHistogram tab (Gridded Surfaces)\\nThe Histogram tab is identical to that for well logs, see Histogram Tab.\\nColors tab (Gridded Surfaces)\\nThe Colors tab gives the option to set a continuous color table for the surface in the Display\\nwindow. All objects of the same category (Z-scale, e.g. depth or thickness) use the same color\\ntable.\\nTo use the whole color scale for the selected object, click on Set by Max and Min arrows to\\nobtain the max and min values from the selected object.\\nTo be able to work with the colortable locally the 'Override global property template' must be\\nchecked.\\nFor further information on the various color table options, see Color tables.\\nSurface settings for Histogram and Function\\nwindows (Gridded surfaces)\\nThese settings are only available when a Histogram or Function window is active.\\nReset icon : Resets all settings to default.\\nOpen viewport settings icon : a shortcut to viewport settings for the function or histogram\\nwindow.\\nHistogram: Available for Histogram windows. Options to set color type, color and pattern for the\\nhistograms and color type, line width and point type/size for the cdf (cumulative distribution\\nfunction) and the line display.\\nCross Plot: Available for Function windows. Options to set color type, color and point type/size\\nfor the cross plot. There is also an option for specifying whether or not points are allowed to be\\nremoved from the plot.\\nOperations tab (Gridded surfaces)\\nFrom this tab it is possible to make it possible to perform calculations and operations on the data,\\nsee Operations tab for information on this tab.\\nCalculations tab (Gridded surfaces)\\nThe Calculations tab includes some of the most used operation.\\nMore tab (Gridded surfaces)\\nLists some of the more commonly used operations for surfaces,\\nSee More tab for information on this tab.\\nVariogram tab (Gridded surfaces)\\nA variogram and a sample variogram can be generated from the Variogram tab.\\nVariogram type: Selection of different mathematical methods to use for the calculations. For\\ninformation about the methods see Variogram types.\\nWhat to generate: Selection between generation of variogram map or sample variogram.\"},\n",
       " {'header': 'Tabs ',\n",
       "  'content': 'Hints tab: Tab with some information and hints for the variogram analysis.\\nTransform tab: Tab for manipulation of the data values before or after calculation. For\\ninformation about transformations see Transformations Available.\\nOrient. tab: Tab for specification of the orientation and tolerances for the data sampling. By\\nselecting Isotropican omni-directional variogram will be calculated\\nXY range tab: Tab for specification of number of lags and maximum search distance in the XY-\\nplane.\\nOverwrite last: This option will allow overwriting of the last generated variogram map or sample\\nvariogram.\\nExecute: Will execute the calculation.\\nMore information about generating variograms is available in Variogram analysis (Data Analysis).'},\n",
       " {'header': 'Line Data Settings ',\n",
       "  'content': 'Line Data imported to Petrel can be a seismic interpretation representing a horizon, fault sticks,\\nfault lines, boundary lines or cultural data. Basically any kind of line data on an ASCII format can\\nbe imported.\\nDifferent line data are described with different icons in the Input pane. Some examples:\\nOne single line\\nOther; a general polygon icon\\nSeismic 3D lines (not interpretation)\\nBoundary polygon\\nContour lines\\nErosion line\\nFault polygon\\nFault line or center line (used in Make/edit surface)\\nFlow line (used in 3D property modeling)\\nFault sticks\\nZero lines\\nMany of the tabs (Except the Style tab) are similar to that shown for points, lines and surfaces.\\nFollow the links below for more information.\\nInfo tab\\nStatistics tab\\nColors tab (Gridded surfaces)\\nOperations tab\\nCalculations tab (Points, lines and surfaces)\\nStyle tab (Line data)\\nPoints - Options on how to display points. Points on Line Data mark the end or corner points of\\nthe lines. By selecting to show all points, all breaks in the curves are represented with a point.\\nThe filter option for Line Data gives the opportunity to show all points, only end points, every\\nnthpoint or every nthpoint, as well as the end points. The n-factor is set with the number in the\\nShow every point box.\\nThe user also have the option to specify the material and transparency for the polygon for use in\\nthe map viewport.\\nLines - Options on how to display lines. The filter option for Line Data gives the possibility to\\nstraighten out lines by displaying them with fewer points. The n-factor is set with the number in\\nthe Show every box.\\nFill inside - Option to add a filling inside polygons. Only available when the polygon is displayed\\nin a intersection, interpretation map or plot viewport.\\nTransparency, color and pattern from attribute - Options to control display behavior for the fill\\ninside the polygon when the polygon is displayed in a intersection, interpretation map or plot\\nviewport\\nAttribute labes - Options to control the labels when the polygon is displayed in a intersection,\\ninterpretation map or plot viewport'},\n",
       " {'header': 'Point Data ',\n",
       "  'content': 'Point data imported to Petrel can be well tops imported to Petrel as XYZ data, isochore points,\\netc.\\nPoint data is described with the icon in the Input pane. By double clicking on this icon, the\\nSettings window is opened.\\nMany of the tabs (Except under theStyletab) are similar to that shown for points, lines and\\nsurfaces. Follow the links below for more information.\\nInfo tab\\nStatistics tab\\nColors tab (Gridded surfaces)\\nOperations tab\\nCalculator tab (Points, lines and surfaces)\\nVariogram tab (Gridded surfaces)\\nStyle tab (Point data)\\nThe Style tab for point data is the same as that for well tops, seeWell Top Settings.'},\n",
       " {'header': 'Info Tab (Point Data) ',\n",
       "  'content': 'The Info tab is similar to that described for Gridded Surfaces. In addition, if the data is editable,\\npressing will open the point editor spreadsheet. If pressing the icon, the point attribute\\ncalculator will open.\\nPoint well data and Checkshots\\nCheckshots and point well data have essentially the same display options in Petrel and share\\nmany display options with well tops, see Well Top Settings\\nThe only exception to this is the style in the well section window where lines can be displayed\\nshowing the depth at which the point data is measured.\\nObject attributes\\nSurfaces, point dataset, polygons and well tops are all object types in the Input pane that have\\nthe option to have attributes attached. These will be listed under the Attributes sub-folder and can\\nbe displayed and edited using the Attribute Spreadsheet (available by right clicking on the object).\\nNew attributes can be created by right-clicking on the Attribute folder. Select Insert new\\nattribute. A menu opens up and the user can select which type of attribute to insert. The types\\nof attributes avialble depends on the objects type bu are typical Discrete, Continuous,\\nBoolean, String, Date, Derived and Dip/Azimuth.\\nSurface attributes\\nCreation of new attribute.\\nTo create a new attribute, right click on the surface and select -\"Insert new attribute\".\\nOptions available for surface attributes are:'},\n",
       " {'header': 'Discrete Continuous ',\n",
       "  'content': 'How to add another surface as an attribute:\\nSurface attributes can also be used to take values from one surface and use as an attribute for\\nanother surface.\\nSee Texture Mapping for details.\\nPolygon attributes\\nCreation of new attribute.\\nTo create a new attribute, right click on the polygon and select -\"Insert new attribute\".\\nOptions available for polygon attributes are:'},\n",
       " {'header': 'Discrete Continuous Boolean String Date ',\n",
       "  'content': 'Imported or created attributes can be used for filling polygons with colors and/or patterns:\\nNew text labels are also implemented for polygons in Petrel 2010.1. They provide information about\\nvalues of attributes associated with polygon and can be displayed in the Map window. Position of\\nthese labels is assigned automatically or interactively adjusted by moving them in Map window.\\nResults of volume/area calculation on surfaces can optionally be automatically assigned as\\nattributes on boundary polygons:\\nPoint attributes\\nCreation of new attribute.\\nTo create a new attribute, right click on the point dataset and select -\"Insert new attribute\".\\nOptions available for point attributes attributes are:'},\n",
       " {'header': 'Discrete Continuous Boolean String Date ',\n",
       "  'content': 'Dip Angle and Azimuth\\nUse the calculator or the Spreadsheet to add vaues to the attributes.'},\n",
       " {'header': 'Wells ',\n",
       "  'content': \"All wells imported or created in Petrel are stored under the Wells folder . The user can choose to\\ncreate sub folders in order to organize the wells in the project. Simply right-click on the Wells\\nfolder and select Insert folder , a sub folder will be created. Each wells folder will control how\\nthe wells within that folder are displayed.\\nWhen inserting a main Wells folder (there can only be one in each project), a sub folder for the\\nGlobal Well Logs is added to the Wells folder. The Global Well Logs folder lists all the logs\\nassociated with the wells. The Global Well Logs folder is a filter for the well logs and is therefore\\nshown in yellow in the Input pane. These are the global settings.\\nWhen a well is imported into Petrel, a sub folder for the well is added to the wells folder. The\\nindividual Well folders are listed with the well name and contain the logs for the specific well.\\nThese are the local log settings.\\nIn the Global Well Logs folder, all well logs are listed with a template icon and name. For further\\nuse of the well logs, it is recommended to assign the correct well log name and template to each\\nlog. This information is shown in the Info tab for each log, but the name can only be changed in\\nthe Global Well Logs folder. For further information on how to assign a well log template and the\\ncorrect log name, see Templates and well logs .\\nFor global calculations on well logs, use the calculator found on the right-click menu under the\\nGlobal Well Logs folder (or use the calculator icon under the Info tab in the settings menu for\\nGlobal Well Logs). To locally calculate on a log for one well only, the calculator found on the pull-\\ndown menu for that specific well, or the one under the Info tab in the settings menu for the\\nspecific well, should be used.\\nThe settings menu is described for the Wells , and the sub folders, Well Log (under well),\\nGlobal Well Logs and Well Log (under Global Well Logs) separately. Double click on these\\nobjects in the Input tab to open the settings window for that object.\\nSettings for Wells folder\\nThese are the settings for all wells. Individual well folders have an almost identical settings dialog\\nexcept for the Style and Thickness tabs which are not present. These functions apply globally\\nfrom the main wells folder.\\nStyle tab (Wells)\\nStyle for the Well Path , Well Symbols , Track and Error Cone can be set in the Settings for\\nthe Wells folder or subfolders. If the Well Design process is active, then settings can also be set\\nfor displaying dog-leg severity and design points for proposed (designed) wells.\\nPath: Options for displaying the well path. The color, line type and pipe width can be\\ndefined.\\nThe colors for the wells are chosen under Color (as long as the dog leg severity coloration\\nis not active). As well means that the wells will show their own color, as defined in each\\nwell's settings window. If the paths color option As folder is chosen for a sub-folder, all\\nwells in that folder will get the color of the folder (can be changed under the folders info\\ntab). Using Z-values , will show the depth variations along the path. White or Black are\\nthe two other options. In a Map window, it is also possible to color well paths according to\\nthe zones in the active model or the active contact set using As Zone and As Contact\\nrespectively. The color of each individual well is defined in each well's settings window.\\nTrack: Option to draw a band next to a well trajectory for displaying well logs and\\nannotation. Define color , material , transparency and Track width . The track will\\nalways be shown 90 degrees from the angle of view. It also gives the user an option for\\ndisplaying depth annotation next to a well trajectory. The annotation will be on the right\\nside when the tick marks are chosen on the right side or on both sides. The annotation will\\nbe on the left side only if the tick marks are shown on the left side only. Set the increment\\nand font size . The Values can be set to Z-units or MD-units .\\nError Cone : Option to visualize a cone along the well path to simulate the error\\npropagation during the drilling operation. The different colors to be chosen are the same as\\nfor the path. Set Material andTransparency . Specify a constant describing the Error\\npropagation per 1000 distance units (MD) in the horizontal and vertical directions (as a\\ndefault these will be the same), or a log describing the absolute error. There is an option to\\nspecify a starting MD for the error propagation. Note: If the vertical exaggeration in the 3D\\nview is not equal to 1, this cone will appear to be oval.\\nHow to set the symbol for wells\\nSymbols: Options to specify the symbol and label size, color and position\\nHistogram: This option is only available when a Histogram or Function window is active.\\nUnder Histogram there is an option to set color type (Specified, As well, Different, Black\\nand White), color and pattern for the histograms.\\nFor Cdf and Line color type (Auto, Specified, As well and Black), line width and point\\ntype/size can be set.\\nCross Plot: This tab is only available when a Function window active. There is an option to\\nset color type (Specified and As well), color and point type/size or the cross plot .\\nThere are also options for specifying if points are allowed to be removed from the cross plot\\nand set different point types for each well.\\nHow to set the symbols for wells\\n1. Close all your open dialogs.\\n2. Go to Tools in the top menu.\\n3. Open the System Settings.\\n4. Click on the Company Profiles tab, and select the well symbols you wish to use from the\\ndrop-down list.\\nWhen the settings are chosen, they will be used for all the projects on the PC. The settings do not\\nfollow the project.\\nNote : It is now possible to generate customized well symbols for use in Petrel. A new\\nexternal XML file stores all the attributes associated with the well symbols. A new well symbol\\nimage can be added simply by inserting the image file in the appropriate file, in the Petrel\\ndirectory. The well symbol for the viewers should be generated in .png format, and the\\nrecommended file size should be no greater than 128 x 128, although the user is free to add\\nhigher resolution images at the cost of using more memory. A duplicate low-resolution image\\nmust also be provided, in order to view the symbol in dialogs and legends. In addition, it is\\npossible to change the label for existing well symbols in the list, by editing the external file.\\nDetails of how to add and manipulate the files are provided in the header of PetrelSymbolFile.xml,\\nin the Petrel installation directory. Once the appropriate images have been generated, the next\\ntime Petrel is opened, the new symbol will appear on the drop-down menu list in the Well\"},\n",
       " {'header': 'Settings. ',\n",
       "  'content': 'Info tab (Wells)\\nThe Info tab gives general information about the wells. The Info window is equal for all objects\\nin Petrel and contains information about the wells file name, color, associated icon and the type of\\ndata.\\nPressing the show Spreadsheet icon will open the Well Manager.\\nIf pressing the Calculator icon, the Well Log calculator will open.\\nTime tab (Wells)\\nThis will determine the time-depth relationship used for displaying the wells in time. All the\\npossible sources of such a relationship (check shots, well tops, sonic logs etc.) are listed in the\\nwindow and can be set in order of preference. For each well, the highest available item on the list\\nwill be used as the time depth relationship. To change the priority list, simply move the objects up\\nor down using the arrows. Make sure the data used are also checked. Click Run to apply the time\\n- depth relationship.\\nApply to all wells can be used if you are applying the time-depth relationship at the local well\\nlevel and want to apply the same settings for all other wells.\\nManual adjustment can be used to stretch or squeeze the time section by adjusting the time-\\ndepth relationship. This is used when events can be correlated between the synthetic seismic and\\nthe extracted 2D lines or 3D seismic cube.\\nShared checkshot : Use this setting if you want to apply a time-depth relationship from a\\ncheckshot belonging to a different well in the project. Drop in the checkshot well name for the\\nappropriate well stored under checkshot, well filter folder under global well logs. Press Run to\\ngenerate a new time log for the target well.\\nLock calculated logs : Checkbox to break all links to the input data so that the time log will not\\nbe updated if the input data changes after it has been activated.\\nThickness tab (Wells)\\nThis tab allows the user to define stratigraphic dips through the geological sequence along the\\nwell path. Once this is defined, Petrel will use this, together with the dip and azimuth of the well\\npath, to calculate True Vertical Thickness (TVT) and True Stratigraphic Thickness (TST).\\nDip and azimuth data can be assigned using well tops or using dip and azimuth logs . When\\nusing dip and azimuth logs, the two logs will be sampled at the same points. Petrel will interpolate\\ndip and azimuth between the points at the spacing specified in Sample Rate using the shortest\\ndistance between two poles on a sphere.\\nLogs of dip and azimuth can also be created to display the interpolation that has been done. It\\nmay be useful to use a combined log to display these, see Combined Well Logs.\\nPress Run to perform the calculation.\\nTST, TVT and the output logs will be updated automatically as the input data is edited. If no\\ndip and azimuth data is available it can be created based on the intersection of surfaces with the\\nwell path. See How to calculate dip and azimuth from a surface and the well paths .\\nStatistics tab (Wells)\\nAvailable statistics for the wells are listed in the Statistics tab. The max and min values for the\\nXYZ-axis of the object are listed under Axis .\\nAll available statistics are listed under Description. The description comprises different information\\ndepending on object. For wells, the number of wells is listed.\\nAll statistics lists can be copied to the Output sheet and exported to another application see'},\n",
       " {'header': 'Gridded Surfaces . ',\n",
       "  'content': \"Operations tab (Wells)\\nOperations are available both on the main Wells folder and on each individual well.\\nDynamic Information about Zmin , Zmax and Dz is given in the top of the window.\\nEliminate outside will cut the well trajectories and all the associated well logs to only cover the\\ninterval given in Top limit and Base limit . Select the given interval (using constants or\\nsurfaces) and click on Eliminate.\\nWhen the operation is done in the settings window for the main Wells folder all the wells will be\\neliminated to the given interval. If the operation is done for one well only, this will be set to the\\ngiven interval.\\nSmooth trace will smooth the trace on a well and is a useful option if the well was imported with\\ntoo few decimals. If that is the case, the well trace may be given a staircase appearance and the\\nMD values will be consequently wrong (if imported from a different file). The operation affects all\\nwells if performed from the settings window of the wells folder.\\nMake logs tab (Wells)\\nThere is an option to overwrite existing synthetic well logs.\\nMake discrete zone logs from zones of a 3D grid : option to make a synthetic zone log from\\nthe main zones, all zones or from all layers, from the active 3D grid. The zone log is a log with\\ninteger numbers from the upper zone, increasing downwards. Create the log by clicking on Make\\nzone log . The log is added to the Well folder.\\nMake continuous log from the properties of a 3D grid: Select the 3D Property model to\\nmake a synthetic well log from. The log values will be sampled from the values of the cells\\npenetrated by the well. Create the log by clicking on Make logs button. The log will be added in\\nthe Well folder. Refresh the property list if the active 3D grid has been changed by clicking on the\\nicon for Refresh .\\nOne value per cell along the well path will be picked, which of course means that a finer vertical\\nresolution of the 3D grid gives a more heterogeneous selection of values.\\nFigure 1. Make synthetic logs process from 3D properties.\\nFigure 2. Make synthetic logs process from zones or layers in a 3D grid.\\nFigure 3. Make synthetic log (single well) process from other logs in other wells.\\nHow to make synthetic logs\\n1. Select a well or the Wells folder in the Explorer Input pane and open the Settings dialog by\\ndouble clicking on the icon.\\n2. Select the Make logs tab and decide whether to make logs from properties, zones or other\\nlogs.\\n3. Check the option to overwrite existing synthetic well log if preferred.\\n4. To make logs from properties, check the appropriate property boxes and press the Make\\nlogs button.\\n5. To make a discrete zone log from zones, specify zones and press the Make zone log\\nbutton.\\n6. To make a new log from other logs or other wells, select those and press the Make log\\nbutton.\\n7. When finished, close the window.\\n8. The log will be added in the respective well log folder (with Synthetic as suffix) and Global\\nWell logs folders.\\nHow to calculate dip and azimuth from a surface and the well paths\\n1. Open the Wells settings dialog and browse to the Report tab.\\n2. Drop the surfaces you would like use to calculate dip and azimuth from the project into the\\nlist box by highlighting them in the explorer and pressing Output tab (Horizon).\\n3. Under Settings for 'Iconize points as' select Active well tops as 'Other' and press Run.\\n4. Open the Thickness tab for the Wells folder and select the active well tops as the input and\\npress OK.\\n5. View the well tops Spreadsheet to see the result.\\n6.\\n4.\\n5.\\n6. Open a well section window - the section can now be displayed in TST or TVT.\\nHow to export well deviation coordinates as a text file\\n1. Open the pull-down menu for a standard or Proposed well, by clicking on it with the right\\nmouse button.\\n2. Select the Export option and the Export as dialog will pop up.\\n3. Enter file name. The file type (format) can be selected from the drop-down menu. Proposed\\n(designed wells) have some more options on different formats than standard wells.\\n4. Press Save and the coordinates will be exported in the given format.\\nHow to export coordinates to MS Excel\\n1. Open the pull-down menu for a standard well or a Proposed well by clicking with the right\\nmouse button on the well.\\n2. Select the View Spreadsheet option and the Well deviation survey will pop up.\\n3. Select the rows and columns of data to export, and copy them by using Ctrl+C or the copy\\nicon .\\n4. Open MS Excel and paste the data into a spreadsheet.\\n5. Operations made in the Operations tab for a specific well will only affect the specific well. It\\nwill mainly cut the well trace and associated data at a given constant or surface level.\\nSpreadsheet for well deviation coordinates of a Proposed (designed) well.\\nSpreadsheet for well deviation coordinates of a Standard well with two rows selected for copy.\\nSettings for well\\nDouble-click on the specific Well under the Wells folder in the Explorer Input pane to get access to\\nthe settings window for the specific well.\\nInfo tab (Well)\\nThe Info tab contains the Well name, unique well identifier (UWI) and the well symbol. The Info\\ntab for a specific well is similar to that of the Wells folder. One difference is that calculations made\\nwith the well calculator will affect only this well. Pressing the show Spreadsheet icon will\\nopen the Deviation survey for that particular well (instead of opening the Well Manager as for the\\nWells folder). The Spreadsheet contains detailed information about X, Y, Z, MD, inclination,\\nazimuth, dx, dy, tvd, twt and calculated DLS (dogleg severity) for each point in the well trace. The\\ninformation can be edited and, once applied, will have an impact on the well trace.\\nThe user is given the opportunity to append or remove rows or columns above or below the\\nmarked line and to copy the selected rows and columns to the clipboard. Although data may be\\nread in any format, the user may only add or edit data in the format it was created (e.g. XYZ or\\nMD, Dip, Azimuth).\\nSettings tab (Well)\\nThe Settings tab can be used for positioning of well header information.\\nFirst MD: allows the user to define a first MD value in the well trace if the 'Trace is curved\\nabove first point' is checked. If a well is vertical there is no need to use this option, as TVD\\n= MD. If the well is curved, and a MD value is typed, the first MD value in the deviation\\nsurvey of the well Spreadsheet is updated (not added).\\nPosition: Type in X and Y location of the well location. Also KB (Kelly Bushing) values can be\\ntyped in (to elevate from MSL - Mean Sea Level).\\nReposition well tops, checkshots and trace - makes sure that the well trace moves to the\\nnew well head position if changes are made. Switch this option off to keep the well logs in\\nposition even if you enter new coordinates.\\nReposition logs and completions - makes sure that the well logs moves along the well trace\\nto the new position according to the new KB value entered. Switch this option off to keep\\nthe well logs in position even if entering a new KB value.\\nBranch assignment: The well can be branched off as a lateral well from a main well. Make\\nsure to drop in a main well (should overlap) using the Blue arrow.\\nStatistics tab (Well)\\nThe Statistics tab is similar to the one described for wells. Under Description the user will find\\nmore detailed information for the specific well such as KB-level, length of the well, number of\\nsample points, number of logs associated with the well and more. All statistics lists can be copied\\nto the Output sheet and exported to another application.\\nOperations tab (Well)\\nThe Operations tab for a specific well is similar to that of wells. Operations made in the Operations\\ntab for a specific well will only affect the specific well. It will mainly cut the well trace and\\nassociated data at a given constant or surface level.\\nTime tab (Well)\\nWell time defines which data is to be used to define the time depth relationship for the current\\nwell. The list contains all of the relevant data available on the current well to build a time depth\\nrelationship. The object at the top of the priority list will be used to build the relationship. If the\\ntop item on the list is not available for that well, Petrel will move down the list and use the next\\nchecked item as the relationship.\\nOverride global settings: This must be checked if an individual time depth relationship is used\\ninstead of the one used in the main Wells folder.\\nLock calculated logs : This will make the resulting logs static (default is dynamic); this breaks\\nall links to the input data so that the time log is not updated if the input data changes.\\nUnchecking it will establish the dynamic behavior again.\\nNote that Petrel (when applying the settings in Time tab) will generate a dynamic Time log\\nwhich is normally updated when the time depth relationship settings change.\\nManual Adjustment: Edited well tops, or more commonly a second checkshot survey, can be\\ninserted to apply a Manual Adjustment to the time depth relationship. This is commonly used as\\nfine tuning after synthetic seismograms have been correlated with the seismic.\\nShared checkshot: If the specific well does not have any checkshots or sonic data to be used for\\ntime depth relationship, the checkshots from another well can be used by checking the box.\\nFor a description of the settings for designed wells see Settings (Designed Well) .\\nReport tab (Well)\\nThe Report tab for a specific well is the same as for wells, see Make Logs tab (Wells) . Using this\\noption will only make a report on the specific well.\\nMake logs tab (Well)\\nThe Make Logs tab for a specific well is the same as for wells, see Make Logs tab (Wells) . Using\\nthis option will only make logs for the specific well.\\nSettings for Global Well Logs\\nDouble-click on the Global Well Logs in the Explorer Input pane to access the settings window.\\nInfo tab (Global Well Logs)\\nThe Info tab for the global well logs is similar to that of wells. The only difference is that\\ncalculations made with the global wells calculator are only applicable for the global well logs.\\nStatistics tab (Global Well Logs)\\nThe statistics window for the global well logs is similar to the one for the wells. However, under\\nDescription, only the number of logs are given.\\nSettings for logs under well logs\\nDouble-click on the specific Well Log under the Well folder in the Explorer Input pane for access to\\nthe settings window for the specific Well Log.\\nStyle tab (Well Logs)\\nThe reset option at the top of the window sets the options back to default. As a default, the\\nsettings here will control how all logs attached to the template are displayed. Toggling on and off\\nApplying to all similar objects in the project , is an option to copy these settings and\\napply them to all other objects which are similar in the entire project. Toggle on/off Applying to\\nall similar objects in the folder is an option to copy these settings and apply them to all\\nother objects which are similar in the folder. Set the settings as default sets these settings\\nas default for all wells in the project.\\nThe Style tab is split in 3 sub tabs, all activated by the selection of drawing logs as 3D pipe or in\"},\n",
       " {'header': '2D: ',\n",
       "  'content': \"General Settings tab:\\nMin value - set the scale to a min. number\\nMax value - set the scale to a max. number\\nMax width - sets the width of the log in an Intersection window in number of points (ppt)\\nReverse - will reverse the log display\\nSet default - will use the max and min values of the selected log\\n3D log tab If the 'Draw log as 3D pipe' radio button is selected the, this tab will be active.\\nColor- will set the color of the log in 3D. Options are As property, specified, Z-values, Black and\"},\n",
       " {'header': 'White. ',\n",
       "  'content': 'Material- will set the look of the color. Options are Plastic, Bright Plastic, Metal, Wood and'},\n",
       " {'header': 'Highlight. ',\n",
       "  'content': \"2D Log tab If the 'Draw log as 3D pipe' radio button is selected, this tab will be activated.\\nLog Curve: Options on how to display the log curve. In 3D the curve will always be shown\\n90 degrees from the angle of view. The color, line width and line type can be set.\\nLog Points: Options on how to display points on the log curve. In 3D the points will always\\nbe plotted 90 degrees from the angle of view. The color, point size and point type can be\\nset.\\nLog Curve Filling: Options on how to display a filled log curve. The curve will always be\\nshown 90 degrees from the angle of view.\\nFor more information about displaying well logs in the well section window see Log Curves.\\nInfo tab (Well Logs)\\nThe Info tab for the well logs is similar to the tab for global well logs. One difference is that\\ncalculations made with the logs calculator are only applicable for the specific well logs. For the\\nGlobal Well log, the name and Template can be set. For the local well log, only the global log itself\\ncan be changed. However, there is also a shortcut option to show and edit this global well log by\\ngoing to the attached color table settings .\\nStatistics tab (Well Logs)\\nThe statistics tabis similar to the tab for Wells. Some additional information is given under\"},\n",
       " {'header': 'Description. ',\n",
       "  'content': 'Histogram tab (Well Logs)\\nA Histogram showing the data distribution is available for the most data objects in the Input\\npane.\\nThe histogram for the well logs, in the Global Well Logs folder, shows the statistics for all the well\\nlogs of this type. While the histogram for the well log in each well shows the statistics for the log\\nof the selected well. Discrete logs are sampled at 0.5 unit intervals in the histogram. This applies\\nto those discrete logs that can be edited in the well correlation process. The re-sampling avoids\\nskewing of the population distribution due to possible irregularity of sampling intervals.\\nFor continuous logs the user can choose:\\nX-axis bins:\\nIntervals - the data range will be split into this number of intervals.\\nInc (Increment) - the data range will be split using the chosen increment.\\nIncrements or intervals can be set in logarithmic scale on the x-axis by checking Log.'},\n",
       " {'header': 'Scale ',\n",
       "  'content': 'Max / Min - by default the range will be defined the maximum and minimum values in the\\ndata. Activating Max and Min allows the user to specify the range. After setting the Max and\\nMin values you must use the refresh button to apply these changes.\\nPercent - Check the % box to set percentage on the Y-axis instead of number of\\ndatapoints.\\nPrint - Print a copy of the histogram.\\nCopy Bitmap - will copy the histogram view to the clipboard. This can then be pasted\\ninto the input pane and displayed on Maps and Plots.\\nColors tab (Well Logs)\\nIs only available for Global Well Logs. If some changes are to be performed on the local log,\\nrevert to the Info tab and change the global template settings from there.\\nThe procedure for how to set a discrete color table is described in Discrete color tables.\\nOperations tab (Well Logs)\\nMinimize Log Size: The option Remove Equals, will remove consecutive points that have the\\nsame value of this well log in all the wells. This will produce smaller logs that are faster to operate\\non.\\nResample Log Points: The points will be re-sampled at the requested interval in project unit\\ndepth. With discrete logs there is also the option to resample as a continuous log, that is, with\\nconstant intervals rather than just at picked points. Click the Resample button to perform the\\noperation.\\nThis operation will change the data in your logs and some may be lost. If you are uncertain\\nof the result, use the calculator to make a copy of the logs before applying operations.\\nRemove log Spikes: This will remove single points in the well which are surrounded by\\nundefined values.\\nAdd values from other log: If another global log with the same template exists, values from\\nthis new log will overwrite the existing log unless it has undefined values; then the original log\\nvalues from the existing log will be used. Hit the Run adding button to perform the operation.\\nBlock/Unblock Logs: This setting will toggle between treating continuous logs as standard lines\\nor blocked logs. Blocking should be used if the value at a point represents the average value down\\nto the next point. Only visual blocking is performed.\\nSettings on logs in specific wells\\nDouble-click on the specific Well Log, found under the specific Well folder in the Explorer Input\\npane to get access to the settings window for the specific Well Log.\\nStyle tab (Specific well logs)\\nThe Style tab is generally the same as for the logs under global well logs, see Style tab (Well\\nLogs). As a default, the lock button will be on, and in this case, the style will be controlled by\\nthe global well log. Unchecking this will allow the style for the log in this particular well to be\\ncontrolled independently.\\nInfo tab (Specific well logs)\\nThe Info tab is the same as for the logs under global well logs.\\nStatistics tab (Specific well logs)\\nTheStatistics tabis similar to that for the logs under global well logs. Additional information about\\nthe log in the specific well is presented under Description.\\nHistogram tab (Specific well logs)\\nThe Histograms tab is the same as for the logs under global well logs, but the histogram for the\\nwell log in each well shows the statistics for the log of the selected well .\\nOperations tab (Specific well logs)\\nThe Operations tab is the same as for the logs under global well logs, but the operations will only\\nbe applied on the well log of the selected well, Operations tab (Well Logs).'},\n",
       " {'header': 'Well Top Settings ',\n",
       "  'content': 'Well tops have the standard Info and Statistics tabs, in addition to Settings and Style tabs. On\\nthe Info tab, there are icon links to the Well Tops Spreadsheet and to the well Tops calculator\\n.\\nThe Style tab changes according to the active window.\\nPoint data and points with attributes share many of the same settings as well tops.\\nStyle tab (Well Tops - Well Section window)\\nThe Style tab gives options on how the well tops are displayed.\\nLine - how the line is drawn between well tops in the well section window.\\nInter well - Option to show lines and/or color fill (of zone stratigraphy) between the lines\\nbased on the active Well tops.\\nShow lines - Option to show the well top horizon lines bewteen wells in the Well\\nSection window.\\nShow color fill - Option to fill color between wells, given by the zone settings in the\\nWell Tops folder. The zone fill can be done at different levels:\\nZone levels 1, 2, 3 etc (depends on how many levels are interpreted in the'},\n",
       " {'header': 'Stratigraphy). ',\n",
       "  'content': \"Zone level Max (takes the highest zone level number found).\\nSymbol - the type and style of the symbol to be displayed at the well top.\\nLabels - the size and color of well top labels. The sub labels refer to the water mark label\\non each well.\\nNote that Color and Font size could be specified for both the main label and for thenot sub\\nlabel. In addition, if the Bold option is used, Petrel will reverse the selection logic of a well top\\nhorizon (active well top will not be bold).\\nStyle tab (Well Tops - 2D/3D window)\\nIn the 2D and 3D windows the settings are as follows:\\nSymbols and Number annotations:\\nColor - choose between coloring the well tops according to attribute, horizon, well, Z-values\\n(depth), white or black.\\nSymbol - choose between displaying tops with the well's symbol, the symbol assigned to\\nthe top, spheres, cubes or squares (recommended for objects with very large amounts of\\ndata).\\nSize - the size of the well tops in 2D/3D display.\\nMaterial / transparency - the appearance of the well tops in 2D/3D display.\"},\n",
       " {'header': 'Depth ',\n",
       "  'content': 'Show discs - this allows the user to display well tops as flattened discs so that dip and\\nazimuth information becomes apparent. The ratio of horizontal and vertical radius should be\\ngiven.\\nShow sticks - this allows the user to display well tops as sticks. There is an option to show\\nboth the strike and an arrow. This is useful when well tops are densely spaced.\\nNumber annotation - choose whether or not to display a label value, and how that value\\nshould be displayed. There is a button to press for 2D display of the annotation so it is\\nalways parallel to camera view. The value to be displayed is selected in the Explorer Input\\npane.\\nBy selecting Filter visible wells only well tops associated with the visualized well traces will\\nbe displayed in the active window.'},\n",
       " {'header': 'Statistical Information ',\n",
       "  'content': 'Select statistical method (Fisher, Kent or Uniform). This option is only available for\\nStereonet windows.\\nStyle tab and Analysis tab (Well Tops -\\nFunction window)\\nThere are a number of options for displaying well tops in Function Window.\\nStyle tab (Well Tops - Map / Intersection\\nwindow)\\nThere are a number of options for displaying well tops in map and intersection windows. The\\noption to use is chosen via the radio buttons at the top of the dialog. There are three different\\noptions; Symbols, Pie charts and Azimuth arrows:'},\n",
       " {'header': 'Symbol: ',\n",
       "  'content': \"Color - choose between coloring the well tops according to horizon, well, depth, black or\\nwhite.\\nSymbol - choose between displaying tops with the well's symbol, the symbol assigned to\\nthe top or any other of the standard geometrical shapes in Petrel.\\nSize - the size of the well tops.\\nOverpost - This option will overcome problems of superimposing annotations in Map or\\nintersection view. Options are:\\n1. Always post - Draw even if items overlap.\\n2.\\n3.\\n1.\\n2. Remove - Will remove items that overlap each other.\\n3. Slightly move - Tries to move slightly overlapping items; if it cannot, it will remove\\none.\\n4. Compass Move - Tries to move items to different compass positions (8 around the\\nitem) before removing items that overlap each other.\\nNumber annotation - choose whether or not to display a label value, and how that value\\nshould be displayed. The value to be displayed is selected in the Explorer Input tab.\"},\n",
       " {'header': 'Pie Chart: ',\n",
       "  'content': 'It is possible to get a pie chart display of your well top attributes if a Map or Intersection window\\nis active.\\nThe first well top attribute selected represents the pie chart radius, and if used with cumulative\\n(or individual fluid) production data, the result will be a simple bubble plot of cumulative\\nhydrocarbon production. If subsequent attributes are added, then they will be used to generate a\\npie chart based on their relative values. Therefore, the attributes should be in the same domain\\n(similar units).\\nThese options are only available for a Map and Intersection Window. These windows must be\\nactive for the option to be shown in the dialog.\\nSize- decides how the pie chart or bubble plot is show in Map view. Size can be selected from:\\n- a fixed size (in ppt), which will keep the same size regardless of zoom.\\n- from an attribute; select an existing well top attribute.\\n- from a cumulative sum of values.'},\n",
       " {'header': 'Azimuth Arrow: ',\n",
       "  'content': 'General color and Style - decides how the pie chart is shown in Map view.\\nArrow - Decide whether to show the arrow or not, and how it should be drawn;\\nFixed size: The arrow will be the specified length\\nDip slope: The arrow length will be calculated from the maximum length and the dip of the\\nwell top (a dip of 0 will give the maximum length, 90 will give zero length).\\nFrom attribute: The arrow length will be set from a third attribute, scaled between the\\nminimum and maximum length.\\nStrike - Decide whether or not to show the Strike direction of the arrow. Select size in ppt.\\nAnnotation - decide whether or not to display the annotation selected in the attributes of the'},\n",
       " {'header': 'Well Tops. ',\n",
       "  'content': 'These options are only available for a Map and Intersection Window. These windows must be\\nactive for the option to be shown in the dialog.\\nHow to make a pie chart on a map\\n1. Open a new Map window.\\n2. Open the settings panel for Well Tops.\\n3. Toggle on the horizon and a well top attribute from the well top folder that you would like to\\ndisplay. Remember to filter under Well Tops Stratigraphy folder.\\n4. Toggle Pie chart under the settings dialog and Petrel takes you to the style page for Pie'},\n",
       " {'header': 'Charts. ',\n",
       "  'content': \"5. Select well top attribute to be displayed and press Apply.\\nHow to make an azimuth arrow plot on a map\\n1. Open a new Map window.\\n2. Open the settings panel for well tops.\\n3. Toggle on Azimuth arrow, Petrel takes you to the Azimuth arrow tab.\\n4. Select well top attribute to be displayed and press Apply.\\n5. Set appropriate settings for Arrow and Strike.\\nSeismic data (Settings)\\nSeismic data can be imported into Petrel in a SEG-Y or ZGY format. To visualize seismic data, use\\ninline, crosslines, timeslices or any Random line. Also, General Intersections can be generated to\\nview the seismic data. Seismic data saved in a Petrel project from Petrel 2005 or earlier version,\\nare saved in the internal raw Petrel format. This can be checked in the statistic stab for the\\nseismic volume under Storage type. Once a cube is imported into Petrel in a SEGY format , it\\nhas to be realized to become a ZGY format (standard in Petrel from Petrel version 2007.1).\\nCropped volumes can be inserted directly under the cube. A cropped volume will be stored as a\\nfolder under the cube in the seismic data folder. The cropped volume will have some Settings\\nwindows equal to the seismic data folder, but in addition, will have a Cropping tab.\\nA seismic virtual attribute volume can also be inserted into the seismic data folder and stored\\nin a similar way to the cropped volume. The seismic attribute volume will have some Settings\\nwindows the same as the seismic data folder, but in addition, will have an Attribute tab.\\nStyle tab (Seismic data)\\nThe Style tab is dependant of whether the data is viewed from the main seismic survey folder or\\ndirectly in SEGY or ZGY cubes:\\nStyle settings for Seismic survey folder  3D survey:\\nIf the Survey folder contains 3D volumes, the 3D seismic annotation subtab will be activated. Set\\nBase map annotation for inlines and crosslines in 2D, 3D and Map windows. Draw every n'th\\ninline/crossline will show a basemap grid with inlines and crosslines displayed with the increment\\nspecified by the user. Text every n't inline/crossline will show the inline and crossline numbers.\\nThe size of the text is controlled from the Font size option. Base Map Annotations will not be\\nshowing if it is not checked.\\nStyle settings for Seismic survey folder  2D lines:\\nIf a seismic survey folder contains 2D lines, the 2D line annotation subtab will be active. Set Base\\nmap annotation for all lines displayed in 2D, 3D and Map windows. Basemap style and Z levels\\nare options available when using 3D windows as 'base maps'. Show lines with a given with and\\nline type in a basemap. Show names will display the line name at the start, end or both.\\nTickmarks can be set at every n'th trace, displayed with either CDP, SP or Trace number.\\nTickmark size can be set when selected.\\nSelecting Hide labels exceeding font size let the user define a value controlling the size of\\nlabels of which they will be hidden when zooming out in the display window. Works for 2D and 3D\\nwindows only.\\nStyle settings for SEG-Y cubes:\\nBase map' annotation  This annotation is, by default, taken from the Style settings of the\\nseismic survey folder. By pressing the lock icon, it will be un-locked and the parent settings can\\nbe overridden.\\nIntersection  Interpolation and decimation of intersetions can be performed:\"},\n",
       " {'header': 'Interpolation ',\n",
       "  'content': 'Interpolation method\\nSmooth interpolation is the default setting for seismic in the 3D window. The user has\\nthe option to turn the interpolation off or to use bilinear interpolation.\\nEnhance intersection resolution\\nThis option will improve the quality of the seismic section. You will use more texture\\nmemory if you enable this option. It is only available for data displayed using the\\nBilinear interpolation method.\\nInterpolate using the edge blending\\nTile blending will give a smooth interpolation across tile borders, where the bricks of\\nthe ZGY volume are tiled together (full neighbor tiles are used, which will decrease\\nperformance slightly).\\nInserting a cropped volume will disable changing this feature. This is done to avoid\\nscenarios where you have different settings in mother cube and cropped volume.'},\n",
       " {'header': 'Visualization ',\n",
       "  'content': 'Enable zone and segment filters for intersections\\nOn a seismic volume attached to a grid this setting enables the use of segment and\\nzone filters to work on the intersections.\\nEnable bump mapping\\nEnables a shading technique on the intersection that enhances features on the seismic\\nslice. It can help the user to see faults on the intersection.\\nEnable transparency for intersections\\nTo be able to control the opacity on the seismic intersection this setting needs to be\\nturned on.\\nMax resolution\\nControls what resolution is used as maximum resolution. If medium resolution is\\nselected you will never see the high resolution seismic.\\nWhen used along with the load into memory option a medium setting will mean that\\nno level of details level 0 (high resolution) will be displayed.'},\n",
       " {'header': 'Performance ',\n",
       "  'content': 'Enable compressed textures\\nCompresses the seismic before it is sent to the graphics card. The compression is not\\nloss-less and should not be used for detailed work. It is especially useful when\\ndisplaying many 2D lines in the 3D window where the option reduces the texture\\nmemory usage.\\nTime to wait for data\\nControls the time the seismic intersection is allowed to wait for seismic data before\\nmoving on to a new position. If your network is too slow to display data while you\\ndrag the intersection, increase the value to allow the slice to wait for more data to\\narrive. A low number will lead to better interactivity with the intersection plane, but\\nthe amount of blank (no data received) tiles will increase. When you sto p moving the\\nintersection, the intersection will eventually display at full resolution.\\nFast scene movement\\nUse the fast scene option to maximize performance when rotating the scene while\\ndisplaying seismic. It will display the seismic intersections with a lower resolution.\\nWhen not enabled the scene will display in full resolution while manipulating.\\nControls if you would like the time to wait controls to be activated while you rotate\\nthe scene. Turning it off can slow down your display while rotating.\\nDecimation while draging\\nThe seismic slice will be decimated according to the selected factor when moving the\\nseismic slice. A high decimation factor will let you browse through large volumes by\\nlooking at a less memory intensive LOD. For SEG-Y or Petrel internal .raw files it will\\nonly display the full resolution.\\nThe Style tab in the Seismic Settings window .\\nAnnotation of seismic lines in a 3D window is controlled also from the seismic cube settings\\nunder the Style tab from Annotation sub-tab. Multiple intersections can be annotated at the same\\ntime. The annotation is not dependent on having the seismic interpretation process active.\\nZGY volumes also have a Volume visualization style tab available, see below.\\nStyle settings for ZGY cubes:\\nBase map annotation  By default, this annotation is taken from the Style settings of the\\nseismic survey folder. By pressing the lock icon, it will be un-locked and the parent settings can\\nbe overridden.\\nThe Intersection settings are identical to the SEGY intersection settings exept the activation of\\nInterpolate using tile edge blending and Enable bump mapping and the deactivation of\\nEnable compressed textures.\\nBut in addition you will have acces to the Volume visualization tab:\\nVolume walls\\nVolume render\\nHide frame/annotation in viewing mode\\nThe Style tab in the Seismic settings window for ZGY data.\\nVolume visualization  options for display of volume walls and do volume rendering.\\nStyle settings for 2D lines:\\nBase map\\' annotation  is unavailable for separate 2D lines. Annotation can only be set from\\nthe Style settings of the seismic survey folder.\\nSEGY style  identical to the SEGY style for 3D volumes.\\nThe Style tab in the Seismic Settings window for 2D line data.\\nInfo tab (Seismic data)\\nSee Info tab for general information on the Info tab.\\nIn addition, it is possible set a new Vintage for the seismic data. Select the wanted vintage from\\nthe Vintages folder and drop it in using the blue arrow.\\nStatistics tab (Seismic data)\\nSee Statistics tab\\nColors tab (Seismic data)\\nThe Color tab gives the option to set a continuous color table for the seismic data on the General\\nIntersections. The color scale for the seismic amplitudes can be compressed by clicking on the\\nscale lines next to the color table, and a new step with an associated color is inserted into the\\ntable. Going to the Non-linear gradient and moving it to the left will compress the color table. In\\nthe Opacity table, transparency can be set to parts of the table. The opacity can be changed using\\nopacity points. For further information on how to manipulate the color table for seismic data.\\nThe Colors tab in the Settings window for seismic objects.\\nOperations tab (Seismic data)\\nSee Operations tab (Seismic data) for information on the Operations tab.\\nGeometry tab (Seismic data)\\nSee Geometry tab (Seismic data) for information on the Geometry tab.\\nOperations tab (Seismic data)\\nThis tab comprises two sub-tabs: Realize tab and Amplitude tab.\\nRealize tab\\nThe Realization tab gives the possibility to create new seismic volumes from the existing volume.\\nThe output will be a new ZGY volume.\\nSet the source amplitude range from:\\n1. as shown above (original value range)\\n2. symmetrical around zero\\n3. User defined range\\nFilter- by checking this option the histogram will remove the spike value from the display only\\n(for conventional seismic this is the crossover/zero value) with a possibility to specify number of\\nbins.\\nNote that the Histogram may not be available, but can be accessed by clicking on the Scan\\nbutton (this scans the entire volume and determines the distribution of amplitudes).\\nRealization quality sets how many bits that are allocated to each trace point. This is especially\\nused for optimizing file transfer and file size. Options are Floating point 32-bit, Integer 16-bit and\\nInteger 8-bit.\\nBy clicking the Realize button the actual Realization operation will be performed.\\nFigure 1. Realize sub-tab under Operations tab for a SEG-Y volume.\\nAmplitude tab\\nIn this tab the amplitude range can be set manually or the Scan and Rescan buttons can be used\\nto determine the amplitude range from the data.\\nGeometry tab (Seismic data)\\nThis tab is used to quality check the lateral geometry, i.e. the origin and end points of inlines and\\ncrosslines, as well as line interval and rotation.\\nAlso the vertical geometry, i.e. top time/depth value, sample interval (in time or depth units; see\\nProject settings) and bottom time/depth is shown.\\nIf any of the parameters are incorrectly set or need to be adjusted, it is possible to do lateral\\ntranslation and/or rotation if the two following criteria are met:\\nAutomatic line detection method is not used during import of the seismic volume.\\nOnly one seismic volume is present in the survey folder (i.e. only one seismic vintage is\\nused for objects in the survey folder).\\nAn already existing seismic volume can be used to set the geometry for the cube by selecting it in\\nthe Input pane and clicking on the Get geometry from selected button. If the walls\\n(inlines/crosslines) of the seismic volume is not perpendicular to each other this can be set by\\nclicking the Rotate the end of the *line around the origin icon. This rotates the end point\\nof inlines/crosslines around the origin (first inline/crossline start) and makes them perpendicular\\nto the crosslines/inlines, respectively. If any of these operations are performed on the volume,\\ninformation will be put into the Petrel message log.\\nIt is also possible to do a vertical shift or correct the sample interval if incorrectly determined\\nduring import.\\nCropping tab (Seismic data)\\nAfter inserting a \"Virtual Cropped Volume\", it will initially be a copy of the source. The new data\\nset can then be cropped (reduced) to contain fewer lines than the original.\\nFor Inlines range and Crossline range, the range of data can be set: From: First line to\\ninclude in the subset. To: Last line to include in the subset. Skip: How many lines to skip\\nbetween each line that has been included in the subset (i.e. a value of 1 will read the first inline,\\nskip the second and then read the third inline and so on).\\nIn Vertical range, the time/depth range can be specified with a From and a To value. Vertical\\nrange values do not have a skip option for trace decimation.\\nAttribute library tab\\nThe Attribute tab is available from a seismic attribute volume created in Petrel. Select attribute in\\nthis tab and press Apply to change the attribute volume. For details on this tab, see Seismic'},\n",
       " {'header': 'Attributes. ',\n",
       "  'content': 'Interpreted horizon settings\\nThe Style settings tab for interpreted horizons are located under the seismic horizon. An\\ninterpreted horizon has to be linked to a seismic survey. If the interpretation is performed in\\nPetrel, the survey needs to be active so the horizon is able to create an interpretation grid\\nassociated to the survey.\\nStyle tab ( Interpreted horizons)'},\n",
       " {'header': '2D Interpretation ',\n",
       "  'content': 'When dispalying the seismic interpretation in an interpretation window, the interpretation can be\\nshown as Points or Lines. The interpretation is defined by color point/line type and size/width\\n(see How to change the style of the interpretation in 3D for 2D Surveys).'},\n",
       " {'header': '3D Interpretation ',\n",
       "  'content': 'When dispalying the seismic interpretation in a 3D window, the interpretation can be shown as\\nPoints, Triangle surface or as a Cell box. Each Style type has its own settings (see How to\\nchange the style of the interpretation in 3D for 3D Surveys).\\nIt is possible to change the Resolution for all styles used. By selecting the Interactive check\\nbox, the Min - Max slider bar for the resolution can be changed interactively. From the drop-down\\nmenu, a Uniform (all displayed interpretation has the same resolution), Focused (displayed\\ninterpretation in your line of sight is the last to lower its resolution) or Mixed (a mixture of the\\ntwo) resolution will be applied when you are using the slider.\\nFigure 1. Fig. 1 Style tab for a horizon interpretation.\\nAvailable colors for 2D interpretation (points / lines) and 3D interpretation are Z-values\\n(elevation time or depth), Specified (color defined in the Info tab) or Standard color (a\\nstandard color (green) for horizon interpretation optimized for display in an interpretation\\nwindow).\\nInfo Tab (Interpreted horizons)\\nSee Info tab\\nAutotracking tab (Interpreted horizons)\\nThe Autotracking tab is very useful for keeping a backup of the tracking settings of a specific\\nhorizon, or to change the tracking settings while making the interpretation.\\nSee Autotracking settings\\nHow to change the style of the interpretation in 3D for 3D Surveys\\n1.\\n2.\\n1. Double-click on one interpreted horizon.\\n2. Select the Style tab.\\n3. Go to Style under 3D interpretation and select Point, Triangle surface or Cell box.\\nHow to change the style of the interpretation in 3D for 2D Surveys\\n1. Double-click on one interpreted horizon which was interpreted on a 2D line.\\n2. Go to the Style tab.\\n3. Select to display as Points or Lines under 2D interpretation.\\n4. Set parameters accordingly.\\n3.\\n4.\\nNote that when displaying any interpretation in an Interpretation window, points or lines\\ncan be shown for both 2D lines and 3D surveys.\\nGeneral Intersection settings\\nStyle tab (General intersection)\\nDefines how the General Intersection is displayed in the Display window.\\nThe Reset option at the top of the window sets the options back to default.\\nPlane Settings (Style tab General Intersection)\\nWhen Show is checked the plane will be seen as more or less transparent. The plane will only be\\ndefined by its frame when Show is off.\\nThe Only when active option indicates that when this option is checked, the plane will only be\\nshown when the plane is active (bold) in the Petrel Explorer. This is useful if several intersections\\nare made in the current project.\\nTransparency of the General Intersection is also user controlled in percentage from 10 to 90%\\nClip Offset is an option to add an offset limit to the clipping tools (clip in front/behind) in the\\nFunction bar below the Display window. The clipping will clip (remove) displayed objects in front\\nor behind the General Intersection. Data such as surfaces will be removed from the display either\\nin front of or behind the plane, depending on selection.\\nMap line settings are only available when in a Map or an Intersection window. Use these\\nsettings to change the color and/or width of the intersection line in the Map window.\\nInput Settings (Style tab General Intersection)\\nDistance limit: The wells will be projected towards the General Intersection within the user\\ndefined maximum distance ( Distance limit) in project units.\\nSurfaces: Option to view selected surfaces in the Input window as lines in the General\\nIntersection. Select color and width for the surfaces.\\nWells: Option to show selected well trajectories on the General Intersection. Define line width\\nand color.\\nSeismic: toggle on Depth offset will move the intersection a bit further away from the user than\\nit really should be (useful if there are difficulties in observing polygons displayed along traces).\\nPolygons: Option to view polygons with a user defined Ghost limit. Useful e.g. when\\ninterpreting seismic in a Seismic Intersection. It allows the user to decide how many traces to see\\naway from the plane. Note that the interpreted polygons should then be viewed on the plane and\\nthat they fade away the further away they are from the plane.\\n3D-Grid Settings (Style tab General Intersection)\\nHorizons: Option to set color and width of the horizons that are displayed on the intersection.\\nFaults: Option to set color and width of the faults that are displayed on the intersection.\\nZones: Option to set color and width of the zones that are displayed on the intersection. The\\ntransparency can also be adjusted on the zones.\\nApply property filter: When checked, the filter on properties will be activated in the\\nintersection.\\nGrid lines: The grid lines of the 3D model will be visualized on the intersection when this option\\nis checked. Ability to change line color and thickness.\\nWells tab (Well Intersection Fence)\\nThis tab contains settings related to what is being displayed on the Intersection Fence.\\nThe fence should already have been set up in the Well Section. Wells are added, removed or\\nmoved around in the Windows tab under Well Section.\\nThe Wells tab will decide how the fence is aligned:\\nTop - aligned from the top point of all wells in the fence.\\nMiddle - aligned from the middle point of all wells in the fence.\\nBottom - aligned from the bottom point of all wells in the fence.\\nWell Top - option to select a well top under Stratigraphy and drop it into the dialog; fence will be\\naligned along the well top.\\nThere are additional options to Add a second tie point at well bottom; it is useful if aligned\\nalong top or middle and the well is deviated to get more of the intersection along the actual well\\npath. Close fence will close the intersection between the first and the last selected well in the\\nfence.'},\n",
       " {'header': 'Vertical Intersection ',\n",
       "  'content': 'Vertical intersections are a group of intersections:\\nWell Intersection Fence - intersections between wells\\nVertical Intersection - vertical intersections along a polygon\\nVertical Wells Intersection - vertical intersection along a well\\nThe Settings windows for these intersections are quite similar. The Style tab is identical to that of\\nGeneral Intersection, see General Intersection.\\nWells tab (Well Intersection Fence)\\nThis tab contains settings related to what is being displayed on the Intersection Fence.\\nThe fence should already have been set up in the Well Section. Wells are added, removed or\\nmoved around in the Windows tab under Well Section.\\nThe Wells tab will decide how the fence is aligned:\\nTop- aligned from the top point of all wells in the fence.\\nMiddle- aligned from the middle point of all wells in the fence.\\nBottom- aligned from the bottom point of all wells in the fence.\\nWell Top- option to select a well top under Stratigraphy and drop it into the dialog; fence will be\\naligned along the well top.\\nThere are additional options to Add a second tie point at well bottom; it is useful if aligned\\nalong top or middle and the well is deviated to get more of the intersection along the actual well\\npath. Close fencewill close the intersection between the first and the last selected well in the\\nfence.\\nVariogram data\\nVariograms can be made from object data (like points) in the Explorer Input pane or from\\nProperties in the Models pane.\\nA variogram folder is generated when a Variogram tab has been accessed from a property in the\\nactive 3D grid, and a variogram map or sample variogram has been made.\\nWhen creating a sample variogram from, for example, a point data set, the result will be placed in\\nthe Input pane.'},\n",
       " {'header': 'Sample Variogram Settings ',\n",
       "  'content': 'The Settings window of the sample variogram has three tabs: Style, Info and Statistics. The Style\\ntab is only active in a Function window. The Info and Statistics tabs are similar to those of the\\ngridded surfaces, see Gridded Surfaces.\\nStyle tab (Sample Variogram)\\nThe Style tab will be active once a Function window is displayed. Points can be viewed as different\\nsymbols and their color and size can be edited. Only width and color can be edited for lines.'},\n",
       " {'header': 'Variogram Model Settings ',\n",
       "  'content': \"The Settings window of the variogram model has four tabs: Style, Info, Statistics and Statistics.\\nThe Info and Statistics tabs are similar to those of the gridded surfaces, see Gridded Surfaces.\\nStyle tab (Variogram Model)\\nThe Reset option at the top of the window sets the selected options back to default.\\nNugget and Sill/Range- Check Show to display the nugget and sill points. There is an option to\\nselect the symbol to represent these points as well as defining their size and color.\\nVariogram Curve- Options to define the color and width of the variogram curve.\\nThe options Show in Min/Max directionrefers to the possibility to show the variogram curve\\n(with points) in both directions when having anisotropy defined. For details on the variogram\\nsettings, see Gridded Surfaces.\\nSetting tab (Variogram Model)\\nThe shape of the variogram curve can be defined here.\\nFunction: Select function, Exponential, Spherical or Gaussian. The different functions have\\ndifferent base shapes.\\nSill/Nugget: Define sill and nugget for the variogram curve - either by entering numbers or by\\nmoving the sill and nugget points with the cursor in the Function window.\\nForce the sill to equal 1.0: Check this option to keep the sill at 1. This could be convenient for\\ncomparing data at a later stage (this will change the nugget).\\nAnisotropy: Option to define the anisotropy (orientation angle, range).\\nFunction curves in a folder (Settings)\\nFunctions can be imported (Import Functions (Lookup curves)), generated from crossplots or\\nhistograms, or created manually by right-clicking on a folder in the Explorer Input pane and\\nselecting Create new function. Wavelets can also be inserted into a folder; however these are\\ndescribed as part of the synthetics process. See Defining the wavelet.\\nThe Settings window of the function comprises four tabs: Style, Info, Statistics and Function.\\nThe tab of interest is the Function tab in which the curve can be edited (alternatively it can be\\nedited in a Function window; which is normal).\\nSelect this tool to edit/create new points along the curve (in XY).\\nSelect this tool to move the whole line (in Y).\\nThe X and Y axis can be swapped by clicking on the 'Swap XY' icon.\\nThe curve can be set as a log X and/or log Y function.\\nThe curve can be viewed with or without using spline curves.\\nThe function can be used for calculations using the calculator. See Functions for details on how to\\nedit a function.\\nA spreadsheet can be opened from the Info tab or by clicking with the right mouse button on the\\nname of the function. The points defining the function will be displayed in the spreadsheet view\\nwith edit and copy/paste options. It is possible to add and remove rows and it is also possible to\\ncopy and paste values from other places (e.g. Excel) and to edit numbers directly.\\nHow to create a new function\\n1. First make an empty folder and call it something relevant (for example Functions).\\n2. Click with the right mouse button on the folder and select Create new function from the\\npull-down menu.\\n3. Define name, min/max X and Y, and number of points for the new function in the pop-up\\ndialog. The initial function will be linear but it may be edited once created.\\n4. Click OK - the Settings window for the new function will be displayed.\"},\n",
       " {'header': 'Points ',\n",
       "  'content': 'Show the points and determine the color, shape and size of the points.'},\n",
       " {'header': 'Interval Bin Lines ',\n",
       "  'content': \"Show the bin intervals (if generated) and determine the color and width of the lines.\\nInfo tab (Crossplot)\\nThis includes the name of the object and its color, as well as the standard Comments and history\\ntabs.\\nIn addition, the primary and secondary data types are defined here and the names and templates\\nassigned.\\nHistogram tab (Crossplot)\\nThe histogram can be used to display the distribution of the data in the cross plot and as the\\nstandard histogram settings:\\nCheckbox for using a log scale for the x axis of the histogram.\\nCheckbox for displaying the bar heights as a percentage of the total number of data points\\nof that type (this allows you to compare upscaled cells with the property, etc.)\\nPrint - a copy of the histogram\\nCopy Bitmap - will copy the histogram view to the clipboard. This can then be pasted into\\nthe Input pane and displayed on Maps and Plots.\\nThe user can choose either:\\nIntervals - the data range will be split into this number of intervals.\\nIncrement - the data range will be split using the chosen increment.\\nMax / Min - as a default, the range will be defined as the maximum and minimum values\\nin the data. Activating Max and Min allows the user to specify the range. After setting the\\nMax and Min values, you must use the Refresh icon to apply the changes.\\nBy toggling on the selection filter , the displayed histogram can be restricted to the selected\\npoints. See Using the Crossplot's histogram for information on using the histogram interactively.\\nSaturation function (Settings)\\nSaturation functions can be generated from the 'Make rock physics functions' process. The result\\nis stored in a 'Rock physics functions' folder in the Explorer Input pane.\\nThe Settings dialog holds details of saturation functions and also of any relative permeability or\\ncapillary pressure selected within a saturation function. For a saturation function, only the Info\\ntab is displayed. For relative permeabilities and capillary pressures, Style, Info and Statistics\\ntabs are also displayed; see Info tab and Statistics tab.\\nTo see the functions, open a Function window.\\nSettings for objects in the Models pane\\nAll objects created in Petrel contain a set of different Settings windows. Many of these Settings\\nwindows are the same as those in the Input pane.\\nIn addition to the different Settings for each object, different sets of right mouse button menu\\noptions are available on the different types of objects. Some of these are the same as those in the\\nInput pane. Not all options are available from all folders.\\nRight mouse button menus in the Models pane\\nThese menus are different depending on data type. Some options are similar for several data\\ntypes, for example, Settings, Export, Delete, etc.\\nGeneral (Right mouse button menus)\\nThe Settings option opens the Settings window for the folder. The Import and Export options\\ngive the possibility to export or import data to or from this folder. Delete will delete the folder\\nand its contents, while Delete content only deletes the content of the folder.\\nInsert General Intersection - inserts a General Intersection into a folder. The General\\nIntersection can be used together with all the different data in Petrel, independent of which folder\\nit was created in. The use of the General Intersection is described in General Intersection.\\nSort by names/depth will sort the files in the folder by names or by depth. Sorting by depth will\\ngive the correct stratigraphic order of the objects.\\nSet colors automatically will automatically put colors on the objects within the folder. A pop-up\\nwindow will ask whether the color selection is OK. If you answer no, another suggestion will come\\nup.\\nSet names automatically will automatically rename the objects within the folder and give the\\ncontent names with consecutive numbers, e.g. Lines 1, Lines 2, Lines 3, etc.\\nCorner point grids: Model, Fault Model and sub-\\nfolders (Right mouse button menus)\\nSort by names - This option will sort data in the folder by names. It can be done for data in the\\nModels folder, the Faults folder, the Trends folder, the Property folder, the Intersection\\nfolder and the Segments folder.\\nSort by length - This option will sort data in the folder by length. It can be done for faults in the\\nFaults folder and for trends in the Trends folder.\\nSet names automatically - This option is available from the Models folder, the Faults folder\\nand the Trends folder. It will automatically rename any sub-grids within the model. The names\\nwill be Name 1, Name 2, Name 3, etc.\\nCopy visible faults - this option is available in the Fault Model folder. It will copy those Key\\nPillars (within the model) that are displayed in the 3D window.\\nPaste Visible faults - this option is available in the Fault Model folder. It will paste those Key\\nPillars copied from another model (using the 'Copy visible faults' option).\\nConvert to Fault Sticks, Fault Surfaces or Fault Polygons - This option is available for the\\nFaults folder, and will convert the fault model to lines or surfaces, that are placed in the bottom\\nof the Input tab.\\nCorner point grid: 3D Grid (Right mouse button\\nmenus)\\nRemove All Horizons, Remove all zones and Remove All Layers - The right mouse button\\nmenu of the 3D grid changes when horizons, zones and/or layers have been added to the grid.\\nWhen these objects have been added, this menu will include the options Remove All Horizons,\\nRemove all zones and Remove All Layers. This is an option to quickly remove the inserted objects,\\nand each menu choice will delete the result of the Make Horizons, Make Zones and/or Layering\\nprocessing steps.\\nCorner point grid: Fault Planes (Right mouse button\\nmenus)\\nSome of the below options are available for the Faults folder and for individual faults:\\nConvert to Fault Sticks - Option to convert the faults to fault sticks and copy these over to the\\nInput pane. If the faults were generated from the main faults folder, the fault sticks will be placed\\nat the base of the Input pane in a folder called 'Faults Sticks from <Grid name>'. If individual\\nfaults are converted, they will be placed as sticks directly in the Input pane.\\nConvert to Fault Surfaces - Option to convert the faults to fault surfaces and copy these over\\nto the Input pane. If the faults were generated from the main faults folder, the fault surfaces will\\nbe placed at the base of the Input pane in a folder called 'Faults Surfaces from <Grid name>'. If\\nindividual faults are converted, they will be placed as surfaces directly in the Input pane.\\nThe fault surfaces will have the same settings as surfaces, and can be exported from Petrel as\\nsurfaces.\\nConvert to Fault Polygons - This menu option converts all the faults to fault polygons and\\ncopies these over to the Input pane. The fault polygons will be organized in a folder called 'Faults\\npolygons from <Grid name>' if generated from the main faults folder. If individual faults are\\nconverted, they will be placed as polygons directly in the Input pane.\\nWhen converting the faults to fault polygons, a question will pop up whether you would like to\\nclose the polygons. By answering Yes to this question, the fault will be represented with a set of\\nclosed fault polygons where each closed polygon represents the footwall and hanging wall lines of\\na horizon. By answering No to this question, the fault will be represented with a set of lines,\\nwhere each line represents a footwall or a hanging wall of a horizon. The fault polygons will have\\nthe same settings as line data, and can be exported from Petrel as line data.\\nThis menu option is also available on the Fault Filter. The Fault polygons converted from the fault\\nfilter are sorted on horizons and not on single faults.\\nIt is not possible to convert fault planes to fault polygons before horizons have been inserted\\ninto the grid. The reason for this is that the process uses the intersection lines between the faults\\nand the horizons to produce the polygon lines.\\nInsert/update 'Faults' property template - This menu option is available only from the main\\nFaults folder. It will make a discrete color legend of all the faults. The color legend lists all the\\nfault names with the color for each of them. The color legend is added to the 'Discrete property\\ntemplates' folder in the Templates pane in the Petrel Explorer. The option to make a discrete color\\nlegend is also available for horizons, zones (on the Zone Filter folder) and segments.\\nCorner point grid: Horizons (Right mouse button\\nmenus)\\nInsert/update 'Faults' property template - See 'Insert/update 'Faults' property template' for\\nFault Planes. This is only available from the main Horizons folder.\\nSet horizon and fault visible - this is a very useful QC option to strip down layer by layer and\\nshow only the horizon and fault related to specific zone.\\nFlatten Model at this horizon - This option is available only on individual horizons. It is an\\nirreversible process that will convert the horizon to an unfaulted horizon. The flattened model will\\nset the model back to the situation when the layers were deposited. This gives a very good quality\\ncontrol of the model with respect to the depositional environment.\\nConvert to structured surface - This action will generate a new surface object in the Input\\npane. The grid geometry is mapped directly from the horizon.\\nConvert horizon nodes to points - Generates a points file in the Input pane representing each\\nnode in the Horizon.\\nConvert locked Horizon nodes to points - Generates a points file in the Input pane\\nrepresenting each node in the Horizon that has been locked.\\nResample horizon-fault lines to/from Fault Model - Available from the Operations tab under\\nsettings for the Horizon folder, or from individual horizons.\\nSamples the horizon/fault intersection back to the fault model. See How to generate Fault-Horizon\\nintersections for the 3D Grid\\nCorner point grid: Intersections (Right mouse button\\nmenus)\\nInsert General Intersection - This menu option inserts the General Intersection into the\\nIntersection folder. The General Intersection will be added to the Intersections folder.\\nFor information of the use of the General Intersection, see General Intersection Settings.\\nInsert I- & J-intersection - This menu option gives the possibility to insert additional\\nintersections in I- and/or J-direction. The extra intersections are added to the Intersections folder.\\nFor further information on how to use the intersections, see I- and J- grid intersections.\\nCorner point grid: Properties (Right mouse button\\nmenus)\\nCalculator - The calculator for properties is available for calculations on all properties from the\\nright mouse button menu on the Property folder.\\nFor information on how to use the calculator on properties, see Property Calculator.\\nSorting - There are four options for sorting of the properties in the Properties folder: Sort by\\nnames, Sort by property templates, Sort by property templates/name and Sort by\"},\n",
       " {'header': 'Time. ',\n",
       "  'content': 'Making fault polygons (Right mouse button menus)\\nConvert to Fault Polygons - This menu option (from the Fault Filter) converts each horizon\\ninterval in the fault filter to fault polygons. One data set of fault polygons is produced for each\\nhorizon in the fault filter.\\nFor more information on how to convert to fault polygons, see Fault models.\\nDefine discrete legend - This option works in the same way as for the faults, see define\\ndiscrete legend in Fault Planes.\\nCorner point grid:Variogram folder (Right mouse\\nbutton menus)\\nInsert Variogram - Will insert a new variogram model that can be adapted to a sample\\nvariogram.\\nSettings for Model, Fault Model and sub-folders\\nFor information on the tabs: Info, Statistics and Colors seeGridded Surfaces Settings, as these\\nare similar for these data types.\\nStyle tab (Fault Model)\\nIn this tab, the layout for the faults can be set. By clicking on the Reset button, all settings will\\nbe set back to the default settings. By clicking on the Apply the settings for all similar\\nobjects in the project, all defined settings will be applied to similar objects in the entire project,\\nthat is, also from one grid to another.'},\n",
       " {'header': 'Shape Points ',\n",
       "  'content': 'Option to select if the Shape Points are to be shown, together with options for the Shape\\nPoint layout (symbol, size and material). This is where you set the size and shape of the\\nShape Points for all of the faults in the model.'},\n",
       " {'header': 'Pillars ',\n",
       "  'content': 'Option to select if the pillars are to be shown, together with options for the line layout (line\\nwidth and line type).\\nFill between Pillars\\nOption to apply a more or less transparent filling along the fault planes. This may help the\\nuser to keep the orientation while moving the structural model around in 3D and to identify\\npotential trouble spots where, for example, Key Pillars are crossing each other in Z.'},\n",
       " {'header': 'Lines Between Pillars ',\n",
       "  'content': 'Option to select if the lines between pillars are to be shown and if they shall be shown as\\nstraight or smoothed lines. There are also options for the line layout (line width and line type)\\ntogether with number of lines to show.\\nGrid Settings (Corner point grid)\\nThe Settings window for the 3D grid contains four tabs: Info, Statistics, Operations and\\nOutput Info and Statistics are the same as for imported objects, and are described in Gridded'},\n",
       " {'header': 'Surfaces Settings. ',\n",
       "  'content': 'Operations tab (Grid)\\nThe Operations tab contains a special feature to flip 3D grids imported from modeling programs\\nwith different definitions of the coordinate system than in Petrel. For further information on\\nflipping of the 3D grid, see. Operations tab (Gridded surfaces).\\nThe other option in the Operations tab is to make eroded horizons consistent. This is a special\\nexpert user feature and it is described in further detail in Make Zones and Layering.\\nIt is possible to remove gaps and thin cells.\\nOutput tab (Grid)\\nThe output tab allow you to make a filtered copy of the 3D grid. This can be useful for example,\\nwhen you want to model a field in two parts. See Output tab on the 3D Grid for details.\\nExport to Simulator and Visualization (Grid)\\nThe content of this tab was moved from the Project Misc Settings 2 to facilitate viewing multiple\\ngrids loaded from diverse sources.\\nThe Petrel Cell Origin controls only the visualization of the cell index and has no effect upon the\\nexport settings (particularly in the Define Simulation Case Export where settings are\\nhardwired to ECLIPSE.\\nSkeleton Settings (Corner point grid)\\nThe Settings window for the skeleton includes Style, Info and Statistics. The settings for Info\\nand Statistics are equal to the settings for an imported gridded surface, and a description of\\neach of these is found in Gridded Surfaces Settings.\\nNote that it is not possible to set the style individually for Top-, Mid-, and Base-skeleton. This has\\nto be set in the Skeleton folder.\\nStyle tab (Skeleton)\\nStyle gives options to define how the skeletons will be displayed in the Display window.\\nThe Reset option at the top of the window sets the options back to default. By clicking on Apply\\nthe settings for all similar objects in the project, all defined settings will be applied to\\nsimilar objects in the entire project; that is, also from one grid to another.\\nGrid: Gives the option to display the grid lines of the skeletons, together with options for the grid\\nlayout (color, width and line type).\\nContour: Options on how to display contour lines of the skeletons. Level annotates how many\\ncontour lines the object will be displayed with, using the selected increment. The layout for the\\ncontour lines (color, width and line type) can also be set.\\nSolid Options on how the skeletons will be displayed with color, material and transparency in the\\nDisplay window. Choice of material will change the reflectivity of the surface.\\nFaults Settings (Corner point grid)\\nThe Settings windows for the fault planes include Draw Style, Info, Edit Draw Style,\\nStatistics and Colors. For information on the tabs Info, Statistics and Colors, see Gridded'},\n",
       " {'header': 'Surfaces Settings. ',\n",
       "  'content': 'Fault name and color is set for each individual fault, while the settings for how to draw the faults\\nare done for all the faults together in the Faults folder.'},\n",
       " {'header': 'Style (Faults) ',\n",
       "  'content': 'The visual representation of the fault planes is controlled through this Style window.\\nThe Reset option at the top of the window sets the selected options back to default. By pressing\\nthe Apply the settings for all similar objects in the project, all defined settings will be\\napplied to similar objects in the entire project, i.e. also from one grid to another.\\nLines tab\\nHorizon-fault lines - gives the option to show horizon lines and sub-horizon lines on the faults.\\nThese lines are divided into footwall and hanging wall lines.\\nPillars - gives the option to view the pillars of the grid on the fault planes. Note that there is a\\ndistinct difference between these pillars and the Key Pillars in the fault model.\\nLines between the Pillars - allows the user to display the lines between the Shape Points of the\\noriginal Key Pillars. The color of these lines will be the same as set for the Pillars.\\nSolid tab\\nGives the option of how to display the fault plane. The As separation diagram option relates to\\ncreating an Allen diagram, see Allen Diagram (Juxtaposition Diagram).\\nEdit tab\\nRefers to the appearance of the points with the Edit 3D Grid process active. The Shape Points\\nare only visible when either of the buttons, Select Shape Point or Select Pillar, are chosen in\\nthe Edit 3D Grid process step. The Horizon Nodes are only visible when the function Select\\nHorizon Node is selected in the Edit 3D Grid process step.\\nShape Points and Horizon Nodes refer to the size and shape of these points.\\nHorizons Settings (Corner point grid)\\nThe Settings windows for horizons include the tabs Style, Info, Statistics and Operations.\\nApart from the Operations tab, these tabs are the same as for gridded surfaces in the Explorer\\nInput pane and are described in Gridded Surfaces Settings. By pressing the Apply the settings\\nfor all similar objects in the project, all defined settings will be applied to similar objects in\\nthe entire project, that is, also from one grid to another.\\nOperations tab (Horizon)\\nIn this tab there is an option to convert the horizons that are part of the 3D grid to separate\\nsurfaces. The surfaces will be placed in the Input pane in the Petrel Explorer. After converting\\nthe horizons to surfaces, they can easily be exported in various surface formats. There are 2\\noptions:\\nConvert Horizon to Surface: This option converts the Horizon to a regularly gridded\\nsurface. The grid rotation and increment is taken from the template surface. If no\\ntemplate is added, then the grid limits of the horizon are used. Select Fill in faulted areas\\nto ensure the grid is continuous across the entire area. Press \\'Make surface\\' for the\\noperation to be performed.\\nConvert Unfaulted Horizon to Surface: This option will attempt to reconstruct the\\nhorizon(s) to a surface before faulting occurred. This option may be useful for visualizing\\nthe structural relationship between surfaces prior to the onset of extension/compression.\\nPress Make unfaulted for the operation to be performed.\\nThe Operations tab is also available for each individual horizon.\\nEdges Settings (Corner point grid)\\nThe Settings for the zones define how the Edges (the \"walls\" of the 3D grid) will be visualized\\nwhen the Edges box is checked. The settings for the edges are the same as for faults, see Faults'},\n",
       " {'header': 'Settings. ',\n",
       "  'content': 'Intersections Settings (Corner point grid)\\nThe Settings for the intersections define how the 3D grid looks on the intersections in I- and J-\\ndirections. How the 3D grid is visualized on the General Intersection is set in the Settings for the\\nGeneral Intersection, see General Intersection Settings.\\nThe settings for the I- and J-intersections are the same as for faults, see Faults Settings.\\nProperties Settings (Corner point grid)\\nA set of different Settings is available both in the Properties folder and for each individual\\nproperty. The tabs Info , Analysis and Variogram are similar to those for gridded surfaces, see'},\n",
       " {'header': 'Gridded Surfaces Settings . ',\n",
       "  'content': 'Style tab (Properties folder)\\nThe Style of properties is set under the Properties folder.\\nThe Reset option at the top of the window sets the selected options back to default. By pressing\\nthe Apply the settings for all similar objects in the project, all defined settings will be\\napplied to similar objects in the entire project, i.e. also from one grid to another.\\nStyle tab for Map, 2D and 3D windows:\\nGrid : Gives the options on how to display the grid lines of the selected properties (color, width\\nand line type).\\nSolid : Options on how a selected property will be displayed with color, material and transparency\\nin the Display window. Choice of material will change the reflectivity of the property.\\nVisual effects : As it is (true view), Regular in XY or Regular in XYZ (simbox view) allows the\\nuser to see the property in a rectangular box, i.e. the topography and faults have been \"removed\"\\nfrom the grid. This is nice to use for QC of the property. See Visualize a property as a regular box\\nfor details. Auto toggle LGR visibility enables Petrel to automatically set as visible any local grid\\nrefinement set which contains data for that property, other local grid refinement sets will be set as\\nnot visible.\\nProperty layer to show in mapping : allows the user to define which layer of the model should\\nbe visualized in a Map window. It offers the possibility to find a layer by selecting the appropriate\\nzone.\\nStyle tab for Function and Histogram windows:\\nHistogram : Options to set color type, color and pattern for the histograms and color type, line\\nwidth and point type/size for the cdf and the line display.\\nCross Plot : Options to set color type, color and point type/size for the cross plot. There is also an\\noption for specifying if points are allowed to be removed from the plot.\\nStatistics tab (Properties)\\nThe Statistics for individual properties differs only slightly from the statistics of other objects in'},\n",
       " {'header': 'Petrel. ',\n",
       "  'content': \"In addition to statistical information of the XYZ values and different descriptions of the object, this\\nStatistics tab also contains information on the max and min values of the property values.\\nThe Statistical information that is found in the Properties folder includes a list of the available\\nproperties and their max and min values. The Statistical information for each individual property\\nincludes the statistics for the original well log and the scaled up cells, if the property was\\ngenerated using a well log.\\nTo look at one zone at a time, check the For Zone box and select the zone from the pull-down\\nlist. Note the updated statistics. When For Zone is not checked, statistics for the entire 3D\\nproperty are visualized.\\nNote that the statistics of a property can be filter sensitive by checking the Use filter in\\nstatistics button.\\nStatistics for Zone (Discrete statistics)\\nThis tab only exists for discrete properties.\\nThere is a zone option list which can be used to view only the selected zone, which can be selected\\nfrom the pull-down menu. The property filter can be used by checking the Use filter option.\\nThere are two sub-windows in the discrete statistics window: The upper window shows the\\nstatistics for the entire 3D property, and the lower window shows the statistics for the upscaled\\nwell logs. For the entire property and the upscaled well logs, the fraction, number of cells and body\\nheight (min, mean, max and standard deviation) are written.\\nOperations tab (Properties folder)\\nFlip property values\\nThe values for all properties can be flipped along either the I, J or K direction. Choose the\\nappropriate direction and click Flip .\\nOperations on several properties\\nThis is a useful method of consolidating multiple realizations generated during facies or property\\nmodeling. A single property will be generated representing the sum, maximum, minimum, mean,\\nstandard deviation, harmonic mean or geometric mean value from a range of properties.\\nChoose the properties to consolidate using Shift or Ctrl , choose the consolidation method and\\nclick Calculate .\\nIf all the properties consolidated have the same template, then the new property will inherit that\\ntemplate, if not, the new property will have a 'general' type property template. The new property\\nwill always be continuous, use the property calculator to consolidate discrete properties.\\nOperations tab (Properties)\\nThere is an option for each property to make standard property operations or maps from\\nproperties.\\nFilter tab (Properties folder)\\nThe Filter option applies to all properties, and is available in the Settings window for the\\nProperties folder.\\nThe Filter gives the option to only show parts of a property model in the Display window. The\\nfilter works according to the same principles as the Fault-, Zone- and Segment filters in the Models\\nwindow in the Petrel Explorer.\\nFilter settings Defines the type of filter to be used on the selected property.\\nIndex filter Defines the settings for the index filter if this type of filter has been selected above.\\nGives the option to show the properties for only selected rows, columns, and/or layers in the grid.\\nValue filter Displays properties in the model. Select a property and check the Use filter option.\\nThe max and min values will be displayed. Edit the filter and click Apply . The filter can be used as\\na combination of values from more than one type of property, which means that only cells that\\nfulfill these conditions will be displayed.\\nHistogram tab (Properties)\\nThe histogram tab is available in the Settings window and shows the distribution of values for the\\nselected data. The histogram can be shown for the whole population in the property.\\nOnly show values that pass the active filter.\\nShow the whole population of the property.\\nShow the upscaled well logs.\\nShow the values for the original well logs.\\nUse volume weighting for the values. (percentage display only)\\nPrint a copy of the histogram\\nCopy Bitmap - will copy the histogram view to the clipboard. This can then be pasted into\\nthe Input tab and displayed on Maps and Plots.\\nThe user can choose from the drop down list either:\"},\n",
       " {'header': 'Intervals ',\n",
       "  'content': 'the data range will be split into this number of intervals.'},\n",
       " {'header': 'Inc ',\n",
       "  'content': 'Increment) - the data range will be split using the chosen increment.'},\n",
       " {'header': 'Max / Min ',\n",
       "  'content': 'as a default the range will be defined the maximum and minimum values in the data.\\nActivating Max and Min allows the user to specify the range. After setting the Max and Min\\nvalues you must use the Refresh button to apply the changes.\\nFor zone : Is a zone filter; data for each zone can be viewed independently, while using the filter\\nbutton allows the user to display different subsections of the data.\\nLog checkbox\\nUse a log scale for the x axis of the histogram\\nPercent checkbox\\nDisplay the bar heights as a percentage of the total number of data points of that type (this\\nallows you to compare upscaled cells with the property etc.)\\nFigure 1. The histogram tab\\nFilters Settings (Corner point grid)\\nThe Settings windows for the Filters (Fault, Zone and Segment) include the Info and Statistics\\ntabs. These tabs are the same as for gridded surfaces in the Input pane, and are described in'},\n",
       " {'header': 'Gridded Surfaces Settings. ',\n",
       "  'content': 'All the filter folders only affect which part of an object should be visualized.\\nZone filter - Output tabs\\nThis tab contains options to convert one or more zones to isochores.\\nIsochores (TVT) - Isochores calculated in the Output tab are calculated in TVT,\\nIsochores (along pillars) - The isochores will be placed in the Input window in the Petrel Explorer.\\nThe option is available for all zones, for each individual zone and sub-zone.\\nFor further information on how to convert zones to isochores, see Gridded Surfaces Settings.\\nVariogram folder Settings (Corner point grid)\\nThe variogram folder appears when a Variogram tab has been accessed in the active 3D grid.\\nWhen creating a sample variogram from, for example, a property, the result will be placed in this\\nfolder. When creating a variogram model, the result will also be placed in this folder.\\nSample variogram (Model Settings)\\nThe Settings window of the sample variogram has three tabs: Style, Info and Statistics. The Info\\nand Statistics tabs are similar to those of the gridded surfaces, see Gridded Surfaces Settings.\\nStyle tab\\nPoints can be viewed as different symbols and their color and size can be edited. Only width and\\ncolor can be edited for lines.'},\n",
       " {'header': 'Variogram Model (Model Settings) ',\n",
       "  'content': 'The Settings window of the variogram model has four tabs: Style, Info, Settings and Statistics.\\nThe Info and Statistics tabs are similar to those of the gridded surfaces, see Gridded surfaces.\\nStyle tab\\nSettings tab\\nThe Parameters tab is where the shape of the variogram curve can be defined.\\nFunction: Select function, Exponential, Spherical or Gaussian. The different functions have\\ndifferent base shapes.\\nSill/Nugget: Define sill and nugget for the variogram curve - either by entering numbers or by\\nmoving the sill and nugget points with the cursor in the Function window.\\nForce the sill to equal 1.0: Check this option to keep the sill at 1. This could be convenient for\\ncomparing data at a later stage.\\nAnisotropy: Option to define the anisotropy (angle, range).\\nSeismic volumes attached to a grid (Settings)\\nThe seismic volumes attached to a grid are virtual volumes. The Settings dialog of these have\\nalmost the the same options as those available for the SEG-Y seismic data in the Input pane, see\\nSeismic data (Settings).\\nStyle tab\\nHowever, there is one additional option on the Style tab; the Enable zone and segment filters\\nfor intersections option.\\nVelocity models (Settings)\\nThis folder will always be present in the Models tab. It does not have a Settings window although\\ntheir sub-objects do.\\nThe sub-objects (Velocity Model 1, 2, 3, etc) have a Settings window with an Info tab containing\\ngeneral information only.'},\n",
       " {'header': 'Streamlines (Settings) ',\n",
       "  'content': 'Streamlines appear as a child of a grid on the Model pane, and have a few basic style settings\\nChoose the Color of the streamlines from the following choices:\\nAs attribute - color streamline according to the chosen attribute\\nSpecified - use the color specified on the Info tab\\nDifferent - use a different color for each streamline\\nStart well - color the streamline according to the source well for the streamlines.\\nEnd well - color the streamline according to the sink well for the streamlines.'},\n",
       " {'header': 'Black / White ',\n",
       "  'content': \"Choose the line type from those available. Choosing Pipe may slow down the display of your\\ndata.\\nChoose the line width of the stream lines to display.\\nChoose whether and how you wish to filter the streamlines:\\nEvery N'th - display only a fraction of the streamlines, N is defined by Show Every. This\\nwill increase the speed of the display.\\nAll - display all generated streamlines.\\nSettings for objects in the Templates pane\\nWhen opening the Settings window for the different templates in the Templates pane, the\\navailable tabs are Style, Info, and Colors. The Color tab is divided into continuous and discrete,\\nand contains the pre-defined color scale for the template. This tab is the same as the Color tab\\nfor all objects in Petrel. To set continuous and discrete color tables see Color tables.\\nThe right mouse button menus for the different folders in the template window includes different\\nsorting options and Insert Property Template, which will insert a user defined new property\\ntemplate into the folder.\\nStyle tab (Templates)\\nSelect here where the legend should be shown in the Display window when switched on. Check\\nthe Manual option to be able to set increments manually.\\nInfo tab (Templates)\\nThe Info tab contains some general information on the template including the Legend label\\n(which can be edited), see Info tab.\\nSettings for objects in the Cases pane\\nThe settings for the Cases folder of the case are only for display and cannot be changed. The sub-\\nfolders will be displayed depending on how the case was generated (volume calculation, refine\\nsimulation case and so on). For more information, see the Volume Calculation or Define\\nSimulation Case processes.\\nDefinition tab (Simulation)\\nWill show a read-only set up of the Define simulation case.\\nDefinition tab (Volume calculation)\\nWill show nothing.\\nSettings for objects in the Windows pane\\nAxis, Compass and Horizon have Settings windows, which define the outline of how the axis and\\nthe compass are drawn in the Display window.\\nLight Sources and Performance Indicator do not have a Settings window. Light Sources have a\\nright mouse button option Insert a new light source . This inserts a new light source in the\\nDisplay window, which lights the objects from a different angle.\\nThe Windows tab also contains settings related to the various Plot windows: Info box, Symbol\\nlegend, Scale box, Header and Frame. All these have Settings windows (described below) with a\\nStyle tab and, in some cases, an Info tab.\\nCursor tracking (Windows)\\nThis is the world cursor which can be used in seismic interpretation to locate the mouse when\\nusing multiple displays.\\nIn the Style tab, the visual setting of it can be changed from Box to Cross with some size settings.\"},\n",
       " {'header': 'Light Source (Windows) ',\n",
       "  'content': \"User-defined light sources are particularly useful for enhancing features in surfaces and 3D\\nobjects. Light sources present in the project are located on the Windows tab of the Petrel\\nexplorer, under Light Sources .\\nTo create a new light source, select Insert a new light source from the right mouse button\\npull-down menu of the Light Sources folder. The new light source will be placed in the Light\\nSources folder. The light source will be placed at the camera's viewpoint.\\nThe Settings window for this new light source allows the user to specify where this light source\\nwill be positioned as well as its intensity. Three types of light sources exist.\\nDirection: is a parallel light source and therefore only has a direction and an intensity.\\nPoint light: is a ball of light which has a position in real space and an intensity.\\nSpot light: is a classic spot light with a true position, intensity, drop off rate and shade\\nangle.\\nLocation and direction allows the user to move either the light or the camera to the current\\ndisplay view.\\nLight sources can also be edited interactively by right-clicking on the name of the light source in\\nthe Petrel explorer and choosing Edit . Move the light using the round widget (will make no\\ndifference for directional light sources), and alter the direction by moving the arrow. In addition,\\nspot light sources will have a 'Shade' which allows the user to focus the light.\"},\n",
       " {'header': 'Axis (Windows) ',\n",
       "  'content': 'Style tabs for Axis\\nDefines how the Axis will look in the various Display windows. The position of the tab and its style\\noptions will change, depending on the type of viewport you are using (for example, from a\\nFunction window to a 2D or 3D window).\\n3D and 2D Window Style tab\\nReset sets the display options back to default.'},\n",
       " {'header': 'Settings: ',\n",
       "  'content': 'Show annotation - Check to view the coordinates along the axis - define font size and color\\nShow axis label - Check to view the X-, Y- and Z-axis text - define font size and color\\nShow tickmarks - Check the Show tick marks option to view the tick marks along the axis -\\ndefine color and axis line width.\\nUse auto colors - will override the color setting'},\n",
       " {'header': 'Grid: ',\n",
       "  'content': 'Show grid - Will draw grid lines (web) along the axis in 3D and 2D space define grid color and\\nline width.'},\n",
       " {'header': 'Axis: ',\n",
       "  'content': 'Visual items - Will show axis around all objects visualized in the 2D or 3D window.\\nThe Selected item - Drop in an object; the axis is drawn around this even if other\\nobjects are visualized in the same window.\\nProperty template - Will only show axis around any object with a given template from the drop-\\ndown menu.\\nFunction Window Style tab\\nIn a Function window the Style tab will contain 4 sub-tabs for various settings:\\nGeneral tab - option to show axis or part of the axis, in addition to color and line width.\\nTicks tab - option to change tick size, increment and number of minor ticks.\\nAnnotation tab - option to change font size, X and Y axis annotation, label font size, etc. and\\ntext (w/autotext).\\nGrid tab - option to show grid; change color, line width and grid spacing.\\nRanges tab - option to change the value range on both the X and Y-axis to a user defined range.\\nAlso options for logarithmic display and to invert the selection on each axis.'},\n",
       " {'header': 'Compass (Windows) ',\n",
       "  'content': 'Defines how the compass arrow will look in the 2D and 3D Display window. For the map window\\nthere is a special North arrow with its own settings.\\nReset button: Sets the display options back to default.\\nCompass type: Select between an arrow, rubber duck and a star.\\nPosition Option on where to position the compass arrow in the Display window.\\nCompass size Option to set the size of the compass arrow (in %)\\nPerspective correct: Allows you to give the compass a perspective. When this option is switched\\noff, the compass is orthogonal.\\nNorth Arrow (Map window)\\nThis option is only available for the Map window. There is an option for changing the position of\\nthe arrow, the type (85 options) in addition to height and color.'},\n",
       " {'header': 'Artificial Horizon (Windows) ',\n",
       "  'content': 'Defines how the artificial horizon window will look in the 3D Display window.\\nReset sets the display options back to default.\\nPosition Option on where to position the artificial horizon in the Display window.\\nAuto Legend (windows)\\nThis option is fully available for Interpretation, Intersection and Function windows. Some of the\\noptions are available for 2D and 3D windows.\\nThe Reset option at the top of the window sets the selected options back to default.'},\n",
       " {'header': 'Show ',\n",
       "  'content': 'Select whether to show the Outer frame, the Inner frame and the Header. The text of the\\nheader can be changed from the template - turn the legend on/off to reflect the change.'},\n",
       " {'header': 'Layout ',\n",
       "  'content': 'The options to show continuous colors for properties and depth/thickness are only relevant\\nwhen working with Plot windows. Otherwise, these will be continuous by default. Define\\nHeight and Width (Plot window only) and define the annotation.\\nPosition of the legend\\nDefines where the legend will be placed in the Display window.'},\n",
       " {'header': 'Fonts: ',\n",
       "  'content': 'Define the font size of the header and the annotation marks. In Plot windows, it is also\\npossible to make the header and annotation bold and/or italic.'},\n",
       " {'header': 'Color/Lines ',\n",
       "  'content': 'Option to set the foreground and background colors in the legend box and the line width.\\nInfo box (Windows)\\nStyle tab (Info box)\\nThe Reset option at the top of the window sets the selected options back to default.'},\n",
       " {'header': 'Infobox ',\n",
       "  'content': 'If this is toggled, another predefined infobox can be used rather than the Petrel Infobox which\\nis default. If this option is used, header, font and other style settings will be grayed out.\\nThere are 2 other existing XML files in addition to the default Petrel Infobox, where one can be\\ncustomized, see User customized info box.'},\n",
       " {'header': 'Header ',\n",
       "  'content': 'Option whether to show the header name and to display a logo brought from a file. The logo\\nwill be displayed in front of the header text. Import the bitmap to your project, select it in the\\nPetrel Explorer and drop it by clicking on the blue arrow.'},\n",
       " {'header': 'Fonts ',\n",
       "  'content': 'Defines the font size of the header, lead text and Variable. It is possible to make the text bold\\nand/or italic.'},\n",
       " {'header': 'Color/Lines ',\n",
       "  'content': 'Option to set the foreground and background colors in the legend box and the line width.'},\n",
       " {'header': 'Data ',\n",
       "  'content': \"Check 'Number of column' to define number of columns for the info box and their width.\"},\n",
       " {'header': 'Layout ',\n",
       "  'content': \"Check the 'corresponding viewport offset' in mm. This will apply an offset of the Infobox from\\nthe frame of the viewport. Also the Position to define where the info box will be placed in the\\nPlot window can be changed.\\nSettings tab (Info box)\\nThe Settings tab is where the data to be included in the Info box is entered. Use the icons in the\\ntop left corner to define the layout in the box (add/remove rows). The information contained in\\nthe Info box can be picked up from the settings in Project/Settings (press 'Project settings'\\nbutton), from the object displayed in the Plot window or be user defined in the Info tab. Where\\nthe information comes from depends on which codes are selected in this tab.\\nClick on Project Settings to open the Project/Settings window. Some information regarding\\nthe location of the field, etc., can be entered in the Info tab here and used for the Info box.\\nThe Reset option at the top of the window sets the selected options back to default.\\nHeaderOption to define the header name of the map.\\nColumn options\\nThere are four columns in the spreadsheet below the header text: Leadtext, Code, Cover\\nrow and Variable.\\nLeadtext represents what will be written in the Info box (as titles). This can be user\\ndefined or predefined depending on the choice of Code.\\nCode is the column where the user can choose what the lead text should be - the pull down\\nmenu for each row in the spreadsheet comprises a mixed selection of options.\\nCover row: Check this option to make a row cover all columns in the Info box. Only\\navailable for information located in the leftmost column.\\nVariable: When User input has been selected as Code and defined in lead text, define the\\nvariable (text) here.\"},\n",
       " {'header': 'Symbol Legend (Windows) ',\n",
       "  'content': 'The symbol legend is only available for Plot windows.\\nThe Reset option at the top of the window sets the selected options back to default.\\nShow: Select whether to show the Outer frame and/or the Inner frame, header and offset\\nof the legend bar to viewport\\nLayout: Define Height and Width of the Symbol Legend. Option to specify columns/rows.\\nPosition of the legend Defines where the legend will be placed in the Plot window.\\nFonts: Define the font size text in the legend. Possibility to make the header and\\nannotation bold and/or italic.\\nColor/Lines: Option to set the foreground and background colors in the legend box and\\nthe line width.\\nScale bar (Windows)\\nThe Scale bar is only available for Plot windows.\\nThe Reset option at the top of the window sets the selected options back to default.\\nLayout: Check whether to display scale and/or unit. Define font size of the annotations and\\ncolor of the annotations and scale bar. Possibility to make the annotations bold and/or italic.\\nDefine type layout type of the scale bar. Define the height of the annotations and tick marks\\nas well as number of increments.\\nPosition of the legend defines where the legend will be placed in the Plot window.\\nData: Check Tick unit to be able to change the unit of the tick marks. Check Increment\\nin order to be able to change the increment between the tick marks. Click on Change next\\nto Project unit to open the Project/Settings window to change the project unit.'},\n",
       " {'header': 'Header (Windows) ',\n",
       "  'content': \"The Header is only available for Plot windows.\\nThe Reset option at the top of the window sets the selected options back to default.\\nPosition defines where the header will be placed in the Plot window.\\nStyles The color and font of the header text can be changed. Possibility to make the text\\nbold and/or italic.\\nLabel: Define the header text. 'Insert autotext' will give a drop-down menu option for\\nputting automatic labels.\"},\n",
       " {'header': 'Frame (Windows) ',\n",
       "  'content': 'The Frame is only available for Plot windows.\\nThe Reset option at the top of the window sets the selected options back to default.'},\n",
       " {'header': 'Logo ',\n",
       "  'content': \"A Petrel logo is displayed as default. Check the option 'Show logo', import a bitmap to your\\nproject, select it in the Petrel Explorer, and drop it by clicking on the blue arrow. Option to\\ndefine the width and height of the logo.\\nPositions and Margin\\nDefine the margin of the frame - a margin of 0 (zero) will make the frame as large as\\npossible. Define the position of the text and the logo respectively.\"},\n",
       " {'header': 'Frame ',\n",
       "  'content': 'Option to show frame, with color and line width.\\nFrame text\\nOption to set the font size, bold, italic, underscore, etc.'},\n",
       " {'header': 'Data Processing ',\n",
       "  'content': 'In many projects, the input data needs to be pre-processed to make it suitable for building\\nreservoir models. Similarly, results may require post-processing prior to mapping and reporting.\\nProcessing includes editing, removing or adding data, as well as logical, mathematical and object\\nrelated operations.\\nIn the Settings window for point, line and surface data there are two tabs, Operations and\\nCalculations, for processing data. In addition, surface objects have a More tab with some\\nadditional functions for dealing with surfaces.\\nAll possible functions are available under the Operations tab, however some of the more\\ncommon operations have been included under the Calculations and More tabs for ease of use.\\nOperations on well logs can be done in the Calculator available on the Global Well Logs\\nfolder (right-click the folder) or under each individual Well . Right-click the well to use the\\nCreate new estimated log tool. Right-click a specific well and select View log editor to edit a\\nparticular well.\\nSimilarly, grids and properties have an Operations tab on the settings dialog for simple\\noperations. In addition, Petrel has a powerful property calculator available by right-clicking the\\nproperty folder in the Models pane.\\nNote that there is an undo function that can be used in many of the operations.\\nOperations tab\\nThe Operations tab can be found in the Settings window for the different data objects. To open\\nthe Settings window, either double-click the object or open it through the option Settings from\\nthe right mouse button pull-down menu.\\nAll of the functions are organized in folders with descriptive names. Open the appropriate folder\\nand select the function to use. A description of the function will appear in the window, and below\\nthat, any input box which might be required. At the base of the tab there are a few tools that are\\ncommon to all operations:\\nCreates a new object instead of overwriting the original.\\nPerforms the same task on all the similar objects in the same folder (this will disable the\\nundo button).\\nUndo becomes active as soon as an action is performed and undoes the last action.\\nRun performs the chosen operation.\\n(Surface calculations only) will perform the operation on the area specified by the\\nsurface filter (follow the link on the tool tip to access the filter).\\nArithmetic calculations on surfaces involving multiple inputs may be easier to perform using the'},\n",
       " {'header': 'Surface Calculator. ',\n",
       "  'content': \"The operations tab\\nDepth conversion\\nDepth converts the surface/points/polygons by general depth conversion. A velocity model must\\nbe available in the project.\\nArithmetic operations\\nSimple mathematical functions, addition, multiplication, power etc. which will change the Z\\ncoordinate of the object.\\nZ=Z+-*/Constant: Perform the operation on the Z-value of the object.\\nZ=Z+-*/Surface: Perform the operation on the Z-value of the object.\\nFor example, import fault polygons with no Z data, then move them to the appropriate depth by\\nsetting Z equal to a surface representing the appropriate horizon.\\nFor surfaces, these operations can also be performed using the Surface Calculator which is\\nparticularly useful for performing operations requiring multiple input surfaces (i.e.\\nsurface=(surface1+surface2)/surface3)\\nGeneral functions\\nFunctions applied to the surface (no additional input required) include exponents, logarithmic\\nfunctions, rounding, etc.\\nZ=-Z: apply Z = -Z. Negate the Z.\\nZ=1/Z: apply Z = 1/Z. Calculates the inverse value of Z. If the Z is 0, the point or the grid\\nnode will be removed.\\nZ=Exp(Z): apply Z = Exp(Z). Calculates e raised to the power Z.\\nZ=Exp10(Z): apply Z = Exp10(Z). Calculates 10 raised to the power Z.\\nZ=Ln(Z): apply Z = Ln(Z). Calculates the natural logarithm of Z, with base e. If Z <= 0,\\nthe point or the grid node will be removed.\\nZ=Log10(Z): apply Z = Log10(Z). Calculates the base 10 logarithm of Z. If Z <= 0, the\\npoint or the grid node will be removed.\\nZ=Abs(Z): apply Z = Abs(Z). Calculates the absolute value of Z.\\nZ=Int(Z): apply Z = Int(Z). Round down to nearest integer number.\\nZ=Round(Z): apply Z = Round(Z). Round to nearest integer number.\\nZ=Sqrt(Z): apply Z = Sqrt(Z). Calculates the square root. If Z < 0, the point or the grid\\nnode will be removed.\\nAngle functions\\nTrigonometrical functions, such as sin, Arcsin.\\nZ=Cos/Sin/Tan(Z): The function uses degrees (not radians)\\nZ=ArcCos/ArcSin/ArcTan(Z): The function uses degrees (not radians)\\nCurvature operations\\nSurface or horizon interpretation curvature operations.\\nThe curvature is calculated in the following manner: At each point on the surface or horizon\\ninterpretation the set of nearest neighbors are found. This is a 3x3 neighborhood.\\nA general quadratic surface is fitted to the neighborhood of the point allowing for easy\\ncomputation of first and second derivatives in any direction. The curvature in any orientation is\\n1/r where r is the radius of the best fitting circle to the surface in that orientation. These circles\\nare known as osculating circles. If for a particular orientation the surface is extremely curved, the\\nosculating circle will have a small radius and so the resulting curvature value will be high and if\\nthe surface is only slightly curved then the curvature value will be low.\\nMin curvature: 1/r where r is the maximum radius of the osculating circle over all\\nmax max\\npossible directions\\nMax curvature: 1/r where r is the minimum radius of the osculating circle over all\\nmin min\\npossible directions\\nMean curvature: (Max curvature+Min curvature)/2\\nGaussian curvature: (Min curvature)*(Max curvature)\\nAzimuth of max curvature: The direction of the osculating circle for the maximum\\ncurvature.\\nA sign is assigned based on a whether the surface within the matrix is concave or convex in\\nshape:\\nConcave: negative value\\nConvex: positive value\\nStraigth line (in any direction): zero value\\nCurvature operations are not available for seismic 2D horizon interpretation and structured\\nsurfaces (i.e. made from converting 3D model horizons into 2D grids).\\nReplace where\\nLogical replacement functions.\\nZ>/</>=/<= Constant: points passing the criteria will be set to the constant specified in\\nthe criteria.\\nZ>/</>=/<= Surface: points passing the criteria will be set to the surface specified in\\nthe criteria. Option to eliminate points outside the surface used.\\nThe exact intersection option will add a point at the limit of the intersection (this is only used in\\npolygons.\\nEliminate where\\nLogical clipping functions.\\nZ>/</>=/<= Constant: points are compared to a constant and points passing the\\ncriteria will be set as undefined.\\nZ>/</>=/<= Surface: points are compared to a surface and points passing the criteria\\nwill be set as undefined. Option to eliminate points outside the surface used.\\nEliminate Inside: Eliminate all points or grid nodes inside the given closed polygon(s).\\nEliminate Outside: Eliminate all points or grid nodes outside the given closed polygon(s).\\nThe exact intersection option will add a point at the limit of the intersection (this is only used in\\npolygons.\\nSurface-surface operations\\nAllows combining of two surfaces. (Surfaces only)\\nA intersect B: Combine the two surfaces and keep A at the overlap.\\nA union B, keep A: Combine the two surfaces and keep the first surface at the overlap\\nA union B, keep B: Combine the two surfaces and keep the second surface at the overlap\\nNot A intersect B: Combine the two surfaces and discard the overlap.\\nReplace A where intersected: Replace surface A with surface B wherever it exists.\\nA where not intersected: Remove surface A where it overlaps with B.\\nStochastic functions\\nChanges the objects' Z value to random or normally distributed values.\\nZ=Random(Z,Surface(x,y)): Assigns random Z values to the object between it's current\\nZ value (min) and the Z value of the surface (max). Option to eliminate points outside the\\nsurface used.\\nZ=Normal (Z,Surface (x,y)): Assigns normally distributed Z values to the object with a\\nmean of it's current Z value and a standard deviation from the Z value of the surface.\\nOption to eliminate points outside the surface used.\\nZ=Random(Z,Constant): Assigns a random Z value to the object between it's current Z\\nvalue (min) and the constant (max).\\nZ=Normal (Z,Constant): Assigns normally distributed Z values to the object with a mean\\nof it's current Z value and the specified standard deviation.\\nCommon operations\\nOptions for moving the objects in space and scaling them, and adding or removing data.\\nScale: Multiply the objects coordinates in the X,Y or Z directions by the specified amount. It\\nis advisable to translate the object to the origin before doing this.\\nTranslate: Shift the object by the specified amount (in project units) in the X,Y or Z\\ndirections.\\nRotate: Rotate the object in the XY plane by the specified amount (degrees) around the\\nspecified point in space.\\nNormalize: Scale the Z values for the object such that it remains within the specified\\nmaximum and minimum.\\nLookup: Translate Z according to a user specified lookup function (see How to create a new\\nfunction)\\nAppend Points: Append a point set (points only)\\nRemove duplicate points: Removes points with the same X,Y,Z coordinates (and on the\\nsame polygon for polygon objects). (Points and polygons only)\\nFilter every n'th point: Only every n'th point will be retained (e.g. n=2 half the points will\\nremain, n=10 one tenth of the points will remain.).\\nSwap X and Y: Swap the X and Y coordinate for each point.\\nSwap X and Z: Swap the X and Z coordinate for each point.\\nSwap Y and Z: Swap the Y and Z coordinate for each point.\\nPoints operations\\nThese operations create random points\\nCreate random points on a surface: creates the specified number of points on the\\nspecified surface\\nCreate random points between max and min: creates the specified number of random\\npoints between the maximum and minimum values using the specified object to get the X\\nand Y limits\\nPolygon operations\\nGeneral edit functions for connecting, splitting or deleting polygons based on geometrical\\nattributes, smoothing and refining polygon lines (Polygons only).\\nAppend Polygons: append the selected polygons to the current polygon.\\nSplit by horizontal angle: Split the polygon where the angle between 3 consecutive\\npoints exceeds the specified angle in the horizontal plane.\\nSplit by vertical angle: As above but in the vertical plane.\\nSplit by horizontal length: Split the polygon where the distance between 2 consecutive\\npoints exceeds the specified length in the horizontal plane.\\nSplit by vertical length: As above but in the vertical plane.\\nRemove polygons by number of points: Remove all polygons with less than the\\nspecified number of points.\\nRemove polygons by min length: Remove all polygons shorter than the minimum\\nlength.\\nRemove end points: Remove the first and last points of each polygon.\\nFilter every n'th polygon: Only every n'th polygon will be retained (e.g. n=2 half the\\npolygons will remain, n=10 one tenth of the polygons will remain.).\\nConcatenate all polygons: combine all the polygons into one long polygon.\\nClose all polygons: Close all polygons.\\nOpen all polygons: Break the connection between the first and last point in all closed\\npolygons.\\nSmooth: Perform the specified number of smoothing operations on the polygons.\\nSmooth Z-Values: Perform the specified number of smoothing operations on the Z-value\\nof the polygons.\\nEqual space: Creates new points along the polygon at the specified interval and removes\\nthe original points.\\nRefine by linear interpolation: adds new points to the line to ensure that there is a point\\nat least at the user specified interval.\\nRefine by spline approximation: adds points to the polygons to generate a smooth\\npolygon (B-spline) within the specified tolerance. The original points are also smoothed.\\nRefine by spline interpolation: adds points to the polygons to generate a smooth\\npolygon (parametric cubic spline) within the specified tolerance. The original points are\\nunchanged.\\nReduce the number of points: deletes points while retaining the shape of the line within\\nthe specified tolerance.\\nSurface operations\\nSurface functions such as smoothing, fault detection, extracting dip and azimuth and local\\ntransformations (Surfaces only).\\nRotate Grid: Rotate the grid about it's origin by the specified number of degrees.\\nSmooth: Uses a low pass filter to smooth the surface. Specify the number of iterations and\\nthe filter width. More iterations and a larger filter width will give more smoothing and\\nincrease the time taken for the operation.\\nExtrapolate: Fills undefined areas based on the existing areas of the grid.\\nExtrapolate within boundary: Fills undefined areas within the boundary based on the\\nexisting areas of the grid. This can also be used to remove sections of the grid and\\nextrapolate back into them in one operation (use Clear area within boundary)\\nFault Detect: Difference between the surface and a smoothed version of the surface (high\\npass filter). Specify the width of the smoothing filter to use. It is advisable to perform this\\noperation on a copy of the surface and then texture the original surface with this attribute.\\nDip Azimuth: Calculate the azimuth of the surface. It is advisable to perform this operation\\non a copy of the surface.\\nDip: Calculate the dip of the surface. It is advisable to perform this operation on a copy of\\nthe surface.\\nExpand: Expands the grid by the specified number of grid cells using interpolation. The\\nnumber of rows and columns in the grid remains constant so this operation will not increase\\nthe size of the grid unless there are undefined values around its edge.\\nShrink: Shrinks the grid by the specified number of grid cells. The number of rows and\\ncolumns in the grid remains constant.\\nRefine: Divides each side of the grid cell into the specified number of cells. Values are\\ninterpolated using the convergent gridding algorithm.\\nResample: Upscales a fine grid into the resolution of a coarser one.\\nFlip I: flips the grid in the I direction.\\nFlip J: flips the grid in the J direction.\\nShift I+: Move the grid towards the east by the specified number of grid cells.\\nShift J+: Move the grid towards the north by the specified number of grid cells.\\nShift I-: Move the grid towards the west by the specified number of grid cells.\\nShift J-: Move the grid towards the south by the specified number of grid cells.\"},\n",
       " {'header': 'Calculation ',\n",
       "  'content': 'Extract information from the object, this information will be reported in the message window.\\nVolume below a surface (constant): Calculates the volume below the surface and above\\na specified constant (Volumes will be calculated much more accurately when using the\\nvolume calculation process on a 3 grid). Surfaces only.\\nVolume below a surface (surface): Calculates the volume below the surface and above\\na specified surface (Volumes will be calculated much more accurately when using the\\nvolume calculation process on a 3 grid). Surfaces only.\\nVolume /Area versus depth: Calculates the volume and the area between a surface and\\na constant value at a series of depths. The minimum, maximum and interval are specified\\nand the result is written to a function on the input tab.\\n2 & 3D area of a surface: Calculate the area of a surface in 2 and 3D. Surfaces only.\\nArea and Length: Calculate the area and length of all the polygons in the object. Polygon\\nonly.\\nMake Thickness Map: Calculates the thickness between the given surface and another\\nusing the dip and azimuth of the surfaces. This requires the user to drop in the second\\nsurface and specify the required format of the result TST (true stratigraphic thickness) or\\nTVT (true vertical thickness).\\nMany of the same operations are available as Get Result operations. These return the result to a\\nvariable in the Workflow editor for use in controlling the workflow.\\nGet result of calculations\\nThis option performs calculations and writes the results back to a variable in a workflow. It is\\ntherefore only available in the Workflow editor.\\nGet Xmin value of data: Retrieves the minimum X value of the selected data.\\nGet Ymin value of data: Retrieves the minimum Y value of the selected data.\\nGet Zmin value of data: Retrieves the minimum Z value of the selected data.\\nGet Xmax value of data: Retrieves the maximum X value of the selected data.\\nGet Ymax value of data: Retrieves the maximum Y value of the selected data.\\nGet Zmax value of data: Retrieves the maximum Z value of the selected data.\\nGet area of closed polygon: Retrieves the area of a polygon.\\nGet length of line: Retrieves the length of a line\\nGet area of surface: Retrieves the area of a specified surface.\\nVolume below a surface- Constant: Retrieves the volume between the chosen surface\\nand a constant.\\nVolume below a surface-Surface: Retrieves the volume between two chosen surfaces.\\nArea of intersection- Constant: Retrieves the area at the intersection between a surface\\nand a constant.\\nArea of intersection-Surface: Retrieves the area at the intersection between two\\nsurfaces.'},\n",
       " {'header': 'Convert Points/Polygons/Surfaces ',\n",
       "  'content': \"Generate objects from the object. The objects will be placed in the input tab.\\nConvert to polygon: Convert points to polygons (points only).\\nConvert to points: Convert the object to points (surfaces and polygons only)\\nCreate boundary: Creates a boundary around the data (points and polygons only)\\nCreate surface edge: Creates a boundary around the surface (surface only)\\nCreate i-gridlines: Generates polygons representing the gridlines in the i direction\\n(surfaces only)\\nCreate j-gridlines: Generates polygons representing the gridlines in the j direction\\n(surfaces only)\\nCreate contours: Generates polygons representing the contours of the surface (surfaces\\nonly).\\nCreate intersection with surface: Generates a polygon at the intersection between the\\nsurface and a user defined surface (surfaces only).\\nCreate intersection with plane: Generates a polygon at the intersection between the\\nsurface and a plane at a user defined Z value (surfaces only).\\nSpilt polygons into several polygons: Will convert a polygon object containing several\\npolygons into several polygon objects, each containing one polygon.\\nSeismic operations\\nAssign Values from a seismic cube and samples the values of the chosen seismic cube onto the\\nchosen object. This requires the seismic sampling module.\\nDepth conversion\\nDepth converts the object with the chosen velocity model.\\nCommon operations\\nOptions for moving the objects in space and scaling them, and adding or removing data.\\nScale: Multiply the objects coordinates in the X,Y or Z directions by the specified amount. It\\nis advisable to translate the object to the origin before doing this.\\nTranslate: Shift the object by the specified amount (in project units) in the X,Y or Z\\ndirections.\\nRotate: Rotate the object in the XY plane by the specified amount (degrees) around the\\nspecified point in space.\\nNormalize: Scale the Z values for the object such that it remains within the specified\\nmaximum and minimum.\\nLookup: Translate Z according to a user specified lookup function (see How to create a new\\nfunction)\\nAppend Points: Append a point set (points only)\\nRemove duplicate points: Removes points with the same X,Y,Z coordinates (and on the\\nsame polygon for polygon objects). (Points and polygons only)\\nFilter every n'th point: Only every n'th point will be retained (e.g. n=2 half the points will\\nremain, n=10 one tenth of the points will remain.).\\nSwap X and Y: Swap the X and Y coordinate for each point.\\nSwap X and Z: Swap the X and Z coordinate for each point.\\nSwap Y and Z: Swap the Y and Z coordinate for each point.\\nPoints operations\\nThese operations create random points\\nCreate random points on a surface: creates the specified number of points on the\\nspecified surface\\nCreate random points between max and min: creates the specified number of random\\npoints between the maximum and minimum values using the specified object to get the X\\nand Y limits\\nPolygon operations\\nGeneral edit functions for connecting, splitting or deleting polygons based on geometrical\\nattributes, smoothing and refining polygon lines (Polygons only).\\nAppend Polygons: append the selected polygons to the current polygon.\\nSplit by horizontal angle: Split the polygon where the angle between 3 consecutive\\npoints exceeds the specified angle in the horizontal plane.\\nSplit by vertical angle: As above but in the vertical plane.\\nSplit by horizontal length: Split the polygon where the distance between 2 consecutive\\npoints exceeds the specified length in the horizontal plane.\\nSplit by vertical length: As above but in the vertical plane.\\nRemove polygons by number of points: Remove all polygons with less than the\\nspecified number of points.\\nRemove polygons by min length: Remove all polygons shorter than the minimum\\nlength.\\nRemove end points: Remove the first and last points of each polygon.\\nFilter every n'th polygon: Only every n'th polygon will be retained (e.g. n=2 half the\\npolygons will remain, n=10 one tenth of the polygons will remain.).\\nConcatenate all polygons: combine all the polygons into one long polygon.\\nClose all polygons: Close all polygons.\\nOpen all polygons: Break the connection between the first and last point in all closed\\npolygons.\\nSmooth: Perform the specified number of smoothing operations on the polygons.\\nSmooth Z-Values: Perform the specified number of smoothing operations on the Z-value\\nof the polygons.\\nEqual space: Creates new points along the polygon at the specified interval and removes\\nthe original points.\\nRefine by linear interpolation: adds new points to the line to ensure that there is a point\\nat least at the user specified interval.\\nRefine by spline approximation: adds points to the polygons to generate a smooth\\npolygon (B-spline) within the specified tolerance. The original points are also smoothed.\\nRefine by spline interpolation: adds points to the polygons to generate a smooth\\npolygon (parametric cubic spline) within the specified tolerance. The original points are\\nunchanged.\\nReduce the number of points: deletes points while retaining the shape of the line within\\nthe specified tolerance.\\nSurface operations\\nSurface functions such as smoothing, fault detection, extracting dip and azimuth and local\\ntransformations (Surfaces only).\\nRotate Grid: Rotate the grid about it's origin by the specified number of degrees.\\nSmooth: Uses a low pass filter to smooth the surface. Specify the number of iterations and\\nthe filter width. More iterations and a larger filter width will give more smoothing and\\nincrease the time taken for the operation.\\nExtrapolate: Fills undefined areas based on the existing areas of the grid.\\nExtrapolate within boundary: Fills undefined areas within the boundary based on the\\nexisting areas of the grid. This can also be used to remove sections of the grid and\\nextrapolate back into them in one operation (use Clear area within boundary)\\nFault Detect: Difference between the surface and a smoothed version of the surface (high\\npass filter). Specify the width of the smoothing filter to use. It is advisable to perform this\\noperation on a copy of the surface and then texture the original surface with this attribute.\\nDip Azimuth: Calculate the azimuth of the surface. It is advisable to perform this operation\\non a copy of the surface.\\nDip: Calculate the dip of the surface. It is advisable to perform this operation on a copy of\\nthe surface.\\nExpand: Expands the grid by the specified number of grid cells using interpolation. The\\nnumber of rows and columns in the grid remains constant so this operation will not increase\\nthe size of the grid unless there are undefined values around its edge.\\nShrink: Shrinks the grid by the specified number of grid cells. The number of rows and\\ncolumns in the grid remains constant.\\nRefine: Divides each side of the grid cell into the specified number of cells. Values are\\ninterpolated using the convergent gridding algorithm.\\nResample: Upscales a fine grid into the resolution of a coarser one.\\nFlip I: flips the grid in the I direction.\\nFlip J: flips the grid in the J direction.\\nShift I+: Move the grid towards the east by the specified number of grid cells.\\nShift J+: Move the grid towards the north by the specified number of grid cells.\\nShift I-: Move the grid towards the west by the specified number of grid cells.\\nShift J-: Move the grid towards the south by the specified number of grid cells.\"},\n",
       " {'header': 'Calculation ',\n",
       "  'content': 'Extract information from the object, this information will be reported in the message window.\\nVolume below a surface (constant): Calculates the volume below the surface and above\\na specified constant (Volumes will be calculated much more accurately when using the\\nvolume calculation process on a 3 grid). The user also have the option to use fault polygons\\nto improve the accuracy of the surface volumetrics (avoid the smearing effect of the fault\\nzone). Surfaces only.\\nVolume below a surface (surface): Calculates the volume below the surface and above\\na specified surface (Volumes will be calculated much more accurately when using the\\nvolume calculation process on a 3 grid). Surfaces only.\\nVolume /Area versus depth: Calculates the volume and the area between a surface and\\na constant value at a series of depths. The minimum, maximum and interval are specified\\nand the result is written to a function on the input tab.\\n2 & 3D area of a surface: Calculate the area of a surface in 2 and 3D. Surfaces only.\\nArea and Length: Calculate the area and length of all the polygons in the object. Polygon\\nonly.\\nMake Thickness Map: Calculates the thickness between the given surface and another\\nusing the dip and azimuth of the surfaces. This requires the user to drop in the second\\nsurface and specify the required format of the result TST (true stratigraphic thickness) or\\nTVT (true vertical thickness).\\nMany of the same operations are available as Get Result operations. These return the result to a\\nvariable in the Workflow editor for use in controlling the workflow.\\nGet Result of Calculations\\nThis option performs calculations and writes the results back to a variable in a workflow. It is\\ntherefore only available in the Workflow editor.\\nGet Xmin value of data: Retrieves the minimum X value of the selected data.\\nGet Ymin value of data: Retrieves the minimum Y value of the selected data.\\nGet Zmin value of data: Retrieves the minimum Z value of the selected data.\\nGet Xmax value of data: Retrieves the maximum X value of the selected data.\\nGet Ymax value of data: Retrieves the maximum Y value of the selected data.\\nGet Zmax value of data: Retrieves the maximum Z value of the selected data.\\nGet area of closed polygon: Retrieves the area of a polygon.\\nGet length of line: Retrieves the length of a line\\nGet area of surface: Retrieves the area of a specified surface.\\nVolume below a surface- Constant: Retrieves the volume between the chosen surface\\nand a constant.\\nVolume below a surface-Surface: Retrieves the volume between two chosen surfaces.\\nArea of intersection- Constant: Retrieves the area at the intersection between a surface\\nand a constant.\\nArea of intersection-Surface: Retrieves the area at the intersection between two\\nsurfaces.'},\n",
       " {'header': 'Convert Points/Polygons/Surfaces ',\n",
       "  'content': 'Generate objects from the object. The objects will be placed in the input tab.\\nConvert to polygon: Convert points to polygons (points only).\\nConvert to points: Convert the object to points (surfaces and polygons only)\\nCreate boundary: Creates a boundary around the data (points and polygons only)\\nCreate surface edge: Creates a boundary around the surface (surface only)\\nCreate i-gridlines: Generates polygons representing the gridlines in the i direction\\n(surfaces only)\\nCreate j-gridlines: Generates polygons representing the gridlines in the j direction\\n(surfaces only)\\nCreate contours: Generates polygons representing the contours of the surface (surfaces\\nonly).\\nCreate intersection with surface: Generates a polygon at the intersection between the\\nsurface and a user defined surface (surfaces only).\\nCreate intersection with plane: Generates a polygon at the intersection between the\\nsurface and a plane at a user defined Z value (surfaces only).\\nSpilt polygons into several polygons: Will convert a polygon object containing several\\npolygons into several polygon objects, each containing one polygon.'},\n",
       " {'header': 'Seismic Operations ',\n",
       "  'content': 'Assign Values from a seismic cube and samples the values of the chosen seismic cube onto the\\nchosen object. This requires the seismic sampling module.'},\n",
       " {'header': 'Depth Conversion ',\n",
       "  'content': 'Depth converts the object with the chosen velocity model.\\nOperations on points, lines, and surfaces\\nMathematical and logical operations can be performed on imported surface-, line-, and point-\\ndata. This will alter nodes/points in the dataset.\\nExamples of uses include moving surfaces up or down (+- constant value), smoothing surfaces,\\nextracting the intersection between fault surfaces and horizon surfaces, calculating volumes under\\na surface, smoothing polygons (spline interpolation), removing excess points, etc.\\nWithin this section you will find a list of available operations from the Operations and\\nCalculations tabs in the Settings windows, together with a few case examples of operations that\\ncan be performed.\\nCalculations tab (points, lines and surfaces)\\nThe first line of the Calculations tab displays min-, max- and delta- Z-values for the selected\\nobject. The following functionality is available in the Operations panel:'},\n",
       " {'header': 'Operations ',\n",
       "  'content': \"Option to perform an operation between a value and selected data object,\\nor between a surface that has been selected in the Input pane and your data object. To add a\\nsurface to the drop area, select the surface in the Input pane (click on it) and then click on the\\nblue arrow .\\nChecking the tick box will ensure that points outside of the area of the surface (which will remain\\nunaffected by the operation) will be deleted from the object.\\nMathematical operations\\nNode- or point-values of a data object can be changed by adding, subtracting, multiplying,\\ndividing, raising by a power or simply assigning a constant value (or the value of the selected\\nsurface).\\nConditional operations\\nNodes/points can be eliminated or set to a constant value or surface value when certain\\nconditions apply:\\n- Less than condition\\n- Less than or equal to condition\\n- Greater than condition\\n- Greater than or equal to condition\\nNumerical operations\\nPetrel's operation panels are equipped with direct numerical functions. By clicking on any of these,\\nthe data object will be transformed according to selected function. Z means depth, thickness, etc.\\nThe following numerical functions are available on the Calculator tab:\\nZ = ln Z if Z = 0\\nZ = log Z if Z = 0\\nZ = e z\\nZ = 10 z\"},\n",
       " {'header': 'Z = Z ',\n",
       "  'content': 'Returns an Integer for Z (e.g. 18.78=18 and 5.32=18)\\nReturns a rounded integer (e.g. 18.78=19 and 5.32=5)\\nZ = sin(Z)'},\n",
       " {'header': 'Z = Arcsin(Z) ', 'content': 'Z = cos(Z)'},\n",
       " {'header': 'Z = Arccos(Z) ', 'content': 'Z = tan(Z)'},\n",
       " {'header': 'Z = Arctan(Z) ',\n",
       "  'content': \"Eliminate operation\\nTo be able to use an operation that eliminates data outside or inside a specific area can\\nsometimes be very useful. Drop a polygon by selecting it (clicking on it) in the Input pane and\\nthen clicking on the blue arrow . Select whether to eliminate data outside or inside the polygon.\\nMore tab\\nThe More tab is found in the Settings window for surface objects. To open the Settings window,\\neither double-click the object or open it through the option Settings from the right mouse button\\npull-down menu.\\nSmoothing of surfaces, option to give number of iterations and filter width for the\\nsmoothing process. Only neighboring cells will be affected when using a filter width of 1.\\nShift, Expand/shrink surface, using linear extrapolation.\\nThe shift operation will move the surfaces the specified number of grid cells along I or J. The\\noriginal grid limits will be kept, the new part of the surface will be calculated using linear\\nextrapolation. The area that the new surface moved away from will be kept in the original\\nshape.\\nThe expand/shrink operation only works for regular grids. An irregular grid needs to be\\nconverted into a regular surface grid before the operation is performed. Use the Make\\nSurface process step to convert an imported surface.\\nLogical operations between surfaces:\\nAnother surface must be selected in the Input pane and dropped as Other surface (click on the\\nblue arrow) to enable operations between two surfaces.\\nWorks only when the 'Expand this surface to cover the other surface' box is checked. Will\\nkeep the defined values from the original surface and insert undefined nodes in the expanded\\narea.\\nRemoves the original surface outside the overlapping area.\\nRemoves the part of the original surface that is overlapping with the selected surface.\\nReplaces the overlapping part of the original surface with the selected surface.\\nMerges the original surface with the selected surface and removes the overlapping area.\\nMerges the two surfaces into one and in the overlapping area the original surface is kept.\\nMerges the two surfaces into one and in the overlapping area the selected surface is kept.\\nFlipping is used to reflect surfaces around axis parallel to one of the grid axis. The flipping\\naxis will be drawn through the central node of the surface. Due to undefined nodes, this axis\\nmay not be in the center of the surface as seen in the Display window.\\nFigure showing an example of flipping a surface.\\nEffects - Dip azimuth and Dip angle will extract these features from the surface. Fault\\ndetect can be used to locate a better definition of the hanging wall and footwall of some\\nfaults. An algorithm will produce a derivative of the surface. Increasing the filter width will\\nresult in more pronounced relief of the resulting surface. Note that these operations will (as\\nall other operations) affect the surface itself so make sure you are working on a copy if you\\nwant to keep the original.\"},\n",
       " {'header': 'Point Editor ',\n",
       "  'content': 'The coordinates for a point dataset can be displayed in a Point Spreadsheet. Open the\\nspreadsheet from the pull-down menu by right-clicking a point set. Through the editor, coordinate\\ndata can be added, edited or removed.\\nThe spreadsheet format makes it easy to copy data to other applications (for example, MS Excel)\\nfor editing. The edited data can easily be imported back into the editor.\\nSee How to edit point data.\\nA figure showing the point editor in Petrel.\\nHow to edit point data\\n1. Open the right mouse button menu for the selected point data set in the Input pane.\\n2. Select the View spreadsheet option, and the Point spreadsheet will pop up.\\n3. Edit the points by entering a new number and pressing OK when finished.\\nCoordinates from the well points are located in rows, with one column for X-, Y, and Z-values.\\nExamples of use of operations\\nThis section lists a few suggestions of useful applications of the operations available in Petrel.\\nHow to add a constant thickness value to a given surface\\nThis operation is often useful when, for example, a base of the reservoir for some reason is not\\navailable. It is necessary to have a base to be able to define the reservoir volumes. The following\\nsimple operation can be done:\\n1. Open the Settings window for the surface you want to start with and select the Operations\\ntab.\\n2. Set A=<the thickness you want to add> and press Z=Z-A.\\n3. Check the Statistics tab to see the new Z-range of the surface.\\nHow to change Z-values of fault polygons\\nSometimes fault polygons have zero as Z-values when imported from various mapping\\napplications. Depth values can be sampled from corresponding structural surfaces by following the\\ndescription below:\\n1. Display fault polygons and the corresponding surface.\\n2. Open the Settings window for the fault polygons and choose the Calculations tab.\\n3. Select the surface (set active by clicking on the surface in the Input pane).\\n4. Click on the blue arrow after A= and press Z=A.\\nSee also How to use the Z-value selector.\\nPoints on the polygons outside the XY limits of the surface will be lost.\\nOperations on grids\\nOperations tab (Grid settings)\\nTwo options are available under the Operations tab of the grid; flipping and erosion tolerance.'},\n",
       " {'header': 'Flipping ',\n",
       "  'content': 'The flipping function of the 3D grid is an option to flip he east-west line along the center of the 3D\\ngrid (with or without properties).\\nThe origin will be reset so that North and South will reverse positions.\\nThe purpose of this function is to gain flexibility to handle input from other applications that define\\nthe origin of the coordinate system differently. It is also possible to change the origin of the\\ncoordinate system at the time of import.'},\n",
       " {'header': 'Erosion Tolerance ',\n",
       "  'content': \"When modeling eroded horizons, if the horizon is not fully 'eroded' in the input data (that is, there\\nis a small gap between the top and bottom horizons of the eroded zone), the horizon will not be\\nproperly eroded.\\nThis can be corrected by setting the minimum allowed gap and clickin on Remove Gaps.\\nThe minimum allowed gap is the minimum thickness (in project units) a zone can have before it is\\ncompletely eroded. Were cells are thinner than the minimum thickness, the Z-value of the horizon\\nforming the bottom of the cell will be made equal to the Z-value of the horizon forming the top of\\nthe cell.\\nThis action is non-reversible. If you are in doubt, make a copy of the 3D grid first.\\nOutput tab on the 3D Grid\\nThere is an option in Petrel to make a filter sensitive copy of the 3D grid. This copy can then be\\nexported in any of the available export formats.\\nThis is a very useful option for those who want to export a selected part of a model.\\n1. Set the filters as required - Index filter, Zone filter and Segments filter.\\n2. Double-click on a 3D grid in Petrel to open the Settings window for the grid.\\n3. Go to the Output tab.\\n4.\\n1.\\n2.\\n3.\\n4. Select the filters you want to use, and press Copy 3D grid.\\nOperations on properties\\nSimple operations on properties are executed through the Operations tab on the settings dialog\\nfor the properties folder. More complex operations on individual properties and the generation of\\nnew properties from existing data can be performed through the Property Calculator. This is\\naccessed by right-clicking the properties folder for the appropriate grid and selecting Calculator.\\nFor more information on the property calculator see Calculator.\\nOperations tab (Individual Properties)\\nThe operations available on this tab depend on the property type, discrete (facies) or continuous\\n(porosity). Operations are also split into two groups:\\nProperty operations - Will alter the properties themselves.\\nMake map from property - Will create surfaces in the Input pane based on the property.\\nAt the base of the dialog are a number of function buttons allowing users to control how these\\noperations are applied and to which cells.\\nWhen selected, the filter ensures that the operation is only performed on the cells\\npassing the current property filter. This includes the zone and segment filters, as well as the\\nvalue and index filters and the filtering of the upscaled cells.\\nWill lock the upscaled cells so they are not affected by the operation. This is\\nrecommended as upscaled cells usually represent hard data.\\nSelect which zone in the model the operation should be applied to.\\nThere are a number of other buttons common to all operations pages.\\nAll of the operations can also be performed in the workflow editor.\\nProperty operations (Operations tab)\\nThe operations available on this tab depend on the property type, discrete (for example, facies) or\\ncontinuous (for example, porosity).\\nSet undefined - Sets the whole property to undefined.\\nExtrapolate (cont) - Extrapolates the property across undefined areas of the grid using\\nthe cells surrounding the undefined area and extrapolating laterally (same K layer). There\\nare two options for the algorithm, minimum curvature and full tension.\\nSmooth (cont) - Smoothes each layer in the property (cells above or below the layer are\\nnot considered).\\nNormalize (cont) - Scales the property so that it lies between a specified minimum and\\nmaximum. This is useful for scaling properties to create e.g. facies probabilities. Requires\\nmin and max values.\\nProperty = Surface(X,Y) - Assigns surface values to property based on the XY position of\\nthe cell center, requires a surface for the property.\\nProperty = Function(Z) - Transforms the property based on the given function, requires\\na function see Functions.\\nA smoothing operation.\\nNormalize = Normalize the values so that the maximum and minimum values are the ones\\nspecified by the user.\\nSum vertically = Sums up the property value in each IJ-column. Can be used in\\ncombination with filters.\\nMake seismic cube = Makes a seismic attribute cube based on the property.\\nThe following explains how a seismic cube is generated from a property:\\n1. Find the cell centers of the seismic cube specified as the Seismic resolution cube. The seismic\\ncell is defined by a hexahedron centered on the sample point/node in the seismic cube.\\n2. Identify the property cells in which the seismic cell centers are located.\\nWhen Interpolate is OFF, the value of the property cell in which the seismic cell center falls inside\\nis assigned directly to the cell in the output cube.\\nWhen Interpolation is specified, continue with the following steps.\\n3. Split the property cell, including the seismic sample point (seismic cell center) into 5\\ntetrahedrons.\\n4. Calculate the corner values for the tetrahedron holding the seismic sample point. Each corner is\\nsurrounded by 8 property cells and the value is taken as the arithmetic mean of the 8 cell values.\\nLet's say we want to calculate the value of the corner marked in red below. This is identical to the\\nupper left corner of property cell a. It is surrounded by cells a, b, c and d in this specific K layer. It\\nis also surrounded by 4 cells with similar I, J positions in the K layer above. The corner value will\\nbe the arithmetic mean of the 8 cells identified as the closest neighbors.\\n5. Map the seismic sample point and tetrahedron to a unit space tetrahedron and interpolate. The\\ntetrahedron including the sample point is transformed to a local coordinate system where the\\nlength of each side is one unit.\\nThe sketch below illustrates the transformation in a two dimensions:\\nThe formula for calculating the interpolated value at the sample point (red spot) within the unit\\nspace tetrahedron is given above.\\n6. The interpolated value is assigned to the actual seismic sample point.\\n7. Repeat the process for all sample points forming the seismic resolution cube.\\nMake maps from properties (Operations tab)\\nThe operations available on this tab depend on the property type, discrete (for example, facies) or\\ncontinuous (for example, porosity). All of these operations create a new surface in the Input\\npane. To specify the resolution and extents of the surface, drop an existing surface with the\\nrequired geometry into the dialog. If none is given, a default geometry will be created.\\nMake average map - Creates a surface with the volume weighted average value of the\\nproperty at each XY location. There are options to smooth the result (this will remove some\\nof the effects of the grid structure and give a better result) and to expand the result such\\nthat fault gaps are filled.\\nMake volume height maps - Creates a surface representing the integral of the property\\nwith respect to elevation divided by the cell volume at each XY location. When performed on\\nvolume properties (porosity, STOIIP, etc.) this represents the volume per unit area in the\\nchosen zone at that point. There is an option to smooth the result.\\nMake net map - Creates a surface representing the sum of the property multiplied by the\\nheight at each point. With volume proportion properties (L3/L3) such as Net to Gross this\\nrepresents the effective thickness of the unit.\\nMake water table map - Create a water table making use of hydraulic head values.\\n(for each zone) - each of the above operations also has a similar option which allows the\\nuser to make one map per zone in a single operation.\\nMake surface attribute property map - Extracts the property values from the selected\\nproperty along the selected surface.\\nA top sand map for tarbert2 in the Gullfaks field.\\nMore tab (Individual Properties)\\nOn the More tab, the user has the option to smooth the property across the boundary between\\ntwo facies. This can be useful for removing the sharp property contrasts in the model which, in\\nturn, can give the simulator problems.\\nChoose the facies model to be applied to guide the areas to smooth and the two facies codes to\\nsmooth between. There are three options available for controlling which side of the boundary the\\nproperty should be smoothed on. To the right, there are diagrams illustrating the effect.\\nOperations on Well logs\\nThere are two options available in the Operations tab on wells; to eliminate the well above or\\nbelow a certain Z-value and to smooth the log. These operations can be perfomred globally for all\\nwells or for one specific well at a time.\\nTo do this globally, open the Settings window for the Wells folder. To do this for a specific\\nwell, open the Settings window for a Well file.\\nTo eliminate a section of the well, choose the appropriate cutoff values and press Eliminate. To\\nsmooth a zig-zagged well, press Smooth. Zig-zagging may be caused by importing the file with\\ntoo few data points, this is a particular problem when importing from simulators. Check the\\nAdjust MD values checkbox if MD values were not read in during well import.\\nUse of calculator\\nThe calculator can be used on the wells in two different ways:\\nGlobally - use the calculator from the pull-down menu of the Global Well Logs folder.\\nIndividually - use the calculator from the pull-down menu of a specific Well file.\\nThe calculator can be used to create new logs, for example, use a Porosity log and a simple\\nformula to create a synthetic Permeability log. For more information and examples of how to use\\nthe calculator, see Well Log Calculator.\\nNote that each log should be attached to the correct template. The template can be defined\\nglobally (for all wells) from the Settings window of the Global Well Logs folder, or individually for\\na specific well from the Settings window of the Well. The template can be changed under the Info\\ntab, option Attach to template - for details see Templates and Well Logs.\\nLookup curves\\nLookup curves can be used to define transformations and can then be used in the calculators or\\nas part of the operations on an object. The number to be transformed will represent the X value\\nof the function and the function will return the corresponding Y value. This is written in the\\ncalculator in the form:\\nFunctionName(x)\\nFunctions can be imported as a table of X,Y data (see Import Functions (Lookup curves)) or\\ngenerated interactively in Petrel by right-clicking on the function folder and choosing Insert new\\nfunction. See Functions.\\nQuality Control of processed data\\nIt is important to check the statistics whenever you have performed any processing operations.\\nAlways compare statistics before and after the operation to check if the results seem logical.\\nEach data object has some statistical information accounted for in the Statistics tab of its\\nSettings window. The information varies depending on which type of data it represents.\\nMax, min and delta values for the extension of the data are typically represented, as is gridding\\ninformation, number of nodes, points, defined cells, etc. A histogram is also available for well logs\\nand properties.\"},\n",
       " {'header': 'Visualization ',\n",
       "  'content': 'Visualizing objects in 3D allows you to observe details that would have been lost by looking at\\nthem in plane view. Bad data, such as spikes or mis-ties in seismic interpretations, are often\\nimmediately obvious. It is essential to perform visual quality control checks on your data\\nthroughout the modeling process.\\nOnce all of the necessary input data has been brought into Petrel, it should be checked and\\ncompared with the other data to reveal inconsistencies; fault lines can be compared with imported\\nsurfaces, well tops can be compared with well logs and surfaces, and so on.\\nTo locate data in the 3D Display window after import, click on the Map View Position icon or\\nthe View All icon. The latter icon works for most types of display windows and enables you to\\ncollect and view all displayed data.'},\n",
       " {'header': 'Annotations ',\n",
       "  'content': 'The Annotations object allows you to attach names, etc. to various objects in the display. First,\\nannotations must be added to the list, then attached to an object and displayed in the window.\\nOnce displayed, the text can be moved in the map window by clicking and dragging it to a new\\nposition. By pressing SHIFT while dragging, the name can be rotated.\\nAnnotations can be added to a project by selecting New Annotations from the Insert\\nmenu. Only one annotation object is allowed per project.\\nStyle tab (Annotations)\\nDefine the font size, the color and define whether to use bold and/or italic. For the Map view, the\\nbackground color as well as the frame view can be defined.\\nUser defined text styles can be added to the Text Styles table by clicking on the Add new text\\nstyle icon. Give the new text style a name and define the new font styles.\\nSettings tab (Annotations)\\nThis is where the different objects that should be associated with an annotation are defined.\\nAppend item in table to insert new objects. Multiple drop is possible: If for instance, 20\\nsegments should be associated with an annotation, insert only one new row, click on the Multiple\\ndrop in table icon , and click on a segment in the Petrel Models tab segment filter. When\\nclicking on the blue arrow, all of the following 20 segments will be pasted into the table.\\nIn the Annotation table, you can copy and paste from Excel. The Excel sheet must have the\\ncorrect columns, but this is easily checked by first making a paste from the annotation table to'},\n",
       " {'header': 'Excel. ',\n",
       "  'content': 'The text can be changed, if desired. The object will be positioned at its midpoint in X, Y and Z. All\\ncoordinates can be changed manually by the user. The difference between Show and Show\\nalways , is that the first will only show the annotation associated with an object if the object itself\\nis being displayed, while the latter will always show the annotations, no matter what is being\\ndisplayed.\\nStatistics tab (Annotations)\\nThis is a standard Statistics tab, see Statistics tab .\\nQuality Control in 3D\\nDisplaying your data in 3D allows rapid identification of inconsistent data. In Petrel, you can\\ndisplay all of your input data and perform quality control in 3D space.\\nThis way, all structural data can be viewed simultaneously irrespective of spatial interrelationships\\nbetween surfaces and faults.\\nThere are several simple quality control steps that quickly reveal the data quality:\\nDisplay several surfaces together to make sure that they do not intersect.\\nCheck that the wells are in the correct position relative to other input data by displaying the\\nwells together with, for example, an input surface in 3D.\\nCompare 3D surfaces with formation tops from well log data, contours and log curves in 3D\\nspace. With 3D visualization, errors become obvious when a gridded surface does not match\\nthe formation well top in the logs.\\nTo check the interpretation of seismic data, make a surface (use the Make Surface process\\nstep) of the interpreted lines and compare it with the original seismic cube.\\nTo compare, for example, porosity models with input logs, make the porosity model\\ntransparent and display it together with the input logs.\\nExtreme values of properties, volumes and so on, can be filtered out using the property\\nfilter. Displaying these values in a 3D window gives an overview of their distribution.\\nPetrel allows you to import all available production data; hence you can compare\\nperforation intervals with the calculated water saturation and production data.\\nUse the Target Zoom tool to check the interrelationship between horizons, fault displacement\\nand details in structure. Display one segment at a time together with faults in that area. Also,\\ndisplay the top and base horizon of the reservoir. Move around inside the segment by using the\\nTarget Zoom. This way of quality checking is even more powerful and informative with 3D\\nglasses.\\nFigure 1. Using Target Zoom inside the model.\\nSynchronized Camera Position for 3D Windows\\nTo sunchronize the camera position for several 3D windows, the windows have to be linked using the\\ncamera linking tool\\n1. Click on the camera linking tool while having the first 3D window you would link active. The\\ntext (Camera link) appear after the name of the 3D window.\\n2. Activate the next 3D window and click the camera link tool again.\\n3. The windows are now linked and any movements, rotations etc will be mirrored in the other\\nwindow\\nView and Switch Between Multiple Object'},\n",
       " {'header': 'Selections ',\n",
       "  'content': 'To view multiple objects in a folder, simply select the name (activate) while pressing the Ctrl or\\nShift key. Once the selection is done, check one of the checkboxes of the selected objects - all of\\nthe highlighted objects will be switched on in the display window.\\nThe same can be done for switching off the selection (the selection is kept until another object is\\nhighlighted - provided the Shift or Ctrl key is not used).\\nThe above operation is restricted to data that is in the same folder, or at the same level in\\nthe tree (this is a Windows limitation).\\nToggle Visibility of Objects in Plot Windows\\nTo view the settings of an object in any plot window, there is a right-click option available; by\\nmoving the cursor over the specific object in the display window, right-click on it and the settings\\nfor that particular object will appear.\\nIn the settings window there are two added options specific to the plot window:\\nToggle visibility - this will turn the object on or off in the display plot window. In addition, Petrel\\nwill then take you directly to the object in the Explorer tree so that it is easy to know which object\\nyou are pointing at.\\nToggle active in tree - this will make the object bold in the Input or Models pane.'},\n",
       " {'header': 'General Intersection ',\n",
       "  'content': 'The General Intersection is a tool for making cross sections and can be interactively moved in the\\n3D Display window. As the intersection is moved, data cut by the intersection can be displayed.\\nGeneral Intersections can be inserted both in the Input pane and the Models pane, and are\\nassigned the icon. A general intersection adapts the extent necessary to encompass the\\nsubjects being visualized on it. On creation, no subjects are visualized, and the intersection\\nassumes the default \"parent extent\", - the union of the extents of all appropriate subjects\\ncontained by the parent folder (that is, if the intersection is placed directly in the tree, all subjects\\nare in that tree). To see how to display objects on the general intersection, see Toggle for\\nActivating Visualization on Intersections (Intersection Mode)\\nToggle for Activating Visualization on Intersections'},\n",
       " {'header': '(Intersection Mode) ',\n",
       "  'content': 'When a General Intersection plane is active (bold in the Input or Models pane), a second view\\nmode becomes available in which data is projected onto the intersection plane. This mode is\\nactivated using the Toggle Visualization on Plane icon, located on the left side of the Tool\\nbar below the Display window.\\nWhen this icon is toggled on, the white checkboxes in front of several data objects listed in the\\nInput pane or Models pane will become blue, indicating that those objects can be visualized in the\\nactive intersection.\\nChecking a blue checkbox will display the object by projecting it onto the intersection plane, only\\ndata in the plane of the intersection will be visualized.\\nActivating the Toggle Visualization on Plane will not deactivate the selection of objects\\ndisplayed in the normal mode (white checkboxes). Nor will deactivating the plane deactivate the\\nobjects displayed on the plane (blue checkboxes). Therefore, in order to remove or display an\\nobject, you must first ensure that the correct mode is selected.\\nFigure 1. Example of General Intersection in Petrel.\\nTools for the General Intersection\\nFor detailed use of intersections with seismic data, see Display of Seismic Data.\\nPlane Play Forwards and Plane Play Backwards will play the General Intersection plane\\nthrough the data.\\nPlane Step controls the increment of the steps used for playing or stepping\\nthrough the data. The units correspond to the project units of the data in the model. The Player\\nspeed can be controlled from the watch icon (in milliseconds). Shortcut keys: Ctrl + PgUp, PgDn\\nStep Plane Forwards and Step Plane Backwards moves the General Intersection only\\none step (forwards or backwards) per click. Shortcut keys: PgUp, PgDn.\\nAlign Vertically will prevent tilting of the General Intersection. Holding down the Ctrl key and\\nmoving the cursor will rotate the plane, but it will remain vertical.\\nAlign North to South (or Inlines) will align the plane in a North to South direction. The\\nplane can no longer be rotated, only moved back and forth along the specified alignment. Seismic\\nIntersections will be aligned along inlines.\\nAlign East to West (or Crosslines) will align the plane in an East to West direction. The\\nplane can no longer be rotated, only moved back and forth along the specified alignment. Seismic\\nIntersections will be aligned along crosslines.\\nAlign Horizontally (Timeslices) will align the plane horizontally. The plane can now only be\\nmoved up and down along the Z axis. This is useful when visualizing a time slice cube.\\nPlane Depth gives the current depth of the General Intersection when the Align\\nHorizontally button is active. It is possible to move the General Intersection to a specific depth,\\ne.g. the OWC, by typing in the depth on this button, as long as the plane is aligned horizontally.\\nAlign camera with plane will move the camera to directly face the currently active\\nintersection when toggled on. The camera will then remain locked to the plane, attempting to\\nrotate the view (with Manipulate Plane depressed) will result in panning, and moving the\\nplane (using PgUp, PgDn) will result in a corresponding move of the camera.\\nClip the Plane in Front and Clip the Plane Behind will cut out the data in front or\\nbehind the plane, and the model can be viewed in a cross section view.\\nSnap Intersection Plane by one , two or three points will allow the user to snap the\\nplane to a specific place. When one of the alignment buttons is active, the different snap buttons\\nare not always available.\\nHow to play through the 3D model with a property\\n1. Open a General Intersection plane from the Intersections folder in the Model pane.\\n2. Click on the blue box to the left in the Tool bar positioned below the Display window.\\n3. Tick the blue colored box beside a property (for example, porosity) in the Models pane.\\n4. Define the plane alignment using the options on the Tool bar below.\\n5. Play through the model with a given plane step increment.\\nTo move the plane manually, click on the Manipulate Plane icon to activate it. Then use the\\ncursor for free movement; combine with the Ctrl key to rotate. Note that activated alignment\\noptions will limit movement freedom.\\nThe way in which items are displayed on the General intersection plane is controlled in the\\nsettings for the General Intersection. See General Intersection settings for more information.\\nGeneral Intersection - Input pane\\nA General Intersection can be created from general folders in the Input pane. Data displayed on\\nthe intersection does not need to be from the folder where the intersection was created.\\nHow to Create a General Intersection in the Input Pane\\n1. Click with the right mouse button on one of the general folders in the Input pane.\\n2. Select Insert General Intersection plane from the pull down menu.\\n3. Observe that a new General Intersection is added to the list of data in the folder. Also, a\\nnew Tool bar will appear below the Display window once the General Intersection is active\\n(bold).\\n4. Click on the Toggle Visualization on Plane in the left corner of the Function bar.\\n5. Observe that some of the white checkboxes, in front of objects in the Input and Models\\npane, are colored blue. By checking the blue boxes, the objects will now be projected onto\\nthe plane.\\n6. Check the blue box for the data that you want to visualize on the intersection plane. Once\\nfinished, toggle off the blue button again.\\nFor details of the Toggle Visualization on Plane icon, see Toggle for Activating Visualization on'},\n",
       " {'header': 'Intersections (Intersection Mode). General Intersection - Models Pane ',\n",
       "  'content': 'In the Models tab in the Petrel Explorer, the General Intersection plane must be generated from\\nthe Intersections folder. Playing through the 3D grid with different properties using General\\nIntersection planes is a very efficient method for performing quality checks and increasing\\nunderstanding of the model.\\nThe procedure for generating a General Intersection plane, under the Models tab, is identical to\\nthat described for the Input tab, but under the Model tab, an intersection plane can only be\\ngenerated in the Intersection folder. See How to create a General Intersection in the Input pane.'},\n",
       " {'header': 'General Intersection Plane Toolbar ',\n",
       "  'content': 'When the General Intersection plane is active (bold), a toolbar appears below the Display window.\\nThis toolbar contains specific tools for manipulating the intersection plane.\\nThe icon in the left corner of this toolbar, Toggle Visualization on Plane , is a toggle for\\nswitching between normal display mode and intersection mode as described above under Toggle\\nfor Activating Visualization on Intersections (Intersection Mode).\\nHow to Use the General Intersection\\n1. With the Play and Step buttons on the toolbar. This toolbar is available (below the Display\\nwindow) when the General Intersection is active (in bold).\\n2. When the button Manipulate Plane is active (shortcut, M), PgUp and PgDn will move the\\nGeneral Intersection along a line normal to the plane (at increments specified in the Plane\\nStep icon window), the cursor and the right and left arrow keys will rotate it around the Z-\\naxis.\\n3. When the button Manipulate Plane is active, you can click with the left mouse button on\\nthe plane and drag it along its normal. Holding down the Ctrl key and moving the cursor will\\nrotate the General Intersection.\\nThe intersection plane can only be moved freely when no align plane button is active.'},\n",
       " {'header': 'Vertical Intersections ',\n",
       "  'content': 'In addition to the General Intersection plane, vertical intersections can be inserted along a\\npolygon/well path, or to go between wells (well fence). These intersections work in much the\\nsame way as the General Intersection, however, they are fixed and cannot be moved once\\ninserted. Therefore, all buttons on the intersection tool bar will be inactive apart from Toggle\\nVisualization on Plane .\\nFor vertical well intersections there are two extra options on the planes settings, Extend Start\\nand Extend End. These will extend the plane by the specified amount beyond the end of the well\\npath in horizontal distance (in project units). If the end of the well is near vertical, this may result\\nin extrapolation in an unexpected direction.\\nFigure 1. Example of Plane extension in a vertical intersection of a polygon.\\nThe intersections are linked to the data they display, so if the original polygon or well(s) change,\\nthe intersection will adjust accordingly. When editing the polygon, the intersection will be updated\\nas you move it around in the 3D Display window.\\nFigure 2. Example of an intersection along a well.\\nHow to Create a Vertical Intersection from a Polygon\\nWhen creating a Vertical Intersection, a polygon must first be digitized in or imported into Petrel\\n(see Digitizing polygons and points or Lines and Points).\\nAny kind of polygon data can be used.\\n1. Click with the right mouse button on a polygon in the Input pane.\\n2. Select Create Vertical Intersection from the pull-down menu.\\n3. An intersection along the polygon will be created and placed at the bottom of the Input\\npane.\\nTo display data on the intersection, select the intersection in the Input pane and use the button\\nToggle visualization on plane (see General Intersection plane toolbar).\\nHow to Create a Vertical Well Intersection from a Well Path\\nVertical Intersections can be created along any well path imported or designed in Petrel. The\\nintersections can be created as a combined intersection for all wells or as separate ones for each\\nsingle well.\\n1. Click with the right mouse button on the Wells folder (to make a combined intersection for\\nall wells) or click with the right mouse button on a single well (to make a single well\\nintersection).\\n2. Select Create Vertical Well Intersection from the pull-down menu.\\n3. An intersection along the well path(s) will be created and placed at the bottom of the Wells\\nfolder.\\nTo display data on the intersection, select the intersection in the Input pane and use the button\\nToggle visualization on plane (see General Intersection plane toolbar).\\nHow to Create an Intersection Fence Between Wells\\nAn Intersection Fence is built up of vertical intersection planes drawn between wells. The\\nalignment is made either from the top, mid or base point of the well paths or from a well top. In\\naddition to e.g. a top alignment, it is possible to tie the plane to the base of the well. Well Fence is\\ncontrolled from the Well Section in the Windows pane. The well fence can be displayed in 3D,\\nIntersection and Map view.\\n1. Insert a new well section from Windows menu. Toggle on the wells of interest.\\nAlternatively, do this in 3D, with the Well Correlation process active.\\n2. Once the wells are selected, double-click on the Well Section Fence under the active Well\\nSection in Windows tab. This will take you to the Wells tab under settings for the Fence.\\n3. Select to align fence to top, middle, bottom or well top. Tie to point bottom if you have\\ndeviated or horizontal wells.\\n4. To close a fence (join the two ends), check the Close option.\\n5. Click OK.\\nTo display data on the intersection, select the intersection in the Input pane and use the button\\nToggle visualization on plane . See Toggle for Activating Visualization on Intersections\\n(Intersection Mode) for information on this option.'},\n",
       " {'header': 'Fault Intersection ',\n",
       "  'content': 'The Fault Intersection plane is a tool for making cross sections perpendicular to faults in a 3D\\nGrid. As the intersection is moved using an Intersection Player, data cut by the intersection can\\nbe displayed.\\nA Fault Intersection plane can be inserted in the Faults folder under a 3D Grid in the Models pane.\\nAs the fault intersection is moved, it will jump from pillar to pillar and will always remain\\nperpendicular to the pillar it is displayed through.\\nHow to Create a Fault Intersection Plane in the Models Pane\\n1. Click with the right mouse button on one of the faults in the Faults folder under a 3D Grid.\\n2. Select Create intersection plane perpendicular to fault plane from the pull-down\\nmenu.\\n3. The fault intersection is stored at the bottom of the Faults folder.\\nI- and J- Grid Intersections\\nThe I- and J-intersections appear in the Intersection folder under a 3D grid in the Model pane.\\nThese intersections will follow the grid cells, which in turn are following the major faults according\\nto the directions and trends set during Pillar Gridding.\\nPlaying through the intersections in the I- and J-directions is a good method for performing\\nquality control of the 3D grid. The intersections will show how the pillars in the grid are placed in\\nrelation to each other.\\nThe property player performs a similar function but displays 3D grid cells so you can QC the\\nmodeled properties.\\nYou need to check the grid after Pillar Gridding before you run the Make horizons process.\\nTwisted cells can cause problems when running the Make horizons process, and as the pillars in\\nthe grid cannot be changed at a later stage, now is a good time to perform a quality control.\\nWhen quality controlling the 3D grid, it is important to look for neighboring pillars that have very\\ndifferent angles. This can introduce errors when inserting horizons and zones to the grid.\\nThe I- and J-intersections can be viewed in the Display window by opening the Intersection folder\\nand selecting one or both of them. A new set of icons will be visible in a Grid player toolbar that\\nappears below the Display window when an intersection is made active.\\nFigure 1. 3D grid Player toolbar.\\nFigure 2. 3D grid in the Model pane with the Intersections folder open.\\nTools for the I- and J-Intersections\\nIn order to move an intersection it must first be active (bold) in the 3D grid. All intersections can\\nbe displayed in the Display window at the same time but only one can be moved at a time. More\\nintersections in either direction can be inserted from the pull-down menu of the Intersection folder\\nor from the Grid player tool bar.\\nIntersect Play Right and Intersect Play Left , the intersection will start moving through\\nthe grid in the appropriate direction.\\nIntersect Line Right and Intersect Line Left moves the intersection one grid cell in the\\nappropriate direction.\\nIntersect Far Right and Intersect Far Left move the active intersection line to the\\ncolumn or row to the far right or far left.\\nIntersect Stop Playing stops the movement of the intersection.\\nSet Player Speed sets the player speed in milliseconds.\\nSnap the Intersect Line by Picking moves the active intersection line to the selected point\\nin the grid.\\nExtend the selected intersect line at one end (this option will only work if the intersection\\nhas been shrunk first because, by default, Petrel will display the maximum width).\\nShrink selected Intersect line at the one end.\\nExtend the selected intersect line at the other end (this option will only work if the\\nintersection has been shrunk first because, by default, Petrel will display the maximum width).\\nShrink selected Intersect line at the other end.\\nAdd a new Intersect line (I-direction) adds a new I-intersection.\\nAdd a new Intersect line (J-direction) adds a new J-intersection.\\nHow to use the I- and J-Intersections\\n1. Go to Models pane, expand a 3D grid and expand the Intersections folder.\\n2. Activate one of the intersections and tick the checkbox to display it.\\n3. To visualize the pillars in the grid (recommended), double-click on the Intersection folder\\nand check Pillars/Show in the Lines sub-tab under Style tab.\\n4. Use the icons in the Grid player tool bar below the Display window to move the intersection.\\n5. Using the I- and J-intersection in the Edit 3D Grid process step can be very helpful in the\\nediting process, see Edit 3D Grid for details.'},\n",
       " {'header': 'Property Player ',\n",
       "  'content': 'A useful way of viewing your property modeling results is by using the Property player in Petrel.\\nThe Property player will go through each layer, row or column, step by step or by animation. It is\\nused as an automatic index filter making it convenient to quickly browse through your results.\\nThe property player is filter sensitive and responds to all filtering techniques that are applicable to\\nproperty models.\\nTools for the Property Player\\nToggle Property Grid toggles the grid lines on/off.\\nToggle Simbox View provides an option to view the grid as a regular box in X, Y and/or Z.\\nShow Property Filter opens the Settings window: Filter tab of the Properties folder.\\nProperty all the way backwards will bring the property player to the last cell of the grid.\\nStep property backwards will move the section one cell backwards.\\nProperty Play backwards will start moving the section backwards through the grid.\\nStop Property Player stops the animation.\\nProperty Play forwards will start moving the section forwards through the grid.\\nStep property forwards will move the section forwards one cell.\\nProperty all the way forwards will bring the player to the first cell of the grid.\\nSet Player Speed will set the player speed in milliseconds.\\nSnap Property Intersection to Point allows the user to click on an object in the Display\\nwindow and thereby snap the intersection to that point.\\nAlign Along I-direction will align the intersection to the I-direction.\\nAlign Along J-direction will align the intersection to the J-direction\\nAlign Along K-direction will align the intersection to the K-direction (horizontally).\\nToggle LGR stepping will toggle whether the player steps through local grid refinements\\ninside host cells.\\nApply Property Value By selecting a property cell in a 3D grid, a new value can be typed in\\nand applied using this button.\\nHow to use the Property Player\\n1. Select a property and display it in a 3D Display window.\\n2. Select which direction the property will be displayed along: I- , J- or K- direction.\\n3. Play through the intersections or layer. Try both forwards and backwards .\\n4. Stop the animation.\\n5. Step through the intersections, or layer, cell by cell. Try forwards and backwards\\nhere too.\\n6. Bring the player back to the first cell or the last cell of your model.\\n7. Move the cross section or layer to a selected index by selecting a point on a simultaneously\\ndisplayed object, use Snap Property Intersection to Point . This could, for example, be a\\nhorizon, fault plane or an intersection. The player will snap to this cell.\\n8.\\n7.\\n8. Switch between showing and hiding gridlines on the grid in a 3D display window .\\nTo activate a filter, double click on the Properties folder and go to the Filter tab or click on the\\nShow Properties Filter icon. For details of how to use the filters, go to Filter.\\nTimestep player\\nProperties with multiple timesteps, such as RESTART files imported from ECLIPSE or Frontsim,\\ncan be animated through time with the timestep player. This can be combined with the Property\\nPlayer to step through the model in any index direction (I, J and K) and time simultaneously.\\nThe time step player is found in the bottom left corner of the Petrel window once a time-stamped\\nproperty is active. It can also be activated or deactivated from the View menu. You can move the\\nTime player by clicking on it with the left mouse button. Drag to the desired place. Hide this\\ntoolbar is placed after the control timestep option. Click on the cross to close the tool bar. To\\ndisplay it again, select Time player toolbar from the View menu on the Menu bar.\\nTools for Timestep player\\nLast time step - will jump to the very last time step\\nNext time step - will jump the next time step\\nPlay time forward - will play forwards through the timesteps.\\nStop time player - will stop the player\\nPlay time backwards - will play backwards through the timesteps.\\nPrevious time step - will jump to the previous time step.\\nFirst time step - will jump to the very first time step.\\nCircular Animation - animation will continue circularly.\\nTime player speed - pops up the Project settings dialog box where the user can change the\\nspeed of the time player.\\nThe Time steps can be selected in three ways:\\n1. Displayed - will take the displayed time-property and play it from the time step selected in the\\nTime Now window to the left in the toolbar.\\n2. User Interval - will use a specified numbered time interval in Years, months, days, hours,\\nminutes, seconds or milliseconds.\\n3. Selection - Select a time-dependant property and drop it in using the blue arrow. By clicking\\non the Get selected time, the time item to be displayed will be copied into the menu. The time\\nitem must exist in the Properties folder in the Models pane. The property selection can be\\nremoved using the red x icon.\\nEach time step should be a separate property object in the Properties folder. These objects are\\ntime stamped and will have a date as suffix in the name. Go to the Info tab under settings for\\nindividual properties to change or set a time.\\nThe Timestep player will not function unless the grid belonging to the data displayed is\\nactive.'},\n",
       " {'header': 'Advanced Display Options ',\n",
       "  'content': 'This section will highlight some specific display features that can be useful.\\nProject Settings: Contains 3D rendering settings for the Display window\\nLight Source: Option for the user to create new or edit light sources\\nFlight Simulator: Fly through the model along a polygon'},\n",
       " {'header': 'Project Settings ',\n",
       "  'content': 'The Project settings window is available from the Project drop-down menu in the Menu bar. All of\\nthe settings here are project specific, that is, they apply to the whole project and include:\\nProject units\\nCoordinates; units and projection\\nSave options\\nGeneral options for Visualization\\nSettings for point selection (widget size),\\nSettings for player speeds\\nIteration settings for Minimum Curvature\\nWell identification\\nAxes orientation.'},\n",
       " {'header': 'Info Tab (Project Settings) ', 'content': 'See Info tab.'},\n",
       " {'header': 'Statistics Tab (Project Settings) ',\n",
       "  'content': 'See Statistics tab'},\n",
       " {'header': 'Project Templates ',\n",
       "  'content': 'Default draw styles for a particular project can be saved from one project and loaded into any\\nother existing project to ensure that data is always displayed in a similar way. Information saved\\nincludes:\\nAll color templates (found under the Template pane)\\nSettings from the Windows pane (light sources, axes & legends, annotation, world cursor,\\netc.)\\nDefault export / import settings to ECLIPSE, VIP, Gslib, CMG (under project settings).\\nUser defined draw styles for objects.\\nDefault draw styles for a particular type of object can be set under the style settings dialog of any\\nobject of that type. All similar objects in the project, whose style settings have not been set\\nmanually, will be given the default settings, as well as any new objects of that type. Set the\\nrequired style settings in the settings dialog for the particular type of object and press Set the\\nsettings as default.\\nChoosing Reset all draw styles from the drop down Project menu on the tool bar will apply the\\ndefault settings to all the objects in the project (whether or not they have manually set styles).\\nChoosing Reset all default draw styles will reapply the default settings to all objects with\\ndefault styles.\\nThe default styles set for a particular project can also be saved and applied to other projects.\\nChoose Save project templates from the drop-down Project menu to save the templates and\\nLoad project templates to import them into the new project.'},\n",
       " {'header': 'Flush Dead Icons ',\n",
       "  'content': 'This is a tool designed to help you with a project when parts of the .ptd files have been destroyed\\nor deleted. A project like this will give you error messages and dead icons upon opening (icons\\nwith a black cross in front). By clicking on the Flush dead icons Petrel will remove all of these\\nicons.\\nUnits and Coordinates Tab (Project Settings)\\nCoordinate system\\nCoordinate system selection is a critical step in defining the project parameters and care must be\\ntaken in picking the right value. For information on how to set correct systems, please see the\\nSpatial enablement chapter.'},\n",
       " {'header': 'Datum ',\n",
       "  'content': 'The project reference datum (PRD) is set for time and depth and is shown in the Units and\\ncoordinates tab. Petrel references the PRD to MSL and SRD which are not possible to edit here\\n(greyed out). As MSL is a fixed datum, it cannot be edited in Petrel. Time datum (SRD) can be set\\nas Z from MSL under settings for SRD and the value returned in the (greyed out) field for\\nDatum (time). See Reference datums for onshore data for more info.\\nFor offshore data, SRD and MSL coincides and, as a result, the two displayed datums in the\\nUnits and coordinates tab are both zero.\\nUnit system\\nThe units set here are used to determine the default units for the project. Changing the Unit\\nsystem will change the units for all of the property templates to match the appropriate system.\\nIndividual property templates can be changed by using the customize option on individual\\nproperty templates; see Units for more information regarding this.\\nUnits are only used for a limited number of activities in Petrel, depth conversion, volume\\ncalculations and simulations. There is no unit conversion once data has been brought into Petrel,\\ntherefore, all conversions must be done on import. After selecting the Unit System, some of the\\nunits can still be changed by checking on the Customize option. You can choose between Metric,\\nField and Field-UTM. XY is the Geographical Distance while Z is the Standard Depth Index.'},\n",
       " {'header': 'Well Settings Tab (Project Settings) ',\n",
       "  'content': 'Well identification section\\nThis is where the user specifies if the well name or the unique well identifier should be used to\\nidentify the wells.\\nDate section\\nDefault date: This is used during the Well completion design process. This will be the default\\ndate for any new object. Select the date from the pop-up calendar by using the black arrow.\\nWell section\\nDecimate when scrolling: This option is checked on by default, so that the well section is\\ndecimated (color and resolution) when scrolling.'},\n",
       " {'header': '3D Settings Tab (Project Settings) ',\n",
       "  'content': '3D transparency: If you have trouble displaying transparent objects (this may happen if\\nyou are using older graphic cards), try changing these settings (switch on Screen door).\\n3D decimation: Here you can choose to limit how often Petrel tries to redraw data while\\nrotating and viewing. If the displayed objects are very large and contain a large number of\\ncells, the zooming, panning and rotation in Petrel can be slow.\\n3D anti-aliasing: Compensates for low resolution display on the screen. When Line anti-\\naliasing is activated, lines will be evened out by removing stair-effects and surfaces will be\\nsmoothed by filling in more color. The Scene anti-aliasing will render the Display window\\ninternally several times (how many depends on the number of Passes defined). This option\\nrequires a large amount of memory and is very time consuming. The option is not\\nrecommended when working with Petrel, but it can be useful for exporting graphics.\\n3D visual effects: This is used with stereo effects.\\nFog: Option to view the objects in the Display window with fog. The fog will make the\\nview darker.\\n3D editing: Keyboard translation increment is used when the keyboard arrows are used to\\nmove the dragger (widget). Specify increment in project units. The Relative dragger\\n(widget) size in % can be specified. Default is 100 % (about 2 times the size of the point\\nthat the dragger hits. Note; the change will take effect when the dragger is set to a new\\npoint.'},\n",
       " {'header': 'Misc Settings 1 Tab (Project Settings) Project Save ',\n",
       "  'content': 'Protect from overwrite by a newer version of Petrel: Protects from overwriting by\\nnewer versions of Petrel. Petrel projects can be opened in newer versions, but once saved in\\na new version, it is not possible to revert to the former version.\\nSave project automatically: Choose whether the project should be saved automatically\\nat regular intervals and whether confirmation is required.\\nPlayer speed\\nSettings for 3D editing: Set the increment that the cursor will move when using the\\narrows on the keyboard for editing and the size (%) of the widget for editing relative to the\\npoints selected.\\nGrid player speed: Set the default speed for the player of the I- and J-intersections. The\\nnumber indicates the pause between steps in milliseconds (ms) (e.g. a small number\\nincrease the speed).\\nPlane player speed: Set the default speed for the Intersection player. The number\\nindicates the pause between steps in milliseconds (ms).\\nProperty player speed: Set the default speed for the property player. The number\\nindicates the pause between steps in milliseconds (ms).\\nTime player speed: Set the default speed for the time player. The number indicates the\\npause between steps in milliseconds (ms).\\nThe Global surface filter has been moved from this tab to the Misc Settings 2 Tab (Project'},\n",
       " {'header': 'Settings). Misc Settings 2 Tab (Project Settings) ',\n",
       "  'content': 'Global surface filter\\nGlobal surface filter: Drop in a closed polygon to use as a surface filter and choose\\nwhether to apply the filter inside or outside the polygon. This can be used during surface\\noperations found on the settings dialog of surface objects.\\nMinimum curvature algorithm\\nSome fine-tuning to Minimum curvature can be performed under this tab. There are a lot of hints\\nand information in the tab together with some options that can be changed by the user. The\\nsettings here will affect several processes (for example, Pillar gridding, Make horizon, and\\nMake/edit surface).\\nMax error tolerance: Default 1 - increase the number to speed up the calculation (the\\naccuracy will decrease with increased number). Keep within the range 0.01-100.\\nMax number of iterations: Increase the value if the results are not accurate enough and\\nthe calculations are relatively rapid. Keep within the range 500-2000. Try to find a balance\\nbetween the number of iterations and the tolerated max error.\\nInitialize values by: Constant/Random: All unknown values must have an initial value.\\nChoose between Constant (average of known values - smoother) and Random (between\\nmin and max - more variable).\\nMultigrid optimization: used in the Make/edit surface process only.\\nThe content of View indices has been moved from this tab to Grid Settings on the Export to\\nSimulator and Visualization (Grid) tab.'},\n",
       " {'header': 'Tools ',\n",
       "  'content': 'The options under Tools are:\\nSystem settings\\nFree memory\\nLaunch FloGrid\\nLaunch FloViz\\nLaunch ECLIPSE Office'},\n",
       " {'header': 'Launch Schedule ', 'content': 'Launch GRAF'},\n",
       " {'header': 'Extensions ',\n",
       "  'content': 'Security settings\\nFree framework model memory\\nLaunch SEG-Y utility\\nLaunch VR hybrid wand\\nLaunch VR site manager\\nLaunch VR on-screen keybord\\nSystem settings: Settings affecting the Petrel system, see system settings for details.\\nFree memory: By clicking yes to the dialog, Petrel will free memory storage that has been\\ntemporarily used by the system. To free disk space, see also Clean Project Directory.\\nIf memory is limiting your system\\'s performance, then this will increase the speed of some\\noperations. The downside is that after freeing memory, open windows must be reloaded into\\nmemory next time they are displayed which may take a few seconds.\\nLaunch FloGrid, FloViz, ECLIPSE Office, Schedule and GRAF: If these applications are\\ninstalled and a valid license is available they can be launched from Petrel.\\nExtensions: This is the place where the new custom menuitems from ocean plug-ins end up\\nSecurity settings: Controll how Petrel will handle different software modules (e.g. plug-ins), see\\nfigure below. The default security level will be low.\\nFree framework model memory: The new structural framework processes are coded using the\\nocean API. At the moment no plug-ins have acces to the Petrel\\'s \"Free memory\" tool, hence the\\nneed for a separate free memory for this operations.\\nLaunch SEG-Y utility: is an option to merge UKOOA Navigation file with the SEG-Y header file.\\nLaunch VR hybrid wand, VR site manager, VR on-screen keybord: See Petrel VR\\nConfiguration and user guide'},\n",
       " {'header': 'System Settings ',\n",
       "  'content': 'The System settings window is available from the Tools menu in the menu bar. All of the settings\\nhere are applied to the system (your Petrel installation) and will be active for all projects.\\nExamples on settings include:\\nTree node behavior\\nOption to resetting the layout (back to default Petrel settings)\\nSpecific company profiles e.g. style on well tops\\nVR settings'},\n",
       " {'header': 'Troubleshooting Effects (System Settings) ',\n",
       "  'content': 'This tab contains options for spin animation, how a selection by keyboard or mouse should act,\\nand dialog transparency.'},\n",
       " {'header': 'Layout ',\n",
       "  'content': 'Multiline tabs - controls how a dialog with a large number of tabs behaves. When\\nchecked, all tabs will be shown at once in several rows. When unchecked, tabs will show up\\nin one line with a scroller on the right side.\\nToolbars style - changes how icons appear in Petrel. The options are Images only\\n(shows icons as images only), Images and shortcuts (shows icons as images together\\nwith keyboard shortcuts) and Images and verbose text (shows icons as images together\\nwith icon names and keyboard shortcuts).\\nYou can reset the layout of how the panes, toolbars and action bars are set up by clicking the\\nReset layout button. It will then reset to the Petrel standard setup.\\nIntermediate files\\nUse the default directory or specify a directory by checking the Overwrite option. Browse for\\nthe location. If it cannot be found, Petrel will use the default location.'},\n",
       " {'header': 'Misc ',\n",
       "  'content': 'Toggle off sounds - will disable the sounds accompanying actions taken in Petrel.\\nDisable spin animation - will disable the rotation in the 3D window. It will apply to all 3D\\nwindows, not only the current window.\\nTree node behavior\\nThe node selection options are available for the keyboard and mouse.\\nThe node selection by keyboard determines the behavior when using arrow keys to navigate in\\nthe tree (does not apply to multiple selections using ctrl/shift + arrow keys).\\nActivation follows selection (keyboard) - the node is activated by selection using\\narrows, and will change activation when moving the arrow up or down the tree.\\nVisualization following selection (keyboard) - turns the next object on in the display\\nwindow when selected, and will change the selection as the arrows are moved up or down\\nthe tree.\\nRename node directly (mouse) - Instead of renaming objects in the Settings>Info tab,\\nthe object name can be renamed directly by clicking on the object name.'},\n",
       " {'header': 'Fonts ',\n",
       "  'content': \"This allows the user to set the default font for the other Petrel windows. The Paper-based views\\nfont is intended to give better control on prints and plots for displays such as well top labels on\\nthe Well section window and well names on the Map window. If you do not specify a font\\npreference, Petrel will continue to use the default Windows font of the user's PC.\\nSeismic (System settings)\\nThis tab contains options for handling seismic data in Petrel.\\nSeismic files\\nDefault directory - the directory path listed here will be used for generating external ZGY\\nfiles to a default location. If the toggle box is checked, the default is to generate external\\nZGY file (and not a default file name in the project's ptd folder as defined under Output file\\nwhen realizing seismic volumes).\"},\n",
       " {'header': 'Misc ',\n",
       "  'content': \"Number of seismic slices - a specified number of slices can be entered. This will decide\\nthe number of slices to use in the seismic volume rendering using virtual cropped volumes\\n(probes). If no number is set, an estimated number will be used, depending on the graphic\\ncard and available memory (accept numbers between 150 to max number of slices in the\\nseismic cube). A higher number gives better rendering quality, but lower performance. The\\ndefault value is 200.\\nSeismic cache size [MB] - the maximum cache size used for rendering seismic. Increasing\\nthis value can provide better performance for seismic data. Setting the value too large, will\\ncause unstable performance and can cause Petrel to crash. Minimum value is 100. The\\nsuggested range is 500 - 1500. The default value is 500.\\nGraphics card memory [MB] - should match the graphic card's available memory.\\nAccepts a number between 32 and 1024. The card manufacturer will provide the correct\\nmemory size. The default value is 256.\\nQueue definition (System settings)\\nThis tab contains options for defining the queues for remote simulation job submissions. See also\\nRemote simulation submission\\nCompany profile (System settings)\\nThis tab contains options for well symbol selection and fluid contact color defaults.\"},\n",
       " {'header': 'Well Symbols ',\n",
       "  'content': 'Choose from the list of available symbols sets. This will control the symbols that are available on\\nthe wells dialog. It will not automatically change the symbols displayed in the current project as\\nno clear mapping is apparent between the different symbol sets. Re-import the wells with the\\nsymbol index to ensure the correct mapping.\\nThe default is Petrel symbols. In addition, you can choose other symbols: Shell, Maersk,\\nRussian, PDVSA, User symbols. You may import an XML file with user-defined symbols.'},\n",
       " {'header': 'Contact Colors ',\n",
       "  'content': 'This determines the default colors for the contact sets in the project. It will not affect the existing\\ncontacts, only new contacts. Neither will it affect the color on contact properties or the contact\\ncolor fill on structures.'},\n",
       " {'header': 'Global Configuration ',\n",
       "  'content': 'This option will read system configuration from an XML file instead of the Windows registry. This\\nenables the same configuration to be shared by multiple Petrel users. The option is ideal for\\nsystem administrators since they can globally configure each license package.\\nVR (System settings)\\nThis tab is used for enabling VR features; see Petrel VR Configuration and user guide.\\nEnable VR - VR features affect only the 3D windows. You must close and reopen the windows or\\nrestart Petrel for the change to take effect.\\nSite name - If specified, the default site name (name of machine) is overridden. If you\\nwant to use non-default site configuration, enter the desired site name.\\nEnable pointers - enables pointers or wands (see Hybrid Wand).\\nEnable frustums - enables extended and partitioned view frustums to cover the handle of\\nthe 3D pointer (wand). It also enables depth range management that can have impact on\\ndepth culling (rendering).\\nTroubleshooting (System settings)\\nProvides alternative ways of showing/drawing pictures in order to avoid problems with certain\\ngraphic cards/laptops.\\nLaptop PCs with an ATI Rage chipset may have problems displaying pillar gridding points\\n(displaying single pixels instead of boxes).\\nDisable high quality 1D texture mapping\\nthis mapping causes problems with Diamond FireGL1 cards. Surfaces must be turned off and\\nback on for changes to take effect.\\nUse alternative method for plotting points\\nEnables an alternative (and noticeably) slower method of drawing the pillar points in the Pillar\\ngridding process. Try this method if your pillar points are not showing on your PC.\\nDisable dynamically sized points\\nDynamically sized points are used in 3D visualization of interpretation to give a greater sense\\nof spatial relations.\\nDisable 16-bit volume rendering texture\\nWith this option on, the volume rendering will be performed using 8-bit, which will demand\\nless memory and will be of slightly lower quality (may not work with nVidia cards).\\nSwap red and blur components when printing gradients\\nRequired for some versions of Windows when printing plots from Petrel.\\nDo not use index map memory management for properties\\nThis option is only to be used on very large grid exceeding 100 mill. cells. Overall, Petrel uses\\nless memory when several properties are loaded simultaneously. If only one property is\\nloaded, Petrel uses a minimal amount of memory.\\nNote: Do not have any properties loaded in memory when changing to this option).\\nLimit size of seismic bitmaps output to printers/metafiles\\nThis will limit the size of the seismic image in I- or J-direction if it exceeds the threshold size\\n(can by typed in the Size limit field). You will get the full extent of the image, but a reduced\\nquality.'},\n",
       " {'header': '3D Glasses ',\n",
       "  'content': 'The stereographic option (3D glasses) offers the most realistic visual representation possible and\\nlets you study the objects and the spatial relationships with depth and perspective for improved\\nunderstanding.\\nTo be able to use 3D stereo glasses you need to have the following stereoscopic hardware:\\nA graphics card supporting 3D stereo glasses.\\n3D glasses and emitter. This is not supplied with the graphics card.\\nThe graphics board usually has a port for an emitter needed for the 3D glasses. The emitter is\\nplaced on top of the monitor.\\nSee Hardware For Use of Stereo Graphic Imaging for more information about hardware\\nrequirements.'},\n",
       " {'header': 'Enabling Stereo ',\n",
       "  'content': \"On the PC platform, stereoscopic imaging is still a fairly new technology. There has been little\\nwork done by graphics card producers to standardize implementations, and to simplify the task of\\nenabling stereo for the user.\\nDue to the different implementations, it is impossible to provide a sure-fire recipe for enabling\\nstereoscopic imaging on all configurations. Also, we cannot guarantee stereo support on hardware\\nthat Schlumberger has not tested.\\nMore information on how to set up stereo graphics and examples can be found in Petrel VR\\nConfiguration and User Guide: Appendix 3 - Enabling Stereo in Petrel.\\nHardware for use of Stereo Graphic Imaging\\nSome general points that must be fulfilled for enabling stereoscopic imaging:\\n1. Make sure your graphics card supports stereoscopic imaging. Consult your vendor or the\\nmanufacturer's technical support if the documentation is not clear on this.\\n2. Make sure that stereo is supported on the operating system and the version of the OS on\\nwhich you plan to use the software (for example, Windows NT 4.0).\\n3. Make sure you have the latest drivers for your graphics card on the OS version you plan to\\nuse. These can usually be downloaded from the manufacturer's web site.\\n4. Purchase the stereoscopic hardware (emitter and stereo glasses) supported by your\\ngraphics card.\\n5. Make sure the graphics card used has a port for the emitter and connect the emitter to the\\nmachine.\\nMore information on how to set up stereo graphics and examples can be found in Petrel VR\\nConfiguration and User Guide: Appendix 3 - Enabling Stereo in Petrel.\"},\n",
       " {'header': 'Flight Simulator ',\n",
       "  'content': 'The Flight Simulator is a special tool used for visualization of a 3D model by \"flying\" through the\\nmodel. The route is located in space by drawing a polygon in 3D. Any kind of polygon or well path\\n(converted to polygon) can be used.\\nTools for the Flight Simulator\\nCamera All the Way Backwards and Camera All the Way Forwards - Moves the\\ncamera to the beginning/end of the polygon.\\nCamera Play Backwards and Camera Play Forwards - Moves along the polygon\\nbackwards/forwards.\\nStep Camera Backwards and Step Camera Forwards - Moves the camera one step\\nbackwards/forwards along the polygon.\\nStop Playing Camera - Stops playing the camera.\\nSet Horizontal - Forces the camera to always be horizontal.\\nReverse Direction - Sets the face of the camera in reverse direction (directed from the end\\ntowards the beginning of the polygon).\\nSet Increment - Sets the increment for the movement of the camera.\\nHide this toolbar - Turns off the Flight Simulator and closes the toolbar.\\nHow to use the Flight Simulator\\nActivate the Flight simulator by selecting Flight Simulator toolbar from View in the Menu\\nbar, or by clicking with the right mouse button on a polygon in the Petrel Explorer and\\nselecting Flight Simulator toolbar.\\nA toolbar for the Flight Simulator will be displayed (below the Display window).\\nMake a polygon active (bold) by selecting it in the Input pane.\\nDisplay the objects you would like to explore.\\nUse the Flight Simulator Player to fly along the polygon (see Tools for the Flight Simulator.)\\nTo turn the Flight Simulator off, use the Hide this toolbar button or deselect Flight\\nSimulator in the same way as it was activated.\\nAlso see the Petrel VR Configuration and User Guide: Appendix 8 - How to Fly.\\nPetrel VR Configuration and User Guide'},\n",
       " {'header': 'Introduction ',\n",
       "  'content': 'The Petrel VR (Virtual Reality) project will be further improved over the next years with VR-based\\nfeature technology. Petrel 2007.1 contained the first deliverables from this project. The features\\nin Petrel are grouped as follows:\\nEnhanced viewing using 6 DOF (Degrees Of Freedom) input devices\\nRegistering input devices using the configuration tool (Site Manager)\\nEmulate mouse input using 6 DOF device input (HybridWand)\\nThe following VR topics are covered in Petrel Online Help:\\n1. A brief overview of the VR features in Petrel\\n2. How to configure a VR site for Petrel\\n3. How to turn on VR features in Petrel\\n4. How to use VR features in Petrel\\nThe appendices contain a lot of useful information for configuration and use of Petrel VR.\\nVR Features in Petrel\\nEnhancements to the 3D window'},\n",
       " {'header': 'The Wand Cursor ',\n",
       "  'content': 'Those who are familiar with Inside Reality will recognize this 3D cursor. The cursor is a graphical\\nrepresentation of the physical 6 DOF input device (e.g. Wanda). The cursor is rendered with a\\nhandle (representing the physical device) and a ray that extends from the handle and into the\\nscene. The point of interaction is where the ray intersects with an object in the graphical scene.'},\n",
       " {'header': 'The Sticky Cursor ',\n",
       "  'content': 'The purpose of the Sticky cursor is to provide a stereo cursor controlled by the mouse when the\\n3D window is in stereo mode. Some users may prefer this instead of the 2D mouse cursor. The\\nSticky cursor is available to the user without any configuration, in both stereo and mono.'},\n",
       " {'header': 'Edit Mode - 3D Picking ',\n",
       "  'content': 'The pick function allows the user to probe an object by clicking on it. Information about the pick\\npoint (or intersection point) is shown on the status bar at the bottom of the application window.\\nThis feature is now supported when using the Wand Cursor or the Sticky Cursor. (Do not confuse\\nthis feature with selection. Selection by any of the 3D cursors is not implemented in Petrel).'},\n",
       " {'header': 'View Mode - World Manipulation ',\n",
       "  'content': 'The view functions in Petrel are enhanced to allow input from 6 DOF input devices. The graphical\\nscene can be rotated and positioned by device gestures in 3D space. The manipulative actions and\\nstereo parameters are automatically calibrated to mimic the presence of the user in the virtual\\ndata world.'},\n",
       " {'header': 'View Mode - Flying ',\n",
       "  'content': 'The fly function is also borrowed from Inside Reality. This feature allows the user to travel\\nthrough the graphical scene as if they were Flying through it. This operation is typically mapped to\\nthe joystick of the input device, see appendix 8.'},\n",
       " {'header': 'Hybrid Wand - Petrel Synchronization ',\n",
       "  'content': 'The Hybrid Wand emulates mouse movements and button clicks by reading 3D input events and\\ntranslating them to mouse events. This utility runs independently of Petrel. Petrel has been\\nenhanced to ignore 3D input when the Hybrid wand is active.'},\n",
       " {'header': 'Input Focus Model ',\n",
       "  'content': 'Only one 3D window in Petrel can receive 3D input events at a time. The 3D input focus follows\\nthe keyboard input focus - this is standard Petrel behaviour.\\n(Unfortunately there are issues by letting the 3D input focus follow the keyboard input focus. It is\\ntherefore likely that a different 3D input focus model will be presented in the future.)\\nHow to Manipulate a Subject with a VR Input Device when out of Input'},\n",
       " {'header': 'Focus ',\n",
       "  'content': '1. Use a Petrel project containing some data.\\n2. Create a secondary 3D window so that there are two 3D windows in total.\\n3. Display some data in both windows.\\n4. Cascade the two 3D windows with an overlap (i.e. one 3D window partially covering the\\nother).\\n5. Open an application other than Petrel (e.g. Notepad).\\n6. Click on Notepad so it gets the keyboard input focus. Verify keyboard input focus by typing\\ntext into Notepad.\\n7. Use the wand and manipulate the world while Notepad still has input focus.\\n8. Notice that manipulation only occurs in the topmost 3D window.\\n9. Click on the frame of the partially hidden 3D window so that it stacks on top. Again, give\\nkeyboard input focus to Notepad.\\n10. Manipulation of the world now happens on the second 3D window that is on top.\\nInstallation and Configuration\\nConnected hardware devices must be configured and mapped to logical commands for Petrel to\\nuse. The canonical VR input device for Petrel VR is a device that features 3 buttons, 2 valuators\\nand one 6 DOF tracker. Two systems that feature this canonical model are the IS-900 from\\nIntersense and the Flock of Birds from Ascension. Several other conformal systems do also exist,\\nlike a new range of 6 degree-of-freedom (DOF) devices from 3Dconnexion\\n(www.3dconnextion.com, a Logitech company).\\nSetting up the Petrel VR environment involves the following steps:\\nObtain trackd license\\nConfigure device mappings\\nEnable Petrel VR features\\nObtain trackd License\\nPetrel features two types of device readers; the trackd device reader and the Microscribe device\\nreader.\\nNo license is needed if you are only going to use the Microscribe reader.\\nIf you are going to connect a 3D device by use of the trackd system from VRCO, you will need a\\ntrackd license. This can be obtained by contacting GSBV licensing. Existing Inside Reality\\ncustomers are likely to already have a trackd license. Petrel can connect to a pre-existing trackd\\nsetup running on networked hardware.'},\n",
       " {'header': 'Configure Device Mappings ',\n",
       "  'content': 'The Site Manager is a tool for mapping hardware devices to Petrel operations.\\nFigure: The Site manager is accessible from the Tools menu in Petrel.\\nThe physical environment (screens and input devices) must be configured in the Site Manager.\\nDepending on the computer literacy of the individual user, some users may choose to let the\\nsystem administrator configure the site, while other users may want to maintain their own\\nconfigurations. The user has the option of maintaining a collection of different setups.\\nFigure: The site manager is a tool for maintaining a database of site configurations.\\nThe Site Manager supports concepts of the site configuration and the site configurations group. A\\nsite group contains several site configurations and is represented by a folder in the Site Manager.\\nThe Local user sites folder contains site configurations maintained by the user. Configurations in\\nthe Local user sites folder override other site configurations of the same name in the other\\nfolders. Site configurations may also be maintained in the Local host sites configuration folder.\\nThis folder may contain default configurations set up by the system administrator. A third\\nconfiguration folder is the Petrel sites configuration folder. This folder is similar to the Local host\\nsites folder but is intended to be populated when sites are maintained in an environment where\\nthere is a central application server. Local users that do not have system administrator privileges\\nwill only be able to define new site configurations in the Local user sites configuration folder.\\nIf the differences between the site configuration folders are difficult to understand,\\nonly concern your self with site configurations in the user site configuration folder!\\nTo map a device, do the following:\\nCreate a new site.\\nCreate a screen configuration for the site.\\nCreate a device for the site.\\nCreate an actor for the site.\\nCreate a primary hand for the actor.\\nMap device input to the control commands for the primary hand.\\nCreate a New Site\\nFigure: Insert new site\\nCreate a new site by right-clicking on the site group folder and select Insert new site .\\nFigure: System properties dialogue\\nFor the first-time user, we recommend you rename the site to the name of your machine. You will\\nfind the name of your machine in the Computer Name tab of your System Properties dialog. Omit\\nthe domain part of the full name.\\nFigure: Site name configuration\\nThe site name will be NONAME-SITE in this example. Omit the domain part of the full name.\\nCreate a screen configuration for the site\\nIn order to provide consistent input to Petrel, it needs to know where the screen is located\\nrelative to the input device. It is required that there will be only one tracked device, and that the\\nscreen location and orientation is configured in terms of that tracking device. In this document we\\nassume that all tracking devices will conform to the CAVE right-handed coordinate system where:\\nPositive X axis points to the right\\nPositive Y axis points up\\nPositive Z axis points backwards\\nFigure: Insert new screen\\nExpand the new site configuration folder and right-click on the Screens folder. Select Insert\\nnew screen . Even though it is possible to define multiple screens, you should define only one\\nscreen.\\nIn the next figures, we will show you different examples of how the screen configuration may\\nlook. Note that screen coordinates are all given in the unit of meters.\\nFigure: This example illustrates a screen configuration where the tracking system is a Polhemus\\nPatriot. The screen is a fairly small desk top screen and the Patriot transmitter is located on the\\ndesk at the right hand side of it.\\nFigure: This example shows the same small desktop screen as above. However, this time we\\nassume that a Microscribe input device is used. The Microscribe in this example is assumed to be\\nlocated at the front-right of the screen. That is why we see that an offset along the Z-axis has\\nbeen defined.\\nFigure: This example shows a typical iCenter configuration. The tracking system is configured so\\nthat its origin is on the floor at screen center. The screen is 4 meters wide and stands 40 cm\\nabove the floor.\\nCreate a Device for the Site\\nA device entry contains information about a physical input device. Petrel provides readers for\\nMicroscribe digitizers and tracking devices that confirm to the trackd tracking system from VRCO.\\n(3D Connection devices like the Space Ball are not supported natively, but may be connected\\nusing trackd. However, connecting the Space Ball this way does not provide good input control.)\\nFigure: Insert new device\\nIn order to create a new device reader, right-click Devices and select the device reader type that\\nyou want to use. Usually, only one input device reader should be defined. However, if you want to\\ntry out some experimental setups, it is possible to define multiple device readers for the site.\\nExperimental configurations tend to be difficult to use. The next figure shows a typical Microscribe\\nsetup. A typical setup of a trackd device is shown in the figure below.\\nFigure: There are a few options available for the Microscribe device reader. We recommend that\\nyou only modify the Used with option. This option must be set in order to align the Microscribe\\ncoordinate system correctly according to the use pattern. The Microscribe reader will\\nautomatically sense if a USB connected Microscribe is available, so no connection information is\\nneeded.\\nFigure: Trackd devices are not automatically sensed. Therefore, the shared memory keys must be\\nentered in this configuration panel. If you want the trackd to be automatically started, you also\\nhave to enter the location of the trackd daemon and the trackd configuration file that you want to\\nuse. We recommend that you specify 1 tracker, 2 valuators, and 3 buttons.\\nCreate an Actor for the Site\\nThe actor concept is used to associate input devices to one user. It is possible to define several\\nactors, but we recommend that you only create one, as only one actor will be recognized in'},\n",
       " {'header': 'Petrel. ',\n",
       "  'content': \"Figure: Right-click on the Actors folder and select Insert new actor in order to create a new\\nactor.\\nCreate a Primary Hand for the Actor\\nIn order to simplify the construction of the Petrel interaction model, we model the user as an\\nactor where Petrel is controlled by a number of gestures from the actor. This model is not yet fully\\ndeveloped, so only the primary hand (a gesture source) of the actor is necessary to define.\\nFigure: Right-click on the Actor icon and select Insert new primary hand to create a new\\nsource.\\nMap Device Input to the Control Commands for\\nthe Primary Hand\\nThe gesture source (in this case the primary hand) provides the mapping between device sensors\\nand input commands. In the most common case (and in the most practical case), the primary\\nhand is associated with only one input device. The optimal mapping is inspired from conventions\\nused with the desktop mouse. (The left mouse button is used for selection and editing, and the\\nright mouse button is used for context menus.) However, context menus are not yet\\nimplemented.\\nThe enumeration of sensors in the Site manager is 1-based and follows the enumaration in the\\ntrackd system.\\nThe following figures shows various ways of setting up the gesture source.\\nFigure: This figure shows the recommended sensor mapping of a trackd device reader. Only one\\ndevice (Trackd) is used and the sensors are sequentially mapped. This configuration assumes that\\nthe trackd configuration file enumerates the sensors in the same way. It is worth mentioning that\\nIntersense devices may have swapped button 0 and 1 compared to the intuitive setup.\\nFigure: This figure shows the recommended mapping for the Microscribe device reader. Note that\\nthe Microscribe device has no valuator sensors. This implies that there is no way to invoke flying\\nwhen only using the Microscribe input device. It is possible to map input from other devices to\\naccommodate flying (e.g. Space Ball), but that sort of configuration tends to be awkward to use.\\nEnable Petrel VR Features\\nVR features are not enabled by default. They can be enabled in the 'System settings' dialog box of\\nPetrel. You should only enable the VR features if you intend to use them.\\nFigure: The System Settings dialog box is accessible form the Tools menu in Petrel.\\nFigure: Petrel VR System settings dialogue\\nTick all checkboxes in the VR tab of the System Settings dialog box and enter/choose a site name\\nif the name of your preferred site configuration differs from the host name.\\nEnable pointers turns on the wand representation in the 3D window. Enable frustum will\\nextend the view frustum to include the entire wand.\\nWhen using Petrel VR it is recommended to always have all three tick boxes checked.\\nHow to use Petrel VR\\nThis section describes how to set up Petrel VR.\\nHow to start up\\nPetrel VR is not enabled by default. Enable the VR features by opening the system settings and\\nselecting the Enable VR tick box. See Enable Petrel VR features for more information.\\nWhen you open a new 3D window, a trackd console window that shows tracker data should open.\\nInput data should continuously scroll up on the console window. Any error messages in this\\nwindow will indicate problems with the trackd setup. Examples on how to set up the tracker can\\nbe found in the appendices.\\nFigure: Data flow from Tracking system to Petrel.\\nInteracting with Petrel VR (VR mode)\\nVR enhancements have been added to the View and Pick modes. It is easy to see if Petrel is in\\nany of these two modes. The Hand icon is activated when Petrel is in View mode, and the Pick\\nicon is activated when Petrel is in Pick mode. A new 3D window will always start in View mode. VR\\nmode refers to the mode where you are using a 3D wand in the 3D window.\\nImages in this section are based on an IS-900 setup with an Intersense wireless wand.\\nThe information in this section is written with the assumption that the device buttons are mapped\\nin the following manner:\\nButton 1 will Pick or Grab.\\nButton 2 will toggle between View mode and Pick mode.\\nButton 3 will scale the scene.\\nThe buttons are enumerated accordingly:\\nFigure1: Intersense Wireless wand and Figure2: Ascension Wanda wand\"},\n",
       " {'header': 'View Interactions World Manipulation ',\n",
       "  'content': 'It is possible to grab, rotate and move the scene in all directions.\\nUse button 1 to toggle into View mode\\nPoint with the device into the scene to the location where you would like to grab it.\\nPress button 1 to grab the scene. If there an object exists at the location where you have\\npointed, that intersection point will become the new center of rotation. If you have pointed\\ninto the void (ie. 3D window background), the center of rotation will be located at the center\\nof the scene. (See figure below)\\nWhile still holding button 1, twist and turn the device. You will see that the scene follows the\\nrotations of the device.\\nWhile still holding button 1, move your hand in different directions. You will see that the\\nscene follows the movements of your device.\\nRelease button 1 - manipulation ceases.\\nFigure: The center of rotation is defined around where the wand ray hits the object.\\nWhen manipulating scene with the wand the center of rotation is set where the wand ray hits the\\nobject in the scene.\\nHow to add a Recalibration Button for a 3D Pointer\\n1. Point into the scene with the wand. See that the location and direction of the wand\\ncursor/ray corresponds (loosely) to the position and direction of the physical wand (old\\nbehavior).\\n2. Rest the wand on the table (wand cursor may disappear from the screen).\\n3. Press CTRL-H, the wand cursor/ray jumps up to the middle of the screen and points inward\\ninto the scene.\\n4. Manipulation and flying works as before but with transformed position and direction.\\n5. Press SHIFT-CTRL-H, the wand works as before.'},\n",
       " {'header': 'World Scaling ',\n",
       "  'content': 'This new feature controls a scaling factor between the tracker coordinate system and the world\\ncoordinate system used in Petrel. When you open a 3D Window, the scale factor between the two\\ncoordinate systems are 1:1. That means that the user (size in meters) is very small compared to\\nthe subsurface model (size in kilometres).\\nThe scaling factor is brought into the calculation of the stereo view and the fly speed (see below).\\nTo scale the scene:\\nToggle into View mode by clicking button 2.\\nPress button 3 to start scaling.\\nWhile holding down button 3, twist (roll) the device.\\nRelease button 3 to terminate scaling.\\nNOTE: The visual feedback on the scaling operation is subtle outside stereo view and\\nmay not be easy to detect.\\nPlease do not confuse the scaling operation with the existing zoom operation. The zoom operation\\nin Petrel will move the camera relative to the subsurface model and thereby create the illusion\\nthat the model grows or shrinks. There is no real scaling going on.\\nThe new scaling operation on the other hand, is a real scaling operation, but since the camera\\ndoes not move relative to the data, the subsurface model will not change size on the screen. The\\nscaling operation is primarily introduced to provide realistic stereo view in par with VR\\nrequirements.\\nFigure: Scale scene by rotating the wand and holding down scale button\\nFlying and scaling speed/sensitivity adjustment will have an intermediate effect when interacting\\nwith the wand. This makes it easier to use the wand to move around in the 3D scene.'},\n",
       " {'header': 'Flying ',\n",
       "  'content': 'The flying feature allows you to control the view of the scene as if you are flying through a\\nsubsurface model in an airplane (like in a flight simulator).\\nTo fly:\\nToggle into View mode by clicking button 2.\\nPush the joystick forward in order to fly into the scene.\\nUse your input devices to point in the direction that you want to fly.\\nTwist (or roll) the device in order to control the speed.\\nRelease the joystick to terminate flying.\\nIn addition to the operations above, you can fly backwards by pulling the joystick backwards, and\\nyou can yaw sideways by tilting the joystick sideways.\\nIt might take some time before you notice the speed change. The flight speed is not limited by a\\nsingle twist movement. You can reach extreme speed values by repeatedly and alternately\\npushing the joystick and twisting the device. This is particularly useful when you are far away\\nfrom the model that you would like view and want to pick up speed in order to quickly get there.\\nWhen you have reached the destination, you will most likely prefer to slow drastically in order to\\ngain manoeuvrability.\\nNOTE: The scale factor multiplies up the fly speed.\\nThis means that fly speed will be slower with a small scale factor (small user, big world), and be\\nfaster with a large scale factor (big user, small world).\\nFigure: Alter flying speed by rotating the wand.\\nFlight path correction\\nIt is easy to end up with a tilted view while rotating the scene in Petrel VR. Petrel VR will try to\\nlevel your view by applying a correction while flying. You will notice that this is slowly applied\\nwhen flying in a non level fashion.\\nPick mode'},\n",
       " {'header': '3D Picking ',\n",
       "  'content': 'It is possible to pick a value from an object in 3D space. Point with the wand at the object you\\nwould like to obtain information from. Click button 1. Information about the object is displayed in\\nthe Petrel info bar as shown in the figure.\\nFigure: Picked object information is displayed in the Petrel info bar.'},\n",
       " {'header': 'Hybrid Wand ',\n",
       "  'content': 'The Hybrid wand application can be started from the Tools menu in Petrel. It converts 3D input\\nevents to mouse events.\\nFigure: Hybrid wand application.\\nThe hybrid wand application enables the user to use the wand as a mouse pointer in Windows.\\nYou should be able to do all the tasks as you can do with a mouse.\\nSwitching Between 3D VR Mode and 2D Hybrid'},\n",
       " {'header': 'Wand Mode ',\n",
       "  'content': 'Figure: The 2 different interaction regimes supported by Petrel VR.\\nWhen the Hybrid Wand application is running, it is possible to move between Hybrid wand 2D\\ninteraction and 3D window scene interaction (VR mode) by using a special set of button clicks and\\ndevice movements typically called \"Gestures\". The special gesture to move between 3D\\ninteractive mode and 2D hybrid wand mode is described in the next figure.\\nFigure: Gesture: Point backwards with the wand and click button #2'},\n",
       " {'header': 'Sticky Cursor ',\n",
       "  'content': 'Figure: Sticky cursor will attach itself on the object you select.\\nThe Sticky cursor will attach itself to whatever object you want. The object turns blue when\\nselected. The object stays gray if it hits the void. The cursor will give you depth feedback a 2D\\nmouse cursor cannot provide. It works especially well in Stereo as well with the Hybrid wand\\napplication.\\nTo enable the Sticky cursor press the button. It works in several interaction modes such as\\nManipulate plane, Pick mode and Moving well design point.'},\n",
       " {'header': '3Dconnexion Device Support ',\n",
       "  'content': 'The 3D window in Petrel now supports a new range of 6 degrees-of-freedom (DOF) devices from\\n3Dconnexion. With six optical sensors, the devices (e.g. SpaceTraveler) allows users to\\nsimultaneously pan, zoom and rotate 3D models or scenes (i.e. it will let you fly). It is a\\nsupplement to normal mouse interactions and will work side-by-side with a mouse. (For more\\ninformation, visit www.3dconnexion.com).\\nImages in this section are used with the permission of 3Dconnexion (3Dx).\\nCombine normal mouse interactions with the 3Dx device to get increased productivity.'},\n",
       " {'header': 'Features ',\n",
       "  'content': 'The 3Dx devices have a controller cap that lets you interact with your 3D scene. Advanced sensor\\ntechnology lets you use the cap to zoom, pan and rotate your 3D objects.\\nWhen connected the 3Dconnexion device will act as an extension of your arm inside of Petrel. The\\nfirst implementation in Petrel will have a model interaction approach, but it is possible inside the\\ndriver to change the behavior of the interaction regime to mimic Inside Reality (IR) and Petrel VR\\nflying behavior.\\nThe midpoint of the scene is calculated on the fly when new objects are added.\\nUsage with Petrel\\nIn Petrel you can use the 3Dx devices in both 3D and 2D windows. The active window will\\nintercept the signal from the device and apply user interaction to it. The user can zoom in and out\\nas well as rotate the object.\\nDefault behavior'},\n",
       " {'header': '(Zoom) ',\n",
       "  'content': 'Dragging the cap towards you makes the model come closer\\nPushing the cap from you makes the model move away'},\n",
       " {'header': '(Pan) ',\n",
       "  'content': 'Pushing up/down pans the image up/down\\nPushing left/right pans the image left/right'},\n",
       " {'header': '(Rotate) ',\n",
       "  'content': 'Tilting the cap to the front/back tilts the model to the front/back\\nTilt (Roll mode) the left/right tilts the model rolls the model to left/right\\nSpin rotates the model around the axis midpoint\\nAll rotate interactions use the dynamically set scene midpoint as the center of rotation\\nAlternative setup\\nIn the advanced setup pages of the 3Dconnexion control panel you can override the default\\ninteraction modes to fit your needs. By reversing the axes on the zoom and tilt modes you will get\\na similar user interaction regime like in IR or Petrel VR.\\nAdditional tips\\nCombine the 3Dx device with the Anti Roll feature in Petrel. It makes sure that the view is level at\\nall times.'},\n",
       " {'header': '3Dx Driver Installation ',\n",
       "  'content': 'The installer is supplied with the 3Dx CD. Alternatively you can download the latest driver version\\nfrom the 3Dx website. Run the installer and make sure that the driver is loaded on startup.\\nConnect the device once the installer is done. Make sure that the driver control panel is running.\\nOnce connected you will see a icon in the task bar. Double click to open the 3Dx control panel.\\nPlease refer to the 3Dconnexion help for specifics on how to set up the device.\\nAppendix 1 - Setting up a Trackd Device\\nThe trackd services from VRCO are needed in order to forward 3D input data from tracking\\ndevices, into Petrel VR. This cook book describes how to install and configure trackd for Windows.\\nDownload trackd\\nDownload the latest trackd from here: www.vrtigo.com/DISTRIBUTION/TRACKD\\nUnzip trackd\\nUnzip trackd into your master directory of VRCO utilities e.g. c:\\\\VRCO\\\\trackd\\nConfigure trackd\\nConfigure trackd according to the hardware you are using. Under are three example files for\\nthe FLOCK, IS-900 and for the PATRIOT.\\nConfigure flexlm\\nCreate a flexlm file that points to the license server for trackd. Under is an example file.\\nTest trackd\\nTest trackd by starting it and watch the status log. Any error should show up there and it is\\nalso possible to check that sensors return data as expected. We assume in the example\\ncommand below that the current working directory (pwd) is C:\\\\VRCO\\\\trackd\\\\etc and that\\nthe license file is named trackd.conf. From the command shell (cmd) issue the following\\ncommand: ..\\\\bin\\\\trackd -file trackd.conf -status all. The trackd will ask for flexlm\\nconfiguration. Select license source to be the flexlm license file described above. Defined\\nonce, trackd will not ask on subsequent start-ups for license information.\\nCreate trackd shortcut\\nit is recommended, for your convenience, that you define a shortcut for trackd so that it can\\nbe easily started when 3D input is needed. When you create the shortcut set the Target to\\n\"C:\\\\VRCO\\\\trackd\\\\bin\\\\trackd.exe -file trackd.conf -status all\". Set Start in to\\n\"C:\\\\VRCO\\\\trackd\\\\etc\"\\nConsult the trackd user documentation for more information. There you can find information on\\nhow to set up a trackd server to let you use one tracking installation across multiple computers.\\n(E.g. Inside Reality on Solaris and Petrel VR on Windows.)\\nTrackd Configuration Files Examples: IS-900,'},\n",
       " {'header': 'Flock, Patriot ',\n",
       "  'content': 'Intersense - IS-900\\n#---------------------------------------------------------------#\\nDefineDevice ISENSE is900'},\n",
       " {'header': '# Windows ',\n",
       "  'content': 'DeviceOption ISENSE port com2\\n# Communcation set up for 38400 baud\\nDeviceOption ISENSE baud 38400\\n# The Head sensor is connected to the first port (A), and the\\n# wand is connected to the second port (B).\\nDeviceOption ISENSE Sensors 1 1 0 0\\nDeviceOption ISENSE Controllers 0 1 0 0\\n# Isense is set up to give date in cm (Not inch wich is default)\\nDeviceOption ISENSE DevDataUnit cm\\n# Do not reset Isense at startup.\\nDeviceOption ISENSE Reset no\\n# Intersense default coordinate system has origin at (0, 0, 0) and\\n# X-axis going into the screen (-Z), Y-axis going to the right (X)\\n# and Z-axis going down (-Y)\\nDeviceOption ISENSE TransmitterRotationMatrix 0 0 -1 1 0 0 0 -1 0\\nDefineConnector SHM shm out 2\\nConnectorOption SHM data tracker\\nConnectorOption SHM key 4126\\nDefineConnector SHM1 shm out 1\\nConnectorOption SHM1 data controller\\nConnectorOption SHM1 key 4127\\n#Scale Valuator/joystick output\\nDeviceOption ISENSE ValuatorScale 2 1.7 all\\nAscension - Flock of birds\\n#---------------------------------------------------------------#\\n# Flock of Birds\\nDefineDevice FOB fobirds\\nDeviceOption FOB port com1\\nDeviceOption FOB baud 38400\\nDeviceOption FOB SRT 1\\nDeviceOption FOB Hemisphere +X\\nDeviceOption FOB transmitterrotationmatrix 0 0 1 -1 0 0 0 -1 0'},\n",
       " {'header': '# Define Wanda ',\n",
       "  'content': 'DefineDevice WANDA wanda\\nDeviceOption WANDA port com2\\n# Define an input connector\\nDefineConnector FOB_SHM shm out 2\\nConnectorOption FOB_SHM data tracker\\nConnectorOption FOB_SHM key 4126\\n# Define an input connector\\nDefineConnector Shm2 shm out 1\\nConnectorOption Shm2 data controller\\nConnectorOption Shm2 key 4127'},\n",
       " {'header': 'Polhemus Patriot ',\n",
       "  'content': '#---------------------------------------------------------------#\\nDefineConnector SHM shm out 2\\nConnectorOption SHM data tracker\\nConnectorOption SHM key 4126\\nDefineConnector SHM1 shm out 2\\nConnectorOption SHM1 data controller\\nConnectorOption SHM1 key 4127\\nDefineDevice PATRIOT liberty\\nDeviceOption PATRIOT reset yes\\nDeviceOption PATRIOT hemisphere +X all\\nDeviceOption PATRIOT sensormap all\\nDeviceOption PATRIOT stylusmap 0x0001\\nTrackd License server link\\nSERVER GST030 80e6f436 1717'},\n",
       " {'header': 'VENDOR VRCO USE_SERVER ',\n",
       "  'content': 'Trackd server\\n#---------------------------------------------------------------#\\n# #\\n# File : /home/inside/etc/trackd.conf #\\n# Desc. : Tracker Configuration file for ICenter, SLB, BERGEN #'},\n",
       " {'header': '# Author : Olav Kindt, # # Tracker : Intersense 900 - Wireless # ',\n",
       "  'content': '# #\\n#---------------------------------------------------------------#\\n#-----------------------------------\\n# Define the ISENCE Tracking device\\n#-----------------------------------\\nDefineDevice ISENSE is900\\n# Device is conencted to ttyb,\\nDeviceOption ISENSE port /dev/ttyb\\n# Communcation set up for 38400 baud\\nDeviceOption ISENSE baud 38400\\n# The Head sensor is connected to the first port (A), and the\\n# wand is connected to the second port (B).\\nDeviceOption ISENSE Sensors 1 1 0 0\\nDeviceOption ISENSE Controllers 0 1 0 0\\n# Isense is set up to give date in cm (Not inch wich is default)\\nDeviceOption ISENSE DevDataUnit cm\\n# Do not reset Isense at startup.\\nDeviceOption ISENSE Reset no\\n# Intersense default coordinate system has origin at (0, 0, 0) and\\n# X-axis going into the screen (-Z), Y-axis going to the right (X)\\n# and Z-axis going down (-Y)\\nDeviceOption ISENSE TransmitterRotationMatrix 0 0 -1 1 0 0 0 -1 0\\n#---------------------------------------\\n# CONNECTOR for TRACKER udp\\n#---------------------------------------\\nDefineConnector Ether1 udp out 2\\nConnectorOption Ether1 data tracker\\nConnectorOption Ether1 port 8001\\nConnectorOption Ether1 remote 134.32.123.151:9001\\n#-----------------------------------------\\n# CONNECTOR for CONTROLLER shared memory\\n#-----------------------------------------\\nDefineConnector Ether2 udp out 1\\nConnectorOption Ether2 data controller\\nConnectorOption Ether2 port 8002\\nConnectorOption Ether2 remote 134.32.123.151:9002\\n#-----------------------------------------\\nTrackd client setup\\n#---------------------------------------------------------------#\\n# #\\n# File : /home/inside/etc/trackd.conf #\\n# Desc. : Tracker Configuration file for ICenter, SLB, BERGEN #'},\n",
       " {'header': '# Author : Olav Kindt # # Tracker : Intersense 900 - Wireless # ',\n",
       "  'content': '# #\\n#---------------------------------------------------------------#\\n#---------------------------------------\\n# CONNECTOR for TRACKER shared memory\\n#---------------------------------------\\nDefineConnector Shm1 shm out 2\\nConnectorOption Shm1 data tracker\\nConnectorOption Shm1 key 4126\\nDefineConnector Eth1 udp in 2\\nConnectorOption Eth1 data tracker\\nConnectorOption Eth1 port 9001\\nConnectorOption Eth1 remote 134.32.123.156:8001\\n#-----------------------------------------\\n# CONNECTOR for CONTROLLER shared memory\\n#-----------------------------------------\\nDefineConnector Shm2 shm out 1\\nConnectorOption Shm2 data controller\\nConnectorOption Shm2 buttonorder 1 2 1 3 4 5 6 7 8\\nConnectorOption Shm2 key 4127\\nDefineConnector Eth2 udp in 1\\nConnectorOption Eth2 data controller\\nConnectorOption Eth2 port 9002\\nConnectorOption Eth2 remote 134.32.123.156:8002'},\n",
       " {'header': 'Appendix 2 - Tested Input Devices ',\n",
       "  'content': 'Ascension Flock of birds\\nIntersense IS-900'},\n",
       " {'header': 'Polhemus Patriot ',\n",
       "  'content': '3Dconnexion Spaceball (With the Patriot)'},\n",
       " {'header': '3Dconnexion Space Traveler ',\n",
       "  'content': 'Appendix 3 - Enabling Stereo in Petrel\\nHow to enable stereo in Petrel (For nVidia Quadro FX series)\\nThis document is a quick introduction in how to enable stereo in some of the nVidia Quadro FX\\ndrivers for Petrel. Screenshots from drivers 91.85 and 97.78 will be used. 91.85 has the driver\\nsettings embedded in the Display properties, the 97.78 uses the new nVidia Control Panel.\\nIn the driver we have a factory profile called Schlumberger Petrel (91.85: Performance & Quality\\nsettings->Active Profile. 97.78: Manage 3D settings->Global settings). For both drivers this one\\ncannot be used and Custom (97.78) or Global driver settings (91.85) needs to be selected, or a\\nnew version needs to be created based on the SLB Petrel profile.\\nEnabling stereo on 91.85\\nOpen the Display properties settings for your graphics card and select \"Advanced\". Go to the\\nnVidia tab. The display settings can be access by right clicking on your desktop\\nChoose \"Performance and Quality settings\". Make a copy of the Petrel profile or select the Global\\ndriver settings profile. Turn \"Enable stereo\" on. Make sure that your \"Stereo display mode\" is set\\nto use the On-board DIN connector if you would like to use the stereo signal that originates from\\nthe card.\\nEnabling stereo on 97.78\\nOpen the nVidia Control panel by right clicking on the desktop, or by accessing it through the'},\n",
       " {'header': 'Windows Control Panel. ',\n",
       "  'content': 'Select the Manage 3D settings option. Choose the \"Custom\" profile. Stereo is enabled by setting\\nthe \"Stereo - Enable\" to on. Make sure that you have set the \"Stereo - Display\" mode to \"Auto-\\nselect\" or if that does not work more specifically to \"Use on-board DIN connector\" if you would\\nlike to use the stereo signal from the DIN port on the graphics card.\\nEnabling stereo in Petrel\\nRight click on the 3D Window and select Preferences > Stereo . A stereo preferences window\\nwill appear. Select \"Raw Stereo (OpenGL)\" and tick the \"Use Stereo\" on.\\nPlease notice that you might want to lower the Camera offset a bit, otherwise the Stereo effect\\ncan feel extreme. Note: This does not apply when using Petrel VR, then this setting is\\ncontrolled by the application. Keep the camera offset turned off.\\nAppendix 4 - Setting up a Microscribe Device\\nThe Microscribe device should be plug and play. (Petrel VR has a built in driver.) Connect the\\nMicroscribe to your PC and set up the Microscribe in the site manager. See Create a device for the\\nsite for more information.\\nAppendix 5 - Petrel VR Terminology'},\n",
       " {'header': 'Wand ',\n",
       "  'content': 'Interaction device that lets the user interact with Petrel in a 3D sense. Both used as a name for\\nthe physical device and for the graphical representation of that physical device.'},\n",
       " {'header': 'World ',\n",
       "  'content': 'The world is a concept inherited from Inside Reality. The world is the box/area where data exist in\\nthe 3D scene. E.g. the bounding box of a number wells and seismic could be referred to as the\\nworld.'},\n",
       " {'header': 'Flying ',\n",
       "  'content': 'Petrel VR has a feature called flying. The real life analogue of Petrel VR flying is flying an airplane.'},\n",
       " {'header': 'Immersive ',\n",
       "  'content': 'An immersive world is a world where the user can interact and work as you can in a normal\\nworld. To feel fully immersed the user should not feel hindered by the fact that they are using a\\ncomputer system to work with their data. For Petrel VR to become an fully immersive application\\nit needs to work with a head tracked system. Petrel VR does not classify as a fully immersive\\nsystem.'},\n",
       " {'header': '6 DOF ',\n",
       "  'content': '6 degrees of freedom. Petrel VR uses 6 DOF input devices to manipulate the world. A 6 DOF\\ndevice is a device that can recognize the following movements: (from Wikipedia)\\n1. Moving up and down (heaving)\\n2. Moving left and right (swaying)\\n3. Moving forward and backward (surging)\\n4. Tilting up and down (pitching)\\n5. Turning left and right (yawing)\\n6. Tilting side to side (rolling)'},\n",
       " {'header': 'Virtual Reality ',\n",
       "  'content': '\"A computer-generated artificial world in which the users are immersed and where they can\\nnavigate and interact with graphical objects in an intuitive and natural manner\".\\nKey components of a VR system:\\nImmersive display environment\\nStereo viewing'},\n",
       " {'header': 'Tracking ', 'content': 'Direct data manipulation'},\n",
       " {'header': 'Appendix 6 - System Requirements ',\n",
       "  'content': 'High End configure PC (see Petrel system requirements for details)\\nHigh end graphics card\\n6 DOF Input device\\nTrackd  compatible input device\\nPetrel VR supports Trackd  version 5.5\\nVisit VRCO for more information:\\nhttp://www.vrco.com/trackd/Overviewtrackd.html\\nMicroScribe  G2 digitizer\\nStereo display is recommended'},\n",
       " {'header': 'Appendix 7 - Troubleshooting ',\n",
       "  'content': 'I am lost?\\nPress the View all button in Petrel.\\nPetrel VR has stopped working! What do I do?\\nClose window. Reopen fresh 3D window\\nI can see the wand, but it does not move when I move the input device.\\nYou need to check if the input device is turned on. Trackd also needs to get information from the\\ndevice.\\nPetrel does not recognize the wand.\\nYou might have to shift input focus to the 3D window.\\nAppendix 8 - How to Fly\\nExactly how flying works is dependent on the device mapping one chooses in the Site Manager.\\nWe would like to recommend a setup similar to the following mapping:\\nJoystick forward - move forward\\nJoystick backward - move backward.\\nJoystick left - turn left\\nJoystick right - turn right\\nTwist input device (tracker) clockwise, speed up\\nTwist input device (tracker) counter clockwise, slow down.\\n3D cursor direction - controls fly path.\\nAutomatic stabilizing (Z-down)\\nTemplates and Color tables\\nAll objects in Petrel are associated with a type (well, interpretation, surface, property, etc.) and\\nmost are also tied to a template. A template is a common object consisting of an icon and a color\\ntable. It describes which colors to use when displaying the data, what precision to use when\\ncreating labels, etc. and which units the property uses. This is important for unit dependent\\nprocesses such as estimation of well logs using standard formulas and generation of synthetic\\nseismograms.\\nA good rule is to always assign the correct template or color table to imported and generated\\ndata.'},\n",
       " {'header': 'Available Templates ',\n",
       "  'content': 'The folders in the Template tab in the Petrel Explorer list different templates for well logs and\\nproperties. Most of these templates can be used both for well logs, distributed properties and\\ntrend data. There are also folders containing color tables for depth and thickness.\\nAs an example, Geometrical templates list grid specific templates that are only used for\\ndistributed properties. Production template are discrete templates, which are well specific and\\nonly used for well logs. The template folder Other well log templates is typically used for raw\\nwell logs. But since the raw logs may be distributed to the 3D grid, these templates can be used\\nfor properties too.\\nAltogether, there are seventeen groups of property templates:\\nDepth/thickness tables\\nGeometrical templates\\nPetrophysical templates\\nGeophysical templates\\nVolume templates\\nFault property templates\\nWell log templates\\nProduction templates\\n2D log templates\\nOther templates\\nCompletion templates\\nDiscrete Property templates\\nSeismic color tables\\nDiscrete well log templates\\nFracture property templates\\nGeomechanic templates'},\n",
       " {'header': 'Datums ',\n",
       "  'content': \"Well section templates\\nUser defined templates can be added to all folders, and those can be moved from one folder to\\nanother. The exception is the 'Depth/Thickness tables' folder in which the user can only insert new\\npre-defined templates. Those can not be moved to another folder.\\nDepth/Thickness color tables\\nThis folder contains the different depth and thickness templates in Petrel. As Petrel can display\\nobjects both in elevation depth (meter or feet) and in time (milliseconds), there are separate\\ntemplates for these two.\\nGeometrical templates\\nThis template folder lists the available geometrical templates in Petrel. These templates are only\\nused for properties in the 3D model.\\nPetrophysical templates\\nThis template folder lists the available petrophysical templates in Petrel. These templates are\\nnormally used both for well logs and for distributed properties in the 3D model.\\nGeophysical templates\\nThis is a list of all templates to be used for geophysical templates as velocity or AI.\\nVolume templates\\nThis template folder lists the available volume templates in Petrel. The templates are used for\\ndistributed properties in the 3D model. In Petrel these volume properties can be calculated in the\\nVolume Calculation process step, see Volume Calculations.\\nFault property templates\\nWell log templates\\nThis folder lists templates that are used as well log templates, normally raw logs. However these\\nwell logs can also be scaled up and distributed in the 3D model as a property.\\nProduction templates\\nThis folder lists the available production templates for Petrel. The production templates will\\nnormally be used for production well logs.\\n2D log template\\nOther templates\\nTemplates that do not naturally belong to any of the other folders are listed here. The general\\ntemplate is the default template that Petrel attaches to all well logs and properties when it\\ndoes not recognize the well log or property name in the importing process. The user should\\nchange the general template when data has been imported into Petrel for best possible data\\nmanagement internally in Petrel.\\nCompletions templates\\nDiscrete property templates\\nIn this folder all discrete property templates in Petrel are listed. Discrete templates can be used\\nfor discrete properties such as facies, but can also be used for color annotation for zones,\\nhorizons, faults and segments for the display in Petrel.\\nSeismic color tables folder\\nThis folder lists the available templates for seismic data.\\nDiscrete well log templates\\nThis folder lists the available templates for discrete well logs.\\nFracture property templates\\nGeomechanic templates\\nThis folder lists the available templates for geomechanical values\"},\n",
       " {'header': 'Units ',\n",
       "  'content': 'Each of the properties has an associated unit, shown on the property template. As a default,\\nthese units are set based on the Project Unit System set under Project, Settings and will\\nchange as those are changed, however the user may override those settings.\\nThe unit definitions are especially important for those processes which rely on units for calculation\\npurposes, that is, simulation and volume calculation. In these situations, it is essential to ensure\\nthat the unit specified in the template agrees with the data that has been imported or created.\\nChanging the unit on a template will not convert existing data attached to that template. It will\\nmerely change the way in which the data is perceived in Petrel.\\nFigure 1. The unit settings for a template'},\n",
       " {'header': 'Customizing Property Units ',\n",
       "  'content': 'Each property template has two categories to determine the unit associated with the property.\\n1. Measurement - This determines the type of property the template represents. Properties\\nwhich have the same measurement type will have the same list of units, e.g. thickness,\\ndistance and height above contact all have the Length measurement type.\\n2. Unit - The unit for the specific property. The list of possible options is determined by the\\nmeasurement type.\\nThe measurement type can not be edited for the default templates in Petrel; instead a copy must\\nfirst be made. As a default, the units cannot be edited but are taken from the Project Unit\\nSystem set under Project, Settings. To change the units, check on the customize option and\\nchange the units as required. The units will no longer be updated if the Project Unit System is\\nchanged.\\nFigure 2. Template settings for a user defined property'},\n",
       " {'header': 'Datums ',\n",
       "  'content': \"The standard Datums used in Petrel are mean sea level (MSL), kelly bushing (KB), Seismic\\nreference datum (SRD) and checkshots reference datum (CRD). If required, the user can enter\\ntheir own datums for use when importing data. Right click on the Datums folder and choose\\nInsert New Datum. On the Datum Settings tab in the datum settings dialog the user should\\nsupply the offset of the datum from mean sea level.\\nBasic use of templates\\nTemplates can be attached to well logs and properties, while color tables can be attached to\\nseismic data, surfaces, lines and points. Discrete property templates can only be attached to\\ndiscrete well logs and discrete properties. When the property template is attached to the data\\nobject, both the color table and the icon of the template are applied.\\nAll templates can be modified, and continuous templates can be moved and copied to other\\ntemplate folders. User defined property templates can be added to every property templates\\nfolder.\\nAssigning templates or Color tables when importing\\nDuring the import process, the template and sub-type (e.g. 'conformable' for a surface or\\n'boundary' for a polygon) can be set for each individual object. When importing an object, an\\nInput data dialog will always pop up. In this dialog the template and type of each object should\\nbe set.\\nTemplate or type can be changed at a later stage, but for easier data management, we\\nrecommend that the proper template and type is defined on import.\\n1. Go to the Template tab in the Petrel Explorer and select the folder to which the new\\ntemplate should be added.\\n2. Click on the folder with the right mouse button and choose Insert Property Template.\\n3.\\n1.\\n2.\\nObserve that a new property template has been added to the selected folder.\\n3. Double click on the new template to open the Settings window, and choose the Info tab.\\nObserve that the 'Type of template' is 'User defined'.\\n4. Rename the template and type in a 'Legend label'.\\n5. Choose template 'Icon' from the pull-down menu.\\n6. It is recommended to add a comment of the use of the template in the 'User comments'\\nwindow.\\n7. Select OK or Apply, and the changed template will be seen in the Template tab in the Petrel\"},\n",
       " {'header': 'Explorer. ',\n",
       "  'content': 'Change template of an object\\nThe template of an object can be changed in the Info tab in its Settings dialog. To open the\\nSettings dialog, double click on the object. Use the drop-down menu to change template or type.\\nUser defined templates\\nUser defined templates can be added in the Templates tab in the Petrel Explorer for all template\\nfolders. The new template that is added will be a continuous template, with the exception of the\\ndiscrete template folders in which the template added is a discrete template. The newly added\\ntemplate will have the title \"Untitled 1\" and the icon for a continuous template and for a\\ndiscrete template. Name and icon can be changed in the Info tab in the Settings window for the\\ntemplate.\\nTemplate settings for a user defined property\\nHow to add a user defined template\\n1. Go to the Template tab in the Petrel Explorer and select the folder to which the new\\ntemplate should be added.\\n2. Click on the folder with the right mouse button and choose Insert property template.\\nObserve that a new property template has been added to the selected folder.\\n3. Double-click on the new template to open the Settings window, and choose the Info tab.\\nObserve that the \"Type of template\" is \"User defined\".\\n4. Rename the template and type in a \"Legend label\".\\n5. Choose template Icon from the pull-down menu.\\n6. It is recommended to add a comment of the use of the template in the \"User comments\"\\nwindow.\\n7. Select OK or Apply, and the changed template will be seen in the Template tab in the'},\n",
       " {'header': 'Petrel Explorer. ',\n",
       "  'content': \"Templates and well logs\\nThe type and property template of well logs should be set on import. You may either select\\n'Autodetect logs', in which case Petrel will attempt to attach appropriate templates to the\\nimported logs, or you may select to 'Specify logs to be loaded'. In that case, you will get a table\\nview of your logs where you can assign the templates and which global log to attach to.\\nTo change the template of a global well log, go to the global well logs folder and double click on\\nthe log from there. Change Template in the Info tab in the Settings dialog.\\nAlways import all of your wells before you start to change well log templates, as this will\\nreduce the amount of work with the templates.\\nGlobal well logs vs. local well logs\\nWhen wells with log data are imported into Petrel, the well logs will be listed under each well, as\\nwell as under the Global Well Logs folder. In the Global Well Logs folder, all well logs\\nassociated with any of the wells in your project will be listed. This is a global folder from where\\nchanges of well logs in all wells can be performed in one go. That is, a change to a log in the\\nGlobal Well Logs folder, applies to all logs in the project attached to this log, no matter which well\\nit belongs to. The Global Well Logs folder is a filter folder, recognized with yellow boxes, for\\nfurther information of this type of filter, see Well Logs Filter.\\nLocal well logs are attached to global well logs. When importing well logs into Petrel, the user\\nshould specify which global well log the local well log should be attached to.\\nPetrel will create one global well log corresponding to each of the local logs for the first well you\\nimport. For the next well, you must specify which of the global well logs to attach each log to.\\nOtherwise, add a new global well log if the log you import does not correspond to any of the\\nexisting logs.\\nIf several files are imported into Petrel simultaneously and the option OK for all is used, the\\nprogram assumes that the different well files lists the well logs in the exact same order.\\nFor further use of well logs in the property modeling steps in Petrel, it is important that all\\nlogs attached to the same global well log are comparable.\\nHow to attach local well logs to more than one global well log\\nTo view the same well log with two different styles, a second template is needed for the property\\nand second global well log.\\nCreate a user defined template by:\\n1. In the Templates tab in the Petrel Explorer, select a template folder for the new template.\\nClick with the right mouse button on the folder and choose Insert Property Template. A\\nnew property template will be listed at the bottom of the folder. Alternatively, copy and\\npaste an existing template.\\n2. Double click on the new template object to open the Settings window and go to the Info\\ntab.\\n3. Type a new name, e.g. Porosity2, and select icon from the Use icon pull-down menu. A\\ntemplate for the new log is now generated.\\nCreate a second global well log.\\n1. Select a well with a well log that should be displayed with the new template. Make a copy of\\nthe log. The copy appears in the Global Well Logs folder.\\n2. Open the Settings window for the new global log, and go to the Info tab. Select your new\\nTemplate, and type an appropriate name. The setting applies to the local log, and you can\\ndisplay it with the new color-table.\\n3. Repeat 1 and 2 for all well logs that should be displayed with the new color table.\\nIt is now possible to display the original log along with the new well log with a different color\\nscale.\\nTemplates for property models\\nThe concept of property template makes it easier to tie together data types associated with the\\nsame property, i.e. porosity log, porosity maps and a porosity 3D model. Data with the same\\nproperty template share a common color table.\\nTemplates for a property model should be set when the property is created or imported into\"},\n",
       " {'header': 'Petrel. ',\n",
       "  'content': \"How to set the property template of a created 3D property model\\nThe template of a property model is set when the property is created in one of the Property\\nModeling process steps. The property template can be changed in the Info tab of the Settings\\nwindow for any property. Open the Settings window by double clicking on the property and go to\\nthe Info tab. Choose a template in the Template tab.\\nColor tables\\nIn Petrel, it is possible to set different continuous and discrete color tables.\\nAll objects with the same template use the same color table. If the depth scale is changed for one\\nobject, it will change for all other objects attached to this template.\\nThe color tables for objects can be altered in two different places in Petrel:\\n1. In the Settings for each object, under the Color tab. The color table will be set for the Z-\\nscale for all objevts attached to the same template unless the the user have selected to use\\na stand alone coller template for that object, see Stand alone color template.\\n2. In the Templates tab in the Petrel Explorer, a number of color tables can be defined for the\\nvarious templates.\\nContinuous color tables\\nTo set the max and min levels of a color table, define the span of the color scale. A quick way to\\nset the max and min levels, equal to the max and min value of a selected object in the depth or\\nthickness domain, is to click on the Adjust Color Table on Selected icon on the Tool bar.\\nThe color tables can be set from the Settings window of the data object or from the Settings\\nwindow of the associated template. Color tables can easily be reversed by pressing .\\nFor a better color scaling, set the color range based on the object with the smallest delta Z\\nvalue (Z-max - Z-min).\\nFigure 1. Color table for Surface. Has the option of Opacity.\\nHow to set a continuous Color Table\\n1. Open the 'Colors' tab for the selected object from its Settings window. It is only possible to\\nhave one color table for each template. This color scale can be split into three different\\nintervals.\\n2. The max and min levels define the color scale. The max and min level can be set equal to\\nthe max and min value of the selected object by clicking on the 'Max' and 'Min' buttons. Be\\naware that Petrel will give an error message if the lowest level is greater than the highest\\nlevel.\\n3. If needed, divide the color table into two or three separate tables by clicking on the scale\\nbar.\\n4. Choose the color scale by clicking on the color buttons for the max and min value.\\n5. Choose the Color interpolation for the selected interval.\\n4.\\n5.\\nStand alone color templates\\nBy default, altering the color settings of a object will influence all other abjects attached to the\\nsame color template. If the user want to make the color for a object a stand alone color scale, go\\nto the color tab an check the Overide global property template options.\\nMax, Min and interval levels for color tables\\nSet Max and Set Min: The levels are set equal to the max and min value of the selected\\nobject by clicking on the Min and Max buttons. The values can be user defined by typing\\nthe max and min levels in the small windows. Petrel will not allow the Min level to be\\ngreater than the Max level. Colors for Max and Min are selected from the pull-down menus.\\nInterval levels: The color scale can be set to have different color intervals by clicking on\\nthe scale bar. Observe that an arrow is inserted on the scale bar. The exact position of the\\ninterval level can be defined in the interval window. Set interval color in the pop-up window.\\nSeveral interval levels can be set. To delete an interval level, make it active and use the Del\\nbutton. Make it active by clicking on the arrow on the scale bar. The active arrow is yellow.\"},\n",
       " {'header': 'Color Interpolation Models ',\n",
       "  'content': \"The continuous color table in Petrel has different settings for color interpolation of the color scale.\\nIn general the HSV(Max) interpolation gives a color scale with max number of colors, HSV(Min)\\nand RGB give two slightly different color scales with a minimum number of colors between\\nselected max and min colors.\\nHSV color interpolation\\n1. Select HSV (Max) or HSV (Min) interpolation in the Colors tab.\\n2. When HSV (Max) is selected, the end colors defined by the user (max and min colors) are\\nmixed traversing the longest path through the corner colors of the top of the HSV single-\\nhexcone. The HSV (Min) interpolates the end colors traversing the shortest path through\\nthe edge colors.\\n3. The HSV color interpolation has a tendency to result in slightly dominating primaries. The\\n4.\\n3.\\neffect is reduced when Emphasize is selected.\\n4. If a non-linear interpolation gradient is preferred, select Non linear gradient. Drag the\\narrow in the pop-up bar towards left or right to compress the color scale.\\n5. The saturation is controlled by the saturation bar S. Drag the arrow towards right to\\ndecrease the saturation. (S=1 is default, S=0 corresponds to white).\\n6. The value V bar adds black pigment to the color scale when the arrow is dragged towards\\nright.\\nThe HSV color model is illustrated by a single-hexcone. The top of the hexcone corresponds to\\nvalue V=1. The V=1 plane contains the primaries (red, green and blue) at corners 1200 from\\neach other. The complementary colors are 180 0 opposite each other. The saturation S is a ratio\\nranging from 0 at the centerline (V axis) to 1 on the triangular sides of the hex cone. The hex\\ncone is one unit high in V, with the apex at the origin. The point at the apex is black and has V=0.\\nFigure 2. An example of the single hex cone HSV color model.\\nRGB color interpolation\\n1. Select RGB interpolation in the Colors tab.\\n2. RGB interpolates along the axis between the two selected colors in the RGB color cube.\\n3. To compress the color scale, select Non linear interpolation gradient. Moving the arrow in\\nthe pop-up bar towards the left or right, controls the interpolation gradient.\\nWhen two end colors are defined, the RGB interpolation will mix the colors along an axis between\\nthe two colors in the RGB color cube.\\nFigure 3. An example of the RGB color model.\\nLogarithmic scale\\nA logarithmic color scale can be selected for a property/well log template that has positive values.\\nIn the Settings window, choose the Colors tab and select Log scale to the right of the color bar.\\nHow to set a continuous color scale in discrete colors\\nContinuous color-scales can be converted to discrete scales in the Colors tab. Click on the 'Make\\ndiscrete' button and select an increment.\\nTo get the original color scale back, delete all interval colors. Click on an arrow on the scale bar to\\nmake it active and use the Del button. The selected arrow gets a yellow color.\\nDiscrete color tables\\nDiscrete color tables are associated with discrete well logs and discrete properties. Lithology logs,\\nZone logs, facies logs and perforation logs are examples of discrete logs. The color tables are set\\nfrom the Settings window of the selected object, or the Settings window of a discrete template in\\nthe Templates tab.\\nFor discrete well logs, the setting of the color table can be done automatically by the option\\nSynchronize colors and labels, which can be found on the right mouse button menu for the\\ndiscrete log in Global Well Logs folder. The option will remove the icons under each individual\\nlog.\\nDiscrete color tables can also be made automatically for the folders: faults, horizons, zone filter\\nand segment filter. To generate the discrete color tables, click with the right mouse button on one\\nof the folders and select Define Discrete Legend .\\nDiscrete color table settings\\nCode The code number of the parameter.\\nAppend item in the table: Adds another row in the bottom of the color table.\\nDelete the last item in the table: Deletes the last row in the table.\\nSet number of items in table: The user can define how many codes (i.e. number of facies,\\nlithologies, zones, etc.) to use.\\nFill rainbow colors on the items in the table: Fills the color scale with maximum number\\nof colors.\\nName Write the name of the item, which should be displayed with this color, e.g. a\\nlithological formation in a lithology parameter.\\nParent Write the code number of the parent (e.g. geological unit) of the parameter. The\\nparent can e.g. be the lithological group comprising formations. The child color will be\\ndisplayed together with the respective parent(s) in e.g. the well section window.\\nColor Give a color to the item, e.g. this zone in the zone log will be displayed with this\\ncolor.\\nPattern Select pattern and color of the parameter. This pattern can be viewed with the well\\nin e.g. a Well Section window.\\nExample on the use of parent/child colors\\nHow to set a discrete Color Table\\n1. Open a discrete color table for the selected object, which has to be a discrete well log or a\\ndiscrete property. Discrete color tables are available from the selected objects Settings\\nwindow or from a discrete template in the Templates window.\\n2. Fill in the name of the zones, facies, e.g. as specified in the log or property and choose a\\ncolor for each in the spreadsheet. If preferred, select pattern for the logs.\\nColor table legends\\nAll color tables in Petrel can be displayed as a legend in the Display window together with the\\nobjects.\\nColor legends in Petrel can be set active in two different ways:\\nAutomatic legend: Use the Toggle Auto Legend icon in the Tool bar menu. This will display\\nthe color legend of a visualized object in the Display window. The auto legend will display only one\\ncolor legend, even when several types of data are visualized. A 3D property is prioritized to a well\\nlog and a well log to a surface.\\nTemplate tab in the Petrel Explorer: In the template tab all the different templates in\\nPetrel are listed with their different color tables. By ticking the box next to a template in the\\ntemplate tab, the legend for the selected template will be visualized. Several legends can be\\nvisualized at the same time.\\nHow to display the Automatic legend\\nTo display the Automatic legend, click on the Toggle Auto Legend icon on the Tool bar\\nmenu. The Automatic legend can also be displayed by selecting Automatic legend for the display\\nwindow under the Window tab.\\nHow to display the color legend of a template\\nOne or several color legends may be displayed at a time. To display a color legend, select the\\nproper template (or templates) in the Templates tab in the Petrel Explorer.\\nPosition of color legends\\nThe positions of the color legends are set in the Settings window of the templates. In the\\nTemplates tab in the Petrel Explorer, double click on a selected template to open the Settings\\nwindow. Select position from the Position of the Legend menu.\\nFor e.g. a continuous color table, select Manual increment and choose increment from the pull-\\ndown menu.\\nColor legend outline\\nThe outline of a color legend can be set in the Settings window for legends. This Settings window\\nis opened by clicking on the little arrow next to the Toggle Auto Legend icon on the Tool bar\\nmenu. In the Settings window select the Style tab.\\nIn the style, the size of the legend window can be set, together with legend frames, tick marks\\nand labels, annotation fonts and foreground and background colors.\\nSeismic color tables\\nTemplates used for images of seismic amplitudes are placed in the Seismic color table's folder in\\nthe Templates tab. The predefined color tables can be copied and modified.\\nManipulating the seismic color table is tightly linked with the use of seismic visualization and\\ninterpretation in Petrel and is described in detail in Color Manipulation.\\nThe Petrel default seismic color table is Blue-White-Red, displaying positive amplitudes in blue and\\nnegative amplitudes in red.\\nNote that opacity can be set to a seismic color table.\\nHow to make a user-defined seismic template\\n1. To make a user-defined seismic color table, click the right mouse button on the Seismic\\ncolor table's folder and choose Insert Seismic Template. A new template is added to the\\nfolder.\\n2. Double click on the new template to open the Settings window, and choose the Info tab.\\nRename the template and the legend label.\\n3. Choose the Colors tab and set the color scale.\\n4. To attach a seismic cube to the user-defined template, open the Settings window for the\\nseismic object and choose the Info tab. Attach the seismic cube to the user-defined\\ntemplate in the pull-down menu.\"},\n",
       " {'header': 'Filter ',\n",
       "  'content': 'Petrel can display the whole model (all elements) or selected parts of it. Powerful filter techniques\\nenable the user to take full control of the 3D grid and visualize only the elements of interest for\\nquality control.\\nConcept of filters in Petrel\\nFilters in Petrel are used booth for visualization and for calculations. There are two basic types of\\nfilters in Petrel. The first type is a simple On/Off type, where an element is either turned on or off.\\nOther filters are more advanced (for example filtering of properties) and are based on values set\\nby the user.\\nCheckboxes act as the simple On/Off filters in Petrel. There are three types of checkboxes in\\nPetrel: white, yellow and blue.\\nWhite checkboxes can only be used for switching a single object on or off.\\nYellow checkboxes work on collections of similar objects. A yellow checkbox for a specific log\\ntype will turn on all logs of that type for all wells that have that log type.\\nThe blue checkboxes are used for enabling or disabling visualization of an element on the\\nactive intersection plane(s). A surface with a blue checkbox enabled will only show the trace\\nof the surface on the active intersection planes.\\nThe more advanced filter options will be:'},\n",
       " {'header': 'Generic Filters (See Generic Filters) Wells Filters (See Wells Filters) ',\n",
       "  'content': 'Well Tops Filters (See Well filter (Well Tops folder)\\nProperties Filters (See Filtering of Property Models)\\nFilters for Input data\\nFilters for Input data are of the simple checkbox type and the more advanced type. In general,\\nthe individual elements will have white checkboxes, and the folder itself will also have a white\\ncheck box. The folder checkbox will turn On/Off all the elements in the folder.'},\n",
       " {'header': 'Generic Filters ',\n",
       "  'content': 'This is a generic filter type that you can create for any data object suitable to be displayed in the\\nfunction window, the histogram window, or the stereonet window. The filter appears in the filter\\nfolder in the Input pane and can then be applied to any object in the project.\\nFeatures of the generic filters\\nFilters automatically appear as an icon in the filter folder in the input tree. They can be turned on\\nor off in each window, and any number of them can be created; important filters can be saved\\nand reused throughout the workflow.\\nAny object displayed in the function window can be used to create a filter. The selected points will\\nbe displayed with a stronger color in the crossplot. If other attributes of the object are displayed\\nin other function windows, the selection can also be reflected in those views.\\nAny object displayed in a histogram window can be used to create 1D filters. Histograms can also\\nbe used to display a selection; the fraction of the data in each bar which falls inside the filter is\\ndisplayed in a stronger color.\\nA single 1 or 2D filter may consist of any number of regions in a function window.\\nIn the 3D window the following items can be filtered: cells in the grid, well tops, point well data\\nand points with attributes.\\nPicks can be made in 3D to create a spatial filter around that point. Picks can also be made on\\nindividual points in the function window and then traced back to their location in 3D.\\nFilters created on one object can be applied to another object. The attributes (properties, well\\nlogs, attributes, and so forth) to use in the filtering are either specified explicitly or mapped\\nimplicitly, by matching the template of the attribute. If more than one attribute exists, the\\nmapping can preferentially choose the displayed attribute.\\nFilters can be used in the calculator to create Boolean properties, logs or attributes representing\\nthe points passing the filter.\\nUsers can select points using the filter and then create a best-fit function through those points.\\nCreating generic filters\\nThere are several types of generic filters and they can be defined in different ways:\\n1. 1D filters - based on a single attribute, such as porosity, is between 0.1 and 0.15. 1D filters\\n2.\\n1.\\ncan be defined in a function window or on a histogram.\\n2. 2D filters - based on 2 attributes. The points to be filtered may be defined by a square or a\\npolygon drawn by the user. 2D filters are defined in a function window.\\n3. Spatial filters - based on position in 3D space. These are defined as a distance around a\\npicked point. The point may be picked in a 3D window or in the function window.\\n4. Logical filters - based on a combination of any of the other filters. The filters may be\\nconstructed using any combination of AND, OR, NOT commands with brackets, to define\\nthe sequence each filter should be applied in.\\nHow to create a filter from a function window\\n1. Open a new function window.\\n2. Toggle on the data you want to apply the filter on.\\n3. Use the Select using 1D range at the x-axis or the Select using 1D range at the y-axis\\nto produce a 1D filter.\\n4. Use the Select using 2D rectangle or Select using freehand draw to produce a 2D\\nfilter.\\nHow to create a filter from a histogram window\\n1. Open a new histogram window.\\n2. Toggle on the data you want to apply the filter on.\\n3. Use the Select using 1D range at the x-axis .\\nHow to create a filter from a stereoplot window\\n1. Open a new stereoplot window.\\n2. Toggle on the data you want to apply the filter on.\\n3. Use the Select using freehand draw to produce a 2D filter.\\n2.\\n3.\\nWell Logs filter (Wells folder)\\nAs seen in the figure below, a yellow box for a well log indicates that all logs of that type are\\nswitched on. In this case the Porosity, Permeability and Fluvial Facies checkboxes are On, and all\\nwells that have these well logs can be displayed. However, they will only be visible if the wells are\\nalso visualized. In this example only the A10 well is turned On with these logs.\\nIt is not enough to turn On a yellow button - the wells must be visualized as well. All well log\\ncurves can be visualized by selecting all the white checkboxes for the log curve in each well folder,\\nbut a shortcut is to use the yellow checkbox under the Global Well Logs folder.\\nFigure 1. Wells folder expanded.'},\n",
       " {'header': 'Well Filters ',\n",
       "  'content': 'There is an option under the Wells folder to insert one or more Well filters. This will limit\\nvisualization to particular sections of a log/well path in Well Section, Map and Intersection'},\n",
       " {'header': 'Windows. ',\n",
       "  'content': \"Filters can be created based on absolute Z value or based on Well Tops or Surfaces.\\nThey include an optional blanking region above and below the chosen subject.\\nMissing Top logic is included so that if a well misses a selected top then the system will try\\nto use the next available top or the top or bottom of the well (Zone logic)\\nThe filter can be applied to all or a selection of wells.\\nFilters are additive so more than one range can be filtered.\\nFilters replace the Simplification option on wells.\\nHow to create a Well Filter\\n1. Go to the Wells folder in the Input pane.\\n2. Right-click on the Well filter folder and select New well filter from the menu.\\n3. Select Wells to apply the filter on.\\n4. Toggle on the TopZ and BaseZ depth to apply the filter on trace/logs on.\\n5. Select either a Constant (type in depth) or From subject (drop in well tops). Apply an\\noffset if applicable in project units. The filter will keep the data between the TopZ and\\nBaseZ and reject data outside.\\n6. Open a Map, Intersection or for example a Well Section window. Toggle on the Well filter\\nunder Wells for it to take effect.\\nYou can create multiple filters and apply them simultaneously.\\nImportant Note: When using well filters in a Well Section window it is recommended to use\\nthe mouse wheel or the up and down arrows for scrolling along the well. For zooming or\\nstretching, it is recommended to use the(+ and -) short cuts on the keyboard.\\nWell filter (Well Tops folder)\\nThe Well Tops folder can be filtered the same way as the Wells folder.\\nThe Well Tops folder contains five folders: Attributes, Stratigraphy, Faults, Others and Well Filter.\\nAll with yellow checkboxes.\\nWhen an attribute and a stratigraphic level are switched on, Petrel only looks for the wells that\\nare toggled On in the Wells Filter folder. This means an attribute; a stratigraphic level and a well\\nmust be selected for anything to be displayed in the 3D window.\\nSeismic filters\\nSeismic data (ZGY format) displayed using volume rendering, as volume walls or on intersections,\\ncan be visually filtered see Color Filtering Techniques for more information. Seismic\\ninterpretations can be filtered according to tracking method, if imported or converted, or survey\\nused for the (partly) interpretation. See Interpretation Filters for more information.\\nFilters for the 3D corner point grid\\nThere are several filtering possibilities available for the 3D grid. These can all be combined,\\nalthough they are described separately for an easier overview.\\nFault filter\\nA filter displaying different offsets on faults defined by the horizons; i.e. selecting fault throws for\\nspecific horizons. The fault filter is only applicable after having generated horizons.\\nWhen the fault filter is activated, the check mark of the Fault filter folder in Petrel Explorer\\nwill be colored in purple.\\nIn the figure below, the same segments and faults are displayed with and without a fault filter.\\nConversion of Faults to Fault Polygons\\nThe Fault polygons converted from the fault filter are sorted on horizons and not on single faults.\\nThis menu option is available on the Fault Filter (right mouse button menu) and places the\\npolygons in the Input window in Petrel Explorer.\\nFor further information on how to convert faults to fault polygons, see Export Data.\\nZone filter\\nA filter with selected zones can be displayed. It is only applicable after having generated Horizons\\nand Zones. The zones are listed in the stratigraphical order defined in the Make Horizons and\\nMake Zones process steps. There are two levels of icons in the Zone Filter folder. Level one\\nconsists of the main zones generated in the Make Horizons process. Level two consists of the\\nzones generated in the Make Zones process. When opening a zone folder for one of the main\\nzones the zones are automatically displayed. Each zone can also manually be switched On/Off\\nwhen zones are checked on.\\nWhen the zone filter is activated, the check mark of the Zone filter folder in Petrel Explorer\\nwill be colored in purple.\\nHow to create a discrete color table for the zones\\n1. Click with the right mouse button on the Zone Filter folder.\\n2. Select Create new 'Zones' property template from the menu.\\n3. A pop-up menu gives you the option to choose which zone level to make a template from.\\n4. Once selected, the template is added to the Discrete property templates folder in\\nTemplates tab. Toggle on to display in a window.\\nHow to use the Zone Filter\\n1. Display selected zones or the I- and/or J-intersections.\\n2. Switch off zones in the Zone filter under the 3D grid in Models tab.\\nConversion of Zones to Isochores\\nThis option is available for one or more zones (also sub-zones). This menu option is available in\\nthe Zone Filter Settings window. For converting all zones to isochores double click on Zone Filter,\\nchoose the Output tab and press Make isochore.\\nFor converting one zone to an isochore, double click on that specific zone filters name. Isochores\\nare placed under the Input tab in Petrel Explorer.\\nFigure 1. Output tab in the zone filter.\\nFor further information on how to convert zones to isochores, see Export Data.\\nOn the Zone filter (right mouse button menu) there is an option to make a Zone property\\ntemplate for all zones or update all Zone property templates made from the selected grid.\\nSegment filter\\nThe Horizons can be displayed one by one, all together or by using the Segment Filter. By using\\nthe Segment Filter, selected parts of the horizon can be displayed. The segments are listed in\\nsequential order starting with the largest one. There is a right mouse button option to sort\\nsegments by name. On the Segment filter (right mouse button menu) there is an option to make\\na Segment property template for the segments.\\nWhen the segment filter is activated, the check mark of the Segment filter folder in Petrel\\nExplorer will be colored in purple.\\nHow to create a discrete color table for the segments\\n1. Click with the right mouse button on the Segment Filter folder.\\n2. Select Create/Update Segments property template from the menu.\\n3. The legend is now added to the Discrete property templates folder in the Templates tab.\\nToggle on to display in a window.\\nHow to use the Segment Filter\\n1. Display selected zones (zones + zone filter selection) and one or two horizons.\\n2. Switch off all segments in the Segment filter and switch on the ones you are particularly\\ninterested in taking a closer look at.\\n3. When viewing and zooming inside a zone or segment use the Target Zoom button for\\nimproved control on the zooming.\\nFiltering of Property Models\\nThe properties are a part of the 3D grid and all the filters in Filters for the 3D grid can be used for\\nthe filtering of all the properties. There are some additional filtering possibilities that can be found\\nunder the Filter tab in the Settings window of the Property folder.\\nWhen a value filter is applied to a property, this property will be colored in purple in Petrel\"},\n",
       " {'header': 'Explorer. ',\n",
       "  'content': 'Figure 1. The property filter tab.\\nUsing Property Filters in Petrel\\nThere are several ways of quality checking a generated property model. The techniques for\\nfiltering on property models are excellent quality control tools. For improved graphical\\nperformance, it helps to switch off some of the segments or zones from the Segment Filter or the\\nZone Filter. The Histogram and Statistics are also tools for improved quality control. Both\\nHistogram and Statistics are filter sensitive in respect to zones and segments. Also the calculator\\nfor making property models is filter sensitive by option.\\nUnder the Properties folder there is a filter option where the user may filter on property models.\\nThe filter is a tool for hiding grid cells, honoring given criteria for display. Open the Filter tab from\\nthe Settings window of the Properties folder (double click the Properties folder). A combination of\\ndifferent and/or several filters may be used.\\nThe property filter includes Use Segment and Zone filters as an option. These filters have to be\\nset for the grid in Petrel Explorer.\\nThere is also an option to invert the filters that are set with the Invert total filter option. This gives\\nthe possibility to quickly visualize opposite filter settings.\\nUpscaled logs filter\\nFiltering on the cells penetrated by the wells. Only selected wells with the cells penetrated by the\\nwell path will be visualized.\\nThis filter is only available for properties that have been distributed on the basis of well logs that\\nhave been up-scaled.\\nSeveral possibilities are available for the Upscaled logs filter:\\nAlways Include: The upscaled logs are always included in the filter, even for the property\\nplayer. (This is the default setting).\\nExclude: The upscaled logs are excluded from the property, i.e. not shown.\\nAs Normal Cells: The upscaled logs are not treated in any special way, i.e. they are regarded as\\npart of the 3D property.\\nOnly: Cells in the property that are not part of the upscaled logs are filtered away enabling you to\\nvisualize the upscaled well logs only.\\nSpecial 1 and 2: This option allows the user to set a volume (1 or 2 cells) around each upscaled\\nwell to invisible. The upscaled cells will be visualized. By using the invert total filter option, the\\nundefined volume will be visualized.\\nIndex filter\\nThe effect of using the Index filter is similar to creating a fence diagram. The filter is based on the\\nindexing of the cells in the 3D grid.\\nTo use the Index filter, toggle on the Use Index Filter box at the top of the Filter tab.\\nThe Index filter is a combination of three different filters - one for each main direction of the grid:\\nI, J, and K.\\nThe I checkbox indicates how to filter cells with the same I index number.\\nThe J checkbox indicates how to filter cells with the same J index number.\\nThe K checkbox indicates how to filter cells with the same index number.\\nThe parameters Min, Start, Width, Skip and Max determine which cells will be shown. The And/Or\\ncheckboxes are additional criteria. If the top And/Or is on, only the intersections between the\\nselected I and K cells will be shown. If both And/Or checkboxes are on, only the intersection of\\nthe selected I, J, and K cells will be shown.\\nMin: No cells with an index number less than \"Min\" will be displayed.\\nStart: Index of the first I/J/K cells to be visualized.\\nWidth: How many consecutive rows of cells to be shown.\\nSkip: How many rows of cells to skip (not to show).\\nMax: Rows with an index larger than Max will not be shown.\\nExample for I and J: Start = 21, Width = 2, Skip = 4, Max = 33\\nI21, I22 are shown. I23, I24, I25, I26 are not shown. I27, I28 are shown, etc. The same numbers\\nare shown for J.\\nValue filter\\nValue filter (filtering on cell values): Use the two cut-off bars to change the cut off values. Select\\nthe property from the list of available properties. Check the Use filter and move the arrows to get\\nthe range of values you want to display, or type in the min and max values for a given property.\\nIf your value filter shows a negative min value for a property, where you would not expect it, e.g.\\nfor porosity or the bulk volume, the negative cell values may be graphically displayed by typing in\\n0 for the max value.\\nThe value filter can be used in a number of different combinations, where value limits can be set\\nfor a number of different properties and only property cells that fulfill the conditions set for all the\\ndifferent properties will be displayed. This can be of particular interest for calculations of volumes\\nof the filtered cells only.\\nNote that if the value filter is set for one property, all other properties that are visualized will\\nalso only display cells that fulfill the value limit set for the first property. The value filter will have\\nto be set inactive or reset in the Filter tab to be able to display all the cells again.\\nHow to set value filter for more than one property\\n1.\\n2.\\n1. Open the filter by double clicking on the Property folder of a 3D Grid. In the Settings\\nwindow select the Filter tab.\\n2. Toggle on Use value filter under Filter settings.\\n3. In Value filter, select the first property, click on Use filter and set the max and min value\\nfor this property.\\n4. Select the next property and set the max and min values to be displayed and repeat for all\\nthe properties that a limit needs to be set for.\\n5. When all necessary value limits are set, click OK.\\n6. In Petrel Explorer, visualize a property and the cells displayed will fulfill all the conditions\\nset in the value filter.\\nVisible filter\\nThis filter is based on the Generic filters applied on what is displayed in the active 3D window\\n(for detailed information see Generic Filters). This could be used to perform operations on a\\nspecific cell layer, segment or zone. It is especially useful to use in workflows using the Workflow\\neditor.\\nDefined values only\\nThe filter is based on the selected property in the menu. All cells with a property value between\\nthe Max and Min values will be displayed.\\nAll the cells with undefined values are displayed in gray if this filter is not in use.\\nOther filter options\\nInvert total filter: Option to invert the filter. Will invert all applied filters.\\nUse Segment / Zone filter: Option to choose whether to use the segment/zone filters or not.\\nUse Local Grid filter: Applies the Local grid filter created when using the Make Local Grids\\nprocess under Structural Modeling.\\nFilter away 0 volumes: If toggled off, all cells will be shown, even if they have 0 volume. If\\ntoggled, only cells with volume greater than 0 will be visualized (default). The option Defined\\nvalues only has to be toggled in order to be able to choose this filter option.\\nFiltering with Property Player\\nA useful way of viewing your modeling results is by using the property player in Petrel. The\\nproperty player will go through each layer, row or column, step by step or by animation. It is used\\nas an automatic index filter, making it convenient to quickly browse through your results. It works\\ntogether with intersection planes that can narrow down the areas for your quality control. All\\nfiltering techniques that are applicable to property models will work together with the property\\nplayer. It is however, not recommended to use the index filter (in the property filter tab), during\\nthis operation since this can make the entire property invisible in the property player.\\nHow to use the property player: See Property Player.'},\n",
       " {'header': 'Import Data ',\n",
       "  'content': 'Petrel has numerous links to related applications to ease the transfer of data in and out of the\\nsystem.\\nFiles to be imported must be prepared in a supported format. To import the file, the file and\\nformat type is selected in a similar way to standard desktop Windows applications.\\nImported data is stored in the Input pane in Petrel. See Importing Process, for further details.\\nWhen saving the Petrel project all the imported and generated data is saved to a project file. The\\nnext time the project file is opened all the data is loaded together with the user and graphic\\nsettings at the time of saving.\\nNote: You can find more details about project administration in Project Administration'},\n",
       " {'header': 'Importing Process ',\n",
       "  'content': 'Importing data to Petrel can be done from different locations and the formats available will\\ndepend upon the active pane in Petrel (Input pane, Model pane or Cases pane) and the\\noptions chosen.\\nPetrel differentiates between Import File , which can be found on the File pull-down menu\\nand on the Tool bar, and Import (on selection) , which can be found on the Insert pull-\\ndown menu, on the top tool bar and on the right mouse button menu on folders in the Petrel\\npanes. With Import (on selection) the imported data is inserted directly into the active folder,\\ntherefore only formats which can be held in the active folder will be chosen.\\nFiles can also be selected for import by dragging them from any Windows Explorer window\\n(including the desktop) into any folder in the Input pane in Petrel.\\nIt is always a good idea to organize the input data at an early stage. It will make it easier to\\ncategorize the different data types as the project progresses. With the Petrel panes, folders and\\nsub-folders can be created using the same principles as in the Windows Explorer.\\nA list of specific formats related to the type of import data is listed here: Available formats when\\nusing import on selection\\nA list of all supported formats is also available by selecting List of available formats from\\nthe Help menu in Petrel.\\nHow to import data\\nThis is a general way of importing data into Petrel. The exceptions are all types of simulation data,\\ngrids, properties and well data, including well tops.\\n1. Click on Insert new folder - a new folder will appear in your Input pane in Petrel.\\n2. Rename the folder directly or double-click on the New folder and the Settings window for\\nNew folder will appear. Rename the folder in the Info tab by typing an appropriate name\\nand press OK.\\n3. Click with the right mouse button on the new folder and select Import (on selection)...\\nfrom the context menu.\\n4. Define the file format and select file(s) to import, click Open. An Input dialog will pop up\\nwhere you can define different optional settings and check the range of the data. To select\\nmore than one file, press and hold Ctrl while selecting.\\n5. When the first folder contains all necessary data for that category, make a new folder and\\nrepeat the process for the next data type.\\nFigure 1. The Petrel import dialog.\\n5.\\nChanging units when importing data\\n1. Run through the importing process as described above.\\n2. In the Input Data Dialog, specify the type of conversion in the pull-down menus for\\nInput unit XY and/or Input unit Z conversion.\\n3.\\n1.\\n2.\\n3. Press OK\\nX, Y, Z units can only be converted on import.\\nAvailable formats when using import on\\nselection\\nWhen using Import (on selection) , the list of formats available in the import dialog is\\ndependant upon which folder is active in the panes in Petrel.\\nGeneral folder active: All formats for points, lines, gridded surfaces, bitmaps and seismic\\ndata will be listed. Well data including Well Tops are NOT listed. Well data can only be imported\\ninto defined folders for Wells or Well Tops\\nGlobal completions folder active: Well event data and well tubing data are available for\\nselection.\\nGlobal observed data folder active: Only well observed data are listed.\\nWell attributes folder active: Only Petrel format (BINARY) is listed.\\nWell Tops folder active: Only the Petrel formats for Well Tops are available for selection,\\nPetrel well tops (ASCII) and Petrel format (BINARY).\\nRock physics functions active: Both SCAL and ROCK keywords format are listed.\\nFluids folder active: Only the ECLIPSE fluid model format is listed.\\nSeismic Survey folder active: Only the formats for seismic are available for selection (like\\nseismic data in SEG-Y, ZGY bricked format, Stacking velocity (ASCII) etc.).\\nModels pane in Petrel is active: Formats associated with the Fault model and grid will be\\navailable for selection.\\nCases pane in Petrel is active: Formats associated with simulation data will be available for\\nselection.\\nA list of all available formats in Petrel:\\nIn the importing process the user can change the units of the data in the file. The units for the Z-\\nvalues can be changed separately from the X/Y-values. The available options are:\\nDepth: Meter (m) to Feet (ft), Feet (ft) to Meter (m)\\nTime: Seconds (s) to Seconds 10-3 (ms), Seconds 10-3 (ms) to Second (s)\\nThe project units are stated in brackets in the import dialog above the unit selection boxes.\\nData types\\nThe following data types can be used in Petrel:\\nLine data (XYZ data). Examples: Interpreted seismic lines, digitized contours, fault polygons,\\nfault sticks, area of interest polygons.\\nPoint data (XYZ data). Examples: well tops, points from seismic interpretation, point clusters\\ndefining faults, isochore points, points with attributes.\\nFunctions. E.g. Lookup curves.\\nBitmaps. Formats supported are BMP, JPG, GIF, PNG and TIFF.\\nGridded surfaces (2D maps). Examples: regular surfaces from standard mapping systems,\\nfault surfaces, property maps.\\nWell trajectories with logs. Example: XYZ points along a well trajectory with associated\\ndeviation survey (e.g. LAS 2.0 CWLS LOG ASCII), Irap RMS well data.\\nProduction data. Perforation intervals with properties, e.g. cumulative oil and gas values.\\n3D seismic volumes in SEG-Y format and ZGY format.\\n2D seismic lines in SEG-Y format.\\nFault Models. Petrel fault model.\\n3D grids with or without properties. Example: flow simulation grids generated outside Petrel,\\ne.g. ECLIPSE.\\nProperties. Example: Gslib, VIP, ECLIPSE, CMG.\\nStreamlines. Example: FrontSim, 3DSL\\nPost-processing data. ECLIPSE summary files.\\nSimulation data. ECLIPSE and FrontSim data and results, Petrel summary data, VIP summary.\\nA detailed description of formats supported can be found in Appendix 1 - Formats.\\nImport well data\\nPetrel handles two types of well data: well tops (points), see Make/Edit Well Tops, and well\\ntrajectories with or without logs. When importing well data in the supported well formats, Petrel\\nautomatically saves the data in appropriate folders and sub-folders in the panes in Petrel. The\\ngeneral workflow for importing well data into Petrel is:\\n1. Import of well heads\\n2. Insert well path/deviation data\\n3. Add logs to the wells\\nFor more details on these steps, see Well import\\nThis system ensures flexibility and accuracy in the import. The procedure allows for multiple well\\nimports, easy update of previously imported wells, and the option to further organize the\\nimported wells in sub folders.\\nWell trace and well logs are stored independently, which allows logs with different sampling\\nintervals to be attached to the same well trace. This may have an effect when using the\\ncalculator.\\nThe supported formats for well trajectory data and/or logs are:\\nWell heads from spreadsheet.\\nDeviation data from spreadsheet.\\nIRAP RMS wells trajectories and logs.\\nPetro works SM1 wells trajectories and logs.\\nGeneral ASCII format for well(s) with associated log(s) (simple well & log and multiple wells\\nand logs)\\nProduction and observed data from spreadsheet.\\nBitmap logs (images)\\nCheckshots from ASCII format\\nCompletion logs for wells with associated event and tubing data logs\\nComment logs.\\nInternal Petrel binary format for use in the project model.\\nGlobal Well Logs and Well Log Templates\\nIt is important to organize the well data to keep the project tidy and in order. Well data has a\\ngreat impact on the resulting volume output and should therefore be given special care.\\nEach log type present in a project will be listed in the Global well logs folder in the Petrel\\nInput pane.\\nEach global well log should be attached to the correct template.\\nEach individual log should be attached to the correct global well log.\\nDuring import of well logs, Petrel will try to match logs with previously imported logs (i.e. global\\nwell logs). A log with the same name as that of a global well log is assigned the template of that\\nglobal well log. The user may override the selection and/or change templates and global well logs\\nafter import.\\nIf wells are imported using the IRAP RMS format, the log names will be assigned automatically for\\nthose logs recognized by the program. The rest are imported with a General template. This\\nshould be changed after import to a template representing the type of the well log.\\nFor more information on how Petrel handles well logs and a description of available well log\\ntemplates, see Templates and well logs.\\nHow to edit a well log\\'s name and template\\n1. Open the Global well logs folder (a sub-folder to the Wells folder).\\n2. Rename the global well log (the node) directly or....\\n3. ...double click on the name of the global well log to edit to open the log\\'s settings window.\\nSelect the Info tab and change the log\\'s name and template as appropriate.\\nHow to create a new global well log and attach logs to it\\n1. Right-click on the Global well logs folder and Insert one of the many data types\\navailable (continuous, discrete, comment, combined, and more).\\n2.\\n1.\\n2. Edit the name and template for the global well log as appropriate (see above).\\nHow to set Well Type\\n1. Double-click the well to open the settings for the well.\\n2. Select the Info tab.\\n3. Change the \\'Well symbol\\' for the well from the drop down menu.\\nThe set of symbols to choose from can also be changed. See Well Symbols\\nData structure for well data\\nPetrel offers an easy way of organizing the well data. When working on projects with many wells,\\nit is essential to keep the project tidy. The user can choose to organize the wells in the Wells\\nfolder by\\n1. Creating sub folders. Simply click with the right mouse button on the well folder and select\\n\\'Insert folder\\' from the context menu.\\n2. Use the \\'Saved searches\\' functionality to temporarily sort well data matching a certain criteria\\n(see Saved searches)\\nThe wells can be imported directly into a sub folder or the user can \"drag and drop\" selected wells\\ninto specific folders. To select more than one well, press and hold the Shift key while selecting the\\nwells and drag and drop all in one step. By renaming the sub folders and organizing the wells, the\\nuser can create a structured setup for all wells. In addition, the settings for each sub folder can be\\nset separately.\\nSub-folders and organization can also be performed using the Well Manager.\\nImport well heads\\nThe recommended way to import wells in Petrel is to start with the well heads, then append the\\ndeviation data and finally the well logs.\\nwell head file is simply an ASCII file containing well header information organized in columns\\n(attributes). By default Petrel will expect 6 columns of information in the well header file,\\nhowever, the user may add as many additional custom attributes as required. A new date\\nattribute can be specified according to the format of the computers regional settings or in any\\ncustom format.\\nOnce the well header information has been imported into Petrel, they are stored in a Well\\nattributes folder under the main Wells folder. There are 15 default system attributes available in\\nthe attribute list:\\nName - the well name - required (must be unique) (string attribute)\\nUWI - the unique well identifier - optional (string attribute)\\nWell symbol - label for the well type - optional (discrete attribute)Surface X coordinate - the\\nX location (in project units) of the well at the well head - required (continuous attribute)\\nSurface Y coordinate - the Y location (in project units) of the well at the well head - required\\n(continuous attribute)\\nKelly Bushing (KB) value - the Z value (in project units) of the Kelly Bushing - required\\n(continuous attribute)\\nTD (TVD) - the vertical depth value (in project units) of the last point in the well - required\\n(continuous attribute)\\nTD (MD) - the measured depth value (in project units) of the last point in the well - required\\n(continuous attribute)\\nTop depth (MD) - optional.\\nBottom depth (MD) - optional.\\nMax INC - the value of the highest inclination from vertical (in project units) in the well path\\n- optional (continuous attribute). This attribute is calculated in Petrel and is a useful\\nattribute for distinguishing among vertical, inclined and horizontal wells.\\nCost - the cost of the well - optional (string attribute).\\nSpud date - the date the well was spudded - optional (date attribute)\\nOperator - the name of the organization operating the well - optional (string attribute)\\nSimulation name\\nZ - depth value\\nTWT auto - time value\\nUser - user defined well attribute - optional (any type of attribute)\\nIf information on the well trace is absent (e.g. only coordinates and KB is available) the user could\\ndefine a TD (Total depth) attribute . The program will then draw the well trace vertically within\\nthe depth interval specified. See Well Heads (*.*) format for an example.\\nPlease note that symbol names should be written as ONE word in the well head file, i.e. remove\\nall empty spaces. The word may contain extra commas, underscores, etc. Each symbol name can\\nbe represented by its corresponding number (see list) instead of the name.\\nUnits in the file can be converted at import.\\nA list of well symbols that Petrel recognizes:\\nThe set of symbols to choose from can also be changed. See Well Symbols\\nCreate new well\\nUse the Insert | New well folder from the main menu if there is no well folder present in the\\nproject. Then from the same Insert menu a new well can be created. A new well can also be\\ncreated by clicking with the right mouse button on the Wells folder or a sub folder inside the well\\nfolder, and select New well from the pull down menu. . If the new well is not placed in the\\ncorrect well folder, use \"drag and drop\" to place the well in the correct sub folder.\\nWhen creating a new well a dialog will appear asking for name, coordinates, KB value and well\\nsymbol. Trace and length of trace (vertical) may be defined. The input figures may be converted\\nto project units if different. Enter desired information and click OK. These specifications may be\\nchanged later from the Settings window of the well or by using the Well Manager tool.\\nHow to import a well head file\\nFor more info on the steps in the import procedure, see Well data are imported in three steps:\\nThe import dialog for well header files allows the import of an unrestricted amount of attributes\\nfor each well (see ). Attributes can be of several types including string, continuous, discrete and\\ndate.\\nGo to the File pull down menu and select Import file , or right-click the Wells folder and\\nselect Import (on selection)... from the context menu.\\n1. Select \\'Well Heads (*.*)\\' as files of type.\\n2. Select the file to import and click Open.\\n3. The import dialog opens. A sample of the import file will be shown at the bottom of the\\ndialog.\\n4. Define which columns that correspond to what information in the file.\\n5. Enter the number of header files (if any) and set the value for undefined value (default is -\\n999).\\n6. Click OK.\\n5.\\n6.\\nThe well header information can be found individually for each well by viewing the settings for the\\nwell or by using the Well Manager tool.\\nImport well path deviation\\nImport of well path/deviation data is the second step in the well import process. To learn the\\nstandard import steps, see Well import\\nThe deviation file can be imported well by well, for several wells together or for multiple wells in\\none file. If multiple wells are included in a single file there are a series of options for determining\\nhow the settings for different wells are distinguished, see Multiple Well Log Formatsfor details.\\nNote that a deviation file can be loaded before or after the logs have been loaded. The\\ndeviation file may also be exchanged for another one - just load a new deviation file and it will\\nreplace the old one.\\nThe deviation file should be in ASCII format with the data organized in columns. Data can be of\\nseveral types:\\nMeasured depth, inclination, azimuth\\nTrue vertical depth, X-offset, Y-offset (MD optional)\\nTrue vertical depth, X, Y (MD optional)\\nX, Y, Z (MD optional)\\nAngles can be Deg or Rad, azimuth (in degrees) should be between -360 and 360, inclination (in\\ndegrees) between 0 and 90, 0 being vertical, 90 horizontal.\\nDeviation files with data listed in the reversed order are auto-detected and reversed in the import\\nprocess. The detection is based on that the first MD value in a reversed file is greater than the\\nlast. See Well Path/Deviation (formats) for an example.\\nWell Import in Petrel (vs GeoFrame)\\nIf the well is imported using MD, dip and azimuth then the resulting well path (XYZ) is calculated\\nusing the same method as that used in GeoFrame and the well should be in the same place. The\\nonly remaining issue is that with no coordinate system in Petrel, scale factors are ignored and this\\ncan result in discrepancies when going from true meters in measured depth to meters in XY in the\\nproject space.\\nIf the well is imported in X, Y, Z or dX, dY, Z then dip azimuth and most importantly MD\\n(assuming MD is not given) must be calculated using a minimum curvature model from the initial\\npoints. This problem has non unique solutions so errors may occur in this case irrespective of how\\ngood the data is. It is recommended that MD is always included in the file if available.\\nWhen MD is not available, the result is sensitive to the initial direction of the well before the first\\npoint. This is varied and the minimum curvature method used to model the well path and match it\\nto the available data. If a solution is not found then a linear interpolation is used and this fact will\\nbe documented in the statistics page of the well. In most cases (all \\'sensible\\' cases) a solution will\\nbe found. If a solution is found, then exporting the well trace and re-importing it using any of the\\ninterpolation mechanisms will give the same result.\\nImporting onshore or offshore wells\\nIn Petrel all coordinate values below sea level are negative and coordinate values above sea level\\nare positive. To make sure the well files are imported correctly, the user has to specify whether\\nthe wells are onshore or offshore:\\nIf a well is offshore but the vertical coordinates are positive, then Petrel will multiply them\\nall by -1. If the well is onshore, then they will be left as they are.\\nIf the well has most of its vertical well path onshore, then it is an onshore well, even if the\\nreservoir is below sea level.\\nIf you are uncertain whether the well is onshore or offshore, you should import it as an\\nonshore well. This option will usually always work. However, do use the offshore option if you\\nknow you are working with offshore wells because this option allows for more checks of the data\\nwhen they are imported.\\nImport settings for deviation files\\nBecause there are several types of deviation files, the file imported needs to be specified. There\\nare four tabs in the import dialog with various settings. The hints tab contains some general\\ninformation.\\nInput Data tab\\nWhen importing files with MD or TVD, the user should specify a reference level (Kelly Bushing,\\nMean Sea Level or other).\\nIf the lines in the file are wrapped, this should be specified also, defining how many columns\\n(tokens per line) there are per measurement point.\\nSettings tab\\nExtend well trace: To extend the well trace, an option to \\'Add top\\' and \\'Add bottom\\' point\\nis given. It will add length in project units (positive number) following the tangents at the\\nend points.\\nWell tops: Ther eis a default option to move well tops and well top attributes with the well\\nas it is shifted up or down.\\nOther: When there are no MD values present in the input file, the option Curved trace\\nabove MD can be checked and a measured depth value at first point can be added.\\nUnits tab\\nUnits: If the units in the import file are different from the project units, this must be\\nspecified at import (required to calculate the trace properties).\\nOther: If MD, azimuth and inclination are used as input, select degrees or radians in this\\ntab.\\nHow to import deviation data for one well\\n1. Click with the right mouse button on the well to be deviated to open the pull-down menu.\\n2. Select Import (on selection). The import dialog will appear.\\n3. Select Well path/deviation ASCII (*.*) as files of type.\\n4. Select the deviation survey file. Click Open. The import dialog will pop up.\\n5. Specify the settings for the deviation file and click OK.\\nNote that the import window is resizable for easier overview of the input file.\\nFigure 1. The deviation survey import dialog.\\nHow to import deviation data for multiple wells\\nTo be able to apply deviation for several wells in one go, each deviation file should have the same\\nname as the well it is related to. The program will try to match the name of the import file with a\\nwell present in the well folder and present a suggestion of matching pairs in the import dialog.\\nThat way the user can make sure that each well is matched with its correct deviation file and\\ncorrect if a mismatch has occurred.\\n1. Click with the right mouse button on the Wells folder or on a sub folder to open the pull-\\ndown menu.\\n2. Select \\'Import (on selection)\\'. The import dialog will appear.\\n3. Select Well path/deviation (ASCII) (*.*) as files of type.\\n4. Select the deviation survey files. Click Open. The import dialog will pop up.\\n5. Make sure that the wells are correctly matched with their deviation file - edit if necessary.\\n6.\\n3.\\n4.\\n5.\\n6. Specify the settings for the deviation file and click OK (or OK for all if all the deviation files\\nare identical in appearance).\\nNote that the import window is resizable for easier overview of the input file.\\nHow to import multiple deviation survey wells from one file\\nTo import several well deviation surveys from one file, the name for each deviation data segment\\nin the file should have the same name as the well it is related to. Petrel will try to match the name\\nof the data segment in the file with a well present in the well folder.\\n1. Click with the right mouse button on the Wells folder or on a sub folder to open the pull-\\ndown menu.\\n2. Select \\'Import (on selection)\\'. The import dialog will appear.\\n3. Select Multiple well paths/deviations (ASCII) (*.*) as files of type.\\n4. Select the multiple well deviation survey file. Click Open. The import dialog will pop up.\\n5. Make sure that the wells are correctly matched with the deviation file names - edit if\\nnecessary.\\nFor more info, see Multiple Well Log Formats\\nHow to import branches/side tracks\\nTo import branches from a main log, the file names must be recognized as P%B (where P is the\\nparent well and B is the branch).\\n1. Click with the right mouse button on the Wells folder or on a sub folder to open the pull-\\ndown menu.\\n2. Select \\'Import (on selection)\\'. The import dialog will appear.\\n3. Select Well path/deviation or Multiple well paths/deviations (ASCII) (*.*) as files of type.\\n4. Select the appropriate files. Click Open. The import dialog will pop up.\\n5. Make sure that the wells are correctly matched with the deviation file names - and that the\\n% naming is correct.\\nNote: If a branch well name is detected, Petrel will assign a parent-branch relationship only\\nif there is a physical intersection point between the two traces.\\nImport logs\\nWhen the well has been imported with the well head data and deviation survey, it is ready for\\nimport of well logs. Well logs in ASCII format require that the logs are listed in columns in the\\nASCII file with a space or tab delimitation. The input log file may have a header - the number of\\nheader lines will be detected automatically. The log file can be imported well by well, for several\\nwells together or for multiple wells in one file.\\nNote that logs can be loaded at any time and added to well with previous logs. Logs on the\\nsame well trace can have different sampling interval.\\nLog files with data listed in reverse order are auto-detected and reversed in the import\\nprocess. The detection is based on the first MD value in a reversed file being greater than\\nthe last.\\nLog files for several wells can be imported simultaneously. The user will then be asked at\\nimport whether the log files and well heads have been correctly matched and make\\nadjustments if needed.\\nIf the logs are imported from a LAS 2.0 file, the import file is scanned and the program tries\\nto determine which logs are present by checking the header. Standard LAS log names will\\nbe recognized.\\nLogs recognized and that already exist in the Global well logs folder will automatically be\\nassigned the correct template (although the user may override the selection).\\nLog import settings\\nThe import dialog for well logs has four tabs: Input data, Settings, Units and Hints. The Hints tab\\nshows general import information.\\nInput data\\nThe user must specify data type at import. Most commonly, the logs are stored together with\\nmeasured depth and this is the default option. If a well has been imported with its trace\\n(deviation data), and logs are imported together with X and Y information, the X and Y\\ncoordinated must match, otherwise the program will give an error message.\\nThe well trace must be defined before importing logs using X and Y information. If the match\\nis close but not perfect, the log value will be projected to the closest point on the already existing\\nwell trace. This could potentially be a source for errors in the log data imported - please be careful\\nwhen using this option!\\nData type: Select data type and columns where data types are found (see file capture at bottom\\nof dialog).\\nLogs that are not recognized will be given a general line in the spreadsheet. The user must then\\nspecify name and select template or global well log.\\nLogs: Petrel will try to autodetect the well logs in the import dialog, but this can be overridden by\\nthe user by selecting the Specify logs to be loaded. Logs with recognized names are listed by\\nname. If a recognized log exists as a global well log, it is automatically connected to that global\\nwell log. The template is then defined and cannot be changed as long as the log is connected to a\\nglobal well log. To be able to change the template, the global well log must be redefined to\\nCreate New - select from the pull down menu in the Global well logs column.\\nIt is important to check that the logs are related to the correct column number of the input file.\\nUse the file capture at the bottom of teh input dialog to identify the correct column for each log. A\\nselection of the logs present in the input file can be imported, add and remove logs manually by\\nusing the icons and above the log list.\\nPetrel offers to auto detect the specified logs when the user press the Force table fill button,\\nand will insert suggested names and templates to the logs. It is important to review the\\nsuggestion that Petrel makes before accepting them and continuing with the import.\\nNote that the import\\nwindow is resizable for easier overview of the input file.'},\n",
       " {'header': 'Settings ',\n",
       "  'content': 'The user should specify the Elevation reference - choose between Kelly Bushing, Mean Sea\\nLevel and Other.\\nCheck the Wrapping option if the lines of the input file have wrapped lines. By default this option\\nis set to be auto detected by Petrel, but the user may manually specify the number of logs in the\\nfile.\\nOther settings allows the user to specify undefined log values, to select whether to add to or\\noverwrite a previously imported log, and to select if the logs imported should be treated as a\\ncontinuous curve.'},\n",
       " {'header': 'Units ',\n",
       "  'content': 'If you have correctly configured license access, Petrel will open the Package Selection window. If\\nyou place the cursor over one of the elements of this window, a description will pop up to help\\nyou. The license packages available to the user on the selected license server(s) are listed on the\\nleft side of the window, while the modules available within this predefined package of modules are\\nlisted on the right. Click on the Package name in this list and click OK to proceed with starting up\\nPetrel. In the bottom of the Import ECLIPSE / FrontSim run dialog you can specify some\\nimport settings. The option Automate handling of import settings will let Petrel automatically\\nchoose the suitable import settings for the selected import files. The coordinate system settings\\nare based on the presence of the MAPAXES keyword and the grid geometry is automatically\\nconverted to the project unit system. Furthermore, unknown keywords are logged in the log\\nwindow and faults are auto detected. To manually control the import settings, turn off the\\ncheckbox in front of the option and click on the Advanced... button.If the units in the import file\\nare different from the project units, this must be specified at import (required to calculate the\\ntrace properties).\\nHow to import logs for a single well\\n1. Click with the right mouse button on the well - select Import (on selection) from the\\ncontext menu.\\n2. Select Well logs (ASCII ) ( *.*) as files of type.\\n3. Select the correct file and click Open. An import dialog will pop up.\\n4. Specify the settings in the import dialog.\\n5. Click OK.\\nHow to import well logs for several wells\\n1. Click with the right mouse button on the Wells folder or on a sub folder - select Import\\n(on selection) from the context menu.\\n2.\\n3.\\n1.\\n2. Select Well logs (ASCII ) ( *.*) as files of type.\\n3. Select the correct files and click Open. A match file name and well dialog will pop up.\\n4. Check that the well trace matching with File name is correct. Edit from pull-down menu if\\nnecessary.\\n5. Click OK. The import dialog will pop up.\\n6. Specify the settings in the import dialog.\\n7. Click OK or OK for all (if the setup is the same for all files).\\nNote that if OK for all is selected, the program will assume that all the files have identical\\nlayout, e.g. same number of columns, logs located in the same columns in all files.\\nHow to import several well logs from one multiple\\nwell log file\\n1. Click with the right mouse button on the Wells folder or on a sub folder - select Import\\n(on selection) from the context menu.\\n2. Select Multiple Well logs (ASCII ) ( *.*) as files of type.\\n3. Select the correct files and click Open. The import dialog will pop up.\\n4. Check that the well log names in the file match with the actual log names and edit if\\nnecessary.\\n5. Click OK or OK for all.\\nImport bitmap logs\\nBitmaps representing core photos or scanned copies of log data can be imported and attached to\\nwells.\\nBitmaps may be in BMP, JPG, TIFF, GIF or PNG format. Once the images are selected, specify the\\nwell, the start and stop MD for the image and the order of the images, if several images are to be\\nimported to the same well.\\nThere is an option to Autogenerate depth values, this may be useful if you have e.g. core\\nimages which have the same length, and are in descending order. Typing in a value and pressing\\nAutogenerate, will make subsequent depth values with the specified increment.\\nImport IRAP RMS wells\\nPetrel directly imports wells in this format, without the need for dialog settings. Petrel assigns a\\ngeneral template (to all continuous logs and to all discrete logs) to well logs imported in RMS\\nformat. It is strongly recommended to attach each log to the correct global well log. See Irap RMS\\nwell (ASCII)(*.*) for a description of the format. If all wells are imported as RMS wells, global well\\nlogs will have to be defined, see Global Well Logs and Well Log Templates for details.\\nImport Petro Works Stratamodel (SM) 1 Well\\nfiles\\nAs for Irap RMS well files, Petrel directly imports wells in this format, without the need for dialog\\nsettings. Petrel assigns a general template ( to all continuous logs and to all discrete logs) to\\nwell logs imported in Petro Works Stratamodel 1 format. It is strongly recommended to attach\\neach log to the correct global well log. see Global Well Logs and Well Log Templates for details.\\nImport production and completion data\\nIn addition to the well logs files, it is also possible to import production data into Petrel. The well\\ntrajectory for the production data has to be imported first. Production data must be organized in a\\nspreadsheet with well names and production data. See Formats for well data for an example.\\nSee Well observed data file formats for importing observed or historical production data into'},\n",
       " {'header': 'Petrel. ',\n",
       "  'content': \"Production log import settings\\nThe import dialog comprises four tabs: Input data, Settings, Units and Hints. The Hints tab\\ncontains some general information about import steps.\\nNote: Wells must exist prior to importing production logs, and their name must match those\\nfound in the file.\\nFigure 1. The well production data import dialog.\\nInput Data tab\\nWell name column: Define which column in the spreadsheet the well names are located.\\nThe well name in the spreadsheet must match the well name in the Input pane in Petrel.\\nTop perf. interval column (MD): Define in which column the depth for the top\\nperforations are located.\\nBase perf. interval column (MD): Define in which column the depth for the base\\nperforations are located.\\nProduction attributes: In the spreadsheet dialog, specify the name and column of the\\nproduction data. Each log to be read needs to be given a name and be attached to a\\ntemplate and/or global well log. If a log is attached to a global well log, it will automatically\\nbe given the corresponding template. Remove rows for logs that you do not want to import.\\nSettings tab\\nNumber of header lines: Specify number of lines before the data listing starts.\\nUndefined log value: Specify undefined log values.\\nFigure 2. The well production data import dialog - Settings\\nUnits tab\\nIf the units in the import file are different from the project units, this must be specified at import.\\nOffshore/onshore: To ensure that well data is imported in true Z values i.e. values below sea\\nlevel are negative\\nFigure 3. The well production data import dialog - Units\\nHow to import production data\\n1. Make a spreadsheet file for the production data, like the one above, with a column for well\\nname, top and bottom of the perforation intervals and production data. Remember that\\nproduction data can only be imported for well trajectories already imported into Petrel.\\n2. Click on the Wells folder or a sub folder with the right mouse button and select Import\\n(on selection) from the context menu.\\n3. In the Import file dialog, select the production spreadsheet file, and in Files of type select\\nProduction logs.\\n4. Enter the correct information into the import dialog and click OK.\\nImported production data will be placed in the Global well logs folder.\\nImport completion event data\\nLoad your completion event data into Petrel. You can visualize and play trough your completion\\nhistory over time in 3D. You can also synchronize the time player to display production and\\ncompletion data simultaneously over time. For a description of the format see Well production and\\nwell event formats.\\nSee also Timestep player for information regarding playing through the data using the time step\\nplayer. If a time is displayed for which the logs have no data, then the logs may not be visible\\nbefore you have played through them with the timestep player.\\nHow to import Completion Logs\\n1. Right-click on the Wells folder in the Input pane and select Import (on selection)...\\n2. In the import file dialog window that appears, select the file type to be Completion logs\\n(*.*).\\n3. Use the import file dialog window to browse and find the completion log file that you wish to\\nimport.\\n4.\\n3.\\n4. Once the file is selected, click on Open and you will get access to the Completion Log\\ndialog window.\\n1. In the Completion Log dialog window, you can convert the units of measured depth to\\nproject units (change between meter and foot).\\n2. Note that the well names in the Completion Log input file must be in quotes if they contain\\nspaces.\\n3. Click OK if you would like to import one file at a time, or OK For all for importing all files in\\none go.\\nThe Completion logs are stored in the Global well logs folder. They can also be found under\\neach single well in separate well folders.\\nHow to import Well Event Data\\n1. Expand the Wells folder in the Petrel Input pane.\\n2. Right-click on the Global completions folder and select Import (on selection)...\\n3. In the import file dialog window that appears, select the file type that you wish to import.\\nPetrel can import two types of completion logs, Well Event Data (ASCII) (*.ev) and\\nWell Tubing Data (ASCII) (*.tub). For a description of the format see Well production\\nand well event formats.\\n4. Use the import file dialog window to browse and find the completion log file that you wish to\\nimport.\\n5. Once the file is selected, click on Open and you will have access to the Import event data\\ndialog window.\\n5.\\nIn the Wells tab you will have to match the well names that Petrel picks up from the file\\nwith wells that exists in your project. If Petrel cannot make a match the completion log for\\nthat well will be ignored. Click in the yellow field below the Petrel well trace to select a\\nwell from a pull-down menu.\\nIn the Import settings tab, you can specify some import options. You can select to add to\\nor replace existing well events and to let Petrel automatically add casing to all wells with\\nevent. When importing well events, you must specify the date format in the completion log\\nfile so that Petrel can import the well event dates correctly. In the bottom half of the Import\\nevent data window, you will see the completion log file that you are about to import. Use\\nthis to find out how the date is formatted in the file and make sure that Petrel reads in this\\nformat by using the Custom date format options.\\nIn the Unknown data tab of the Import event data window you will see the well events\\nthat Petrel either cannot import or cannot understand. This is useful for quality checking the\\ncompletion log file to check for syntax errors.\\nClick OK to import the files into Petrel.\\nThe completion events are stored in the Global completions folder. They are also found under\\neach single well in separate well folders.\\nHow to import well tubing data\\n1.\\n2.\\n3.\\n1. Expand the Wells folder in the Petrel Input pane.\\n2. Right-click on the Global completions folder and select Import (on selection)...\\n3. In the import file dialog window that appears, select the file type that you wish to import:\\nWell Tubing Data (ASCII) (*.tub). For a description of the format see Well production\\nand well event formats.\\n4. Use the import file dialog window to browse and find the completion log file that you wish to\\nimport.\\n5. Once the file is selected, click on Open and you will get access to the Import tubing data\\ndialog window.\\nIn the Wells tab you will have to match the well names that Petrel picks up from the file\\nwith wells that exist in your project. If Petrel cannot make a match, the tubing data for that\\nwell will be ignored. Click in the yellow field below the Petrel well trace to select a well\\nfrom a pull-down menu.\\nIn the Unknown data tab you will see tubing data that Petrel either cannot import or\\ncannot understand. This is useful for quality checking the completion log file to check for\\nsyntax errors.\\nClick OK to import the files into Petrel.\\nThe tubing data is stored in the Global completions folder, and are also found under each single\\nwell in separate well folders.\\nImport point well data\\nPoint well data is data collected along the well with several attributes at each point, e.g. fracture\\nmeasurements, dip measurements or core data. See Point Well Data for a comparison between\\nthese and standard well logs.\\nWell tops, point well data, checkshots and points with attributes are all imported in the same\\nformat, using the same dialog with a few modifications see Importing point data.\\nWell tops and checkshot data can be imported with one file for each well or with a single file\\nfor all wells. If no column is defined for the well name, then Petrel will assume (says the exact\\nsame thing 2 paragraphs below) that a single file is used for each well and will attempt to guess\\nwhich existing well a file belongs to, based on the file name. The user can override this by typing\\nin a well name. If a column is defined with a well name then these options are grayed out.\\nImport checkshots\\nCheckshots are time/depth pairs for a borehole obtained by analyzing the first seismic arrival for\\nknown depths in the borehole. They are used to obtain a time depth relationship for the borehole\\nand are essential for generating synthetic seismograms.\\nWell tops, point well data, check shots and points with attributes are all imported in the same\\nformat, using the same dialog with a few modifications, see Importing point data.\\nWell tops and checkshot data can be imported with one file for each well or with a single file\\nfor all wells. If no column is defined for the well name, then Petrel will assume that a single file is\\nused for each well and will attempt to guess which existing well a file belongs to, based on the file\\nname. The user can override this by typing in a well name. If Petrel can not guess which well the\\ncheckshot belongs to, the checkshot will be imported but it will not be linked to a well and you\\nneed to link the checkshot manually to a well. This is done in the settings dialog for the well under\\nthe Checkshot wells filter folder. If a column in the import checkshot file is defined as well name\\nthen the option to link a checkshot to a well is grayed out in the import window and Petrel will\\nassign the check shot to the well with identical name in the project.\\nMultiple checkshots objects (one object for each well) can be merged into one object for the\\nease of handling and QC'ing the data.\\nHow to import checkshot to wells\\n1. Right-click on the Wells folder and select Import (on selection)...\\n2. Select the checkshot file(s) and the correct Checkshot format (ASCII) format\\n3. If more than one file is selected, click yes to merge all data into one sheckshots object or\\nno to load each file into separate objects.\\n4. In the import dialog, select the correct amount of attributes to import (quality check\\nagainst header info).\\n5. Select also the correct attributes from the drop-down menu; with corresponding attribute\\nnames, types and units.\\n6. Select Time datum (SRD or CRD). See How are SRD and CRD used in Petrel\\n7. Negate Z and Time values (if not already done in the file).\\n8. Press Ok or Ok for all to import the checkshots. they are now stored under the Global well\\nlogs folder.\\n8.\\nNote: If the Z attribute is used, Depth datum is fixed (grayed out) at MSL. If MD is used, the\\nDepth datum is fixed at KB. If TVD is used, one can select Depth datum from the drop-down\\nmenu (options are MSL, KB, CRD and SRD). Time datums can be chosen as CRD or SRD.\\nHow to merge checkshots data\\nMultiple checkshots objects can be merge into one spreadsheet following this workflow:\\n1. From Insert in the Menu bar, select New checkshots.\\n2. Open settings for the new object found under the Global well logs folder.\\n3. Go to the Operations tab and expand the Common operations folder.\\n4. Select Append points with attributes.\\n5. From the Input pane, select the first checkshots object and drop it in the Points to\\n6.\\n7.\\n3.\\n4.\\n5.\\nappend field using the blue arrow.\\n6. Subsequently, select the remaining objcts and follow the same procedure to merge all data.\\n7. As a last step, using the Remove duplicate points operation will make sure the new\\ncheckshots object is consistent.\\nNote: If the Z attribute is used, Depth datum is fixed (grayed out) at MSL. If MD is used, the\\nDepth datum is fixed at KB. If TVD is used, one can select Depth datum from the drop-down\\nmenu (options are MSL, KB, CRD and SRD). Time datums can be chosen as CRD or SRD.\\nHow to share checkshot to a well\\nIf the checkshot file does not contain a column with the well name or if the user does not specify\\nto link a checkshot to a well trace during import the checkshot will be imported to Petrel but it will\\nnot be linked to a well. Before the check shot can be used, you need to tell Petrel which well the\\ncheckshot belongs to.\\n1. Open the Checkshot folder located under the Global well logs folder.\\n2. Expand the Well filter folder and identify the well that is not in the well filter list. This\\nwell does not have checkshots assigned to its well path.\\n3. To link the checkshot to the well, open the settings dialog for the well by double clicking on\\nit in the Petrel Input pane.\\n4. Go to the Time tab and click in the Override global settings checkbox.\\n5. Click on the Shared checkshot checkbox and find the well from the Well filter list under\\nthe check shot folder in the Global well logs folder. Use the blue arrow to drop this well\\nin the dialog and to use the checkshots from this well.\\n6. Press the Run button to confirm the new Time/Depth relationship.\\n6.\\nImport well tops\\nWell tops are markers that define the intersection bewteen a well and a horizon or a fault. They\\nare interpreted or created in Petrel. alternatively they can be imported into Petrel based on the\\nfunction of their position (X, Y, Z coordinates), their name and the well they belong to. In\\naddition, they can contain other information, such as the Interpreter's name, measured depth,\\ntime values, average properties for a zone, etc. Wells are also assigned to one of several types,\\nhorizon, fault etc. (see Make/edit well tops for more information about types).\\nWell Tops have a pre-defined folder. The reason for this is that Well Tops are both stored as\\nbelonging to a type e.g. a horizon or a fault and also stored depending on which well the point\\nbelongs to. If one doesn't exist in your project, insert it using Insert | New well tops\\nWell tops, point well data, check shots and points with attributes are all imported in the same\\nformat, using the same dialog with a few modifications see Importing point data.\\nWell tops and checkshot data can be imported with one file for each well or with a single file\\nfor all wells. If no column is defined as holding the well name, then Petrel will assume that a\\nsingle file is used for each well and will attempt to guess which existing well a file belongs to,\\nbased on the file name. The user can override this by typing in a well name. If a column is defined\\nas well name then these options are grayed out.\\nWell Manager after import\\nAfter import, the wells contain a lot of information from the well attributes, imported logs etc.The\\nwell manager is a tool that collects all the information associated with each wellbore and presents\\nit in a spreadsheet format.\\nSee The well manager for more information.\\nHow to use the Well Manager tool\\n1. Right click on the Wells folder and select View well manager from the context menu.\\n2. The dialog will display all wells in the project, one row for each well, with all attributes. Use\\nthe toolbar at the top and bottom to edit, filter and handle well attribute information.\\n3. For project with a large number of wells it can be advantageous to use the Folder filter\\ndrop-down option at the top of the dialog to filter the well manager tool to only show wells\\nbelonging to a sub-folder in your project.\\n4. Alternatively, you can use an active Saved searches to limit the wells in view to a\\npredefined search criteria (see Saved searches).\\n5. To restrict the number of attributes to see for the wells use the Show button and select\\nwhich attributes to view from the drop-down menu. The options are:\\nDefault attributes\\nUser attributes\\nCheck shots\\nWell log\\nWell completions\\n6. Double click on a column header to sort the column ascending or descending.\\n7. You may only edit on the fields that has a white background, using either a drop-down\\nmenu or manual input.\\n8. In order to edit the Surface X / Y values, the Kelly Bushing (KB), and the TD\\nMeasured Depth by selecting to edit them from the Edit points button at the bottom left\\ncorner of the Well manager dialog.\\n9. Select a well by clicking on the index number in front of the well. This will select the entire\\nrow. The toolbar buttons at the top of the well manager dialog have the following actions:\\nShow settings - open the well settings for the selected well.\\nFind item in the well manager - opens a find dialog that can be used to search\\nin the well manager tool.\\nTurn on the selected well in the current window - will turn on the well in the\\ncurrent window.\\nTurn off the selected well in the current window - will turn off the well from\\ndisplay in the current window.\\nToggle visible of the selected well in the current window - will turn the well\\non or off from display in the current window.\\nDelete the selected well - will delete the selected well from the project.\\nMove to folder - will move selected well(s) to a sub-folder. A pop-up dialog will list\\nthe sub-folder under the main Wells folder. This will also allow you to create a new\\nsub-folder.\\nFolder filter - filter the wells shown in the spreadsheet by any sub-folders under\"},\n",
       " {'header': 'Wells. ',\n",
       "  'content': 'Show - drop-down menu where one can select which columns (attributes) to display\\nin the spreadsheet. The options are: Default attributes, User attributes, Check shots,\\nWell logs, Well completions\\nFilter well based on active search - will filter the well spreadsheet on the basis\\nof an active Saved search.\\nHelp - will display a popup with help information for using the well manager.\\nScroll to top - quick shortcut to scroll to top of a long list of wells in the\\nspreadsheet.\\nScroll to bottom - quick shortcut to scroll to bottom of a long list of wells in the\\nspreadsheet.\\n10. The toolbar buttons at the bottom of the well manager dialog have the following actions:\\nEdit points - displays a drop-down menu where one can activate fields to be edited.\\nThe options are Edit Surface X/Y, Edit KB, Edit TD (MD).\\nMove well tops, checkshots and trace to new position - ensures that well tops,\\ncheckshots and well trace are moved to the new position of the well if changed by the\\nuser.\\nMove logs and completions - ensures that the well logs and completions are\\nmoved to the new well trace position.\\n11. Apply - applies the changes made in the spreadsheet without closing the dialog.\\n12. OK - applies the changes made in the spreadsheet and closes the dialog.\\n13. Cancel - cancels any changes made and closes the dialog.\\nSaved searches after import\\nSaved searches will allow the user to display/access/filter wells based on specified search criteria.\\nThis will help in organizing well data into different place holders without the need to duplicate\\ndata.\\nSeveral types of search criteria can be applied. Each search can be used in isolation or in\\ncombination with other searches.\\nSaved searches are applied using one of the search criteria available. Once saved, the searches\\nare stored in the Saved searches folder under the Wells folder.\\nIt is possible to use the saved searches directly in Petrel processes and calculators. For example,\\nyou can set a saved search that you want to use in the Scale up well logs process for a desired\\nproperty. When the search is applied in the Petrel Input pane, the filtered list will be shown in the\\nScale up well logs process dialog window. Only the wells meeting the search criteria will then be\\nused in processing.\\nFor more detailed information, see Saved searches\\nHow to create saved searches\\n1. Right click on the Saved searches folder and select New search from the context menu.\\n2. In the dialog that opens you can add the search criteria to apply for the saved search. The\\nfollowing search criteria can be selected:\\nMatch primary well identifier: searches for wells that meet the preferred name\\ncriteria specified\\nWell log data: searches for all wells that have the logs or completions specified.\\nWell attributes: searches for all wells that have the attributes within the range\\nspecified. Several attribute filters can be specified in the same search.\\nUser specified list: use this search for custom lists. It is possible to generate the\\nsearch from wells displayed in the active view.\\nWell tops: uses the well top Stratigraphy\\nWithin boundary: searches for wells whose trace lies with a specified polygon or\\npolygon set\\n3. Press Apply to store the search. To make the search work, simply toggle it on under the\\nSaved search folder.\\nHow to update/combine saved searches\\nThere are several ways in which the search can be updated. In the settings dialog for Saved\\nsearch, the following options are available and are applied to all the saved searches defined:\\nApply search to:\\nTree: applies the searches to the Petrel Input pane only (views are not updated with search\\ncriteria). It is not possible to synchronize the views if this option is selected.\\nActive window (or All windows): applies the search(es) to the Petrel Input pane and the\\nactive viewer (or all viewers). When wells are displayed in the active window and a search is\\napplied, all wells not meeting the search criteria are removed from view. The Petrel Input\\npane removes all wells not meeting the criteria but does not turn on automatically the wells\\nmeeting the search criteria. It is always possible to show only the wells that meet the\\nsearch criteria by selecting the Synchronize view check box. Note that in situations where\\nwindows have been applied with a visual link to another window, this setting will take\\nprecedence over the saved searches.\\nMultiple searches:\\nAND: If this is toggled only one search will work at any given time.\\nOR: If this is toggled two searched will work together.\\nNOT: If more than one search is toggled, only the topmost search will work (highest\\npriority). To change priority, move searches to the top of the folder (drag-and-drop).\\nImport Lines and Points\\nPetrel supports various formats for line and point data and, in addition, has a general reader that,\\nwith some user-defined settings, can import any ASCII data set.\\nIRAP classic lines, ASCII\\nIRAP classic lines, BINARY\\nIRAP classic points, ASCII\\nZmap+ lines, ASCII\\nZmap+ fault traces, ASCII\\nCPS-3 lines, ASCII\\nCharisma lines, ASCII\\nCharisma fault sticks, ASCII\\nSeisworks fault sticks, ASCII\\nSeisworks horizon picks, ASCII\\nIESX 2D/3D seismic lines\\nIESX fault polygons\\nIESX fault sticks\\nKingdom 2D/3D seismic lines\\nKingdom fault sticks\\nGeneral reader for XYZ data for lines and points, ASCII\\nLine data\\nimported into Petrel can, for example, be seismic interpretations, fault polygons, fault lines,\\ncontour data or cultural data, like block and license boundaries.\\nPoint data\\nimported into Petrel will normally be various point data from Wells, but can also be e.g. points\\nrepresenting the nodes in a grid. For the best use of Petrel we recommend that formation\\ntops and fault points be imported into Petrel as Well Tops, see Make/Edit well tops.\\nNote that Line data in Petrel is treated as points with a line through. Therefore, points can\\nbe converted directly to lines and vice versa.\\nHow to import Lines and/or Points\\nCreate a folder for the data to import in the Input pane, by clicking on Insert new folder in\\nthe Toolbar.\\n1. Rename the new folder by typing an appropriate name and press OK.\\n2. Click with the right mouse button on the new folder and select Import (on selection).\\n3. In the Import file dialog, browse to the correct folder and select your file. When the\\ncorrect file type is set in Files of type (e.g. here: Zmap+ lines (ASCII). click Open.\\n4. More than one file can be selected at a time as long as the files have the same format. To\\nselect more than one file, press Ctrl while selecting.\\n5. An Input data dialog will pop up where you can rename the file (and in the below case\\nset the Template (time or depth) and the data type (Line type) of the file. The z-value\\nrange of the file will be listed and should be checked.\\n6. If some settings are changed and the OK for all option is used, these settings will be saved\\n6.\\nfor all the files. If Petrel does not recognize the format of the data file, e.g. if the wrong\\nformat has been chosen, an error message will pop up when importing the file.\\nFigure 1. The input data dialog.\\nIt is important to know the format of the data to be able to use the defined formats. If the\\nformat of lines or points is not known, the files can be compared with the format examples in\\nAppendix 1 - Formats. For formats not supported by Petrel, the General data reader for lines and\\npoints can be used to import the data, as long as the data are in ASCII format.\\nGeneral lines/points reader - Settings\\nThe General data reader for lines and points gives the possibility to import lines and points into\\nPetrel on a general ASCII format. In the dialog for the general reader the first 30 lines of the file\\nare viewed and number of header lines and the columns for X, Y and Z must be specified. It might\\nbe useful to view more than the first 30 lines of the file e.g. to find flag values, in that case it is\\nrecommended to open the file in an editor, e.g. Notepad or Word Pad.\\nIn the dialog these settings must be specified:\\nNumber of header lines\\nNumber of lines before the data listing starts.\\nNewline value\\nThis is a value that normally indicates a new line or a new cluster of points. The number will\\nbe the same for X, Y and Z. The number -999 is usually used. If there is no flag value in the\\nfile, use 0. If a flag value is present without being specified, Petrel cannot distinguish between\\nthis value and real values.\\nUndefined Z-value\\nThis value indicates that a data point is not of real value. This is normally a very large\\nnumber, e.g. 1.0E10. If no undefined value is present, use 0.\\nRead as\\nSpecify whether the file should be read as lines or points. If the file is read as lines then all\\npoints between flag values will be connected.\\nX-, Y- and Z-value column\\nIndicates which column in the file the X-, Y- and Z- values are listed. For the Z-value three\\nsettings can be selected. If no Z-values are present, Petrel will set all Z-values to 0. If some\\nZ-values are present, Petrel will set the missing Z-values to 0.\\nHow to use the General lines/points reader\\n.To export horizons from a 3D grid created in Petrel, they can be converted to a surface using the\\ni, j grid of the Horizon. To export IsoChore maps in Petrel, they first have to be made from the\\nzones created in the 3D grid.\\nFaults can be converted to polygons, which are sorted by fault or by horizon. To make fault\\npolygons sorted per fault, the conversion is done from the Fault folder. To make fault polygons\\nsorted per horizon, the conversion is initiated from the Fault filter folder. To export faults from a\\n3D grid as fault surfaces they first have to be converted to regular 2D grids.\\nNote that the default settings may be overwritten so that the user is always free to choose\\nexactly what to export. Also note that the name of a fault is restricted to 8 characters in ECLIPSE.\\nTo export horizons from a 3D grid created in Petrel, they can be converted to a surface with a\\nregular grid (x,y). The available setting for importing in GSLIB properties format is:\\nUndefined property value\\nSpecifies the number used as undefined property value.\\nOpen the Import dialog, by selecting Import (on selection), in the right mouse button menu of\\nthe Properties folder for a selected grid. Each of these objects hold essentially the same\\ninformation the main difference being that well tops, point well data and check shots are\\nconnected to wells. For simplicity these objects share a common format for import and a similar\\nimport dialog. Some differences are essential and these are discussed under the sections of the\\nspecific objects.\\nCreate a folder for the data by clicking on Insert new folder in the Toolbar.\\nHow to import cultural data\\nAny type of cultural data of the ASCII format can be read into Petrel by using the General\\nlines/points reader. When cultural data is imported into Petrel, all Z-values are set to zero. To be\\nable to view cultural data together with depth data, Z-values for the cultural data can be assigned\\nin Petrel, see Operations.\\nNote: Cultural data can also be imported using plug-ins.\\n1. Create a folder in the Input pane and give it an appropriate name.\\n2. Click with the right mouse button on the new folder and select Import (on selection).\\n3. In the Import file dialog, browse to the correct folder and select the file with cultural data.\\nIn Files of type select General lines/points (ASCII) (*.*). Click Open.\\n4. Fill in the settings in the Import lines/points dialog to fit with the file by browsing the\\nfile. For Z-values select None.\\n5. An Input data dialog will pop up. Change the name of the file if needed, and set the\\ncategory to boundary polygon. Click OK.'},\n",
       " {'header': 'Importing Points Data ',\n",
       "  'content': 'Each of these objects hold essentially the same information the main difference being that well\\ntops, point well data and check shots are connected to wells. For simplicity these objects share a\\ncommon format for import and a similar import dialog. Some differences are essential and these\\nare discussed under the sections of the specific objects.\\nThe dialog is divided in three sections; at the top is a small template spreadsheet which describes\\nthe order and type of data found in the file. The user should edit this to ensure data is imported\\ncorrectly. The central section holds any settings required for the import. At the bottom is a text\\nwindow which displays the first lines of the file.\\nand can be used to add or remove columns to the template spreadsheet. If some of the\\ncolumns of data in the spreadsheet are not required for import then their Attribute should be set\\nto User and the Attribute type should be set to Unknown. Then they will then be ignored.\\nThe lines of the template spreadsheet are as follows:'},\n",
       " {'header': 'Attribute ',\n",
       "  'content': 'What the column of data represents, standard attribute data (i.e. not related to positioning of\\npoints; X, Y, Z, or special properties) should be imported as User and assigned to a template\\nafter import.'},\n",
       " {'header': 'Attribute Name ',\n",
       "  'content': 'The name given to the attribute. For special attributes these will be defined automatically\\nwhile for User attributes this is editable.'},\n",
       " {'header': 'Attribute Type ',\n",
       "  'content': 'The variable type to be used to store the attribute see Variable Types.'},\n",
       " {'header': 'Units ',\n",
       "  'content': \"The unit used for the attribute, if the unit is different from the project unit then the data will\\nbe converted during the import process.\\nThe number of header lines will be automatically detected by identifying the position of the first\\nnumber in the first column of the file. Therefore if the first column of the file contains a data string\\n(such as well name) then the number of header lines must be input manually.\\n1.\\nHow to import points with attributes\\n1. Choose Import from the File menu or toolbar\\n2. Choose 'Petrel points with attributes (ASCII)(*.*)'\\n3. Add or remove columns to the import dialog until they are the same number of\\ncolumns in the template as in the file to be imported.\\n4. Define the correct columns as holding spatial attributes (e.g. X, Y, Z).\\n5. Define attribute columns as User and columns which should not be imported as Unknown.\\n6. Write in appropriate names for the User attributes in the row for attribute names.\\n7. Write in the correct variable type to use for each of the User attributes (as a rule of thumb\\nuse Continuous for numbers, text for text, discrete for discrete properties, Date for\\ntime-related data and True/False for yes / no, true/false attributes).\\n8. Choose the correct units for the attribute.\\n9. Ensure the correct number of header lines has been identified.\\n10. Press OK.\"},\n",
       " {'header': 'Import Gridded Surfaces ',\n",
       "  'content': 'How to import gridded surfaces\\n1. Create a folder for the data that you want to import by clicking on Insert new folder .\\n2. Rename the folder by typing an appropriate name.\\n3. Click with the right mouse button on the new folder and select Import (into selected).\\n4. In the Import file dialog, browse to the correct folder and select your file. When you have\\nset the correct file type in Files of type e.g. Zmap+ grid(ASCII). click Open. More than\\none file can be selected at a time as long as the files have the same format. To select more\\nthan one file, press Ctrl while selecting.\\n5. An Input data dialog will pop up where you can rename the file and set the Template\\nand Surface type of the file. The data extension of the file will be listed and should be\\nchecked. If several files are imported together and some settings are changed and the OK\\nfor all option is used, these settings will be applied on all the files.\\nHow to import grid formats not supported by Petrel\\nFor more info on formats for 2D grid/Surface data, see Formats for Grid Data\\nThere are many different available mapping packages used in our industry. Petrel supports\\nformats of the most common 2D mapping packages. New formats are continuously being added\\nas links to Petrel.\\nSome mapping packages, for example, Surfer, have the possibility to export surfaces as points\\nrepresenting the nodes of the grid. These points can be imported into Petrel and a new surface\\ncan be created in Petrel.\\n1. Export the gridded surface as a point file from your mapping package.\\n2. In Petrel create a folder for the file and rename the folder.\\n3. Click with the right mouse button on the new folder and select Import (on selection).\\n4. In the Import file dialog , select the file and select General lines/points as the format.\\n5. Fill in the General lines/points dialog, as described in Settings - General lines/points reader.\\nRead the file as points.\\n6. Use the Make/edit surface process in Petrel to create a surface from the point data set,\\nsee Make/Edit Surface. To keep the surface as the original, use the original X- and Y\\nincrement.\\nHow to import IsoChores and property surfaces\\nand property surfacesIsoChores are imported as other gridded surfaces into Petrel, but the\\nsettings in the Input data dialog in Petrel have to be changed for these data types.\\n1. Follow step 1 - 4 in How to import gridded surfaces\\n2. For IsoChores, set the Template to thickness.\\n3. For Property surfaces, set the Template to correct Property, see Templates and Color'},\n",
       " {'header': 'Tables. ',\n",
       "  'content': 'Note that values for thickness data and properties are not forced to be negative in Petrel.'},\n",
       " {'header': 'Import Seismic Data ',\n",
       "  'content': \"Seismic 2D lines and 3D cubes in SEG-Y and ZGY format can be imported into Petrel. A method\\nspecially designed for handling large data sets has been developed and implemented in Petrel.\\nThe only limitation is the size of your hard disk. To speed up the processes of handling large 3D\\ncubes, cropping of the original cube can easily be performed. In this way users can work on\\nseveral sub-cubes especially designed for different projects.\\nPetrel automatically creates a folder for the seismic data in the Input pane with the original\\nfilename as default name.\\nNote that the original seismic file is not saved in the Petrel project - only a link to the file.\\nTherefore, if you move the project somewhere else the link to the seismic file will not be found\\nand the seismic data icon will be marked as unconnected . To reconnect to the seismic file,\\nopen the settings dialog for the seismic and, in the bottom of the Info tab, type in or browse\\nfor the new location of the seismic file.\\nWhenever a new realization of the seismic cube is created within Petrel e.g. time slices cube,\\nthe new seismic volume will be stored together with the project.\\nFig: Folders for the seismic cube in Petrel.\\nHow to import seismic data\\nSelect the option Import file from the Toolbar.\\nAlternatively Insert a New seismic main folder from the menu bar (right-click on the new folder\\nand Insert seismic survey). Right-click on the survey and use Import (on selection).\\n1. Choose format (SEG-Y seismic data, SEG-Y Import with preset parameters, Seismic data in\\nZGY bricked format), select the file to import and click Open.\\n2. In the Vintage selection dialog select the vintage that the loaded seismic should belong\\nto. Vintages are used to group together seismic of the same version.\\n3.\\n4.\\n2.\\n3. In the Input data dialog, make sure that Template is correct and that Domain is\\ncorrect (Elevation time or Elevation depth).\\n4. Check the Data range to check that the ranges are being read in correctly, and set any XY\\nand Z conversion if needed. Then click OK.\\nA new Seismic tree will appear in the Input pane:\\nNote that an imported 2D Seismic line will have a\\ndifferent icon:\\nThe program will auto-detect whether the data is 2D lines or a 3D cube.\\nMore information on import procedures for:\\nSEG-Y files can be found in SEG-Y Data Import. Details of the Settings window for an\\nimported seismic cube can be found in Seismic Data (Settings). See also Editing Of The\\nTrace Headers for information about manipulating the imported volume.\\nZGY files can be found in ZGY Data Import\\nSeismogram and VSP data can be found in How to import a synthetic seismogram from\\nfile\\nWavelets can be found inHow to import a wavelet\\nImport Grids and Properties\\n3D grids and 3D property models generated outside of Petrel can easily be imported to Petrel. The\\nformats supported by Petrel are described in detail in Appendix 1.The supported 3D grid formats\\nare:\\nOpen Petrel format\\nECLIPSE keywords (grdecl) (ascii)\\nECLIPSE / FrontSim data and results (data) (grid) (egrid) (init) (smspec) (slnspec)\\nECLIPSE .GRID (binary)\\nCMG grid (ASCII)\\nVIP grid (ASCII)\\nOpen RMS grid (BINARY)\\nPetrel format (BINARY)\\nPetrel fault model (ASCII)\\nRescue format\\nFracture Patches in FAB format\\nThe supported property formats are:\\nECLIPSE properties (ASCII) (grdecl) (data)\\nECLIPSE properties Restart (BINARY)\\nECLIPSE properties Init (BINARY)\\nECLIPSE / FrontSim data and results (data) (grid) (egrid) (init) (smspec) (slnspec)\\nBlockK properties (ASCII)\\nGolder grid properties (ASCII)\\nCMG properties (ASCII)\\nVIP properties (ASCII)\\nVIP Init/Restart properties (ASCII)\\nGSLIB properties (ASCII)\\nPetrel format (BINARY)\\nNote that the Models pane must be active when importing 3D grids and 3D property models.\\nImport 3D grid\\nImport of grids can be done by using Import file or Import (on selection) . When using\\nthe Import file option, Petrel will create a new model containing the imported grid. The grid can\\nalso be imported into an existing model by using Import (on selection) from the right mouse\\nbutton menu of the 3D Model .\\nWhen importing a grid Petrel can, on the users command, detect and insert faults in the model.\\nThe offset for detecting faults is zero and if two Z-values are detected on one pillar, Petrel will\\ninsert a fault.\\nHow to import a 3D grid\\nIf the file for the 3D grid contains properties, these will be imported together with the grid.\\n1. Open the Import dialog, by using Import file or by selecting Import (on selection) from\\n2.\\n3.\\n1.\\nthe right mouse button menu of a selected model.\\n2. Select file and proper file type. Press Open and the Import dialog pops up.\\n3. Select the coordinate system used in the file, Local or Global coordinate system, and enter\\nthe number (value) that represents undefined value.\\n4. The settings specified for the grid formats (ECLIPSE import settings, CMG import settings,\\nVIP import settings and Gslib import settings) under the Project menu in the Menu bar are\\nset as default.\\n5. When the settings are done, press OK.\\n6. When reading the data a dialog will pop up where the user can specify if Petrel should\\nsearch for faults and segments.\\nFigure 1. Import settings.\\nImport 3D property models\\nProperties can be imported together with a 3D grid, see 'How to import a 3D grid' (above) or from\\nseparate property files.\\nNote that if separate property files are imported, a 3D grid must first have been created in,\\nor imported into Petrel.\\nHow to import grid properties (ASCII)\\nOpen the Import dialog, by selecting Import (on selection), in the right mouse button menu of\\nthe Properties folder for a selected grid.\\n1. Select file and proper file type.\\n2. Press Open and the properties will be imported.\\n1.\\n2.\\nFor ECLIPSE Restart and Init files, the different time steps in a file will be added to the property\\nfolder as separate files, annotated with the date of the time step.\\nUsing the ECLIPSE / FrontSim data and results import\\nwizard\\nAny results from an ECLIPSE or FrontSim simulation can be imported into Petrel through the\\nECLIPSE / FrontSim data and results import wizard. Choose ECLIPSE /FrontSim data and\\nresults (*.*) at the import dialog and select any .DATA, .GRID, .EGRID, .INIT, .SMSPEC or\\n.SLNSPEC file. Petrel will automatically locate any associated data files and present them in the\\ndialog.\\nSelect the data items and time steps to import and press OK.\\nIt is recommended to import simulation results along with the grid file from ECLIPSE /\\nFrontSim the first time a case is loaded into Petrel.\"},\n",
       " {'header': 'Import Settings ',\n",
       "  'content': \"Different settings for the importing of 3D grid and properties can be set and used as default in the\\nimporting process.\\nThe Import settings dialog for each format can be reached under Project in the Menu bar. The\\ndialog will also pop up when importing the data.\\nSettings for ECLIPSE, CMG and VIP format\\nFor ECLIPSE, CMG and VIP format the following settings can be specified:\\nFile coordinate system\\nSpecifies the use of local or global coordinates in the file. If local coordinates are used in the\\nfile, then the 'mapaxes' keyword in the file is used to transform the coordinates into global\\ncoordinates.\\nRemove cells\\nIf none of the selections are checked, the whole grid will be imported, including undefined\\ncells. If the first option is checked, cells set to undefined (with the ACTUNUM keyword) will be\\nleft out when importing the grid. If the second option is checked, cells that have a volume\\nequal to zero will be left out when the grid is imported. One, both or none of these options\\nmay be checked.\\nOther settings:\\nUndefined property value\\nSpecifies the value used as undefined in the file.\\nAdd extra zones for Z-splits\\nSelect to add extra zones automatically when splits in Z-direction are detected.\\nHandle unknown keywords\\nWarnings are sent to the message log during import.\\nAutomatic fault detection:\\nRun automatic fault detection during import.\\nSettings for GSLIB properties format\\nThe available setting for importing in GSLIB properties format is:\\nUndefined property value\\nSpecifies the number used as undefined property value.\\nUse zero based I, J, K\\nOlder versions of Petrel exported Gslib properties with zero based I, J, K. If you get a result\\nwith values shifted one place, try activating this setting.\\nImport Functions (Lookup curves)\\nFunctions can be imported into Petrel from a standard text file. The text file should contain two\\ncolumns with X and Y values. Right click on the folder and select Import (on selection) from\\nthe context menu.\\nWhen imported (use the format Function XY (ASCII)), the file will be saved with its file name in\\nthe Petrel Input pane with the icon .\"},\n",
       " {'header': 'Import Crossplot ',\n",
       "  'content': 'Crossplot objects are simply a list of points with two corresponding properties which can be used\\nto describe bivariate distributions when performing Petrophysical property modeling. The file\\nshould be in an ASCII format and have two columns of numerical data. It is important to know\\nhow many header lines the file has.\\nFor import procedure, see Import Functions (Lookup curves)'},\n",
       " {'header': 'Porosity Permeability ',\n",
       "  'content': '0.12 23\\n0.16 55\\n0.15 65\\n0.22 213\\n...'},\n",
       " {'header': 'Import Bitmaps ',\n",
       "  'content': 'Several types of bitmaps can be imported and several formats are supported formats are BMP,\\nJPG, TIFF, GIF and PNG. Petrel is detecting the bitmap format by the file extension.\\nImported bitmaps can be viewed in the plot windows. Drag in the corners or along the sides of the\\ndisplayed bitmap to change its size. Press Shift as you drag to keep XY-scaled during resizing.\\nA bitmap can also be given coordinates manually after import. A bitmap with defined coordinates\\ncan be draped across a surface (See Bitmap Settings Window)\\nFor more details about bitmaps and their use, see Bitmaps and Surface Imaging.\\nFor more info on importing bitmap logs, see Import bitmap logs\\nImport ECLIPSE / FrontSim data and results\\nExisting ECLIPSE and FrontSim data and results files created outside of Petrel can be imported\\ninto Petrel. Petrel will read directly from the simulator output files, and results will be accessed\\ndirectly using the index created by the simulator.\\nPetrel will on import of the simulator files generate Petrel objects for controlling and edit the\\nsimulator input and output files from within Petrel.\\nHow to import simulation data\\n1. Right click in the Cases pane and select Import (on tree) from the context menu.\\n2. Select files of type (ECLIPSE / FrontSim data and results, Petrel Summary Data, VIP\\nsummary ASCII) and the file(s) to import.\\n3. Click OK. In the case of importing ECLIPSE and FrontSim data and results, Petrel will\\nautomatically select the various input and results files if they are located in the same\\ndirectory. In the Import ECLIPSE / FrontSim run dialog you can also select to browse\\nfor this input if they are located elsewhere.\\n4. In the top of the dialog select which simulator the simulation files are defined for. This will\\naid Petrel in the import and conversion of the simulation files into Petrel objects.\\n5. Click OK to continue with the import.\\nIf you have correctly configured license access, Petrel will open the Package Selection window. If\\nyou place the cursor over one of the elements of this window, a description will pop up to help\\nyou. The license packages available to the user on the selected license server(s) are listed on the\\nleft side of the window, while the modules available within this predefined package of modules are\\nlisted on the right. Click on the Package name in this list and click OK to proceed with starting up\\nPetrel. In the bottom of the Import ECLIPSE / FrontSim run dialog you can specify some\\nimport settings. The option Automate handling of import settings will let Petrel automatically\\nchoose the suitable import settings for the selected import files. The coordinate system settings\\nare based on the presence of the MAPAXES keyword and the grid geometry is automatically\\nconverted to the project unit system. Furthermore, unknown keywords are logged in the log\\nwindow and faults are auto detected. To manually control the import settings, turn off the\\ncheckbox in front of the option and click on the Advanced... button.\\nQuality Control of Imported Data\\nAfter importing data into Petrel to build 3D models, it is very important that all the input data is\\nquality controlled before the data is used to create new data.'},\n",
       " {'header': 'Visualizing ',\n",
       "  'content': 'The best way to quality check the input data is to visualize different data together in the 3D\\nDisplay window to look for data inconsistencies. This is a unique way of comparing data from\\ndifferent sources e.g. interpreted seismic lines can be compared (in 3D) to seismic data, well logs\\nand well tops. Another great feature in Petrel is the possibility to zoom in between different\\nsurfaces and inspect how the layers between surfaces look.\\nVisualization of the data is a very important feature in Petrel and is described in more detail in'},\n",
       " {'header': 'Visualization. Statistics ',\n",
       "  'content': 'Another important data tool that can be performed in Petrel is to inspect the statistics for objects\\nboth imported and created in Petrel. Each data object in Petrel has a Settings window, which\\nconsists of different tabs with different options. The settings windows for every object in Petrel are\\ndescribed in detail in Settings for objects in the Input tab. The Statistics window is a tab that is\\navailable in every settings window. The settings window can be opened by double clicking on an\\nobject in the Petrel panes or by clicking on the object with the right mouse button and select\\nSettings from the context menu.\\nTo check the statistics of an object in Petrel, open the settings window and select the Statistics\\ntab. In the statistics tab the max and min coordinates of the X-, Y- and Z- axis are listed,\\ntogether with different information about the object, e.g. number of closed and open polygons in\\na polygon data-set or number of well logs with min and max values for a well.\\nThe important part to check in the statistics is that the values are within the area that you expect\\nthem to be. Check that the log curves look reasonable and that the min and max values for a log\\ncurve are within the expected values.'},\n",
       " {'header': 'Export Data ',\n",
       "  'content': \"Petrel can export data in many different format types and is continuously updated to handle new\\nformats as users request them.\\nDifferent format types are available for the export of different types of data. When exporting an\\nitem, Petrel lists all the available format types.\\nThe format types Petrel supports are briefly described in Data Types, and these formats are\\ndescribed in detail in Appendix 1 - Formats.\\nExport multiple objects\\nPetrel has an option to export multiple objects at once in the same file; select individual\\nobjects using CTRL/SHIFT or select a folder containing the objects. One right-click option is\\n'Export multiple'.\\nData that can use this export functionality are:\"},\n",
       " {'header': 'Polygons Points Surfaces ',\n",
       "  'content': 'For more details and an example, see Gridded Surfaces\\nNote that multiple Seismic interpretations can be exported as described above, but will be\\nput in separate files.\\nNote that all items in Petrel can be exported in Petrel binary format.'},\n",
       " {'header': 'Well Data ',\n",
       "  'content': 'Wells and well data (trajectory and associated logs) can be exported from Petrel in the following\\nformats:\\nIrap RMS (trace and logs)\\nWell heads, ASCII (well positions)\\nWell path/deviation file, ASCII (trace)\\nLAS 2.0 file with well logs (logs)\\nPetrel format, BINARY (trace)\\nPoint well data, ASCII (points)\\nCheckshots format, ASCII (points)\\nWith a well folder or multiple wells selected (use Ctrl or Shift), all of the wells or all of the well\\nlogs for the wells in the folder can be exported in a single operation.\\nRight-click the selected wells and choose:\\nExport selected wells\\nwill export selected deviations\\nExport logs from selected wells\\nwill export logs\\nRight-click on the main Wells folder or the selected sub-folder and choose:'},\n",
       " {'header': 'Export ',\n",
       "  'content': 'will export the well header file\\nExport all wells in folder\\nwill export selected deviations\\nExport all logs in folder\\nwill export logs\\nHow to export single well data\\n1. Open the pull-down menu for the well to export, by clicking with the right mouse button on\\nthe well.\\n2. Select the Export option.\\n3. Enter output file name. Select output format (Irap RMS well (ASCII), Petrel format\\n(Binary), Well logs (ASCII), Well/Path deviation (ASCII).\\n4. Click Save, and the well data will be exported in the format selected\\nA format description can be found in Appendix 1 - Formats. Well heads are exported from the well\\nfolder and will contain information on all wells in the project.'},\n",
       " {'header': 'Well Tops ',\n",
       "  'content': 'Well Tops that have been created or edited (See Make/Edit Well Tops) in Petrel can be exported\\nas\\nPetrel Well Tops (ASCII)\\nPetrel format (Binary)\\nHow to export Well Tops\\n1. Open the pull-down menu for the Well Tops folder, by clicking on it with the right mouse\\nbutton.\\n2. Select the Export option.\\n3. Enter the file name. Select file type.\\n4. Press Save, and the Well Tops data will be exported.\\nLines and Points\\nLine and point data, stored in the Input pane, can be exported in several different formats.'},\n",
       " {'header': 'Points: ',\n",
       "  'content': 'IRAP classic points (ASCII)\\nPetrel format (BInary)\\nPetrel points with attributes (ASCII)'},\n",
       " {'header': 'Lines: ',\n",
       "  'content': 'IRAP classic lines (ASCII)\\nIRAP classic lines (Binary)\\nIESX Fault polygons (ASCII)\\nZmap+ lines (ASCII)\\nCPS-3 lines (ASCII)\\nPetrel format (Binary)\\nLines can be fault polygons/lines converted from a 3D model created in Petrel (See Fault models),\\nimported fault polygons or other linear data which has been edited in Petrel.\\nHow to export lines and points (general)\\n1. Click with the right mouse button on the item to export (in the Input pane in the Petrel'},\n",
       " {'header': 'Explorer). ',\n",
       "  'content': \"2. Select the Export option and the Export as dialog will pop up.\\n3. Enter file name and select file type from the list.\\n4. Press OK and the item will be exported in the given format.\\nGridded surfaces\\nGridded surfaces stored in the Input tab can be exported in several different formats:\\nIrap classic grid, ASCII\\nIrap classic grid, BINARY\\nZmap+ grid, ASCII\\nEarthVision grid, ASCII\\nCPS-3 grid, ASCII\\nPetrel format, Binary\\nSurfaces which can be exported include:\\nSurfaces created with the Make Surface utility (See Make/Edit Surface).\\nFault surfaces converted from a 3D grid created in Petrel (See Fault models).\\nHorizons from a 3D grid, which are converted to surface grids.\\nIsoChore maps made from zones of a 3D grid.\\nSeveral surfaces can also be exported in the same file as a layer model in Irap classic layer,\\nBINARY format.\\nPetrel has a multiple object export option, automatically appearing when selecting multiple\\nsurfaces for export.\\nNote that fault surfaces can only be exported in EarthVision grid (ASCII) format.\\nHow to export a gridded surface (general)\\n1. Open the pull-down menu for the surface to export, by clicking on it with the right mouse\\nbutton.\\n2. Select the Export option.\\n3. Enter file name and select file type.\\n4. Press OK and the surface will be exported in the given format.\\nHow to export horizons as regular (XY) surface grids\\nTo export horizons from a 3D grid created in Petrel, they can be converted to a surface with a\\nregular grid (x,y).\\nThe conversion can be done on individual horizons or all horizons can be converted at the same\\ntime. To convert a single horizon, open the settings window for the horizon. To convert all the\\nhorizons at once open the settings window for the Horizons folder.\\n1. Open the Settings window for the Horizon folder/specific horizon (for a 3D grid in the\\nModels tab), by double clicking on the icon.\\n2. Select the Operations tab.\\n3. Drop in a template surface if you want to use the settings (grid spacing) from an existing\\nsurface.\\n4. Select whether or not to 'Fill in faulted areas'.\\n5. Click the Make surface button to generate the regular grid. Note that the surfaces are\\n6.\\n4.\\n5.\\nplaced in the Input pane of the Petrel Explorer.\\n6. The horizons can now be exported as regular grid (see How to export a gridded surface\\n(general)).\\nFigure 1. The Output tab for a horizon.\\nHow to export horizons as irregular (IJ) surface grids\\nTo export isochore maps in Petrel, they first have to be made from the zones created in the 3D\\ngrid.Faults can be converted to polygons, which are sorted by fault or by horizon. To make fault\\npolygons sorted per fault, the conversion is done from the Fault folder. To make fault polygons\\nsorted per horizon, the conversion is initiated from the Fault filter folder.To export faults from a\\n3D grid as fault surfaces they first have to be converted to regular 2D grids. Note that the\\ndefault settings may be overwritten so that the user is always free to choose exactly what to\\nexport. Also note that the name of a fault is restricted to 8 characters in ECLIPSE.To export\\nhorizons from a 3D grid created in Petrel, they can be converted to a surface using the i, j grid of\\nthe Horizon.\\n1. To convert a single horizon, right-click on the horizon and select Convert to structured\\nsurface\\n2. The surface is placed in the Input pane of the Petrel Explorer.\\n3. The horizons can now be exported as regular grid (see How to export a gridded surface\\n(general)).\\n2.\\n3.\\nNote that by default the fault gaps in the 3D grid horizons will be interpolated (filled) using\\nthis method.\\nHow to export isochores made from zones in a 3D\\ngrid\\nTo export IsoChores maps in Petrel, they first have to be made from the zones created in the 3D\\ngrid.\\nIsoChores can be generated for individual zones or for all zones simultaneously. Single IsoChores\\nare generated from the settings dialog for individual zones. IsoChores for all the zones can be\\ngenerated from the settings dialog for the Zone filter folder.\\n1. Open the Settings window for the specific zone or zone filter folder under the models Zone\\nfilter in the Petrel Explorer, by double clicking on the Zone icon.\\n2. Select the Output tab.\\n3. You can choose to compute the IsoChore in TVT or along pillars. If you choose to compute\\nin TVT, select whether to 'Fill in faulted areas' and then press Make IsoChore. If you\\nchoose to calculate the IsoChore along pillars, select whether to remove eroded parts of the\\nzone, and press Make IsoChore. Note that the IsoChore is placed in the Input pane of the\"},\n",
       " {'header': 'Petrel Explorer. ',\n",
       "  'content': \"4. The IsoChores maps can now be exported as a regular grid, see How to export a gridded\\nsurface (general).\\nFigure 2. The Output tab from the Zone filter.\\nHow to export multiple surfaces\\nTo export multiple surfaces, they have to be stored in their own folder in the Input pane in the\\nPetrel Explorer, or you can select the instances you want to export using Ctrl/Shift for multiple\\nselection.\\n1. Open the pull-down menu for the folder that contains the surfaces, or select the surface\\nyou wish to export.\\n2. In the right-click menu, select the Export multiple option.\\n3. The file type can be set from the list above (see Gridded Surfaces)\\n4. Select a folder to save in.\\n5. Enter file name and Pattern tag.\\n6. Press Save, and the surfaces will be exported in the given format.\\n7. Petrel will ask if you want to negate the values of each file to be exported\\nNote that since Petrel works with negative Z-values and many other applications work with\\npositive values it is a good idea to negate (default). Pattern tag will add a suffix to the\\ngeneral (typed) name based on:\\nName - name of object\\nParent name - surface\\nType - Regular surface\\nTemplate - Elevation time/depth\\nUnique tag - object name in .Ptd folder\\nHow to export surfaces as a layer model\\nTo be exported as a layer model, all surfaces have to be stored in their own folder in the Input\\npane in the Petrel Explorer.\\n1. Open the pull-down menu for the folder that contains the surfaces.\\n2. Select the Export option.\\n3. Enter file name. The file type will be set as default (only IRAP Classic layer (Binary) format\\nis available for this operation).\\n4. Press Save, and the surfaces will be exported in the given format.\\nNote that for this option to work all grid sizes must be equal.\\nFault models\\nFaults can be exported from Petrel, as fault models, fault surfaces or fault lines/polygons.\\nIn a 3D model in Petrel there are two types of fault models, and these can be exported from\\nPetrel in different formats.\\nThe fault model created from Key Pillars (subfolder to the 3D model on the Models pane)\\ncan be exported in Petrel fault model (ASCII) format.\\nThe fault model created in the pillar gridding process (subfolder to a specific 3D grid on the\\nModels pane) can be exported in ECLIPSE Fault Data (ASCII) format. This fault model can\\nalso be converted to a Key Pillar fault model.\\nFaults created in Petrel can be converted to fault surfaces, polygons, and lines in four different\\nways. The converted faults can then be exported as lines or surfaces in different format types.\\nThe faults from the fault model created from Key Pillars (subfolder to the 3D model on the\\nModels pane) can be converted to fault sticks or fault surfaces.\\nThe faults from the fault model created in the pillar gridding process (subfolder to a specific\\n3D grid on the Models pane) can be converted to fault sticks, fault surfaces or fault\\npolygons. The converted fault polygons can be sorted per fault or per horizon.\\nHow to export a Fault model from Petrel\\n1. Right-click and open the pull-down menu for the Fault model folder (under the 3D model\\nin the Models pane).\\n2. Select the Export option and the Export as dialog will pop up.\\n3. Enter file name. The file type (Petrel fault model (ASCII), Petrel format (Binary).\\n4. Press Save and the fault model will be exported.\\nHow to convert an existing fault model to a separate\\nfault model\\n1. Click with the right mouse button on a 3D Grid .\\n2. Select the Convert to fault model option from the pull-down menu.\\n3. A new model will appear on the Models pane. This model now contains the converted\\nfault model.\\nHow to export faults from a 3D grid using\\nECLIPSE/VIP formats\\nFor this format, the user can export an individual fault or any combination of faults in one\\nprocess. If the export is done from the pull-down menu for the Fault folder (for a specific 3D grid),\\nexport of all faults is set as default. If the export is done from the pull-down menu for a specific\\nfault, export of only that fault is set as default.\\nThere are three format options:\\nECLIPSE Fault Transmissibility Multiplier Data (ASCII)\\nVIP Fault Transmissibility Multiplier Data (ASCII)\\nECLIPSE fault data (ASCII)\\nFaults can be converted to polygons, which are sorted by fault or by horizon. To make fault\\npolygons sorted per fault, the conversion is done from the Fault folder. To make fault polygons\\nsorted per horizon, the conversion is initiated from the Fault filter folder.To export faults from a\\n3D grid as fault surfaces they first have to be converted to regular 2D grids. Note that the\\ndefault settings may be overwritten so that the user is always free to choose exactly what to\\nexport. Also note that the name of a fault is restricted to 8 characters in ECLIPSE.\\n1. Open the pull-down menu for the fault model to be exported by clicking with the right\\nmouse button on the Fault folder/specific fault (under a 3D grid in the Models pane).\\n2. Select the Export option and the Export as dialog will pop up.\\n3. Enter file name. Select format.\\n4. Press Save and the Export dialog will pop up.\\n5. Choose which faults to export. If all settings are done, press OK or press Advanced to\\nchange the ECLIPSE export settings (See Export settings).\\nHow to export faults from a Fault model as fault lines\\nTo export faults from a Fault model as fault lines, they first have to be converted to fault sticks or\\npolygons.\\n1. Open the pull-down menu of the Fault model to be converted by clicking with the right\\nmouse button on the Fault folder (under a 3D model on the Models pane).\\n2. Select the option 'Convert to fault sticks' (or 'Convert to fault polygons').\\n3. The fault model will be converted to fault sticks and stored in the Input pane.\\n4.\\n2.\\n3.\\n4. The fault sticks can then be exported as lines in different format types (See Lines and\"},\n",
       " {'header': 'Points). ',\n",
       "  'content': \"To be able to export as polygons you need to export from the main Faults model folder. To\\nexport only fault sticks, you can do it from the individual faults in the model.\\nHow to export faults from a Fault model as fault\\nsurfaces\\nTo export faults from a Fault model as 2D grids, they first have to be converted to fault surfaces.\\n1. Open the pull-down menu of the Fault model to be converted by clicking with the right\\nmouse button on the Fault folder (under a 3D model on the Models pane).\\n2. Select the option 'Convert to fault surface'.\\n3. The fault model will be converted to fa surface and stored in the Input pane.\\n4. The surface can then be exported as lines in different format types (See Gridded surfaces).\\nHow to export faults from a 3D grid as fault surfaces\\nFaults can be converted to polygons, which are sorted by fault or by horizon. To make fault\\npolygons sorted per fault, the conversion is done from the Fault folder. To make fault polygons\\nsorted per horizon, the conversion is initiated from the Fault filter folder.To export faults from a\\n3D grid as fault surfaces they first have to be converted to regular 2D grids.\\n1. Open the pull-down menu for the Faults folder/specific fault (under a 3D grid on the Models\\npane) to be converted by clicking on it with the right mouse button.\\n2. Select the option 'Convert to fault surface'.\\n3. The faults will be converted to fault surfaces and stored in the Input pane. If the conversion\\nis done from the Fault folder, a new folder, containing the surfaces, will be created in the\\nInput pane.\\n4. The fault surfaces can then be exported as surfaces in different format types (See Gridded\\nsurfaces).\\nHow to export faults from a 3D grid as fault polygons\\nTo export faults from a grid as fault polygons, they first have to be converted to polygons.\\nFaults can be converted to polygons, which are sorted by fault or by horizon. To make fault\\npolygons sorted per fault, the conversion is done from the Fault folder. To make fault polygons\\nsorted per horizon, the conversion is initiated from the Fault filter folder.\\n1. Open the pull-down menu of the Fault folder or the Fault filter folder, by clicking on it with\\nthe right mouse button.\\n2. Select the option 'Convert to fault polygons'.\\n3. In the pop up menu, decide if the fault polygons are to be closed or not.\\n4. The faults will be converted to fault polygons and stored in the Input pane. If the\\nconversion is done from the Fault/Fault filter folder, a new folder containing the polygons\\nwill be created in the Input pane.\\n5. The fault polygons can then be exported as lines in different format types (See Lines and\"},\n",
       " {'header': 'Points). ',\n",
       "  'content': 'Grid and properties\\n3D grids and properties created or imported into Petrel can be exported in various formats. 3D\\nproperties can be exported along with the grid (except for ECLIPSE grid, BINARY) or as separate\\nfiles in property formats. Petrel can also export data for cells penetrated by wells in different\\nformats.\\nThe grid units can be converted at export.\\nThe origin of a Petrel 3D grid depends on the format of the input data and on the grid orientation\\n(which the user specifies by directions and trends in the Pillar gridding process).\\nWhen exporting, Petrel finds the grid origin and arranges the data to be exported in the correct\\nformat. The user has the option to specify the origin and the cell order of the exported grid\\nmanually (See Export Settings). The export settings can be reached from the pull-down menu for\\nProjects in the Menu bar, or from the export dialog in the export process.\\nFilter sensitive export\\nThere is an option in Petrel to make a filter sensitive copy of the 3D grid. This copy can then be\\nexported in any of the available export formats.\\nThis option is very useful if you want to export a selected part of a model.\\n1. Set the filters as required in the 3D window - Index filter, Zone filter and Segments filter.\\n2. Double-click a 3D grid in Petrel to open the Settings window for the whole grid.\\n3. Go to the Output tab.\\n4. Check the filters to use (Zone, Segment and/or Index) and click on Copy global grid.\\n5. A new 3D grid is created and named Part of <3Dgrid name>.\\nExport of 3D grid\\nThe available format types in which to export the 3D grid are:'},\n",
       " {'header': 'ECLIPSE .GRID (BINARY) ',\n",
       "  'content': 'ECLIPSE Extended Grid (egrid, fegrid)\\nECLIPSE style geometry and properties (grdecl) (ascii)\\nCMG grid (grdecl) (ASCII)\\nVIP grid (ASCII)\\nOpen RMS grid (BINARY)\\nPetrel *.pet (BINARY)\\nRescue format\\nWhen a 3D grid is exported and then re-imported, information such as horizon status is lost (for\\nexample, whether a horizon was erosional, truncated, etc).\\nThe user can choose whether the 3D grid is exported with or without properties in the same file.\\nFor exporting properties to a separate file, see Export of 3D Property Models\\nNote that the ECLIPSE style geometry and properties (grdecl) format is the recommended and\\nmost common way to export data for ECLIPSE simulation runs. This method specifies the Corner\\nPoint Geometry using the ECLIPSE keywords COORD and ZCORN. The .GRID file has the format\\nof an ECLIPSE .GRID output file, that is; composed of a set of topologically cuboidal cells, with (X,\\nY, Z) position of the 8 corners specified. This allows for a more flexible definition of the grid\\ngeometry than what is possible with ZCORN and COORD keywords.\\nNote: The .GRID file option (using ECLIPSE keyword GDFILE) is issued with a warning in the\\nECLIPSE 100 reference manual \"This keyword should be used with care and is not recommended\\nfor general use\". The standard ECLIPSE format is based on linear coordinate lines, which can be\\nvertical or deviated. The GRID format exported from Petrel might contain curved coordinate lines\\nor listric faults that are not supported by all programs in the ECLIPSE family. For example, listric\\nfaults will result in erroneous \"holes\" or overlapping cells in standard ECLIPSE models. Also, the\\nGRID format does not allow radial geometry, vertical equilibrium and Local Grid Refinement. The\\nRescue format is for export to FloGrid.\\nThe Open RMS file format is limited to linear faults with no truncations.\\nHow to export a 3D grid\\n1. Open the pull-down menu of the Petrel 3D grid to be exported by right-clicking the grid in\\nthe Models pane.\\n2. Select the Export option and the Export as dialog will open up.\\n3. Enter the file name and select file type.\\n4. Click Save. If you selected one of the Eclipse file formats, the ECLIPSE Export Grid dialog\\nwill open up.\\n5. Check the Export properties box if properties are to be exported along with the grid.\\n6. If properties are to be exported together with the grid, specify which properties to include\\nby checking the box in front of the property.\\n7. To change the Export settings press Export settings.... The Export settings dialog opens\\nup (See Export Settings).\\n8. When all settings are correct, press OK.\\n9. A unit conversion dialog will open up - change the units if you wish, or simply press OK\\nagain.\\n8.\\n9.\\nExport of 3D Property Models\\nThe available formats to export properties in are:\\nECLIPSE style properties (ASCII)\\nCMG properties (ASCII)\\nVIP properties (ASCII)\\nGSLIB properties (ASCII)\\nProperties can either be exported from Petrel together with the 3D grid (ECLIPSE (ASCII), CMG\\n(ASCII) and VIP (ASCII)) or as a separate properties files.\\nTo export properties together with the grid, see Export of 3D grid\\nHow to export 3D Property Models\\nThe default settings in the Export dialog depend on where the export is done. If the export is done\\nfrom the pull-down menu for the Properties folder, export of all properties is set as default. If the\\nexport is done from the pull-down menu for a specific property, export of only that property is set\\nas default.\\nNote that the default settings may be overwritten so the user is always free to choose exactly\\nwhat to export.\\n1. Open the pull-down menu for the 3D grid property by right clicking it in the Models pane.\\n2. Select the Export option and the Export as dialog will pop up.\\n3. Enter file name and select file type.\\n4. Press Save and the export dialog pops up.\\n5. Choose which properties to export. Press OK or press Advanced to change the Export\\nsettings (see Export Settings).\\nExport of cell geometries for cells penetrated\\nby wells\\nThree formats for export of cell geometries for cells penetrated by wells are available in Petrel.\\nThese are:\\nECLIPSE Well Connection Data (ASCII)\\nECLIPSE Well Completion Data (ASCII)\\nVIP Well Connection Data (ASCII)\\nECLIPSE Well connection data provides information such as cell index, entry/exit points, entry/exit\\nfaces and entry/exit depths. The well connection data is input to the ECLIPSE pre-processor called\\nSchedule (GeoQuest product), which can be used to generate the COMPDAT keyword data for\\nECLIPSE simulation runs. Well logs can be exported together with the well connection data.\\nThe ECLIPSE Well completion data is used to generate the COMPDAT (completion data) keyword\\nwitch defines the type and position of completions (perforations, casings) (see Formats for well\\ndata).\\nHow to export ECLIPSE (VIP) well connection data\\n1. Open the pull-down menu for the 3D grid to export data from by clicking with the right\\nmouse button on the grid in the Models pane.\\n2. Select the Export option. Select ECLIPSE (or VIP) Well connection data (ASCII) as Save as\\ntype in the pop up dialog. Enter file name.\\n3. Press Save and the Export dialog will pop up.\\n4. Select wells and properties to export. Define unit conversions if needed.\\n5. To change the export settings press Advanced. The Export settings dialog pops up (See'},\n",
       " {'header': 'Export Settings). ',\n",
       "  'content': '6. When all settings are done, press OK and the connection data will be exported in the given\\nformat.\\n6.\\nHow to export ECLIPSE well completion data\\n1. Open the pull-down menu for the 3D grid to export data from, by clicking with the right\\nmouse button on the grid in the Models pane.\\n2. Select the Export option and, in the pop-up dialog. Select ECLIPSE Well completion data\\n(ASCII) as Save as type. Enter file name.\\n3. Click Save and the Export dialog will pop up.\\n4. Select wells to export.\\n5. To change the export settings click Advanced. The Export settings dialog pops up (See'},\n",
       " {'header': 'Export Settings). ',\n",
       "  'content': '6. When all settings are done, click OK and the completion data will be exported in the given\\nformat.\\n6.\\nExport Settings (3D Grids and Properties)\\nFor export of 3D grids and 3D property models, the user can define some settings. There are\\nslight differences in the settings for the ECLIPSE, CMG and VIP formats. There are settings for the\\nuse of global or local grid coordinates, the grid origin, and the order of cells in the grid.\\nThe settings of the file content can be specified for export of properties in GSLIB properties\\nformat.\\nThe origin of a Petrel grid depends on the format of the input data and the grid orientation (which\\nthe user specifies in the Pillar gridding process). Because Petrel does not operate with a fixed grid\\norigin/orientation, it tries to find the grid origin and to arrange the data to be exported in the\\ncorrect format. In the export settings, the user has the option to manually override this choice\\nand to specify the grid origin and the cell order of the exported grid.\\nThe export settings dialog can be opened from the Projects pull-down menu in the Menu bar, or\\nfrom the export dialog in the export process.\\nHow to set the export settings for ECLIPSE, CMG and VIP format\\n1. Open the Export settings for the specific format under Projects in the Menu bar. The\\nExport settings dialog opens up. Note that these dialogs can also be accessed from the\\nexport dialogs.\\n2. Select the type of coordinate system for the exported grid: Local or Global Coordinate\\nSystem. The user can specify the x and y origin of the grid when using the local coordinate\\nsystem option. Note that the global (e.g. UTM) location will be lost in the exported grid if\\nLocal coordinate system is selected.\\n3. Select if keywords are to be included in the file (only ECLIPSE and CMG).\\n4. For ECLIPSE, the Export MAPAXES keyword option saves the origin and axes information\\nfor the Petrel grid. A rotation angle can also be defined.\\n5. For CMG, there are two options; either Export CORNERS keyword or Export COORD\\nkeyword. Use of the COORD keyword requires that the fault pillars are straight. The\\nkeyword CORNER is more flexible and allows any geometry of fault pillars.\\n6. Select User defined cell origin to specify the grid origin and cell order manually.\\nOtherwise, Petrel will try to find the grid origin/orientation and arrange the data thereafter.\\n7. To specify the cell order for the exported grid manually, the user needs to know the internal\\ncell numbering of the specific Petrel grid. The position of a Petrel cell is defined by the three\\nindices (I, J, K). The index K specifies the cell layer, and the top layer is always K=0. J and\\nI give the position in layer K.\\n8. If the option Set K to max K is selected, the bottom layer will be exported first.\\n9. The user specifies which cell in the layer to be exported first by selecting one of the four\\nCell origin options.\\n10. Finally, the direction J or I to traverse needs to be specified. This means, the reader/writer\\ntraverses the grid along the selected direction.\\n11. Undefined property value: this is an option for the user to set a value to be exported for\\ncells that are undefined in Petrel.\\n12. When finished with the settings, press OK.\\nFigure 1. The ECLIPSE export settings.\\n12.\\nHow to find cell origin, I and J directions of a Petrel grid\\n1. Display your Petrel grid and select Show grid under Settings style (click on the icon Map\\nView Position if the grid is rotated).\\n2. Click on a grid cell with the cursor in \"select mode\", and the cell indices (I, J) will be\\ndisplayed on the Status bar (A property grid will show (I, J, K) indices). Click on other cells,\\nand you will find the cell origin and the I and J directions.\\nNote that undefined Petrel cells are not displayed.\\nExport RESCUE Model\\nThe 3D grid can be exported as a Rescue model. Petrel supports export in Rescue version 19-37.\\nRescue models can be exported in both Binary and ASCII formats, although binary is\\nrecommended since that format works best between Unix and Windows.\\nThe export will create a number of files that can be put into an existing folder or in a new folder\\nthat will be automatically generated.\\nNote that there is an option in Petrel to make a filter sensitive copy of the 3D grid. This copy can\\nthen be exported in any of the available export formats. See Filter Sensitive Export for more\\ninformation\\nHow to export a RESCUE model\\n1. If you want to export a local grid set with the 3D grid, make sure it is active (bold).\\n2. Open the pull-down menu of the Petrel 3D grid to be exported by right clicking on the grid\\nin the Petrel Explorer.\\n3. Select Export Rescue Model to open the Export dialog.\\n4. Select file format: Binary or ASCII.\\n5. Select Rescue version by entering the version number. Petrel only supports version 19 to\\n37.\\n6. Select properties to be included in the export from the list.\\n7. To choose faults and any fault transmissibility multipliers for exporting, click Faults and\\nselect from the list.\\n8. To choose wells (X,Y,TVD & MD) for exporting, click Wells and select from the list.\\n9. Type in the path or browse for the directory to export the Rescue model files into.\\n10. Type in a name at the end of the string if a new directory should be created.\\n11. Click OK.\\n10.\\n11.\\nExport using the Reference project tool\\nIt is possible to use the Reference project tool to export data from a Petrel project to another\\nPetrel project. For more information on how to use the tool, see the Reference project tool.\\nReference project tool\\nThe Reference project tool is designed to share data between projects. The Reference project tool\\nenables asset team collaboration by comparing data in two different projects in an easy to\\nunderstand manner, where groups of data can be filtered out and you can move subsets of data\\nitems between projects.\\nPrior to using the Reference project tool, your Data Manager should establish projects as\\nReference projects and follow the Petrel Data Management best practice procedure described in\\nthe Petrel Deployment guide (accessible from the Petrel download site (Help > Check for\\nupdates)), and aslo taught in the Petrel Data Management course. These are Petrel projects that\\nhave been designated as Reference Projects by saving the Petrel project with a .petR extension\\n(File > Save project as > selecting Reference project files in the Save as type).\\nBuilding Petrel Template projects before using\\nthe Reference project tool\\nWhen you deploy Petrel into your environment or company, there are many initial steps and best\\npractices that you can put in place. These, in turn, will benefit the Data Manager controlling the\\nPetrel projects and the Petrel data flow. Recommended steps to follow would be to implement\\nbest practices for using the Reference project tool and reference projects and to standardize\\ncoordinate systems. These initiatives will improve the Petrel user experience and productivity.\\nIt is recommended to organize data into predefined folders in Petrel. To standardize this, a Petrel\\ntemplate project can be generated.\\nCreating a Petrel Template project\\nPrior to loading/importing data into Petrel, consider whether you would like to use a Petrel\\nTemplate project. To fully utilize the Reference project tool functionality it is recommended to\\nbuild Petrel Template projects. This template would be used by all Petrel users, similar to how a\\nMicrosoft Word (.dot) template is used so that everyone has the same look and feel for their\\ndocuments. Creating and using a Petrel Template project for all of your Petrel users has these\\nbenefits:\\n Ensures easy data transfers since all user projects have a similar data structure.\\n Provides each user with the same starting point.\\n Propels each user towards organizing data in a consistent manner.\\n Allows consistent data organization throughout a company.\\n Allows for storage of standard organizational workflows (if existing).\\nHow to create a Petrel Template project\\n1. Create a new project in Petrel.\\n2. Set the coordinate system under the project settings.\\n3. Set the Seismic Reference datum (SRD).\\n4. Create the Template project folder structure within the Input pane.\\n5. Customize templates, create predefined windows, workflows, etc.\\n6. Save the project and name it to recognize it as a Template project. Store it in a location that is\\nshared and accessible to all users. Make sure the project is read-only for the users to prevent\\naccidental overwriting.\\n7. Make the stored Template project available for users. There are two ways of doing this:\\na. Send a short cut to the desktop for this Template project .pet file and rename the short cut\\n\"Petrel Template project\" or similar. Make it recognizable for the users that they will launch the\\nTemplate project.\\nb. It is also possible to edit the target field of the Petrel.exe file to point to this Template project.\\nGo to the Program files folder and send the Petrel.exe file as a short cut to the desktop, open the\\nsettings for the new short cut and edit the target field. Enter the full path of the Template project\\nand add quotes in the name of the Template project.\\nMake sure this is the only short cut to Petrel on the desktop. Both ways will force the users to\\nopen the Template project every time they want to run Petrel, meaning that no users should be\\nable to generate a project themselves from scratch.\\nThe use of Template projects is beneficial for the Reference project tool workflow since it will be\\neasier to recognize the folder structures between users.\\nHow to use the Reference project tool\\nThis section will describe how to transfer data between projects by the use of the Reference\\nproject tool. How to match and compare data before and after transferring and also explain any\\ndata specific considerations to have in mind while using the Reference project tool.\\nLaunching the Reference project tool\\nTo open the Reference project tool, go to Petrel\\'s File menu (Ctrl+M), and select Reference\\nproject tool . When the projects are properly launched within the Reference project tool window,\\nthe open Petrel project\\'s data will be displayed in the left pane, while the background project\\n(typically a reference project) will be displayed in the right pane. At this point, you can compare\\ndata between the two projects and transfer data back and forth.\\nYou can also launch the Reference project tool by clicking on a file name in the project\\nhistory under the File menu and keeping <Shift> pressed down at the same time. The selected\\nproject is opened as the background project in the Reference project tool.\\nChoosing the background project\\nYou can open any project as the background project (even if the extension is not .petR) by\\nclicking Open project in the top right-hand corner. Petrel is thorough in regards to opening\\nthe correct reference project and adheres to the following guidelines:\\n1. If you have only transferred data between the open project and one specific reference\\nproject, it will automatically be opened as the background project when you launch the\\nReference project tool.\\n2. If you have transferred data between the open project and more than one reference\\nproject, you will be prompted to choose which one you would like to set as the background\\nproject.\\n3. If you have not transferred data between the open project and a reference project, you will\\nbe prompted to open one from disk.\\nTransferring data between projects\\nYou can transfer data between the working project and the background project by simply\\nselecting the checkbox to the left of the data name. Note that the checkbox functionality is not\\nthe same as in the Input pane or the Models pane, where the selection will result in visualization\\nof the items in the Petrel display window.\\nOnce the data is selected for transfer, the arrows for moving the items (in the center of the tool)\\nturn blue and are activated. You can then transfer the data to the other project.\\nMultiple data items can be transferred across projects in a single transfer. Also, different data\\ntypes can be grouped in a single transfer, such as some items in the Input pane, some workflows\\nand some Models.\\nIf you want to select all data in the project for transfer, simply select the checkbox for the\\nhighest tree node in the project, which is the name of the project.\\nThe following are some guidelines about data transfers:\\n- When transferring data from the working project to the background project, the background\\nproject is automatically saved and data is overwritten when it exists. Transferring data to the\\nworking project does not automatically save the working project; the changes are only updated in\\nmemory. You must save (or \"Save As\") the project to commit the changes. If you exit Petrel\\nwithout saving, the working project is not updated.\\n- Active filters (time stamp or advanced) are always taken into account when transferring data.\\nData selected but later filtered out will not be transferred.\\nTo disable two way transfers, you must make the background project a read-only project.\\nYou can do this by changing the disk-access permissions (make the files read-only or expose a\\nnetwork share folder with restricted permissions). This way, you can prevent accidental updates\\nto the background project while still allowing data to be transferred from it. Petrel will give a\\nwarning to make you aware if the background project is a read-only project.\\n- One difference between the Reference project tool and old data sharing functionality from the\\nsecondary project function from Petrel 2005 is that it is now possible to copy only one node in the\\nmiddle of a sub-tree if this is necessary. For example, it is possible to copy the well trace without\\nany of the logs. The checkbox selection allows you to select all the data in a folder with one click\\nand then unselect individual data that you do not want in the transfer.\\n- Certain objects can only be moved as a whole, for example some of the nodes and their content\\n(children) within Petrel\\'s Input or Models pane. The folders and data inside these objects are not\\nvisible in the Reference project tool dialog. An example of such an object is a velocity model. This\\nrestriction is necessary to ensure accurate data transfers.\\n- In general, when data is transferred between two projects, nothing will be deleted from the\\ntarget, meaning the transfer results only in additions and replacements. For example, when\\ntransferring a well trace, all the logs in the target project are preserved.\\n- When one node represents an entire sub-tree, the entire sub-tree in the target project will be\\nreplaced by the sub-tree in the source project. For example, in the case of the velocity model, this\\nincludes all the horizons.\\nData and folder synchronization\\nWhen you select data for transfer, Petrel may also select the data\\'s parent folder. If the parent\\nfolder does not exist in the destination project, Petrel will transfer the parent folder along with the\\ndata. If the folder already exists, Petrel will just transfer the data. This is called conditional\\nsynchronization.\\nWhen an item is selected, a purple tick mark appears next to the item and a black tick mark\\nappears by the parent data, as shown in the figure below:\\nA purple tick mark indicates a Normal Synchronization of data, meaning that the data will be\\ntransferred as a new object or will overwrite the object if it already exists in the destination\\nproject. The black tick mark indicates a Conditional Synchronization of the data, meaning the data\\nwill only be transferred if it does not already exist in the destination project. The conditional\\nsynchronization is required to parent the object correctly.\\nFor parent nodes, clicking on a purple \"Normal\" tick will turn it to a black Conditional\\nSynchronization. A third click will remove the check mark entirely. For those nodes that are not\\nparents, clicking on a purple \"Normal\" tick will remove the check mark entirely. The Details area\\nType field (at the bottom of the Reference project tool) indicates whether the data will be\\ntransferred as a Conditional or a Normal Synchronization.\\nWhen the object is updated in another project, meaning it already exists and is being\\noverwritten, the folder structure is not updated, even if there is a mismatch in the folder structure\\nbetween the two projects. This means that if well A10 exists in the working project\\'s \"Wells\"\\nfolder, but exists in the background project\\'s \"Wells - A\" sub-folder, updating well A10 in the\\nbackground project will still leave it in the \"Wells - A\" sub-folder.\\nEasily selecting logs for transfer\\nThe Reference project tool allows you to easily select the same well log in multiple wells for\\ntransfer without having to search within each well to specify the individual log.\\nTo easily transfer select well logs, follow this procedure:\\nOn the Reference project tool, click the log selector icon above the project you want to select logs\\nin.\\nThe title of the window indicates which project you are selecting logs in. In this example, the user\\nclicked the log selector icon above the Working Project.\\nThe Select logs window displays, showing a list of the well log types that are available in the\\nproject.\\nChoose the well log you want to select for transfer, and then click OK . The logs of the type you\\nchose will be selected in all the wells in the project where they appear. The wells will be selected\\nas conditional selections.\\nYou may want to select one type of log in all the wells, and another type of log in only a few wells.\\nThe log selector selects the log type you choose in all the wells; however, you can manually select\\nadditional well logs for transfer from a select number of wells.\\nIn this example, the user selected the Perm log for transfer from a small number of wells, then\\nused the log selector to mark the Gamma log for transfer from all wells. The log selector shows\\nthe Perm log as a partial selection as a black checkmark. The Gamma log is a complete selection\\nshown as the purple checkmark.\\nThe tool can also be used to unselect logs that are selected. Simply click the checkbox to clear it\\nand remove the log for selection.\\nChoose to not overwrite data when using the Reference project tool\\nYou can select an object or a group of objects to send or retrieve as a copy. This is valuable when\\nyou want to compare two similar objects in the same project, and you do not want to overwrite\\nthe original object. Objects transferred with the copy mode toggled on will be issued a new GUID\\ntherefore will not match with their counterpart. The full workflow for the complete comparison of\\ndata in the Referance project tool would be:\\n-highlight on both side\\n-compare details\\n-fetch as a copy\\n-compare in Petrel\\n-decide which one to keep\\n-delete copy\\n-fetch/send original\\nItems that are copied into a project are not meant to be stored there permanently. Rather, the\\ncopy function provides a way to compare data and decide which data object to keep and which\\none to discard.\\nTo copy an object, select the copy mode checkbox in the center of the Reference project tool.\\nSelect the items you want to copy from either project and make a normal transfer. Copy works in\\nboth directions.\\nThe copied items will get a \"Copy of\" prefix similar to the behavior in Windows Explorer. Only the\\nparent object in the transfer node will get the \"Copy of\" prefix. The other children items are\\ncopied, but not renamed.\\nSelect well A10 to transfer it as a copy to the background project so you do not overwrite it.\\nSelect the Copy mode checkbox to indicate that you want to send it as a copy.\\nClick the blue arrow to send the well to the background project.\\nCopy of A10\\nappears in the background project as a copy of the original well as shown below. Note that none\\nof the logs have the \"Copy of\" prefix. They are actual copies of the well\\'s logs, but none of the\\nobjects under the main node are given the \"Copy of\" prefix (just as in Windows Explorer).\\nIn the example below, the Well Tops 1 folder was selected for copy. It appears in the Reference\\nProject with the \"Copy of\" prefix in the main node heading. Note that none of the objects in the\\nCopy of Well Tops 1 folder have the \"Copy of\" prefix.\\nSome items can be copied, but the parent of the selected item is forcibly copied. For\\nexample, if you select a well log to be fetched as a copy, it is done, but the well is fetched as\\n\"Copy of\" well and the log is not renamed. Well tops and fault models are also fetched using this\\nmodel.\\nIn this example, the Perm log in the B2 well was copied to the background project. In the\\nbackground project, the well log is located under the B2 that is given the \"Copy of\" prefix. Also\\nnotice that Copy of B2 and its Perm log do not match any more with B2 and Perm in the working\\nproject (see purple icon in the background project) because both of them have been issued a new'},\n",
       " {'header': 'GUID. ',\n",
       "  'content': 'Chasing data\\nWhen transferring data, Petrel analyzes the data that has been selected for transfer and\\ndetermines if the data has dependencies on other data which should also be transferred. This is\\ncalled data chasing. These are mostly common sense dependencies. For example well logs cannot\\nexist without their well. If you transfer well logs, Petrel makes sure that their well is transferred in\\ncase it does not exist on the other side. In some other cases this dependency is not so trivial but -\\nthanks to data chasing - Petrel will take care of it. For instance if you transfer seismic data, its\\nvintage is automatically transferred even though you did not select it in the Reference project\\ntool. Another example is non-existing templates. If you transfer a log for instance, and its\\ntemplate does not exist on the other side, it will be automatically transferred by Petrel.\\nThere are some data that depend on other data that must be separately selected for transfer\\nbecause Petrel does not perform chasing automatically. You will need to select and transfer both\\n(or all) items to successfully update your target project. One example is when transferring seismic\\ninterpretation. As interpretations are linked to the survey folder (which stores the geometry) you\\nhave to transfer the survey folder first, and only after it is present in the working project, transfer\\nthe interpretation. Petrel will warn you when you have selected seismic data for transfer because\\nit requires additional selections to be complete. In addition to this, there are other dependencies\\nwhich are not chased by Petrel and they are not required. For example you can transfer a 3D\\nwindow without transferring all the objects that are visualized in it.\\nMatching and Comparing data\\nPetrel uses a simple matching rule to help guide you as to what data should be transferred. First,\\nit checks what data matches with the data in the other project. This matching is done by seeking\\na pair of data items that have the same Petrel identifier. Petrel uses globally unique identifiers\\n(GUIDs) to identify the data item. If a match is found, Petrel compares the time stamp of the last\\nupdate to find out which project has the newer version of the data item.\\nOnce Petrel has determined the matches, all data in the projects will be marked with one of the\\nfollowing icons:\\n- Indicates that a counterpart was not found in the other project (might be intended to be\\nthe same data, but the objects have different GUIDs)\\n- Indicates that the counterpart is the same (has the same time stamp)\\n- Indicates that the data item is newer\\n- Indicates that the counterpart is newer\\n- Indicates that at least one data item\\'s time stamp status differs from this node\\'s\\nFor wells, you can specify other match criteria, besides having them match based on the\\nGUID. See the section titled \"Well Matching in the Reference project tool\" for more information.\\nNote that the following steps will create an object with a new GUID:\\n1. Create an object via a process (such as the make/edit surface process which creates a new\\nsurface)\\n2. Copy and paste an object in the Petrel Explorer tree\\n3. Import an object via File> Import using an ASCII file or via the OpenSpirit transfer method\\n4. Use the copy mode in the Reference project tool\\nThe following steps will create an object without a new GUID:\\n1. Import an object via the Reference project tool (copy mode toggled off)\\n2. Copy and save the entire project using the File > Save As option or copying the entire\\nproject using Windows based tools.\\nSpecial Considerations for some objects\\nSome objects will always match in the Reference project tool. These objects are\\nWells main folder and all the Vintage folder Flow constraint IDs under Input\\nfixed sub-folders\\nLight source folder under Flow control folder under Input\\nDatums under Templates Windows\\nSymbolic time set folder under\\nVariables under Workflow Cursor tracking under Input'},\n",
       " {'header': 'Windows ',\n",
       "  'content': 'Default templates under Well-flow sets/Well\\nTemplates Well cost models folder segmentation folder under Input\\nunder Templates\\nVolumetrics folder under Fluids folder under Input\\nResults Optimized wells folder\\nPVT folder under Input\\nSeismic main folder Proposed wells folder\\nSaturation functions under Input\\nSurvey filter folder\\nRock physics folder under Input\\nDevelopment strategy folder\\nunder Input\\nFiltering data\\nWhen you use the Reference project tool, you rely on the icons next to the object name to let you\\nknow if an object is older, newer, equal to, or has no counterpart to an object in the background\\nproject.\\nWhen an object in a folder is of a different status than the folder itself, an exclamation point\\ndisplays on the folder\\'s status icon.\\nIf there is no exclamation point indicator on top of the equal sign, then all the objects in the folder\\nshare the same status as the parent folder.\\nIf you are just interested in viewing or transferring data based on its time stamp comparison, you\\ncan filter the data in the project to show just that subset of interest. For example, if you do not\\nwant to see data that is equal in the projects, you can click the filter option . This will remove\\nall the data from the tree that is equal to its counterpart.\\nThe Reference project tool allows you to filter out data in one or more of these groups:\\nClicking on one of the filter option\\'s icon will toggle that filter on and off. Filters for the working\\nproject and the background project are applied separately.\\nSometimes you see data items displayed in the tree with an exclamation mark on their\\nstatus icon whereas they should disappear according to the time stamp filter settings. The reason\\nis that these data items have children which still fulfill the filter criteria and they cannot be\\nvisualized without their parents. If the filter symbols do not seem to reflect the actual situation,\\nopen up the sub-folders to view the child nodes and see the correct filter symbols. You can\\nexpand and collapse the entire sub-tree by right-clicking on an object. For example, suppose a\\nparent Models node has an equal status and the Models sub-tree is collapsed, but one of its 3D\\ngrids has a newer status. Toggling off the equals filter will leave that Models node (and its equals\\nicon) showing, since one of its child nodes, the 3D grid, has a newer than status. You need to\\nopen up the sub-tree to find this item.\\nFiltering based on a shape, rectangle and saved search\\nAreal filtering allows you to filter data in a project based on a shape. A shape is any object that\\nhas a minimum/maximum X and a minimum/maximum Y value.\\nOnce you specify a shape, the bounding rectangle is \"drawn\" based on the minimum/maximum X\\nand minimum/maximum Y coordinates. The Reference project tool filters the trees based on the\\nsmallest rectangle that defines that object.\\nThe filter creates a rectangle still based on the minimum/maximum X and minimum/maximum Y\\ncoordinates, but is now including some regions that are not technically within the shape itself.\\nIn the figure below, refer to wells A, B, and C. A bounding rectangle is created around the\\nspecified shape. Well A is included, as expected. Well C is ignored, also as expected. However,\\nwell B is included in the filtered data because it is inside the bounding rectangle, even though it is\\nnot within the shape.\\nData without geographical information will always be visible, regardless of the filter settings.\\nTo specify the filter criteria, follow this procedure:\\nClick on the filter icon above the project that you want to filter.\\nThere are several different options you can choose for your filter. You can combine the spatial\\nfilter criteria and criteria from a saved search within the project, or apply them separately. These\\nare the various options you can use to set the filter criteria:\\n- Select Spatial filter for wells and geographical data as shown below.\\n- To enter a shape from your project, select it in the Petrel Explorer pane and click the blue arrow\\nnext to the Petrel shape field. Notice that the minimum and maximum values for X and Y are\\nautomatically populated in the Extents section. You can only add an object from the project you\\nare filtering.\\nThe minimum and maximum X and Y values are based on the object you select.\\nAlternatively, you can manually set the X and Y values without selecting an object, or after\\nselecting an object.\\n- If you want to manually adjust the minimum and maximum settings, click Extents to make the\\nfields editable.\\n- Click Include objects that are partially within the range to keep objects that do not fall\\ncompletely within the specified range, but are included.\\nFilters accept saved searches only from the current project where you are creating the filter\\n(working to working and background to background). You can apply a saved search that is\\ncurrently in the project to act as an additional filter. Click Additional filter for wells only , then\\nspecify a search in the Saved searches drop-down menu.\\nShapes are handled differently. If you are setting a filter in the background project, you can\\nselect a shape from the working project.\\nOnce you have specified all of the filter criteria, click OK to close the window. The active filter is\\nindicated in the Reference project tool as shown below. You can reopen the filter window at any\\ntime to change the criteria for the filter.\\nWhen you filter wells, well top information is also filtered.\\nIn this example, the user has chosen to display only the wells in the project beginning with \"C\"\\ninside the specified shape. The information shown in the Well Tops folder relates only to those\\nwells.\\nTo turn off the filter, click the filter icon again, clear all the settings, and click OK .\\nRefreshing the data trees\\nYou can refresh the list for both projects by clicking Refresh which is located in the upper right\\ncorner of both project panes. The working project is refreshed based on the latest transfers, or\\nany changes you have made outside of the Reference project tool (directly in the Petrel tree).\\nClicking Refresh on the background project side will update the background project according to\\nthe last transfers and transfers that other users have made.\\nUsing projects from previous Petrel versions\\nPetrel projects saved in version 2007 and newer can be used as reference projects with no issues.\\nSome restrictions apply to the use of projects created with versions of Petrel prior to 2007:\\n1. You can use these projects as read-only background projects. You can transfer data from\\nthe project; you just cannot transfer data to the project.\\n2. Seismic data in these projects is not visible in the Reference project tool. As a workaround\\nto see the seismic, save the project in the Petrel 2007 or newer format, and re-open it as a\\nbackground project.\\n3. Comparison information should be ignored because the way in which comparisons were\\nmade in previous versions of Petrel is different than how they are made in Petrel versions\\n2007 and newer.\\nUnits and coordinate system considerations\\nThe Reference project tool is units and coordinates aware. Projections and units within the two\\nprojects must match for the Reference project tool to fully enable transfers. Some exceptions apply:\\n1. If the units and coordinates do not match, you can still transfer workflows and windows, as\\nthese objects do not have a coordinate systems or units impact. When it comes to Petrel Spatial\\nproject (read more under Spatial enablement) ,\\nthe Reference project tool will support coordinate conversion of supported data items. This\\nopens the door for companies to minimize data duplication by creating a set of a spatial aware\\nmaster project where the user transfers data into their working project in a different coordinate\\nsystem. When there is a coordinate system mismatch between the working project and the\\nbackground project, the Reference project tool\\'s data trees are filtered so the user can only\\ntransfer and coordinate convert supported data. When there is a coordinate system mismatch, a\\nwarning will appear to warn the user that only spatially supported data items will displayed in\\nthe Reference project tool.\\n2. Keep in mind that template units must match to be able to transfer templates by the use of the\\nReference project tool. The Reference project tool will check unit consistency between the\\ntemplates in the working project and the background project, especially all predefined templates\\nand user-defined templates with matching GUIDs. The usage of, for example, Caliper template\\nunits must be consistent throughout the communicating projects and not altered after imported.\\nIf there are any mismatches between template units, there will be a dialog displayed listing the\\nmismatched pairs.\\n3. If the background project does not have a coordinate system value, data can still be copied, but\\nthe Reference project tool will warn you about it.\\nPetrel will assist you in ensuring that units and coordinates are matched, under limited circumstances:\\nIf the working project is empty or the working project\\'s coordinate system and/or unit is not set, the\\nbackground project\\'s unit and coordinate system values can be copied from the background project.\\nAdvanced alteration allowing transfer of mismatched template units\\nThere is a possibility to alter the petrel.exe.config file to allow transfers of mismatched template units\\nto be done with the Reference project tool. This is only recommended to be used when the user\\nunderstands the impact it will have on the asset team\\'s reference project network data flow. To enable\\nthe transfer simply open the petrel.exe.config file and add the following flag:\\n<add key=\"allowRPTCopyWithTemplateUnitsMismatch\" value=\"On\"/>\\nAdvanced alteration allowing selection of variants of ft\\nThe petrel.exe.config can be extended to allow variants of ft, which are used in some OpenWorks and\\nGeoFrame coordinate systems. To enable this, add this following section to the config file:\\n<appSettings>\\n<add key=\"enableFtSearsAsLengthUnit\" value=\"On\"/>\\n<add key=\"enableFtUSasLengthUnit\" value=\"On\"/>\\n</appSettings>\\nOnce enabled, users can choose ftUS and ftSears as variants. Petrel does not store these units as\\nproject units, but as standard ft and a modifier flag.\\nThe Reference project tool must ensure that not only the units are the same, but also the modifiers,\\nwhich are stored as booleans in the ProjectStyle and ProjectUnitsStyle. These flags are accessible via\\nProjectStyle by:\\nbool getUnitXYisUSFeet() const;\\nbool getUnitZisUSFeet() const;\\nbool getUnitXYisSearsFeet() const;\\nbool getUnitZisSearsFeet() const;\\nWhen copying data into an empty project the flags need to be copied as well using the ReasonId\\nsetUnitXYisUSFeet(bool in);\\nReasonId setUnitZisUSFeet(bool in);\\nReasonId setUnitXYisSearsFeet(bool in);\\nReasonId setUnitZisSearsFeet(bool in);\\nUnit conversions Petrel 2010.1\\nIssues related to import/ export are altered because the Ocean unit service uses more accurate\\nconversion factors. In general, Petrel 2010.1 honors the \"number of decimals\" set in templates for\\nmore values than previously.\\nSome inconsistencies in scaling factors used for unit conversions in Petrel 2009.2 are now corrected\\nautomatically in Petrel 2010.1:\\ng/cm (grammes per centimetre): conversion to/from SI\\n2009.2: g/cm = 100 kg/m\\n2010.1: g/cm = 0.1 kg/m\\ng/m (grammes per metre): conversion to/from SI\\n2009.2: g/m = 1 kg/m\\n2010.1: g/m = 0.001 kg/m\\nBtu/(s.degF.ft) (Btu per sec per Fahrenheit per foot): conversion to/from SI\\n2009.2: Btu/(s.degF.ft) = 2080.0411 W/(m.K)\\n2010.1: Btu/(s.degF.ft) = 6230.64479893701 W/(m.K)\\nh/cm3 (oil non Darcy D factor): conversion to/from SI\\n2009.2: h/cm3 = 3.5999E10 s/m3\\n2010.1: h/cm3 = 3.6E9 s/m3\\n(cP.cm3)/(h.atm) (cp cubic centimetre /hour /atm): conversion to/from SI\\n2009.2: (cP.cm3)/(h.atm) = 1.14227E-19 m3\\n2010.1: (cP.cm3)/(h.atm) = 2.74145351865559E-18 m3\\nMolar masses (in the \"mol\" unit) are now displayed in the correct SI\\nPetrel 2009.2: 1 mol = meaning 1 kg-mole\\nPetrel 2010.1: 1000 mol =meaning 1000 gm-mole\\nData specific considerations\\nChanges to object properties such as attributes (for wells and horizons) must be handled in a\\nsequential manner. These cannot be edited simultaneously by two different users in two different\\nprojects and sent back to a reference project. (If this is done, the work done by the first user will\\nbe lost). In this case, the users must work sequentially. This limitation does not apply to well tops\\nwhere individual well tops can be updated independently. Attribute definitions can also be updated\\nindepdently.\\nWells folder\\nWhen copying the wells folder between projects, changes in time settings within the wells folder\\nwill not be synchronized. To synchronize the time settings for wells, you must synchronize the\\ntime logs.'},\n",
       " {'header': 'Wells ',\n",
       "  'content': 'Typically, a well is marked with an equal icon after a copy. Sometimes, such as when a comment\\nlog is added, the wells will be marked as newer. This is because the well log specifically caused a\\nrecomputation of the well information.\\nUnexpected well time stamps\\nWhen upgrading projects from Petrel version 2005 to 2007 or newer, the time stamps for all data\\nis set to the time of upgrading. The reason for this is that the time stamp was introduced in Petrel\\n2007. The only place it is possible to see the time stamp used by the Reference project tool is by\\nselecting the object data item and looking at its Detail information.\\nSometimes, there is no correlation between the time stamp for the last history of an item (as\\nseen in the Properties dialog) for a well and the time stamp used by the Reference project tool.\\nThis is because the well can be updated by well-related objects like well tops and logs, but Petrel\\ndoes not consider this to be a change to the well itself. For example, if you change the time log\\nfor a well, the time stamp in the Reference project tool for the well is updated. However, the time\\nstamp for the history of the well in the Properties dialog is not updated.\\nSometimes, the well (or any other object) may not be regarded as updated by the Reference\\nproject tool when a minor attribute is updated. In such a case, consider the following workaround:\\nUpdate a major attribute (such as the name of the object) from the settings dialog and select\\nApply, and then change the name back. Now, the object will be marked as updated in the\\nReference project tool.\\nWell logs\\nConsider the following when transferring well logs:\\n- When transferring well logs, it is not possible to select the well log in the Global well logs folder.\\nInstead, for transfer, select the well log appearing within the well name (such as Producers >\\nA10) or use the advanced well log selection tool (toolbar with icon highlighted) to select the same\\nlog for multiple wells\\n- When copying well logs using Reference project tool, the corresponding log template under the\\nGlobal well logs will be copied, but only if it does not already exist in the target project. Therefore,\\nif the name of a log template is modified in the background project, this change will not be\\nreflected in the working project, if a log template with the same GUID already exists. In this case,\\nthe only way to propagate the change to the working project is to explicitly select the log\\ntemplate in the Reference project tool and transfer it.\\n- When transferring ELAN logs, the folder structure for the log templates will not always be copied\\ncorrectly.\\nDerived Well logs\\nGlobal settings apply to all connected logs, unless they have local settings. Derived logs can be\\nset to use either the local settings or the global settings. The derived logs appear in the Reference\\nproject tool as a node and can be selected for transfer like any other Petrel object.\\nWhen a derived log is copied using Reference project tool,\\n1. The derived log itself is copied\\n2. The derived logs values are copied\\n3. If the derived log has local settings, these are copied\\n4. The derived logs log template (incl. the global derived settings) is copied\\n5. If the input for a derived log is replaced using the Reference project tool, then the new copy\\nwill end up unchecked at the end of the list in the settings for the derived input\\n6. The values for all derived logs are regenerated at the end of each transfer, regardless of\\nwhether the input or settings are changed\\nNote that the log template will be replaced each time a derived log is copied, regardless of\\nwhether the derived log has local derived settings or not. This may result in the values and\\nderived settings becoming inconsistent for all derived logs after the copy of one derived log.\\nThe derived settings are lost when the input objects are replaced. Objects that are input to\\nderived logs, will be removed from the input list and be inserted at the end, unchecked. To fix\\nthis, the derived settings must be updated manually.'},\n",
       " {'header': 'Checkshots ',\n",
       "  'content': 'In general, the Reference project tool treats a checkshot folder as one data item. This means\\nchanges made to individual checkshots will still require the user to transfer the entire folder.\\nWell tops\\nConsider the following when transferring well tops:\\n- The selection mechanism for well tops is slightly different than other objects (See figure 1):\\nWhen you select a well filter for transfer, the Reference project tool transfers all of the wells\\nassociated with that well filter. If the wells do not exist in the working project, they will be\\ncreated; if they already exist, they will be updated. The well filters will be regarded as\\ncounterparts provided that the well tops subject they belong to are counterparts and that\\nthe names of the well filter (i.e. the name of the well if the filter is linked) are the same. If a\\nproject has several well filters connected to the same well (or, in fact, to wells with the\\nsame name), they will all be regarded as counterparts to the first well filter in the working\\nproject with the same name. Thus, copying all these well filters to the working project will\\n\"merge\" the well filters into one.\\nWhen you select an item from the Stratigraphy, Faults or Others node for transfer, the\\nReference project tool transfers all of the data belonging to the selected item. Put another\\nway, this is equivalent to selecting all well tops belonging to that interpretation in the\\nspreadsheet. All well tops for this interpretation are removed from the working project and\\nnew rows are created for those elements that exist in the background project. If the\\nbackground project contains a custom attribute, it will not be transferred. However, if the\\ndata does not exist in the working project, it will be created.\\nWhen you select an attribute for transfer, the Reference project tool transfers the values in\\nthe attribute column. If the attribute does not exist (such as for user-defined attributes), it\\nwill be created; if it already exists it will be updated. Attribute values in the background\\nproject that do not have corresponding records in the working project are ignored. Likewise,\\nworking project records not present in the background project are left unchanged. When\\nderived data is transferred, no regeneration of derived data takes place in the working\\nproject.'},\n",
       " {'header': 'Figure 1 ',\n",
       "  'content': '- Note that in Petrel, inside one given Petrel project, attributes can either be plain, calculated or\\nderived. The values for a plain attribute are typically those that are specified by the user. The\\nvalues for a calculated attribute are calculated from other data. When the input data are changed,\\nthe calculation must be reapplied manually to update the calculated values. The values for a\\nderived attribute are derived from other data. When the input data are changed, the derived\\nvalues are updated automatically. When derived attributes are copied using the Reference project\\ntool, the derived values are recalculated only if the source data is present in the project. The\\norder of transferring the source and the derived attribute is irrelevant. You can transfer the\\nderived attribute first, then the source data later or the other way around, even in a separate\\nsession.\\n- If you copy well tops but not the well tops attributes explicitly, the well tops will inherit the\\nstandard set of attributes.\\n- Individual well tops (markers) are identified by their GUID. This means that even if the working\\nproject has a marker of the same horizon assigned to the same well, transferring this data will\\nresult in a duplicate, since they do not have the same GUID\\n- User-defined attributes are matched by GUID. This means that even if the working project and\\nthe background project both have an attribute with the same name (say, \"My attribute\"),\\ntransferring this to the working project will result in duplicates (two attributes named \"My\\nattribute\"), when they do not have the same GUID.\\n- Changing attribute operation settings for an attribute will potentially change all of the well tops\\nvalues for the attribute. To avoid a ripple effect to other attributes, only the current attribute is\\nmarked as newer when it is changed.\\n- The settings for calculated and derived attributes are stored on the well tops folder. These\\nsettings are copied when the folder itself is copied.\\n- The derived settings are lost when the input objects are replaced. Objects that are input to\\nderived attributes, will be shown in the settings page, but the derived values are not updated\\naccording to changes to the input. To fix this, the settings must be changed, applied and then\\nchanged back and applied again.\\n- Note that some attributes are not available in the Reference project tool, but the values for\\nthese attributes will be copied when the row is copied. These attributes are \"X\", \"Y\", \"Used by\\ndep. conv.\", \"Used by geo mod\", \"Symbol\", \"Well\", \"Start MD\" and \"Zone Log\". Copying these\\nvalues using the Reference project tool will potentially create inconsistencies. Such inconsistencies\\ncan be resolved by the user choosing to run \"Synchronize XYZ\\'s\" from the well tops context\\nmenu. This is illustrated below in Figure 2:'},\n",
       " {'header': 'Figure 2 ',\n",
       "  'content': '- In Petrel 2007.1, a time stamp for object comparison was introduced. You can only view this\\ntime stamp in the Reference project tool when you select the data item and look at its Detail\\ninformation (Note that this time stamp is different than the time stamp for data in the Properties\\ndialog). For example, changing the well tops value for TWT picks will not affect the time stamp for\\nthe TWT-picked attribute. However, other types of changes to the attribute will change the time\\nstamp.\\nIf you update an attribute in the spreadsheet, it will only be flagged on the corresponding\\nwell top listed under the associated well in the well filter folder. Updates made to the attribute\\nusing the attribute calculator, as well as changes made in the settings for the attribute, will be\\nflagged on the attribute itself (which resides under the well tops folder).'},\n",
       " {'header': 'Models ',\n",
       "  'content': 'Consider the following when transferring models:\\nTransferring a model from the working project to the background project does not\\nautomatically set it to \"active\", even though there are no other active models in the\\nbackground project. To enable the transfer, you must manually set the model to active.\\nTransferring a model from the background project to the working project sets the model to\\nactive if there are no other active models.\\nIt is possible to copy grid properties for a grid separately. You can select individual grid\\nproperties and a local grid, or just a local grid (with no properties) for transfer. For the\\nproperties alone to be successfully transferred, the grid dimensions in both projects must\\nmatch exactly.\\nIf the grid already exists in the working project, then only the attribute or selected local grids will\\nbe transferred. Attributes or local grids that are already present for that grid in the working\\nproject will not be changed if they are not selected.\\nIf you select attributes or a local grid that does not exist in the working project, the grid will be\\ntransferred as well.'},\n",
       " {'header': 'Cross Sections ',\n",
       "  'content': 'Consider the following when transferring models:\\nIt is necessary to copy the following when transferring a cross-section between two projects.\\nThe data that is displayed in the cross section (if they do not already exist in the project)\\nThe templates for the data (if not, the default templates will be used)\\nThe intersection window itself'},\n",
       " {'header': 'Well Sections ',\n",
       "  'content': 'Well sections can no longer be copied directly from the templates node. To copy well section\\ntemplates, first copy the Well section window (where the template is applied) to the working\\nproject, then select to use a well as template and finally apply the template to all the wells in the\\nwell section.\\nHow to locate your Reference projects\\nThe Reference project tool remembers the background projects that have been used\\npreviously. Each time a transfer is made, the transfer is \"recorded\".\\nRead more under Choosing the background project .\\nTo view all background projects (or reference projects) that have been used for transfering data\\nwith the working project, click List the reference projects .\\nThe References for working project window opens, as shown below, listing all previously used\\nreference projects as well as whether they are still located in the same directory path (exists) and\\nhow many times the working project has transferred data with the specific project (References).\\nTo open a different reference project, select it and click Load . To update the path to a reference\\nproject, click Change . To remove a project from the list, select the one you want to remove,\\nclick Load and locate a project which is already on the list but different from the one you want to\\nremove.\\nWell Matching in the Reference project tool\\nThe Well matching feature in the Reference project tool allows you to declare a different\\nmatching criterion for wells, rather than just matching based on the GUID. A common situation\\nwhen trying to match data from different projects, is to have a number of wells that you know are\\nidentical, but have been loaded into each project separately, such as via an ASCII load, thereby\\ngetting two separate GUIDs. They are the same well, but since they have separate GUIDs, the\\nReference project tool treats them as unmatched. One key point about Petrel is that data\\nitems are related and linked to each other. By using the Well matching feature, you are\\nspecifying that the wells are the same based on criteria such as UWI or surface location. Once you\\ndeclare the wells are a match and transfer data dependent on the wells (such as logs), the\\nReference project tool will keep links between the dependent data and the wells intact.\\nOnce you declare the matches, the newly matching wells will appear as matched in the\\nReference project tool. These matched entities can be moved from one project to another as if\\nthey were matched by GUID.\\nExisting GUID matches will not be affected by the Well matching tool, it will only match\\nwells that could not be matched base on their GUIDs\\nMatches are not remembered; the intention is to declare the match, and then synchronize\\nthe wells and dependent data such as logs and well tops so that in the future, there is not data\\ndisparity. If you close the Reference project tool, the matches must be declared again\\nSpecifying well matches\\nNotice that in the Reference project tool below, there are several unmatched wells. These wells\\nare shown with the purple unmatched icon .\\nTo declare these wells as matches, click the Well matching button. The Well\\nmatching dialog opens:\\nYou can declare matches based on specific criteria (Advanced mode) or by manually selecting a\\nwell from each side and declaring it a match (Manual mode).\\nHow to match wells in Advanced Mode\\nYou can match wells based on the following criteria:\\n- Well name: matches if the well names are identical\\n- Unique well identifier: matches if the Unique Well Identifiers (UWIs) are identical\\n- Surface location, Bottom hole location: matches if the tolerance between the two well\\nheads or two bottom hole positions is less than that specified\\n- KB Elevation: matches if the vertical difference of KB elevations is less than the tolerance\\nspecified\\n- Total depth: matches if the difference in total length of the well, from first point to last point, is\\nless than the tolerance specified\\n- Number of points in well trace: matches if there are less unequal points in the well trace\\nthan the tolerance specified\\nUnits shown are derived from the units set for the project.\\nSelect one or more of the match criteria, and click Apply. Note that only those wells that meet all\\nof the selected match criteria are considered matches.\\nFor example, the criteria below declares wells to be the same if they have the same name, are\\nwithin 10m on the surface, and KB is within 5m:\\nIn our example, clicking Apply results in the following matches, which are shown in the Match\\nreport:\\nThe Match report allows you to verify that the match criteria you specified was correct.\\nTo have a record of the matched wells, click Export. A comma-separated values (.csv) file is\\nproduced for the matched wells. The report shows the criteria you specified and also includes the\\nGUIDs for the wells.\\nEach match has a check mark next to it. Select which matches you would like to approve, and\\nclick OK. The approved matches are populated back into the main Well matching dialog in the\\nbottom pane, as shown below:\\nWhen there are multiple matches for a given well, the tool picks the first available match. In\\nmost cases, you can eliminate multiple matches by using more criteria or lower tolerances.\\nTo undo a match from those shown in the bottom pane, select the match, and return it back to\\nthe unmatched group, by clicking the blue up arrow.\\nHow to match wells in Manual Mode\\nAnother method for declaring matched wells is by manually selecting a well from each side. You\\ncan do this by clicking the Manual tab in the Well matching dialog:\\nAll unmatched wells in each project are shown within their tree. You can declare two wells to be a\\nmatch by selecting them in both lists and clicking the blue down arrow. The matched wells are\\nthen moved to the bottom pane. For example, in the above dialog, wells A10 are being declared\\nas a match.\\nYou can undo a match by selecting the wells (A15 shown selected above) and returning it back to\\nthe unmatched group, by clicking the blue up arrow.\\nTo export the unmatched wells information to a CSV file, which can be viewed in Microsoft Excel,\\nclick Export. The report shows the criteria you specified, and also includes the GUIDs for the\\nwells.\\nThe Export feature works even when a background project is not loaded. This allows you to\\nexport information on all the wells in the project for any data management purpose. This is only\\napplicable to the Export button on the Manual tab (not the export option in the Match report\\ndialog).\\nThe well matcher will work even if there are units or coordinates mismatch. However, the\\nstandard limitations on the Reference project tool will prevent data transfers if the units or\\ncoordinates are mismatched.\\nViewing the results of the matched wells in the\\nReference project tool\\nOnce you have all intended matches in the bottom pane of the Well matching dialog, click Close\\n. The wells you have matched are then compared by the Reference project tool and the time\\nstamp status is updated, as shown in the below dialog with wells A15 (the only one that was\\nselected not to be matched):\\nAt this point, you can transfer data between the matched wells with all of their child data\\nrelationships (such as models) remaining intact.\\nKnown limitations of the Reference project tool\\nInaccuracies in time stamps\\nThe Reference project tool works by comparing internal data time stamps. This time stamp is\\ncurrently visible in only one place: the Reference project tool, when you select data and view the\\nDetails time stamp information. There are some inconsistencies around when a data item is\\nconsidered to be updated. For example, changing the well tops values for TWT picked will not\\naffect the time stamp for the TWT picked attribute. Other changes to the attribute itself will\\nchange the time stamp. In another case, changes to the values of well tops values will not only\\nmark the well tops as changed, but will also mark the well filters and horizon as changed. The\\nreason for this is that currently the only way to copy well tops are through their related well filter\\nor horizon.\\nWhen upgrading projects from Petrel version 2005 to 2007 or newer, the time stamps for all data\\nis set to the time of upgrading. The reason for this is that the time stamp was introduced in Petrel\\n2007. The only place it is possible to see the time stamp used by the Reference project tool is by\\nselecting the object data item and looking at its Detail information.\\nSometimes, there is no correlation between the time stamp for the last history of an item (as\\nseen in the Properties dialog) for a well and the time stamp used by the Reference project tool.\\nThis is because the well can be updated by well-related objects like well tops and logs, but Petrel\\ndoes not consider this to be a change to the well itself. For example, if you change the time log\\nfor a well, the time stamp in the Reference project tool for the well is updated. However, the time\\nstamp for the history of the well in the Properties dialog is not updated.\\nData not showing as equal after being transferred\\nWhen transferring data, in some cases the transferred data appears to be newer than the original.\\nThis is caused by the fact that the transferred version is actually modified after being inserted in\\nthe working project.\\nAn example of this is when transferring well top\\'s well filters. If the original well filter is linked to a\\nwell and the well does not exist in the working project, the transferred well filter will be unlinked\\nin the working project. This operation will update the time stamp for the well filter.\\nAnother example is when transferring wells with a time log. The wells folder (and not the\\nindividual well) defines how the time logs are calculated (such as depending on the well tops). In\\nthis case, as soon as well tops appear for the well, the time log is always recalculated. When the\\ntime log is recalculated, the time stamp for the well and the well log is updated. In addition, when\\nthe time log is explicitly changed, the well is changed when viewed in the time domain. This\\nconfuses some users who expect the transferred well to be equal, but more likely; the transferred\\nwell will be tagged as new.\\nErroneous visualization states\\nIn some cases, the visualization state for data is not transferred correctly. As a general solution,\\ntry one of the following: Copy the window one more time or set the visualization state manually.\\nThe erroneous visualization states are related to the following:\\n- The Results tree where the visualization information is not copied at all. In this case the only\\nsolution is to manually set the visualization state\\n- Well section tracks where the order of the tracks will be changed. In this case, the well section\\nmust be transferred from the background project to restore the order.\\nStyles not transferring correctly\\nThe information in the Styles pages is transferred along with the data. This transfer does not\\nalways produce the correct result.\\nOne such example is a grid property where isosurfaces are defined. If this property is transferred\\nusing the Reference project tool, the isosurfaces will not be visible in the working project.'},\n",
       " {'header': 'Well Sections ',\n",
       "  'content': \"Well Sections can no longer be copied directly from the templates node. To copy well section\\ntemplates, first copy the well section window (where the template is applied) to the working\\nproject, then select to use a well as template and finally apply the template to all the wells in the\\nwell section.\\nSeismic Survey parameters are not verified in the working project\\nWhen seismic data is transferred, the survey parameters are not verified in the working project. If\\nthe survey has interpretation associated with it in the working project, it will no longer fit. The\\nuser should make changes to the survey parameters only when interpretation is not associated\\nwith the project in any linked projects.\\nVisual attributes set to default\\nWell tops can have three visual attributes: visual vertical position, dip azimuth and dip angle. The\\ntwo latter types can only be defined for stereonet windows. When a well tops object is\\ntransferred, these values will be set to the default value, regardless of the settings in the\\nbackground project.\\nChange time-depth relationship\\nWhen the user change time-depth relationships for wells, the user will not see any updates in the\\nReference project tool. The explanation: These changes are assigned to the 'Global time 1' in the\\n'Global well logs' folder, but this object is not exposed in the Reference project tool.\\nReal-Time Data Link in Petrel\\nThe Real-Time Data Link component accepts streaming real-time data, such as logs, events and\\ntrajectories from InterACT* as well as other third-party WITSML data and files servers.\\nIn Petrel, the Real-Time data link maps wellbores from real-time data servers to the wells and\\nallows mapping of data channels to logs. Data is immediately incorporated into Petrel for real-\\ntime sessions or modeling.\\nThe Real-Time Data Link allows rapid assessment of the impact of the new geological knowledge\\non the well being drilled, enhancing understanding and improving collaboration.\\nThe Real-Time Data Link interface is available from any single Petrel well, via the well right-click\\nmenu. The real-time data will display in the 3D and well section windows. The data is immediately\\nsaved in Petrel formats and available for real-time sessions or modeling in all related Petrel\\nworkflows.\\nReal-Time Data Link accepts data in WITSML 1.2.0 and 1.3.1 format only. For more\\ninformation, refer to www.witsml.org.\\nSetting up Real-Time Data Link\\nPetrel Real-Time Data Link Module allows you to load and display well data in real time. You can\\naccess the real-time settings by selecting Project > Real Time Settings.\\nA dialog opens, containing two tabs:\"},\n",
       " {'header': 'Settings ',\n",
       "  'content': 'Log mappings\\nSettings tab\\nThis tab allows you to specify:\\nThe trajectory azimuth reference of grid north/true north.\\nThe depth log samples to load. These log samples can be within the trajectory MD range\\nand deeper, or only within the trajectory MD range.\\nThe time log samples to load. These log samples can be from the latest time or all from the\\nbeginning. This option is only available with the Drilling Visualization plug-in.\\nLog mappings tab\\nThis tab allows you to determine how to map information in data logs to valid Petrel data and\\ntemplates.'},\n",
       " {'header': 'Unit Mappings ',\n",
       "  'content': 'The Unit Mappings pane allows you to set up Petrel so that if your incoming data uses\\nmeasurement units that Petrel does not recognize, you can map the units to a known unit. To\\nmap a unit so that Petrel recognizes incoming data:\\n1. Click the Add row icon to add a row to the grid. If you need to remove a row from the\\ngrid, click the Delete row icon.\\n2. Enter the unit used by the incoming data in the Incoming unit field.\\n3. In the Mapped unit field, select a valid Petrel unit from the list.\\n4. Enter a Scale factor (multiplier) as desired.\\n5. Click OK.'},\n",
       " {'header': 'Template Mappings ',\n",
       "  'content': 'The Template mappings pane allows you to set up Petrel to use a preset log template. To map\\na log to a template:\\n1. Click the Add row icon to add a row to the grid. If you need to remove a row from the\\ngrid, click the Delete row icon.\\n2. Enter the name of the log in the Log Name field.\\n3. Select a valid template from the list from the Template Name field.\\n4. Click OK.\\nConnecting to a Real-Time data source\\nUse the following steps to connect to a real-time data source from Petrel and to view and use the\\ndata:\\n1. Right-click a well and select Connect to Real-Time data link.\\n2. Enter the WITSML Source information and your login credentials in the Osprey Connect\\nwindow that opens.\\n3. Note: By default, the Show Orgs/Fields in tree check box is selected. This will allow you\\nto view the Focus on Source tree using the same structure (organization, field, well,\\nwellbore) from InterAct when you click Select Wellbore.'},\n",
       " {'header': '4. Click Select Wellbore. ',\n",
       "  'content': '5. Expand the Focus on Source data tree and browse to the wellbore you would like to\\nconnect to.\\n6. Click the wellbore and then click Connect to wellbore.\\n7. Select the data channels.\\n8. Click Start Transfer to begin receiving data.\\nIf a different wellbore is attached, you will be prompted to confirm whether you want to\\ndisconnect before the Real-Time Data Link interface loads.\\nIf the incoming channel is not recognized, a Petrel Log Template selection window will\\nappear so that you can manually map the channel to an existing Petrel log template.\\nIf the incoming log has a unit that is not recognized, a unit selection window will help you\\nmap the unit to the correct Petrel unit.\\nIif the incoming log data has a measured depth outside the trajectory range, use the Real-\\nTime Settings to determine how to display the data.\\nFor more information about using Real-Time Data Link, see the Real-Time Data Link online help\\nby clicking Help from the Real-Time Data Link dialog.'},\n",
       " {'header': 'Real-Time Data Link Icon ',\n",
       "  'content': 'The Real-Time data link icon is activated in the toolbar when a well is connected to a real-\\ntime source.\\n1. The icon is grayed out when no connection is established.\\n2. Click on the colored activated icon to end a real-time connection.\\nWriting well log data to Real-Time server\\nThe Real-Time Data Link allows Petrel to write data logs back to InterACT 5.8 WITSML servers\\nusing the Export well log to a real-time server menu option. The write-back functionality is\\nenabled only when you are connected to a well using Real-Time Data Link.\\nUse the following steps to write data logs back to InterACT 5.8 WITSML servers:\\n1. Browse to the well log from where you want to write data.\\n2. Right-click the well log and select Export well log to a real-time server.\\nThe Export well log to real-time server dialog box opens, displaying the Real-Time\\nconnection information. The log file will be written back to the server with the prefix \"PRT_\".\\n3. Click OK.\\nNote: If you selected to write the log to a location where it cannot be written to, an error\\nmessage will appear, prompting you to change the connection settings.\\nThe Real-time exports dialog box appears, displaying the write-back status of the log.\\nNote: You can also view the monitor for each well at the well level by double-clicking a\\ngiven well on the Petrel tree, and then clicking the Real-time exports tab on the Settings\\ndialog box.'},\n",
       " {'header': '4. Click Close. ',\n",
       "  'content': 'Note: You may initiate multiple write-back operations simultaneously and follow their\\nprogress.\\nStratigraphic modeling\\nTo determine the similarity of rock bodies at different locations we can display well data in a Well\\nSection window.\\nBoth lithostratigraphic and chronostratigraphic correlations can be performed.\\nThe Well correlation process in Petrel allows the possibility to bring up multiple wells in a well\\nsection, create marker picks (well tops) and bring up new wells to compare with already\\ncorrelated wells. Also, as new wells are drilled they can easily be zoned. If you are connected to a\\nserver that provides logging data, the well section window is updated in real-time. Well Tops\\n(picks) can be edited by dragging them to their new location, and a depth track can give an\\ninstant depth reading of the new pick depth in, for example, MD, TVD or TVDSS. New well tops\\ncan also easily be interpreted.\\nDifferent types of discrete data, i.e. facies logs and stratigraphic divisions, can also be generated\\nand edited in the Well Correlation process.\\nWell Section with well tops correlation surfaces based on two different logs (here: lithology and\\ngamma ray).\\nWell data Import\\nPetrel handles two types of well data:\\n1. Well path trajectories, with or without logs, included in the unique Wells folder.\\nWell paths help position the well in the 3D and the measurement depth along the\\npath.\\nWell logs are the logs values along the well path. The log data can be displayed as\\npoints. To do so, turn lines off and points on in the global template to display these\\ndata as points. The data can be upscaled into the active grid (use the treat data as\\npoints option). Points cannot be filtered, no spreadsheet display for all attributes, no\\nstereonet display, limited display of dip and strike data in 2D and 3D. It is\\nrecommended for core data.\\nPoint well data can also be imported into the Wells folder. They can be displayed as\\ndiscs, strike bars or dip sticks in 3D, and dip arrows or pie charts in a map window.\\nPoints can also be displayed in a stereonet and filtered on any text attributes they\\nhave. The point well data must be converted to standard points before they are\\nupscaled into the grid. It is recommended for dip and fracture observations.\\n2. Well tops (points)or markers included in one of the Well tops folders. These well picks\\nalong the well path usually represent a change in stratigraphy. You can create three types\\nof well tops:\\nStratigraphic well tops corresponding to geological unit boundaries\\nFault well tops marking a break in the natural geological sequence\\nAny other type of markers\\nWell path import with logs\\nInitially all wells are organized under a unique Wells folder in the Input pane. Logs are stored in\\ntwo levels:\\n1. Under Global well logs there is a single entry for each log type. Here you can modify\\nparameters for the log type.\\n2. Under each individual well you will see all the logs for that particular well listed. Not all\\nGlobal logs may be found for each well.\\nPreferred well data import\\nTo import Well data into Petrel, right-click on the main Wells folder and select Import (on\\nselection) .Choose the right format and complete the necessary steps depending on the data\\ntype.\\nTo avoid using large files and to easily be able to visualize and quality check the data imported we\\nrecommend well data to be imported in three steps :\\n1. The Well header (as well heads (*.*) format) : A well head ASCII file must be created to\\nspecify the top position of the well path, the well name and optionally a well symbol.\\nIn the import dialog for well header, insert as many attributes columns as required. Attributes can\\nbe of several types, including string, continuous, discrete and date.\\n2. The Deviation survey (as well path/deviation (ASCII) (*.*) format) : If the well is not\\nvertical, an ASCII file containing the deviation survey must be imported describing its path. In the\\nimport dialog for the well/path deviation, specify the attributes being used from the survey (MD,\\nInclination, Azimuth here). It is also important to set the appropriate MD and TVD elevation\\nreference.\\n3. The Well logs (as Well logs (LAS) (*.las) files) : Are attached to the existing well path. Specify\\nthe logs to be loaded to have better control over them, and attach them to an already existing\\nPetrel template.\\nNote: The Reference Project tool can also be used to copy wells, logs and well tops between\\nprojects. Petrel Reference Project tool supports user-defined matching of wells with different\\nGUIDs.\\nThe LAS 3.0 loader has been replaced with a general loader that supports LAS 1.2, 2.0 and 3.0.\\nThis offers several improvements over Petrel s existing LAS import capability:\\nLoading errors and warnings are now written to the message log. This means that batches\\nof files can be imported without user intervention.\\nThe loader is able to match files to wells using information in the LAS file header\\nThe loader will help ensure that logs and global logs have unique names.\\nThe loader now includes a file preview area so that the header and first line of data can be\\nQC ed before import.\\nWells Logs in DLIS format\\nPetrel supports importing well log data in DLIS format. Data recorded in DLIS (Digital Log\\nInterchange Standard) format is using an \"object-oriented\" technology. It provides a powerful\\nmechanism for recording frame data. Static and transient information by means of uniform syntax\\nand an \"object-oriented approach\". DLIS supports the definition of an object described in terms of\\nattributes and can be organized in sets. This is a general technique of representing new\\ninformation. A range of information items can be represented under the DLIS and be extended\\nindefinitely.\\nHow to import DLIS files\\n1. Right-click on the Wells folder and select Import (on selection) .\\n2. Browse for the DLIS file to import, and select Well logs (DLIS) as a format. Click Open.\\n3. In the dialog window that opens, make sure the logs and the well header names already\\nimported into Petrel match (if not, select the correct name from the drop-down menu), click OK\\nwhen done.\\n4. The import dialog window will open. Notice that by default, all the logs are selected. If only a\\nfew logs should be loaded, click Unselect and click Load in front of the desired logs. Click OK.\\n5. The new imported logs will be stored under Global well logs in the Input pane.\\nWell data export\\nWells and well data (trajectory and associated logs) can be exported from Petrel in the following\\nformats:\\nIrap RMS (trace and logs)\\nWell heads, ASCII (well positions)\\nWell path/deviation file, ASCII (trace)\\nLAS 2.0 file with well logs (logs)\\nPetrel format, BINARY (trace)\\nPoint well data, ASCII (points)\\nCheckshots format, ASCII (points)\\nWith a well folder or multiple wells selected (use Ctrl or Shift), all of the wells or all of the well\\nlogs for the wells in the folder can be exported in a single operation.\\nRight-click the selected wells and choose:\\nExport selected wells\\nwill export selected deviations\\nExport logs from selected wells\\nwill export logs\\nRight-click on the main Wells folder or the selected sub-folder and choose:'},\n",
       " {'header': 'Export ',\n",
       "  'content': 'will export the well header file\\nExport all wells in folder\\nwill export selected deviations\\nExport all logs in folder\\nwill export logs\\nHow to export single well data\\n1. Open the pull-down menu for the well to export, by clicking with the right mouse button on\\nthe well.\\n2. Select the Export option.\\n3. Enter output file name. Select output format (Irap RMS well (ASCII), Petrel format\\n(Binary), Well logs (ASCII), Well/Path deviation (ASCII).\\n4. Click Save, and the well data will be exported in the format selected\\nA format description can be found in Appendix 1 - Formats. Well heads are exported from the well\\nfolder and will contain information on all wells in the project.\\nWell data organization\\nDifferent tools will help you organize, identify and visualize your well data. This is done in the\\nwells and well tops attributes tree and can be visluaized in both the well manager and the well\\ntops spreadsheet.\\nWell attributes\\nAttribute storage\\nOnce the wells have been imported into Petrel, they are stored in the main wells folder. Projects\\nsaved in previous versions of Petrel (before Petrel 2008) will automatically acquire a new Well\\nattributes folder. There are 18 system attributes available in the attribute list.\\nThe attributes which are in italics cannot be changed or deleted.\\nWell Attribute display options\\nAttributes can be displayed in most of the available viewers in Petrel. In plot views (interpretation,\\nintersection and map) it is possible to display multiple attributes, by checking the selection box\\nadjacent to the desired attribute(s). Only one attribute can be displayed in 3D view at any one\\ntime, to avoid unnecessary cluttering of the view. The style settings for the attributes are applied\\non the Style tab at wells folder level, under the heading Well label.\\nWell Attribute description\\n*Name: The well name (string attribute).\\nUWI: The Unique well identifier (string attribute).\\nWell symbol: The type of well. This attribute, when selected, is a label for the well symbol\\n(discrete attribute). To display the symbol, check the Show well symbol in the Style tab at\\nWell folder level.\\n*Surface X: The X location (in project units) of the well at the well head (continuous).\\n*Surface Y: The Y location (in project units) of the well at the well head (continuous).'},\n",
       " {'header': 'Latitude: Longitude: ',\n",
       "  'content': '*KB: The Z value (in project units) of the Kelly Bushing (continuous).\\n*TD (TVDSS): The vertical depth value (in project units) of the last point in the well\\n(continuous).\\n*TD (MD): The measured depth value (in project units) of the last point in the well\\n(continuous).\\nMax inc: The value of the highest inclination from vertical (in project units) in the well path\\n(continuous). The attribute is calculated in Petrel. This is a useful attribute for distinguishing\\nbetween vertical, inclined and horizontal wells - for more information please refer to the\\n\"Saved searches\" paragraph.\\nCost: The cost of the well (string).\\nSpud date: The date the well was spudded (date attribute).\\nSimulation name: User specified simulation name alias (string).\\nSimulation export date: The date the well is going to take effect in the simulation case.\\nOnly applicable for history strategies.\\nOperator: The name of the organization operating the well.\\nZ: Vertical positioning in TVD\\nTWT auto: Vertical positioning in TWT\\nThe attributes preceded by an asterisk (*) are required fields; the other attributes are non-\\nmandatory and can be ignored if desired.\\nHow to add new attributes to an existing point\\n1. Expand the Wells folder and go to the \\'Well attributes\\' sub-folder.\\n2. New attributes can be inserted by right-clicking on the attributes folder and selecting Insert\\nnew attribute from the context menu.\\n3. Select Continuous, Boolean, String or Date as attribute.\\nWell attributes and OpenSpirit\\nThe above system attributes are supported in data transfer via OpenSpirit to existing data stores.\\nFor a full description of how attributes are mapped, from OpenSpirit to Petrel, please refer to the\\nOpenSpiritMapping.xml XML file, in the Petrel directory.\\nThe well manager\\nThe Well manager is a tool that collects all the information associated with each wellbore and\\npresents it in a user friendly spreadsheet format. Each well in the project is presented as a row,\\nwith all associated attributes, logs, well completions and coordinates system listed as columns.\\nMost of the fields are writable, allowing copy and paste actions from other spreadsheets. Surface\\nX/Y, KB and TD (MD) are editable.\\nTo access the Well manager right-click on the Wells folder in the Input pane and select Well\\nmanager (1). You can access the well manager from the Info tab under the Settings of the Wells\\nfolder (2).\\nWell manager tools\\nA series of tools allow the user to move wells into new or existing folders, edit fields, filter wells\\nbased on the active saved search (see Saved searches) and access short cuts. It is also possible\\nto copy data from the well manager to other spreadsheets and vice versa. The well manager also\\nprovides a convenient way to add new wells to the project.\\nWhen a well position is shifted using the well manager fields, or directly at the local well level, all\\nthe well information attached can be linked to the trace.\\nFor example: if an x location was initially entered erroneously, the user can insert a new\\nposition; well tops, checkshots and any other trace data can be shifted along with the new\\nposition on MD. This is an improvement on previous releases, where only edits on Kelly Bushing\\nwere linked.\\nFor more detail information about Well Manager tool see Well manager after import.'},\n",
       " {'header': 'Sorting ',\n",
       "  'content': 'Sort by double-clicking on a column header.'},\n",
       " {'header': 'Viewing ',\n",
       "  'content': 'Select the rows to view by highlighting the row(s) and then select the view on/off icon to\\ncontrol the display.\\nAlternatively, use toggle view icon.\\nVisible columns are controlled by using the Show column control button. This button shows\\nthe different attributes in the Well Manager.This option is quite important as it will limit the\\namount of data shown at any time in the Well Manager. The Show button is located at the\\ntop of the manager which has a drop-down menu of view options. The selected (checked)\\nattributes will show in the Well Manager.\\nThe filter icon will enable active saved searches (see Saved searches).'},\n",
       " {'header': 'Editing ',\n",
       "  'content': 'Only fields with a white background are editable.\\nX, Y and KB surfaces and TVD (Md) fields can be made editable by using the Edit point\\nbutton.\\nIt is possible to copy data from spreadsheets into the Well manager for all editable fields.\\nDate attributes: If the date format is different from the format set in the computer regional\\nsettings, Petrel will attempt to convert the data to this format.\\nCare should be taken when there is data ambiguity for instance, 07/12/80, 12/07/80\\nWell symbols: Text or ID can be pasted into Well symbol fields, example, Minor oil and 6 are\\nboth valid entries.\\nNew attributes can be added by selecting Insert new attribute from the context menu of\\nthe Well attributes folder.'},\n",
       " {'header': 'Well Tops Structure ',\n",
       "  'content': 'Each well tops object has five sub folders:\\nAttributes - Folder for properties for the stratigraphic zones.\\nStratigraphy - Folder holding stratigraphic well tops corresponding to geological unit\\nboundaries.\\nFaults - Folder holding fault well tops marking a break in the natural geological sequence.\\nOther - Folder holding any other well tops.\\nWells - Filter for choosing which wells to display well tops for.'},\n",
       " {'header': 'Stratigraphic Well Tops ',\n",
       "  'content': 'Well tops held in the stratigraphy folder should be organized in the correct geological order and\\nwith the correct hierarchy. A hierarchy can be created by dragging and dropping horizons into\\nzones or by inserting them directly.This order will be used to create the Zone log.\\nThe geological tops will also have assigned one of the four different types:\\nErosional - Horizons below will be truncated (displayed with an undulating line).\\nBase - Horizons above will be truncated.\\nDiscontinuity - The horizon is both a base and an erosional. Horizon below and above will\\nbe truncated.\\nConformable (default) - Horizon will be truncated by erosional, base and discont. Lower\\nconformable horizons will be truncated by upper conformable horizons in the make horizons\\nprocess.\\nThis means that if an erosional top occurs at exactly the same point as a conformable top found\\nstratigraphically below it, the conformable top will be deleted. This prevents Petrel from correcting\\neroded horizons back to zero thickness at the well during well correction in Make Horizons or'},\n",
       " {'header': 'Make Zones. ',\n",
       "  'content': 'To change the type of an existing well top, rigth/click on it and select Settings, once the settings\\nwindow is open go to the settings tab, in Horizon type select the rigth type for the well top.'},\n",
       " {'header': 'Fault Well Tops ',\n",
       "  'content': 'Fault well tops can cause a change in the geological sequence, but are not forced to do so like the\\nstratigraphic well tops. Use the fill tool to change the geological unit on one side of the fault top\\nwithout changing the position of the other well tops.\\nThe fault top can also be tied to a fault pillar in time or depth, so that the fault in the geological\\nmodel passes through the appropriate point in the well path. Any fault top that is locked in this\\nway will have a lock icon both in the main and sub labels in a Well Section panel.\\nA fault separating zones in the well correlation panel.\\nFault tops locked to a 3D model showing a Lock icon in Well Section.'},\n",
       " {'header': 'Well Tops Spreadsheet ',\n",
       "  'content': 'The Well top spreadsheet in Petrel can be found by right-clicking on the Well Tops folder and\\nselecting Spreadsheet .\\nThe Petrel Well top spreadsheet is an interactive tool for managing the well tops in Petrel. Within\\nthis spreadsheet, the user can edit the positions of well top points and add new well tops, and also\\ndefine which of the well tops should be used in the horizon correction for model building and depth\\nconversion.\\nTo open the Well tops Spreadsheet, right-click in any Well tops folder in the Input pane and select\\nSpreadsheet (1). Alternatively you can open the spreadsheet form the Info tab under the Settings of\\nthe Well tops (2).\\nIn addition, the spreadsheet holds attributes assigned to a well top and these can be edited here.\\nAny part of the spreadsheet can be copied to the clipboard and pasted into any Windows software. It\\ncan also be edited and pasted back again afterwards.'},\n",
       " {'header': 'Well ',\n",
       "  'content': \"Tops spreadsheet.\\nSettings for the Well Tops Spreadsheet\\nUse the Well Filter list box to choose which well the tops should be\\ndisplayed for (or all).\\nWell tops in the spreadsheet can either be un-editable, edited by MD or edited by XYZ. Choose which\\nsystem to use with the edit point list box\\nLines can be added or removed from the spreadsheet in the usual way:\\nInsert new line at the bottom.\\nInsert N number of new well tops.\\nInsert a new line above the active one.\\nInsert a new line below the active one.\\nRemove the active well top.\\nCopy the active lines.\\nPaste into the active lines.\\nColumns can be made wider or narrower by simply dragging the column boundaries. Clicking in the\\ntop left corner of the spreadsheet will select the entire spreadsheet for copying.\\nData in the well tops spreadsheet\\nWell lists the well the well top belongs to. The well names can be changed.\\nSurface name lists the name of the horizon described by the well top. Well Top/Surface\\nnames can be changed from a drop-down list.\\nX-, Y- and Z-coordinates list the coordinates of the well tops. The coordinates can be edited\\nwhen Edit Point is set to X, Y, Z , by clicking in the coordinate box and type or copy in a new\\ncoordinate can change the coordinates. If some X,Y,Z values at well tops are shifted or\\nmissing, you can use the option Synchronize XYZ's from the right mouse button menu, from\\nthe well tops folder. This action will synchronize all x,y,z values to MD (if defined).\\nMD lists the MD of the well top. The MD value can be edited when Edit Point is set to MD by\\nclicking in the MD box and typing or copying in a new MD, you can change the MD value. If\\nsome MD values are missing at well tops, you can synchronize them using the option\\nSynchronize MD's from the right mouse button menu from the well tops folder. This action\\nwill synchronize them taking reference the well trace. If well tops already have MD values, this\\naction will not change anything.\\nThe following predefined columns of Attributes are always present: TWT Picked, TWT Auto,\\nTVT, TST, Interpreter, Dip Angle, Dip Azimuth, Missing and Confidence factor . The\\nattributes can be imported when the well tops are imported or the attributes can be calculated\\nwith various methods in Petrel (for more information see Attributes for well tops and zones\\n).Clicking in the attribute box and typing or copying in a new attribute can change the\\nattribute values.\\n- TWT Picked lists the manually picked time for the well top. The time value has to be typed in by\\nthe user.\\n- TWT Auto lists the calculated time value for the well top when the Time Depth Relation is set for\\nthe wells. The value can only change if the Time Depth Relationship (TDR) for the wells changes.\\nUsing e.g. checkshots will update the TWT Auto once you establish a TDR.\\n- TVT lists the cummulative TVT depth from the top horizon, calculated in the Thickness tab in Well\\nSettings. Note: This is not the true TVT zone value; that is listed in the Zone spreadsheet.\\n- TST lists the cummulative TST depth from the top horizon, calculated in the Thickness tab in Well\\nSettings. Note: This is not the true TVT zone value; that is listed in the Zone spreadsheet. .\\n- Interpreter lists the name of the interpreter. The name has to be imported or manually entered\\ninto the spreadsheet, or Petrel will take the current user name automatically.\\n- Dip Angle lists the Dip Angle for the well top. The value can be imported or entered manually by\\nthe user. The Dip Angle can be used as basis for Thickness calculations for the Wells.\\n- Dip Azimuth lists the Dip Azimuth for the well top. The value can be imported or entered\\nmanually by the user. The Dip Azimuth can be used as basis for Thickness calculations for the Wells.\\n- Missing lists the missing section for the well top and are used to indicate fault gaps or eroded\\nsections. If the user has calculated TVT and TST, the missing section can be used for panel splitting\\nin the Well Section Window. Negative numbers represents missing sections (e.g. normal faults) while\\npositive numbers represents repeated sections (e.g. reverse faults).\\n- Confidence factor is only an open list for setting the confidence of a certain well top pick. It acts\\nlike a comment and is not used for anything else.\\nDepth Conv lists the well tops that will be used to guide the depth conversion of the 3D grid.\\nThis only applies to the types Horizon and Truncated . Single well tops in a file can be\\nselected so as NOT to be used in Depth Conversion , although the file is selected to be used.\\nGeo Mod lists the well tops that will be used for guiding creation of new horizons in the 3D\\ngrid. This only applies for the types Horizon and Truncated . Single well tops in a file can be\\nselected so as NOT to be used in Make Horizon and Make Zones, although the file is selected\\nto be used.\\nWell symbol select symbol for each well top. Well tops can be given the symbol of their\\nrespective well; this is done from the right mouse button menu option, Synchronize Well\\nSymbols , from the well tops folder.\\nHow to select well tops for use in the Geo Model or Depth conversion\\nFor well tops of type Horizon and Fault the Geo Mod and Depth Conv columns are active. Select\\nwhich well tops should be used for the vertical layering in the 3D grid (Geo Mod) or in the Depth\"},\n",
       " {'header': 'Conversion. ',\n",
       "  'content': 'In the bottom of the spreadsheet, there is the possibility to select All or None of the well points to\\nbe used in either Depth Conv and/or Geo Mod .\\nAdd new well tops using the well tops\\nspreadsheet\\nHow to add a new well top using the well top speadsheet\\n1. Open the well tops spreadsheet by right-clicking on the Well Tops folder and select'},\n",
       " {'header': 'Spreadsheet. ',\n",
       "  'content': '2. Add a row to the well tops list in the spreadsheet, using Append Item to the table\\n3. Add above selected , or Add below selected .\\n4. To select a row in the spreadsheet, click on the number of the row in the left column.\\n5. Enter the X-, Y- and Z-coordinates of the new well top by typing or copy them from a\\ndifferent file.\\n6. Select Well and surface name of the well top.\\n7. Give the well top the correct stratigraphical name. By using an existing stratigraphical\\nname, the well top will be added to that file.\\n8. Select whether the well top should be used for correcting creation of the vertical layering in\\nthe 3D grid or in the depth conversion.\\n9. Click Apply or OK in the spreadsheet for the changes to be taken into account.\\nEdit well tops using the well top spreadsheet\\nHow to edit well tops using the well top spreadsheet\\n1. Open the well tops spreadsheet by right-clicking on the Well Tops folder and select'},\n",
       " {'header': 'Spreadsheet. ',\n",
       "  'content': '2. Find the row for the well top you want to edit.\\n3. If you want to edit the coordinates for the well tops, activate the X, Y, Z option in the Edit\\nPoint icon located on the top menu for the spreadsheet. The MD can\\nalso be changed from here.\\n4. The well top coordinates and Z value are now available for update\\n5. Type or copy new coordinates for the well top.\\n6. Check that the Well and Surface Name is still valid.\\n7. Check that you have the correct settings for Geo Mod and Depth Conv.\\n8. Click Apply or OK in the spreadsheet for the changes to take effect.\\nAttributes for well tops and zones\\nThe well tops and the zones can both have attributes associated with them. These will be listed\\nunder the Attributes sub-folder and can be displayed and edited through the Well tops\\nSpreadsheet and the Zones Spreadsheet. Both of these spreadsheets are available by right-\\nclicking on the Well Tops folder.\\nThe attributes can be sampled from well logs, written in manually, imported with the well tops or\\ncopied and pasted from another spreadsheet. Attributes on well tops are point attributes\\n(sampled directly from a point in the log) while zone attributes apply to the geological zone\\nbetween two well tops.\\nThe following attributes are predefined on each well top:'},\n",
       " {'header': 'Depth ',\n",
       "  'content': 'TWT Picked (User specified two way time)\\nTWT Auto (Two way time from check shots etc.)\\nMeasured depth (MD)\\nSurface (Horizon name)\\nWell (Well name)'},\n",
       " {'header': 'Interpreter ',\n",
       "  'content': 'Confidence factor\\nDip angle (0-90 degrees, 0 means horizontal, 90 vertical)\\nDip azimuth (0-360 degrees, 0 is north, clockwise)\\nTVT (True vertical thickness cumulative depth of the well top horizon)\\nTST (True stratigraphic thickness cumulative depth of the well top horizon )\\nMissing (The amount of missing section due to fault gap or erosion).\\nTWT Auto, TVT and TST are all automatic attributes which will be calculated according to the time\\ndepth relationship and the dip of the stratigraphy in the well; see Time (wells) and Thickness\\n(wells). These will be updated automatically as the well tops move.\\nNote: It is possible to copy well tops and attributes using the Reference Project tool. If you\\ncopy the well tops but not the well attribute, the well tops will inherit the standard set of\\nattributes. For each copied well top, the attribute values will be copied automatically for all the\\nattributes that are common to the source and target projects. As for attributes that only exist in\\nthe target project, default values will be given.\\nNew attributes can be created by right-clicking on the Attribute folder. Select Insert new\\nattribute. A menu opens up and the user can select which type of attribute to insert, Discrete,\\nContinuous, Boolean or String.\\nNote: Well tops can have the following three visual attributes; Visual vertical position, Dip\\nazimuth (it can only be defined for stereonet windows), and Dip angle (as well it can only be\\ndefined for stereonet windows). When a well top object is copied, these values will be set to the\\ndefault value, regardless of the settings in the source project.'},\n",
       " {'header': 'Calculating Well Top Attributes ',\n",
       "  'content': 'Attribute values can be calculated directly from a well log, simply open the settings for a\\nparticular attribute and browse to the Operations tab.\\nAttributes are assigned either to a Surface or a Zone:\\nSurfaces - The attribute is a point attribute relating to the well top itself. Its value will be\\nsampled from one point in the well and it will be displayed in the well tops spreadsheet.\\nZones - The attribute represents a region between two well tops. Its value will be an\\naveraged value of all the well log values between the two well tops and it will be displayed\\nin the Zone Spreadsheet.\\nOnce attributes have been generated, they can be moved from zones to tops and vice versa by\\nselecting the desired location and pressing Change.\\nWhen creating a zone attribute, the user must also decide at which level of the hierarchy the\\nattribute should be sampled. This is only relevant if a hierarchical zone stratigraphy has been built\\nwith different levels. If level 1 is chosen, then values will be averaged throughout the main zone\\nsubdivisions and the two sub zones belonging to the same zone will get the same value.\\nThe type of well top attribute (zone or surface) becomes important if the attributes are\\nupscaled into the grid; see Scale up of Well Logs.\\nWell top attributes from well logs\\nIf the attribute is to be held as a Surface attribute, then the closest point to the well top will be\\nsampled onto the well top and most of the options in the dialog will be grayed out.\\nZone attributes are averaged from the length of the well between the well tops in much the same\\nway as when up scaling well logs, see Scale up well logs dialog for a more detailed description.\\nA few additional options are available:\\nIntegrate (continuous logs): Will integrate the log between the two well tops according\\nto the chosen depth scale.\\nThickness (discrete logs): Calculates the thickness of a particular facies on a log\\nbetween the two well tops according to the chosen depth scale.\\nPercentage (discrete logs): Calculates the percentage of a particular log which belongs\\nto a specific facies between the two well tops according to the chosen depth scale.\\nSelect the required settings and press Run to perform the calculation. Petrel writes the result of\\nthe calculation to the attribute. If the filter button is depressed, values will only be written to\\nthe well tops currently displayed.\\nOperations tab for a Zone attribute.\\nHow to calculate average attributes\\n1. Right-click on the attributes icon. Select Insert New Attribute.\\n2. Select continuous.\\n3. Go to the Operations tab.\\n4. Select to store the attribute on a zone (select level on which to do the averaging).\\n5. Choose the log to use to sample the values from.\\n6. Choose the type of averaging to perform.\\n7. Choose the required depth scale in which to perform the averaging.\\n8. Choose a Cut off if required.'},\n",
       " {'header': '9. Press Run. ',\n",
       "  'content': 'How to change attributes using filters\\n1. Under Well Tops folder, use the well filter and/or stratigraphy/fault/other filters to\\ndisplay the well tops which are to be changed.\\n2. Open the Settings for the attribute to be changed.\\n3. Browse to the Operations tab.\\n4. Toggle on the filter button .\\n5. Choose the required settings for the sampling.\\n6. Press Run - only the filtered well tops will be changed.\\n4.\\n5.\\n6.\\nChanging the attribute operations settings for an attribute will potentially change all the well\\ntops values for the attribute. To reflect this change in the Reference Project Tool all filters and\\nhorizons should be marked as newer (\">\"); therefore, to get everything back \"in sync\", all objects\\nunder the well tops folder must be copied again. To avoid this, such changes should only be\\nreflected on the attribute itself.\\nWell top attributes from surfaces\\nAttributes can also be sampled directly from a surface into a zone in Petrel. If the attribute is a\\npoint attribute, the surface will be sampled at the XY value of the well top. If it is a zone attribute,\\nthen the surface will be sampled at the midpoint between the two well tops (by MD).\\nDrop the required surface into the dialog box and press Execute to perform the calculation.\\nPetrel writes the result of the calculation to the attribute. If the filter button is depressed,\\nvalues will only be written to the well tops currently displayed.\\nHow to sample surface values to a single well top\\n1. Use the stratigraphy filter (and or wells/faults/others) to display the well tops you want to\\ngive a value.\\n2. Right-click on the Attributes folder under Well Tops and select Insert new attribute.\\n3. Select Surface from the Sample from options.\\n4. Toggle on the filter button .\\n5. Choose the required settings for the sampling.\\n6. Press Run - only the filtered well tops will be given a value.\\nInsert a new well top attribute\\nHow to insert a new well top attribute\\n1. Open the well tops spreadsheet and right-click on the Attributes folder.\\n2. Select Insert new attribute.\\n3. An option to select Discrete, Continuous, Boolean or String appears.\\n4. The new attribute is added to the Attributes folder, and a column is added in the Well Tops\\nSpreadsheet. The column is empty and can be filled in.'},\n",
       " {'header': 'Make/Edit Well Tops ',\n",
       "  'content': 'Well tops are used to mark the boundary between geological units as seen in the borehole. They\\ncan then be used during the model building phase as an additional control of the positions of the\\nmodel horizons. This will ensure the horizons match the observed horizon data in the well\\nlocation.\\nIf well tops are used together with well correction in Make Horizon or Make Zones, then the\\ncorrect attribute (time or depth) will be used, depending upon whether the horizon is in time or\\ndepth.\\nA common problem when picking points as geological boundaries, is that it does not show what\\nhappens between the points and can therefore be quite ambiguous. For this reason well tops in\\nPetrel are tied into the Zone concept where the user also defines which geological zones occur\\nbetween the well tops. An additional benefit of this approach is that well logs can be averaged\\nacross individual zones and the values stored as attributes for that particular zone in that\\nparticular well.\\nTo generate a zone log for a well tops folder, right-click on the well tops and choose:\\nInsert/Update Zone Log,the zone log will then be located in Global well logs and can be\\ndisplayed in the well section window.\\nThe zone log and template will be updated automatically when changes is done in the well tops. If\\na new well is added to the well top, the operation of generating a zone log must be redone in\\norder to add the zone log to the new well.'},\n",
       " {'header': 'Making Well Tops ',\n",
       "  'content': 'As a general rule, it is best to organize the stratigraphy in your project before the interpretation\\nbegins. This will give a clear picture of the behavior of erosive horizons and make it easier to see\\nwhen tops are missing from the sequence. The hierarchy can also be organized at this stage, as\\nwell as the nature of each horizon (conformable, erosive, etc.).\\nAny number of well top objects can be created, either manually from scratch, by copying and\\npasting from existing objects, by importing data from a well tops file or by copying and pasting\\ndata from a spreadsheet.\\nTo create a new set of well tops from scratch, choose New Well Tops from the Insert menu.\\nNew tops can now be inserted in the Stratigraphy, Faults and Others folders by right-clicking\\non the folder and choosing Insert New Well Top.\\nWithin the Stratigraphy folder the order and hierarchy of the well tops is also important and a\\nzone icon will be inserted between each well top. Select a well top and use Insert Zone/Horizon\\nAbove ... Below to create the required geological sequence. Well tops and zones can also be re-\\narranged by dragging and dropping, and can even be dropped into a zone to create a hierarchy.\\nYou can drag and drop between the Faults, Others and Stratigraphy folder as well.\\nWhen using multi select, click and drag on the last selected object to move all the objects\\ntogether.\\nHow to make a new well tops object with stratigraphy\\n1. Click on New Well Tops option under the Insert menu on the Menu bar. A new folder\\nwill appear in the Petrel Explorer.\\n2. Right-click on the Stratigraphy subfolder under the new well tops object and choose'},\n",
       " {'header': 'Insert Zone/Horizon Into. ',\n",
       "  'content': '3. Right-click on the new horizon under the stratigraphy subfolder and choose Insert\\nZone/Horizon Above or Insert Zone/Horizon Below.\\n4. To create a hierarchy, either right-click on a zone icon and choose Insert Zone/Horizon\\nInto or drag existing well tops into the zone.\\n5. Repeat 3 and 4 until you have created the required geological sequence.\\n6. Rename the zones and horizons as required.\\n7. If you only want to see the horizons, right-click the folder and select Hide Zone icons.\\n5.\\n6.\\n7.\\nHow to make new well tops by picking in the 3D window\\n1. Click on the New Well Tops option under the Insert in the Menu bar. A new folder will\\nappear in the Petrel Explorer.\\n2. Display the wells you want to work with.\\n3. Display the input data you will use for placing the well tops (surface, well logs, etc).\\n4. Select the Make/Edit Well Tops process step in the Process diagram. New icons will\\nappear in the Function bar.\\n5. Select Create Edit Well Tops . When you digitize a point, a new horizon will appear\\nunder the stratigraphy subfolder to the active well tops.\\n6. Continue digitizing well tops for the current horizon on different wells.\\n7. To start digitizing a new horizon, select Add New Well Top Surface . To continue\\ndigitizing a horizon, select the horizon in the explorer so that it becomes bold. If no well\\ntops are bold, then a new well top will be created in the active folder.\\nHow to make new well tops by picking in the well section window\\n1. Select New Well Section Window from the Window menu.\\n2. Click on the New Well Tops option under the Insert menu at the Menu bar. A new folder\\nwill appear in the Petrel Explorer.\\n3. Display the wells you want to work with.\\n4. Display the logs you will use for placing the well tops.'},\n",
       " {'header': '5. Select Create Edit Well Tops . ',\n",
       "  'content': '6. Clicking in the log panel will now create a new well top at the point corresponding to the\\nactive well top in the active well tops folder.\\n7. If no well top is active, then clicking on a log panel will create a new well top (normally\\ncalled Horizon 1, 2, etc.).\\nThere are Undo and Re-do controls available when making well tops, press (shortcut\\nCtrl+Z)or (shortcut Ctrl+Y).The Undo and Re-do options are imited to 5 steps.\\nHow to make new well tops from point data\\n1. Find the appropriate point data in the Input tab.\\n2. Right-click on the point data and select to add to active well tops as horizon, fault or well.\\nConvert well tops to isochore points\\nHow to convert well tops to isochore points\\n1. Click on one of the well top names to make it active (bold).\\n2. Right-click on one of the other well top names and select Convert to isochore points.\\n3. Isochore points of the thickness between these two well tops are created.\\nThe isochore thickness produced by this method will only be 100 percent correct if one of the\\nfollowing three situations occurs:\\n1. The well is vertical\\n2. The layers are horizontal\\n3. The well tops contain TVT and TST attributes.\\nIn situations 1 and 2, the isochore will equal the thickness attribute. In situation 3, the isochore\\nwill be the TVT attribute.\\nConvert XYZ points to well tops\\nHow to convert XYZ points to well tops\\nThere can be cases when your data set only contains XYZ coordinates representing the well tops.\\nIt is not necessary to create a Petrel well tops file. You can import the data as point data and then\\nconvert it into conceptual well tops. This approach is only applicable if you import all wells\\ntogether in one step. All surfaces should have been imported before starting this process.\\n1. Sort your XYZ points e.g. by surface. Make ASCII files of each set with three columns: X, Y\\nand Z.\\n2. Make a new folder in Petrel and make it active.\\n3. Import the ASCII files using the general reader.\\n4. One point file at a time, right-click to open a menu and select one of the options Add to\\nWell Tops as horizon, Add to Well Tops as fault, or Add to Well Tops as well. A new\\nfolder with well tops will be created and each file stored in there. Do this with all the files.\\n5. Make one of your input surfaces active, preferably the mid-surface.\\n6. In the Wells Tops folder, open the Well Filter sub-folder and find the Not specified well.\\nRight-click on the Not Specified and select Split into different wells. Answer Yes to the\\npop-up question. Your well points are now positioned correctly.'},\n",
       " {'header': 'Editing Well Tops ',\n",
       "  'content': 'Well tops can be edited interactively in the 3D window, in the well section window and in the well\\ntop spreadsheet. The effects of these changes are shown in real time in all visible windows.\\nWhen editing stratigraphic tops, Petrel has two modes, with or without restricted well tops. If the\\nwell tops are restricted, they must occur in the correct stratigraphic sequence in the borehole,\\nallowing for faults and eroded horizons. If well tops are unrestricted, then no such rules need to\\nbe followed. As a default, restricted well tops are toggled on, but they can be switched off using\\nthe toggle in the Function bar. Faults and Other well tops are unaffected by the order of the\\nwell tops and are never restricted.\\nEditing well tops in a Well Section\\nBy selecting the Create / edit well tops tool , well tops can be edited interactively.\\nMoving existing well tops - click on the well top and drag it.\\nDelete an existing well top - click on the well top once to select it (the well top name will\\nbecome bold in both the well section view and the Petrel explorer) and press delete.\\nInserting a well top for an existing horizon - click on the horizon once in the Petrel\\nExplorer to select it (the horizon name will become bold), click in a well panel at the\\nrequired depth to insert the well top.\\nInserting a well top for a new horizon - ensure that no horizons are active or press .\\nClick in the appropriate well panel at the required depth to insert a well top, a new horizon\\nwill be added to the active subfolder of the active well tops object (Stratigraphy, Faults or'},\n",
       " {'header': 'Other). ',\n",
       "  'content': 'When the well tops are restricted ( toggled on), and the user attempts to drag a stratigraphic\\nwell top beyond another well top, the top being edited will stop at the second well top and move\\nno further. If the user then clicks on these two well tops, they will be dragged together. To\\nseparate them, simply press Shift and drag one of the well tops to the side.\\nThere are Undo and Re-do controls available when editing well tops, press (shortcut\\nCtrl+Z)or (shortcut Ctrl+Y) after making an error and the well tops will delete the last action\\nyou performed. The Undo and Re-do options are limited to 5 steps.\\nPetrel has a new interactive navigation well tops tool:\\nNext Horizon (keyboard shortcut Ctrl+Down).\\nPrevious Horizon (keyboard shortcut Ctrl+Up).\\nIt allows you to navigate through the active horizons via context menu / key shortcut.\\nFor instance; imagine you have 3 tops (A, B, and C) under your Stratigraphy folder in the well\\ntops folder. Next, you want to pick the tops for the well 1, the workflow could be to pick the well\\ntop for Horizon A, then you want to move down in the same well to the next horizon, Horizon B.\\nTo do this you can use the Next Horizon (shortcut Ctrl-Down) new tool, this will change\\nthe active well top in your Stratigraphy folder one move down, so that well top B is now active.\\nThen you click on the Well section to pick well top B, then keyboard shortcut Ctrl-Down again\\nto make well top C active. This is a more intuitive workflow that Petrel 2005 route. In Petrel 2005,\\nit was sort of assumed that the user would pick horizon A in all wells and then move to picking\\nhorizon B in all wells, where as in reality a geologist is more likely to want to pick all tops in Well 1\\nand then move on to picking all tops in Well 2. Using the shorcuts in the keyboard, you will reduce\\nthe amount of mouse movement required when correlating well tops.\\nHow to change the position of an already existing well top surface\\n1. Make the well section active.\\n2. Click on the Create/Edit Well Tops icon in the function bar.\\n3. Make sure the well top surfaces are visible in the Well Section window.\\n4. Move one of the well top surfaces by dragging the correlation line within one of the\\ndisplayed wells.\\nTo place a well top surface at a specified depth, simply right-click on the well top in the Well\\nSection window and type in the depth in the depth display that opens up.\\nPop-up dialog for specifying accurate depth of a well top surface.\\nLocking well tops\\nLocking well tops ensures they are not accidentally moved during editing. This can happen if the\\nuser accidentally clicks on a well top and moves it, but also if the well top being edited is moved\\nonto another well top such that the two become collapsed and are then moved together.\\nIf the user attempts to edit a well top, or a group of collapsed well tops in which one is locked,\\nthen the message At least one of the selected well tops are locked will appear.\\nThere are two methods for locking well tops:\\nLocking hidden well tops - As a default, well tops that are not displayed will be locked.\\nThis is a setting on the well tops settings panel.\\nLocking specific horizons - Specific horizons within the well tops can be locked by either\\nright-clicking on the horizon in the Stratigraphy folder under the Well Tops and choosing\\nLock well top, or by double clicking the horizon and locking the well top on the horizons\\nsettings page.\\nAs mentioned before, Locking the well tops will prevent accidental movement on the Well\\nSection window. However, the well top can still be moved to a different position using alternative\\nmethods.\\nAs an example, you can reposition a locked well top by right clicking the well top in the well\\nsection window and writing in a new depth in the pop up box. The well top will then be moved\\nto the new position even if it is locked!. In addition, the spreadsheet can also be used to\\nassign a new position to a locked well top. Finally, by using the undo or redo buttons, the\\nlocked well top will be repositioned as well.\\nWorking with the Zone log\\nTo generate a zone log in a well tops folder, right-click on the well tops and choose\\nInsert/Update Zone Log. The log will then be located in Global well logs and can be\\ndisplayed in the well section window. It will automatically be updated with any edits to well tops,\\nnew horizons, etc.\\nPetrel will automatically attempt to fill in the correct zones between well tops, however in certain\\nsituations, particularly where faults exist or if well tops are deleted, it may not be successful. In\\nthis case use the flood fill tool to change the zone, see Creating and editing discrete log\\ncurves.\\nEditing well top time\\nOnce a time depth relationship has been established, pressing Show Well Top Time will\\ndisplay the well tops in time in the well section window at the same time as they are displayed in\\ndepth. The time top will be displayed with a dotted line and will be connected to the depth top\\nlevel. If the time at the top has not been previously edited or inputted manually, then it will be\\ninitially in the same place as the depth top.\\nToggle on Edit Well Top Time to edit the time top when it is displayed.\\nCreate / Edit well tops must be active before these tools are available.\\nEditing well tops in 3D\\nTo edit the well tops in 3D, the Make/Edit well tops process must be active. The editing\\nfunctionality is similar in principle to that of the Key Pillars with the widget moving in a similar\\npattern, although the user cannot leave the well path (assuming that the well top is linked to the\\nwell path). Picking the tangent turns this yellow and you can pull the widget along the tangent\\nline. If Well Tops are close, you can pick the plane (turns yellow) and by pulling it out first, you\\ncan now do the cylinder (tangent) editing outside the path while the well top actually moves along\\nthe path.\\nWell tops displayed in 3D\\nHow to edit well tops in 3D\\n1. Display the wells and well tops you wish to work with.\\n2. Activate the Make/Edit Well Tops process step in the Process diagram. A new set of\\nicons will be displayed in the Function bar.\\n3. Click on the well top to be edited; it turns into a widget with a cylinder and a plane.\\n4. Click and press the left mouse button on the cylinder of the white widget. Drag the well top\\nalong the well trajectory to where you want it.\\nTo display depth values, rather than stratigraphic names on the well tops, open the Well Tops\\nfolder and change by toggling on Z in the Attributes folder.'},\n",
       " {'header': 'Zone Spreadsheet ',\n",
       "  'content': 'If attributes are assigned to a zone instead of a well top, then they will appear in the Zone\\nSpreadsheet rather than the Well Tops Spreadsheet . This is very similar to the well top\\nspreadsheet, with a filter for wells and the option to edit or insert attribute values. Data from this\\nspreadsheet can be copied and pasted into any other windows program, edited and copied back in\\nagain.\\nThe Zone spreadsheet lists the folowing default attributes:\\nWell - well name.\\nStart MD - Starting point of the zone (top horizon).\\nZone log - Name of zones from Stratigraphy folder (can be shown at different Zone levels listed at\\nthe top of the Zone spreadsheet.\\nTVT Zone - Lists the True Vertical Thickness (0-90 degrees, 0 means horizontal, 90 vertical)\\ncalculated in the Thickness tab in Well Settings. The value can only change if the Thickness calculations\\nchange.\\nTST Zone - Lists the True Stratigraphic Thickness (0-360 degrees, 0 is north, clockwise) calculated in\\nthe Thickness tab in Well Settings. The value can only change if the Thickness calculations change.\\nZone Spreadsheet; show average attributes between zones (note different zone levels).\\nThe Well section window\\nThe Well section window has undergone substantial development in Petrel 2010.1, resulting in\\nsignificant changes to the user experience.\\nEverything that appears in the well section window is controlled by a template. The tree structure\\nin the Windows pane on previous Petrel versions, has been moved to some settings dialogs:\\n1. To access the list of wells being displayed, you need to go to the Well section window\\nsettings dialog.\\n2. To access the list of tracks and logs, you will need to go to the Well section template\\nsettings dialog.\\nThe enhancement allows the user to:\\nDefine a log curve preference system for the Well section window.\\nImport/export the well section template.\\nShare templates through the Reference project tool.\\nDefine your own default Well section templates.\\nChoose from a set of default Well section templates.\\nThe new system is template-centric, allowing the user to:\\nCustomize all the Well section window settings at one time.\\nCustomize all the well section template settings at one time.\\nBuild the Well section template interactively.\\nToggle between well section templates on the fly.\\nWorking with Well Sections\\nEach well section window has its own icon and is stored on the Windows pane. The well section\\nwindow in Petrel 2010.1 uses a new template-centric system.\\nThese well icons are only links to the data under Wells, so deleting the icons in the Well section\\nwindow will only remove them from the visualization window, and the well data will not be\\ndeleted. To temporarily remove a well from the well section, uncheck the checkbox in front of it.\\nWell sections can be copied through the normal copy/paste functions and copies can be edited\\nand displayed independent of the original. However, changes to common log curves and well tops\\nwill be reflected in both.\\nChecking a well section will display it in a well section window. To display a well section outline in\\na 2D-, Map- or 3D- window, toggle on the checkbox in front of Well Section fence.\\nHow to add wells to the Well Section\\n1. Activate an already existing well section in the Windows pane by clicking on its name. The\\nWell Section window should appear.\\n2. Select the wells by checking the boxes in front of the well in the Wells folder on the Input\\npane.\\n3. The selected wells will now be visible in the Well section window.\\n4. Note that you can create a folder to put the Well section windows in.\\nThe Well sections are located in the Windows pane.\\nHow to add wells by picking in 3D or 2D window\\n1. Make the Well Correlation process active by clicking on it in the Processes pane.\\n2. Make sure that a 2D or 3D window is active.\\n3. Display your wells in a 2D or 3D window by clicking the check boxes in front of the wells in\\nthe Wells folder.\\n4. Click on the Add Well to Well Section icon in the Function bar.\\n5. Select the wells by clicking on the well paths in the 2D or 3D window .\\n6. If no Well section or its Well Section Fence are active, a new Well section is automatically\\ncreated and activated. Therefore, to create additional sections, simply deactivate the\\ncurrent section before clicking on more wells.\\n7. As wells are added to the section, the section \"path\" is shown in the 3D/2D window as an\\n8.\\n7.\\nintersection (Well Section Fence).\\n8. By default the wells in a new Well section fence are aligned at the bottom of the wells. Go\\nto the Wells tab under Settings for the Well Section Fence to align the wells at top, middle\\nor bottom - or on a Well top. The Well Top is inserted from the Well Tops stratigraphy\\nfolder.\\nThe Well Fence is aligned along the top of wells and in addition, tied to the well bottom.\\nThe Well Fence can also be shown directly in a Map Window.\\nIncreasing the thickness of the well paths may make selection easier. You can do this from\\nthe Style tab of the Settings for the Wells folder in the Input pane.\\nStyle settings for wells.\\nTools for Well Correlation\\nThere are a number of tools available in the Function bar while performing well correlation.\\nTo access the tools, remember to activate the Well correlation process.\\nAdd Well to Well Section - Create or extend a well section by selecting wells from a\\n2D or 3D window. Can be activated when a 2D/3D window or a Map window is active.\\nWhen a Well Section window is active, the available tools are:\\nCreate/Edit Curve Fill - Create or edit already existing curve fills in a log panel.\\nCreate/Edit Well Tops - Create new well tops or edit already existing well tops in a\\nwell section.\\nPaint discrete log class - Activate painting of the selected facies class into the log and\\nedit existing class intervals.\\nPick up discrete log class - Pick a log class from an existing log by clicking.\\nFlood fill discrete log class - Flood fill a previously defined interval with the selected\\nclass.\\nCreate/Edit continuous logs\\nCreate/Edit comment logs\\nCreate/Edit image control points\\nUndo Well Tops edits\\nShow Curve Value - Show or hide the log curve value in the upper right corner of the\\nlog panels (changes as the cursor is moved up or down).\\nToggle Synchronized Well Scrolling - Relative scroll synchronization of all wells in a\\nwell section (toggles between the first two scroll options in the well section setting panel).\\nToggle Synchronized Well Scaling - Relative scale synchronization of all wells in a\\nwell section.\\nToggle on ghost panel - Turns the ghost panel on or off.\\nView Entire Well - View the full length of the active well in a well section.\\nView Entire Wells - View the full lengths of all wells in a well section.\\nApply Template To All Wells - Apply the current well template to all wells in the active\\nwell section.\\nRemove empty tracks\\nAdd new well tops surface\\nRestricted Well Tops - Enables enforcement of the stratigraphic order between well\\ntops.\\nShow Well Top Time - Shows the well top in time if a time/depth relationship exists.\\nEdit Well Top Time - Enables interactive editing of well top time in the Well section\\npanel.\\nCreate new discrete log - Creates a new discrete global well log, one of the facies\\nediting tools must be active before this button is visible.\\nCreate new comment log\\nPrevious Horizon (shortcut Ctrl+Up) - Activates the previous well top under the\\nStratigraphy folder on the Well tops folder in the Input pane.\\nNext Horizon (shortcut Ctrl+Down) - Activates the next well top under the\\nStratigraphy folder on the Well tops folder in the Input pane.'},\n",
       " {'header': 'Shortcut Keys ',\n",
       "  'content': 'The displayed part of the active well in the Well section window can be manipulated by using\\ndifferent keyboard keys:\\nArrow key Down: Steps downwards in the displayed well\\nArrow key Up: Steps upwards in the displayed well\\nPageDown: One page down\\nPageUp: One page up\\nHome: Up to the uppermost part of the well\\nEnd: Down to the lowermost part of the well\\n-: Decrease scale\\n+: Increase scale\\nArrow key Left: Activates the previous well in the well section\\nArrow key Right: Activates the next well in the well section\\nThe manipulation can be done in smaller steps by pressing down the Shift Key when a keyboard\\noperation is done, with the exception of the Home, End, Left and Right keys.\\nShow the log value\\nTo display the value of a log at any given point, toggle on the Show log value icon , located in\\nthe Function toolbar on the rigth hand side of Petrel, when having the Well correaltion process\\nactive. Then, position the cursor on a specific depth and the value for the log will be displayed at\\nthe top of the well.\\nWhen the button is INACTIVE (OFF), you will get an on-the-fly read-out of the track value when\\nmoving the mouse along the well log displayed. It uses the vertical line of the cross-hairs. In this\\ncase, even if you have no well log visible, you will still get an on-the-fly read-out.\\nMake a correlation panel\\nThe Well section window allows the possibility to bring up several wells, well logs, point well\\ndata and several marker types (well tops) in the same correlation window.\\nEach well section window has its own icon and is stored on the Windows pane. The Well\\nsection window in Petrel 2010.1 uses a new template-centric system.'},\n",
       " {'header': 'Ghost Curve ',\n",
       "  'content': \"The ghost curve is a transparent copy of one of the wells in the well section and can be moved\\nindependently in the well section window and compared with the logs from other wells. It is\\ndesigned as an aid to correlation between wells in a well section.\\nOnly one ghost curve can be held in each well section at one time.\\nHow to create a ghost curve\\n1. Activate and visualize a Well section window containing wells being displayed.\\n2. Click on the header of any of the wells (colored area at the top of the well with the well\\nname) and drag it to one side, the ghost curve will now appear in the window. Grabbing a\\nnew well header will also remove the current ghost curve and replace it with the new one.\\nAlternatively, if no ghost curve exists, pressing toggle ghost panel button from the\\nFunntion bar. It will create a ghost curve from the active well.\\n3. The Ghost curve for a specific Well section window is stored togehter with the Well section\\ntemplate and the Well section fence in your Windows pane.\\n4. To remove the ghost curve completely, right-click on the Ghost curve icon in the well\\nsection folder of the Windows pane and select delete.\\n4.\\nWhen creating a ghost curve for the first time, it is created at 50% of the window height\\n(user defined setting). This can be changed by opening the settings for the ghost curve, style tab,\\nand under Height you can select a different Fraction of window to be displayed.\\nScaling and scrolling in the ghost curve\\nBy default, the ghost curve is given an additional depth track panel for making scrolling and\\nscaling easier. If you need to remove it, go to the ghost curve in the Windows pane, and toggle\\noff the depth track panel from here (or simply delete it).\\nTo change the scale on the ghost curve, select the ghost curve and then use + and - to change\\nthe scale. Using Shift together with these buttons will allow you to make finer adjustments to the\\nscaling. Alternatively, position the cursor on the line between the grey and white area in the depth\\ntrack panel of the ghost curve. When the cursor becomes a double arrow, move it to stretch or\\nsqueeze the well. Use arrow up and arrow down to scroll (with Shift for incremental scrolling). You\\ncan also scroll by positioning the cursor on the white depth panel, and move the hand icon while\\nusing the left mouse button to scroll the display up or down the well.\\nThe ghost curve can be set to use either its own scale or the scale of the underlying well\\nsection. By default the ghost curve does not scale in synch with the background well section\\nwindow, in this way you can more easily fix the scale of the ghost curve independent of the scale\\nof the well section. This should help the user in cases where the log signatures are similar, but\\nstratigraphic thicknesses are different between wells. This behavior can be overridden by\\ndeselecting the Specify depth scale option in the settings for the ghost curve.\\nBy using the Toggle synchronized well scaling icon , you can scale the ghost curve in synch with\\nthe well section.\\nNote: The ghost curve does not scroll or flatten in synch with the background well section,\\nand this cannot be overridden.\\nSettings for the Ghost curve\\nDouble-click on the ghost curve icon, under the well section folder in the Windows pane, to open\\nthe settings panel. The Info tab contains the name of the ghost and a comment field. The Style\\ntab has the following settings:\\nHeight- Set the fraction of the window height to be displayed (%).\\nBackground- Set the background color of the ghost curve and transparency.\\nCurves- Select whether or not to display curve fill (the underlying well must have curve\\nfill).\\nDynamic adaptation- This setting controls how the curve behaves as it is dragged across\\nother wells in the well section. There are three options:\\nNone - The curve will no longer change depending on the underlying well. Logs can\\nbe turned on and off under the ghost curve on the Windows pane. If this option is\\nused, it is wise to first change to underlying well so that all the log panels are\\navailable in the windows panel.\\nUnderlying curve (default) - As the ghost curve is dragged across the section, it\\nwill change according to the log panel it is being dragged over. The ghost will look for\\nthe equivalent panel in the well where the ghost is applied and display that data in the\\nstyle of the underlying well.\\nUnderlying well - As the ghost curve is dragged across the section, it will change\\naccording to the well panel it is being dragged over. The ghost will display data from\\nthe well where the ghost is applied in the style of the underlying well; all of the well\\npanels will be displayed.\\nThe Settings tab allows you to select the Depth measurement type to be displayed\\n(SSTVD, TVD, MD, TWT, etc), to specify the Depth range to use, and also has the option of\\nSpecifying a fixed depth scale if required.\\nNote: In previous version of Petrel it was possible to pick well tops in the ghost curve\\nby clicking on the ghost curve directly, then the well tops were placed on the wellbore from\\nwhich the ghost curve was created originally. This functionality has been removed. Now, if\\nyou place the ghost curve over a well, and then pick well tops, the tops will be assigned to\\nthe underlying well. You can click inside the ghost, but the well top will be placed on the\\nbackground well. This should help you to match the patterns more intuitively.\\nSelecting a template\\nThe adoption of a template does away with the tree of visuals on which the user previously had to\\ngroup and ungroup curves, define color fills, and so on. Rather than having to create and apply\\nthe template in separate work steps, you can now work directly on the template, seeing\\ninteractively edited curve fills and track widths updated instantaneously across the entire well\\nsection window.\\nWhen you open a new Well section window, you will have to select the well section template you\\nwish to use. You can:\\n1. Create a new well section template\\n2. Use from an existing template (any of the Petrel system templates, a user defined or an\\nimported template)\\nIn addition to these direct benefits, we have been able to build on features enabling you to:\\n1. Define a log curve preference system for the Well section window.\\n2. Choose from a default well section templates.\\n3. Share well section templates between projects.\\n4. Define your own default well sections templates.\\nFor safety reasons, Petrel will not allow you to delete a well section template that is in use in a\\nwell section window. These templates will appear in italics.\\nHow to use a well template\\nWhen you open a new Well section template, you will have to select between:\\nCreating a new Well section template. The new well section template will be added to the\\nTemplates pane. The new template will contain a depth track by default. Next, you will\\nhave to build the template.\\nUse an existing template. Any of the previously created, imported, project converted or\\neven predefined Petrel system templates can be chosen from a drop down menu in the\\nSelect new well section template dialog box. All wells added to the new window will use the\\ndefault Well section template.\\nTo open the Settings for the Well section template , click the short cut placed in the Tool bar.\\nToggle between well section templates on the\\nfly\\nThe Well section window toolbar has been extended to allow interactive template selection.\\nChanging the template will affect all of the wells. You can choose from any of the Petrel system\\ntemplates (default well section templates) or any user defined, imported or project converted (pre\\n2010.1) templates.\\nThe settings for the well section template shown in the selection menu can be opened up by using\\nthe shortcut button alongside it.\\nReduce the number of templates\\nReducing the number of templates to the minimum that you need to preserve your windows is\\nhighly reccommended. The following scenarios are a few suggestions which can be helpful:\\nIf one well section template was applied to many windows you can point them all to one\\ncopy of the template and delete the others\\nIf you had to use different global well logs in different wells - different GR's for example -\\nPetrel will create one template for each. This can be replaced with a single template that\\nincludes all candidates for the non-unique measurement type\\nUsing different Well section templates in a\\nsingle well section window\\nIt is possible to use different Well section templates for different wells in the same Well section\\nwindow. Do the following:\\n1. Select the well in the Definition tab under the Settings for the Well section window (1)\\n2. Deselect the Use default check box (2).\\n3. Select a different template from the Template drop-down list (3)\\n4. Click Apply to visualize the changes in the Well section window.\\n5. You can still edit data styles on the Template settings dialog, that can be accessed using\\nthe shortkey next to the drop-down list.\\nChoose from a set of default well section\\ntemplates\\nThe separation of the template settings from project data also enables us to equip Petrel 2010.1\\nwith a set of default templates. These have been based on standard templates, with some Petrel-\\nspecific additions.\\nThe templates are encoded in a Petrel xml schema and installed in the program files directory on\\nyour computer. Because the list of candidate data in the definition is part of the schema, two\\ntypes of templates are supported:\\n1. Naked templates, in which the curve is only defined by a property template and there are\\nno candidates. These templates will be populated automatically with any project data that\\nmatches the property template.\\n2. Templates in which a log curve preference system has been defined for each curve in the\\ntemplate. These templates will also be populated automatically with project data, but only\\nthose data with matching property template and name.\\nTriple combo\\nThis combination of curves and scales is one of the most common standards in the logging\\nindustry. The curve colors used in the Petrel template are consistent with other petrophysics\\napplications. As with other Petrel default templates, the definition is left open. In this case\\n(Gullfaks) you can see that 2 candidates have been found for the Gamma ray. You can also see\\nthat SP is defined in the template, but no data has been found.\\nResistivity sonic\\nThis combination of curves and scales is another logging industry standard. The curve colors used\\nin the Petrel template are consistent with other petrophysics applications. Like other Petrel default\\ntemplates, the definition is left open. As with the Triple combo template the Resistivity curves are\\ndefined using specific templates for the 3 depths of investigation. This could be loosened if non-\\nspecific resistivity curves are to be used.\\nDensity neutron shaded\\nIt is customary to shade between the density and neutron curves to highlight crossover and aid\\nlithology interpretation . This template includes fills in standard colors.\\nComposite log\\nThis template is designed to show the type of information typically shown on a composite well log\\n(or completion log). The Completions track is restricted to show only casing and perforation\\nobjects.\"},\n",
       " {'header': 'Raster ',\n",
       "  'content': 'This template is designed to simplify the process of creating a well section window with multiple\\nraster logs. The definition tab can contain the raster logs for all the wells.'},\n",
       " {'header': 'Signatures ',\n",
       "  'content': 'This template contains the kind of reservoir data that is useful in creating signature plots in the\\nmap window. Note that the template also defines which curve is to be used to fill the GR.'},\n",
       " {'header': 'Core ',\n",
       "  'content': 'The template can also include photos and point data and define their scale and styles . There is\\nroom for more than 1 set of core photos, but the number can be altered to suit the needs of your\\nproject.'},\n",
       " {'header': 'Lithology ',\n",
       "  'content': 'This template includes a summation track, including fill colors and patterns. A sample definition is\\nprovided for illustration, but will need to be edited to fit the volumetrics mnemonics in your\\nproject. Note also that Petrel now includes a property template for PEF curves, which are included\\nin this template. No PEF data has been found for these wells.'},\n",
       " {'header': 'Velocity ',\n",
       "  'content': 'This template brings together the velocity data from logs and check shots. It could be extended to\\nshow the velocity logs output from the Velocity modeling process. Note also that a TWT index\\ntrack is included in the template.\\nAdd a well to a Well section window\\nTo add a well to the Well section window , first make sure that the Well section is active.\\n1. Select the wells from the main Wells folder in the Input pane. Select the checkbox in front\\nof each well you want to add.\\n2. Alternatively, open the Settings for the Well Section window and under the Definition\\ntab, you can bring multiple wells from the Input pane by using the blue arrow button(Add\\nwell to well section).\\nThe well icons in the Well settings area represent a link to the data. Deleting any well in the\\nDefinition tab will not delete any data from the project. To hide a well temporarily, uncheck its\\ncheckbox either in the Definition tab or in the Wells folder in the Input pane..\\nAdd wells by picking in 3D or 2D\\n1. Make the Well Correlation process active by clicking on it in the Processes pane.\\n2. Make sure that a 2D or 3D window is active.\\n3. Display your wells in a 2D or 3D window by clicking the check boxes in front of the wells in\\nthe main Wells folder.\\n4. Click on the Add well to well section icon in the Function bar.\\n5. Select the wells by clicking on the well paths in the 2D or 3D window .\\n6. If no Well section or its Well Section Fence are active, a new Well section is automatically\\ncreated and activated. Therefore, to create additional sections, simply deactivate the\\ncurrent section before clicking on more wells.\\n7. As wells are added to the section, the section \"path\" is shown in the 3D/2D window as an\\nintersection (Well Section Fence).\\nDefine a log curve preference system\\nIt is normal for a Petrel project to contain many logs of the same type, for example, Density. In\\nprevious versions of Petrel, this made it difficult to work with templates because the styles were\\nspread over many global well logs, but in Petrel 2010.1 a single curve in the template can\\nrepresent many real logs. This means that;\\nThe same style can be applied to multiple global well logs simultaneously.\\nThe list of candidates can be ordered, so it can be used as a log curve preference system as\\nwell. Changing the order of rows changes the preferred log.\\nA preference system can also be built interactively using the same context menu system as the\\nother template building activities. Right-click on the log stored under the Global well logs folder\\nin the Input pane and Add to template in a new track, an existing track, or on a existing log\\ncurve.'},\n",
       " {'header': 'Well Section Settings ',\n",
       "  'content': 'There are four tabs on the settings panel for the well section.\\nInfo - the standard info tab, see Info Tab for a description of these settings.\\nSettings - these settings control scrolling and depth measurement type.\\nLayout - the horizontal spacing of the wells in the panel are controlled together with panel\\nsplitting.\\nSetup paper - settings for paper size and orientation.\\nThe Settings window for a well section.\\nWell Section Settings tab\\nScaling and vertical positioning of wells in a well section can be set via the Well sections settings\\ndialog. Double-click on the well section in the Windows pane to open the settings.'},\n",
       " {'header': 'Well Position Synchronization ',\n",
       "  'content': 'There are six different ways to synchronize the position of all wells in a well section.\\nNo Synchronization - All the wells in a well section are positioned individually ( is\\ntoggled off).\\nScroll relative - Will enable synchronized scrolling of wells ( is toggled on).\\nFlatten on well top - Will flatten the entire well section on a specific well top surface. After\\nthe operation, the specified well top surface will appear all over the section as one\\nhorizontal line.\\nReference well (Tie to these well tops) -With this option all tops are flattened, with the\\nwells stretched and squeezed between the tops (tram lines).\\nHere are all wells flattened on a well top set, using C6 as reference.\\nFlatten on depth - Will flatten the entire well section on a specific depth value (MD, TVD\\nor SSTVD).\\nFlatten from window top - Will flatten the well section at a certain percentage from the\\ntop of the Well Section window.'},\n",
       " {'header': 'Well Scale Synchronization ',\n",
       "  'content': 'The following global settings are available for a well section:\\nDepth measurement type - Defines the vertical scale the logs are plotted in. This is\\nseparate from the depth scale panel shown in the window. I.e. wells printed in TVD can\\nhave an MD scale panel for reference. Available scales are MD, TVD, SSTVD, OWT, TWT,'},\n",
       " {'header': 'TVT, TST. ',\n",
       "  'content': \"No Synchronization - The wells are scaled independently of each other ( toggled off).\\nRelative - The wells in the well section will be scaled relatively by the same factor (\\ntoggled on). Apply an absolute scale first if you want all the wells to be attached to the\\nsame scale.\\nAbsolute (printed scale) - The wells printed scales are set to the same absolute value. If\\nthe Fixed tick box is enabled, interactive well scaling will be disabled.\\nSome Depth measurement types require additional data and are not available unless the\\ndata is also available. Time scales require a time depth relationship (see Time (Wells)), while\\ndepth scales require dip and azimuth data (see Thickness (Wells)).\\nAccount for missing Well Tops when Flattening\\nA very useful feature of the Well Section is the ability to flatten on a Well Top. Sometimes one of\\nthe wells does not contain the well top data.\\nIf the chosen well top is missing, Petrel will look for the next top up in the stratigraphic\\ncolumn. If there is no top there, it will go down the column.\\nWells will be aligned based on the nearest top present.\\nHow to perform synchronized scrolling of a well section\\n1. Activate the Settings window for the active well section by double-clicking on the well\\nsection's icon.\\n2. Select Scroll relative under the Settings tab, and click OK (alternatively use the icon for\\nsynchronized well scrolling in the Function bar).\\n3. Click with the cursor in the depth panel for one of the wells and start scrolling.\\nHow to change global settings for wells in a well section\\n1. Activate the Settings panel for the active well section by right-clicking the well section name\\nin the Windows pane.\\n2. Go to the Settings tab.\\nHow to flatten a well section on a particular well top\\n1. Activate the Settings window for the active well section by double-clicking the well sections\\nicon.\\n2. In the Settings tab, select Flatten on well top.\\n3. Go to the Stratigraphy folder under Well Tops, select a Well Top and drop it in using the\\nblue arrow option.\\n4. Press Apply and see the changes in the well section.\\nHow to flatten a well section on multiple well tops (tram lines)\\n1. Activate the Settings window for the active well section by double-clicking the well sections\\nicon.\\n2. In the Settings tab, select Reference well.\\n3. Go to the Input pane, select a reference well and drop it into the reference well field by\\npressing the blue arrow .\\n4. Select the Well Tops folder and drop it in.\\n4.\\nWhen multiple wells are used with a single log curve, no depth track and minimum well\\nspacing, then the display starts to look similar to seismic correlation. This is a very good way of\\ncontrolling and presenting field wide correlations for a large numbers of wells. The input well is the\\nReference, while the other wells are Referenced.\\nWell section Layout tab\\nThere are two sections on this tab:\\nHorizontal spacing:\\nThese options determine the space between the wells in the well section. There are three options:\\nManual - the user can grab the left hand side of any of the well panels and drag the panel\\nmanually. Irrespective of the method used for spacing the panels, the user can do this once\\nthe settings panel has been closed.\\nConstant - the user specifies a constant distance in mm that should be used between each\\npanel.\\nRelative - the user specifies a well top on which to base the panel spacing and a horizontal\\nscale. The distance between the wells will be scaled to the distance between the well tops.\"},\n",
       " {'header': 'Panel Splitting ',\n",
       "  'content': \"Splitting essentially takes a copy of the well panel and displays it to the side of the original panel.\\nThis is used when the well is inverted in the displayed depth scale, i.e. in a horizontal well when\\nTVD starts decreasing with increasing MD, or with reverse faults displayed in a TVT or TST scale\\nwhen stratigraphically equivalent sections have more than one value.\\nThis well path has two tangent points (TVD decrease).\\nUsing Panel split for the two tangent points.\\nOnce the panel splitting has been selected in the Well section window, fault gaps can be\\nintroduced by entering the offset in the missing section in the Well Tops Spreadsheet. Negative\\nvalues indicate a missing stratigraphic section, while positive values indicate a repeated section.\\nThese offsets will only be visible if the well is displayed in TST or TVT mode (the absolute MD and\\nTVD of a point on the well trace are always reported correctly).\\nA well showing fault gaps (missing section). Needs to be displayed in TVT/TST mode.\\nHow to split panels\\n1. Open the Settings panel for the well section by double-clicking in the well section name, in the\\nWindows pane.\\n2. Under Panel Splitting choose By domain from the pull down menu.\\n3. Choose one of the options available, the options are:\\nGroup by intervals - arranges split panels so that identical intervals are put side by side.\\nGroup by data - arrange split panels so that panels from the same data object are side by\\nside.\\nCompact interval - will try to put intervals in existing split panels (from left to right) to\\nconserve screen space.\\nMin. interval length - will hide intervals smaller that the given length.\\n4. Press Apply / OK to see the changes.\\nWell position synchronization\\nThere are six different ways to synchronize the position of all wells in a well section.\\nNo Synchronization - All the wells in a well section are positioned individually (be aware\\nthat the Synchronized well scrolling button in the Function bar is toggled off).\\nScroll relative - Will enable synchronized scrolling of wells ( alternatively toggle on the\\nSynchronized well scrolling in the Function bar).\\nFlatten on well top - Will flatten the entire well section on a specific well top surface. After\\nthe operation, the specified well top surface will appear all over the section as one\\nhorizontal line.\\nReference well (Tie to these well tops) -With this option all tops are flattened, with the\\nwells stretched and squeezed between the tops (tram lines).\\nHow to perform synchronized scrolling on a well section window\\n1. Activate the Settings window for the active well section by double-clicking on the well\\nsection's icon.\\n2. Select Scroll relative under the Settings tab, and click OK (alternatively use the icon for\\nSynchronized well scrolling in the Function bar).\\n3. Click with the cursor in the depth panel for one of the wells and start scrolling.\\nHow to flatten a well section on a particular well top\\n1. Activate the Settings window for the active well section by double-clicking the well sections\\nicon.\\n2. In the Settings tab, select Flatten on well top.\\n3. Go to the Stratigraphy folder under Well Tops, select a Well Top and drop it in using the\\nblue arrow option.\\n4. Press Apply and see the changes in the well section.\\nIf the chosen well top is missing, Petrel will look for the next top up in the stratigraphic\\ncolumn. If there is no top there, it will go down the column.\\nWells will be aligned based on the nearest top present.\\nHow to flatten a well section on multiple well tops (tram lines)\\n1. Activate the Settings window for the active well section by double-clicking the well sections\\nicon.\\n2. In the Settings tab, select Reference well.\\n3. Go to the Input pane, select a reference well and drop it into the reference well field by\\npressing the blue arrow .\\n4. Select the Well Tops folder and drop it in.\\nWhen multiple wells are used with a single log curve, no depth track and minimum well\\nspacing, then the display starts to look similar to seismic correlation. This is a very good way of\\ncontrolling and presenting field wide correlations for a large numbers of wells. The input well is the\\nReference, while the other wells are Referenced.\\nWell scale\\nThe well scale can be controlled interactively in the Well section window or from the Well\\nsection window settings. The following possibilites are available:\\n1. Arbitrary: In the Well section window, click at the top or bottom border of the white area\\nand squeeze or stretch this area to zoom in and out (using the double arrow together with\\nthe left mouse button).\\nNo Synchronization - The wells are scaled independently of each other (\\nSynchronized scaling in the Function bar is toggled off).\\nRelative - The wells in the well section will be scaled relatively by the same factor (\\nSynchronized scaling in the Function bar is toggled on). Apply an absolute scale\\nfirst if you want all the wells to be attached to the same scale.\\n2. Absolute (printed scale) - The wells printed scales are set to the same absolute value. If\\nthe Fixed tick box is enabled, interactive well scaling will be disabled.\\nHow to change the scale of a well\\nInteractively in the Well section window:\\n1. Activate the well section in the Windows pane and display the selected well in the Well\\n2.\\n1.\\nSection window.\\n2. Place the cursor inside the depth panel, where the color changes from white to grey. A\\ndouble-arrow appears.\\n3. Left click and drag to a new position to change the scale.\\nOr from the Settings for a Well section window:\\n1. Open the Settings panel by double clicking on the well name under the Well section folder\\nin Windows pane.\\n2. Select the Absolute Well scale in the Definition tab.\\n3. Specify the depth measurement type (MD, TVD or SSTVD).\\nSet the depth range of a well\\nTo set the depth range of a well being displayed in the Well section window you have to:\\nOpen the Settings window by double-clicking on the specific well name under the Well\\nsection folder in the Windows pane.\\nSelect the Set depth range checkbox.\\nSelect the depth range under the Settings tab. The minimum and maximum depth (Top\\ndepth and Bottom depth, respectively) for a well can be inserted by pressing the blue\\narrow.\\nDepth measurement type\\nThe Depth measurement type (Domain) defines the vertical scale the logs are plotted in. This is\\nseparate from the depth scale panel shown in the window. I.e. wells printed in TVD can have an\\nMD scale panel for reference. Available scales are :\\nMD- Measured depth\\nTVD- True vertical depth\\nSSTVD- Sub sea true vertical depth\\nOWT -One way time, requires a time relationship\\nTWT -Two way time, requires a time relationship\\nTVT -True vertical thickness, requires stratigraphic dip and azimuth data\\nTST -True stratigraphic thickness, requires stratigraphic dip and azimuth data\\nThis will change which scale is displayed linearly down the well section view, and should not be\\nconfused with the depth scales which are displayed next to the well section (which need not be\\nlinear). If a scale requires additional data (OWT, TWT, TVT, TST) and this data is not available,\\nthen it will not appear in the list.\\nGeneral track settings\\nWhen a log curve is added to the Well section, it will get a track folder and a corresponding log\\npanel. The track panel's Style tab controls the settings for the scaling, grid line colors, whether\\nthese should be displayed (vertical and horizontal), and background color and transparency for\\nthe panel. The width of the well panel can be changed from here too. To access the Style tab\\nopen the Settings for the Well section template and go to the Well section template settings tab.\\nChanging the width of the well panels\\nThe size of the log panels can be changed by dragging the edge of the panel header to the\\nrequired size. You need to be in Select/pick mode to do so. To change the total width of all\\nthe panels for one well, grab the wells header (blue ellipse in the picture). To change the size of\\nindividual log panels, grab the edge of that panels header (red ellipses below).\\nHow to change the width of a log panel in Well Section.\\n1. Activate the Well Section in the Windows pane and display the selected wells in the Well\\nSection window.\\n2. Make sure you are in the Select/pick mode. Place the cursor on the panels right edge.\\nThe cursor changes to the double-arrow. Then drag the right edge of the panel to the new\\nposition.\\n3. Alternatively, open the well section template associated to the Well section window. Go to\\nthe Style tab in the Well section template settings for any existing track and specify the\\nwidth of the panel. Select Fixed to prevent accidental interactive changes.\\nHow to change the width of the Well in the Well Section.\\n1. Activate the Well Section in the Windows pane and display the selected wells in the Well\\nSection window.\\n2.\\n1.\\n2. Place the cursor on the well headers right edge. The cursor changes to a double-arrow.\\nThen drag the right edge of the well header to the new position.\\nCurve fill for continuous curves\\nThere are two ways to insert curve fills:\\n1 . To quickly fill a continuous curve with the colors from the color template, click on the\\nappropriate side of the curve using the Create/edit curve fills icon. The following options are\\navailable:\\nPressing SHIFT and clicking will truncate either the top MD or the base MD of the fill\\n(depending on which one is closer). Once truncated, more truncations can be added in MD\\nusing the SHIFT key and clicking in the empty field. Hold down the SHIFT key while\\ninserting the color fill.\\nPressing C with the mouse pointer over a fill, will toggle through the coloring of the fill by:\\nproperty, specified, black, and white.\\nPressing X will toggle the pattern fill on and off.\\nPressing SHIFT and X , will toggle through all of the available pattern fills.\\nPressing DELETE will remove the curve fill. If the mouse pointer is over the fill limit (top or\\nbase MD, curve truncations, etc.), it will be removed .\\n2 . More complex curve fills can be designed through the Curve filling tab under the Well\\nsection template settings . Remember to highlight the track you want to fill color in. There is\\nno limit to the number of curve fills that can be drawn on a single well log. To add a new curve fill,\\nclick the Append row icon. There are a few setting to specify for each curve filling:\\nDepth interval - Can be specified either by specifying a MD value or by selecting\\ntop/bottom of the well.\\nFill edge - The fill can be specified to and from: Panel edge , Curve and Level .\\nFill style - This is where you specify whether to use a pattern to fill the log curve or a\\ncolor. If you select color, choose between: Specified , As property , As grid property ,\\nBlack, and White .\\nColor fill for discrete curves\\nBy default, discrete curves will be filled and will not have any lines or points shown. The settings\\ncan be changed at the log level. Highlight the log under the track containing the discrete log and\\ngo to the Style tab. Select the 2D log sub-tab. There are additional options for discrete curves:\\nDiscrete value border ; show the border between facies.\\nFill with color ; fill the panel with the color of each facies.\\nFill with pattern ; fill the panel with the color of each facies.\\nShow value label ; post the name of each facies on each interval in the panel.\\nTo review the color settings of a discrete well log, open the Settings for the template directly in\\nthe Templates pane. Alternatively, open the Settings for the log under the Global well logs\\nfolder in the Input pane and go to the Colors tab.\\nDisplay of grid lines\\nThe settings for the display of gridlines are on the Style tab under the Well section template\\nsettings. There are separate settings for vertical and horizontal lines. The vertical lines can be\\neither Logarithmic or Linear . If linear is chosen, there are 3 options:\\nAuto - Petrel picks the amount of lines according to scale of data.\\nDivisions - You can assign a fixed amount of lines irrespective of log data range (limited to\\n1,2,3,4,5,10).\\nIncrement - You can specify increments of the data, the options depend on the max and\\nmin value of the log data (if auto) or the scale set by the user.\\nRemenber to select the Draw vertical lines check box. The same applies for the horizontal lines.\\nBackground track color\\nThe settings for the background color of track can be found under the Style tab in the Well\\nsection template settings. Transparency can be given to the background color.\\nGeneral log settings\\nWhen a log curve is added to the Well section, it will get a log panel stored under a track folder.\\nThe log panel Style tab controls the settings for the scaling of the curves, the position of the\\ncurve along the track (left or right), and the possibility of showing the log points. To access the\\nStyle tab open the Settings for the Well section template and go to the Well section\\ntemplate settings tab.\\nLog scales\\nTo set the curve scales appropiately, go to the General settings tab under the Style tab of the\\nWell section template settings for any continuous log. This will override the scale determined\\nby the colors tab of the attached template. The type of scale (linear or logarithmic) is a\\nparamenter of the track where the log is displayed. The default set is the maximum and minumin\\nvalues contained in the log. The scale can also be reversed here.\\nAdjust log curve scale\\nHow to adjust log curve scale\\nIt is important to understand how the log curve scale works when working with two curves or\\nmore with the same measurement type and same template (example GR and GR_30) in the same\\ntrack. When they are displayed in the same track, they share the log curve scale (i.e. they use\\nthe min and max value that apply to both). In other words, the log scale will look for the log\\nminimum value of all the curves with the same template and the maximum value of all the\\ncurves, and it will use this value for the log scale of the track panel.\\nIf you want to display two or more curves with the same measurement and same template, but\\ndifferent log scale, you can do it in two ways:\\n1. Display them in separate tracks, then each track will hold its own scale.\\n2. If you want them in the same track, but with different scale, there is a different approach:\\n- Create a new global template in the templates pane.\\n- It will be created at the bottom of the main templates folder it was created from. Open the\\nsettings of the new template, go to the Info tab, rename the template (for instance 'My gamma\\nray'), in the Measurement choose the one you need (for example for Gamma Ray select\\n'APIGammaRay'). Click OK.\\n- Next, go to the curve (under Global well logs folder) you want to display, open the settings and\\nin the Info tab, select the new Template you just created (My gamma ray). Click OK.\\n- Now each curve will act independently, you can set the log curve scale different for each of the\\ncurves.\\nTwo logs of same measurement type, with different scales, GR from 0-150 and GR_20 from 0-\\n100.\\nShowing the log points\\nThe measurement data will be shown as points along the log. To show the points, go to the 2D\\nlog tab under the Style tab of the Well section template settings for any continuous log.\\nChoose the color, symbol, and point size to be drawn along the log curve.\\nWell section layout\\nThe layout for the well section window can be controlled from the Layout tab under the Settings\\nfor any Well section window. From there you can control:\\n1. Horizontal spacing - controlling the space between wells in the Well section window.\\n2. Panel splitting - splits panels to avoid data overlap for faults, repeated stratigraphy or\\nhorizontal wells.\\nHorizontal spacing\\nHorizontal spacing determines the space between the wells in the well section. There are three\\noptions:\\n1. Manual - grab the left hand side of any of the well panels and drag the panel manually.\\nIrrespective of the method used for spacing the panels, you can do this once the settings\\npanel has been closed.\\n2. Constant - specifiy a constant distance in mm that should be used between each panel.\\n3. Relative - specifiy a well top on which to base the panel spacing and a horizontal scale.\\nThe distance between the wells will be scaled to the distance between the well tops.\\nPanel splitting\\nSplitting essentially takes a copy of the well panel and displays it to the side of the original panel.\\nThis is used when the well is inverted in the displayed depth scale, i.e. in a horizontal well when\\nTVD starts decreasing with increasing MD, or with reverse faults displayed in a TVT or TST scale\\nwhen stratigraphically equivalent sections have more than one value.\\nPanels can be splitt by:\\nGroup by intervals - arranges split panels so that identical intervals are put side by side.\\nGroup by data - arrange split panels so that panels from the same data object are side by\\nside.\\nCompact interval - will try to put intervals in existing split panels (from left to right) to\\nconserve screen space.\\nMin. interval length - will hide intervals smaller that the given length.\\nDisplay of other data in the Well section\\nwindow\\nData related to your 3D model as well as interpreted or imported data stored in the Input pane\\ncan be displayed across the whole Well section window. This data will be displayed as lines\\n(either continuous or dotted lines).\\nSurfaces, Horizons and Contacts\\nSurfaces, horizons, and contacts can all be displayed in the Well section window and appear in\\nmuch the same style as well tops.\\nThese data are displayed by selecting the appropriate object in the project explorer for viewing.\\nGo to the Input pane to select any generated or imported surface. To edit the style, open the\\nSettings for a particular surface.\\nGo to the Models pane to select any grid related structural horizon. To edit the style, open the\\nSettings of the horizons folder.\\nGo to the Models pane to select and contact. To edit the contact, open the Settings of a\\nparticular contact.\\nThe point where the chosen surfaces, horizons, or contacts cut the well path will be displayed in the\\nwell section as a dotted line.\"},\n",
       " {'header': 'Fig. 1 ',\n",
       "  'content': \"When displaying contacts, it is important to remember that the contact will only be displayed if\\nthe contact cuts the well path. If the contact is above the top of the zone, it will not be displayed in\\nthe well path. In figure 2, the highlighted change in fluids will not result in a contact in the well\\nsection.\\nFig. 2 A diagram showing how changes in fluids may not coincide with a contact.\\nWell Tops and Well Top surfaces\\nIn the Well Correlation process, Well Tops are used to store correlation picks. Well Top surfaces\\nare stored in the Stratigraphy sub-folder of the Well Tops folder in the Input pane and\\ncorresponds to a correlation surface.\\nWhen working with the Well Correlation process, it is possible to pick and correlate surfaces for all\\nthe wells that are included in a well section. This will create well tops surfaces for all the\\ncorrelated wells.\\nOnly one well top surface can be active (bold) at a time. A well top surface is activated by left-\\nclicking on the icon. Well tops that are not displayed in a well section are regarded as disabled\\nfrom that section.\\nWell tops surfaces are visualized as horizontal lines that cross the displayed wells in a Well section\\nwindow. The line color and the line width belonging to the active well top surface can be changed\\nin the Settings window for that specific well top surface.\\nHow to change settings for well tops\\n1. Make the Well section window active.\\n2. Go to the Input pane and right-click on the Well Tops folder to open the Settings\\npanel.\\n3. The Style>Symbols and labels tab are controlling all of the style setting for the Well\\ntops. For example, color and width of the line, symbols size, labels and sub labels font\\nand color, and more.\\n4. Apply the new settings and check the changes in the well section panel.\\n4.\\nFor more information about Well tops see Make/Edit well tops.\\nDisplaying well tops attributes\\nWell tops attributes can be displayed in different type of windows (for example, Well section\\nwindow, 3D window, Intersection window and Map window). In 3D windows only one attribute can\\nbe displayed at the time, while in other type of windows (for instance in a well section window)\\nseveral attributes can be displayed at the same time. When the attributes has a yellow circle\\ncheck box, than mean that just one attribute can be displayed at the time. When the attributes\\nhas a yellow square check box, means that several attributes can be displayed at the same time.\\nDisplaying well tops attributes in the well section\\nWell top attributes can be displayed directly in the well section by toggle on the desire attribute\\nunder the Welltops>Attributes folder in the Input pane. Zone attributes are displayed in\\nmuch the same way as blocked logs or 3D grid properties across the relevant zone in the model,\\nwhile attributes stored on the well top are displayed as points.\\nThe Style settings for the well tops attributes and zone attributes in the Well Section are\\ncontrolled from the Style tab of the attribute. This will only be available when a well section is\\nactive.\\nWell Section Style settings for attributes.\\nFigure below shows a porosity log together with well top attribute of the log, and a gamma ray log\\nand the corresponding gamma zone attribute.\\nWell section display with Porosity log and porosity zone attribute.\\nDisplay color fill between the well tops in the well\\nsection\\nIt is possible to display color fill between the well tops in the well section. The color is controlled\\nby the color of the zone in the stratigraphic folder (Well Tops > Stratigraphy > Settings for Zone).\\nTo turn on the color fill between wells in the Well Section display, open the Settings for Well Tops\\n>Style tab. Under the Inter well options toggle 'Show color fill at zone level'. The options are each\\nstratigraphic level (1, 2, 3 etc) or max (takes the highest level number).\\nDisplaying well top attributes in 3D\\nWell top attributes can be displayed in 3D together with the well tops.\\nThe rules are as follows:\\nThe attribute controlling the well tops elevation will be shown in pink, to change this, right\\nclick a different attribute and choose, Use as visual vertical position .\\nThe label color is taken from the highlighted attribute, unless a different color selection has\\nbeen made in the Well Tops settings dialog, Style tab, Common subtab ( As Attribute is\\nused as default). If the attribute is undefined it will be colored gray.\\nThe label is taken from the ticked attribute.\\nIf the attribute is shown in its true X,Y and attribute position, the attribute can be edited by the\\ndragger. The Z-value will then represent the true attribute value.\\nSee Well Top Settings for more information about displaying well tops.\\nStyle settings for Well Tops; shown for 3D.\\nHow to visualize attribute data in 3D window\\n1. Display the wells and well tops you wish to work with.\\n2. Select the depth attribute (becomes bold).\\n3. If labels are too small, go to the Well Top settings dialogs Style tab, Common subtab and\\nincrease the font size and press Apply .\\nDisplaying well top attributes in intersection or\\ninterpretation window\\nThe well tops can be displayed in intersection or interpretation windows. The points are projected.\\nUnder the Input Settings tab, in the settings for the intersection/seismic line, the user can\\nspecify the maximum Distance limit for the projection. Other settings are grayed out and only\\nfor use in 3D display. If you want to change style settings for surfaces or well tops displayed in\\nIntersection or interpretation window - go to Well Top Style settings or individual surfaces for\\nstyle changes.\\nSeveral different attributes can be displayed at the same time, and the vertical elevation is set by\\nright clicking on an attribute and selecting Use as visual vertical position from the pull down\\nmenu.\\nSee Well Top Settings for more information about displaying well tops.\\nStyle settings for data in Explorer Input tab (here seismic inline) - Projection distance limit.\\nHow to display well tops in time in an Interpretation window\\n1. Open an Interpretation window.\\n2. Select the seismic line to be displayed.\\n3. Toggle on the Well Tops folder to display the Well Tops in the interpretation window.\\n4. Open the Attributes folder under the Well Tops folder.\\n5. Select to display just the Time attribute.\\n6. Automatically the time attribute will be used as a visual vertical position, and it will be\\ncolored in pink. If the time attribute is not in pink color (Used as visual vertical position),\\nright-click on the Time attribute and select Use as visual vertical position from the pull\\ndown menu.\\n7. The Time attribute will be now used for visual vertical position and will be pink in the Petrel\\nexplorer.\\n7.\\nDisplaying attributes on maps\\nThe attribute values can be posted around the well symbol at different positions (a maximum of 8\\nvalues can be posted).\\nThe draw style is found in the settings dialog for each attribute. The user can set a prefix and\\nsuffix to each of the values. The user can use optional control font parameters for each of the\\nattributes individually. The number of digits shown is controlled by the property template.\\nAttributes can also be displayed as pie charts and azimuth arrows, see Well Top Settings for more\\ninformation about these options.\\nHow to plot well top attributes on a map\\n1. Open a new Map window.\\n2. Select horizon under the Well Tops Stratigraphy folder.\\n3. Zoom in on one of the wells.\\n4. The well symbol and depth value is displayed as default. The well symbol is set in the well\\nfolder.\\n5. The label parameters are set in the Well Tops settings Style tab, while the positioning of\\nthe attribute value around the well symbol is controlled by the Attribute settings Style tab.\\n6. Display the Well name attribute together with the Horizon name.\\n7. See Well Top Settings for more information.\\nPlotting well top attributes in a function window\\nWell top and zone attributes can be cross plotted in the Function window. The first attribute\\nselected will be used for the X-axis, the second for the Y-axis and the third will be used to color\\nthe points. The style of the points displayed is controlled by the Crossplot tab under the Well\\nTops folder settings. See Well Top Settings for more information.\\nCreate your own system templates\\nThe template-centered approach developed in Petrel 2010.1 allows you to create templates you\\nwish to use frequently, or wish to disseminate among a large user community. There are two\\nways to create new system templates:\\n1. Create the template in Petrel and export it. If the template is exported to the correct folder\\nin the Petrel install directory Petrel will read it next time a new project is created\\n2. Create the template directly in an xml editor. The xml schema is described in the Petrel\"},\n",
       " {'header': 'Online Help ',\n",
       "  'content': 'Add a log curve to a well section template\\nThere are different ways to add log curves to a well section template:\\n1. Select the log from the Global Well Logs folder in the Input pane, and check the logs (1) you\\nwant to add in the Well section window. The log will be displayed in a new track. To add the log to\\nthe existing Well section window template (3), click the Save active window to well section\\ntemplate (2) button from the Tool bar. The logs will then appear in a track and a corresponding\\nlog panel in the Well section template settings.\\n2. Alternatively, right click on any log in the Input pane and select to Add to template in a new\\ntrack or in an already existing track.\\n3. You can insert a track directly into the Well section template using the Add new object button\\nin the dialog window (1). Once the track is inserted in the Well section template settings, add a\\nLog from the drop down menu that appears as you click on the Add new object button (2).\\nOnce the log is inserted, select the Template in the Definition tab for the log curve (3). If the\\nShow data with similar templates is toggled on, a list with all the logs will populate the\\nDefinition interface. Notice that you can group several logs in one track. Alternatively, select the\\nlog in the Input pane, and bring it to an existing row by using the blue drop arrow (4).\\nSpecial panels\\nAdding and editing depth annotation\\nAdditional depth annotation scales can be adding a new Depth track object in the Well section\\ntemplate settings . You can choose which depth system to use and how to annotate the scale.\\nHow to insert a new depth panel and to change its depth type\\n1. Open the Well section template settings .\\n2. Select Add new object . Select Depth . A new Depth panel will be created in the\\nTemplate objects .\\n3. Specify the depth scale measurement. Choose the depth reference as MD (measured\\ndepth), TVD (true vertical depth), or SSTVD (true vertical depth subset). OWT, TWT, TVT\\nand TST are available if the appropriate data is present. If Automatic is selected, the index\\ntrack will show the depth measurement type of the Well section window.\\nHow to edit the depth scale panel\\nThe depth scale panel shown in the Well section window can be changed. Go to the Style tab of\\nthe Well section template settings and specify the depth scale panel shown.\\nDepth panel style\\nThe settings controlling how to annotate the scale can be found in the Style tab for the Depth\\npanel in the Well section template settings.\\nTick marks : Choose which side the tick marks should be displayed.\\nAnnotation : Orientation of the annotation.\\nFlattening : Allows you to choose if the scale should go from datum (absolute) or the well\\ntop the section was last flattened on (relative).'},\n",
       " {'header': 'Point Well Data ',\n",
       "  'content': 'Point well data can be displayed as lines, indicating the position of the measurement by checking\\nthe point well data icon, or as points indicating individual attributes. The display of the data in the\\nwell section window as well as other windows, is generally the same as that for well tops.\\nAvailable display features include:\\nPoint data - The default display.\\nTadpoles - A combined plot typically used for displaying dip and azimuth together with\\nother attributes. See Tadpole Panels.\\nRose diagrams - A circular histogram normally used to display the spread of data in a\\nparticular interval. See Rose Diagrams.\\nPoint well data displayed as tadpoles and as straight attribute points. Lines indicating the point of\\nmeasurement are also displayed.'},\n",
       " {'header': 'Tadpole Panels ',\n",
       "  'content': \"Tadpole diagrams allow the user to display several attributes in a single point in the log panel.\\nTypically, these will be used for displaying the dip (the x position of the point) and azimuth\\n(direction of the tail) of a feature in the log together with other information (such as the length of\\nthe tail or the color of the point).\\nFor example, you can have the dip and azimuth of a fracture together with its aperture (tail\\nlength) and infill (color).\\nThe data can be in the form of logs, point well data or well tops.\\nAn example of a tadpole diagram.\\nHow to display log data as a Tadpole Diagram\\n1. In the Well section template settings, Add a new obejct and choose Tadpole track.\\n2. In the Values from box choose Logs.\\n3. Select As Property under the color drop down box and select the log to determine the\\npoints color from in the box beneath.\\n4. Next to Dip azimuth (tail), select the log that should define the angle of the tadpole tails.\\n5. Next to Dip angle (x-pos), select the dip log.\\n6. Set the number of points to display by typing a number in the Draw every box.\\n7. Set the points radius.\\n8. Set the Fixed Length of the tadpole tail in the Tail (dip azimuth) part of the dialog. By\\ndefault it is set to 10.\\n9. Set the range of the log values to display, typically 0 to 360 for the azimuth, and 0 to 90 for\\nthe dip\\n9.\\nTadpole track Style\\nAfter the tadpole diagram has been inserted in the well section, go to the Style tab under the\\nWell section window template settings. Choose between the log data or point data (well tops or\\npoint well data) to display. Next, select the logs or attribute to display.\\nThe x position (dip angle) will define the lateral position of the point in the panel with respect to\\nthe scale selected. The azimuth will define the angle of the tail, while Length will define the length\\nof the tail. Point color and tail length can be used to display other attributes of the points.\\nRose diagrams\\nRose diagrams are circular histograms ideally suited for displaying angle information such as dip-\\nor current- directions. The circle is divided into a number of sectors and a section of that sector is\\ncolored according to how many data points that occur within the sector. Logs, well tops or point\\nwell data can be displayed in the panel.\\nPoints representing the individual data points can also be displayed, with the position of the point\\naround the circle dependant upon the azimuth (as above) and the distance from the center of the\\ncircle to the point dependant upon the dip (0 in the center of the circle, 90 at the edge).\\nData can be collected between well tops or at a constant interval (e.g. every 50m MD).\\nA rose diagram showing dip directions in Petrel\\nHow to create a Rose Diagram\\n1. Right-click on the well icon, under the well section in the Windows pane.\\n2. Choose Insert rose diagram panel.\\n3. Check the box in front of Draw Roses or Draw Points, or both.\\n4. Select the appropriate logs for the required attributes and choose the colors/symbols to\\nuse.\\n5. On the Limit settings tab, choose between using well tops or a constant interval to define\\nthe data for each diagram.\\n6. Click Apply or OK.\\n6.\\nRose diagram track style\\nAfter the Rose diagram has been inserted in the well section template settings, go to the Style\\ntab.\\nIn the topmost part of the Style tab, you can select:\\nDisplay data as points or roses\\nWhether to use logs or points as input data\\nThere are three tabs on the Style panel:\\nLimit Settings - used to specify how to collect data points for the individual diagrams.\\nValue limit settings - The circle will normally show angles from 0 to 360 but this can be\\noverwritten by checking on Specify value limit .\\nMD limit settings - These options determine the interval at which to create a rose\\ndiagram. There are two basic options, one rose between each well top or a constant MD\\ninterval between roses. The user must select either a well top set or an interval.\\nSector settings - The number of sections in the rose diagram.\\nRose Diagrams - Specify the color of the rose segments and how the roses are displayed.\\nPoint Diagrams - Choose the attributes or logs to be used for dip and azimuth in the rose\\ndiagrams and how the points should be displayed.\\nZone logs\\nZone logs that reflect the stratigraphy of the Well Tops folder can be created. The stratigraphy\\ncan then be visualized as a zone log in the Well section window.\\nHow to create a Zone Log\\n1. Right-click on the Well Tops folder and select Insert/update zone log. This creates the\\nfollowing items:\\nA discrete zone log stored at the bottom of the Global well Logs folder.\\nA new Discrete property template stored in the Templates pane.\\nA well attribute called Max Zone from 'Well Tops', stored under the Attributes folder in\\nWell Attributes. This gives the max number of zones in the well tops folder and cannot be\\nedited.\\n2. Open a Well Section window and display the Zone log linked to Well Tops from the Global\\nwell logs folder.\\nNote that the zone log is automatically updated for the well it belongs to. However, if a new\\nwell is inserted, it must be updated manually.\\nComment logs\\nComment logs can be used to insert annotation to particular sections of a well. These can be\\ncomments on particular features of a log; edits you have made or it can be imported ASCII files of\\ncore descriptions.\\nThe comment log is an independent log, associated with a well trace in much the same way as\\nany other well log. It is not explicitly associated with any particular log. Comments can relate to a\\npoint in the log or a zone in the log.\\nHow to create a comment log\\n1. Activate the Create/edit comments tool together with Create a new comments\\nlog from the Function bar.\\n2. Select the Comment log added in the Global well logs folder in the Input pane.\\nInteractively paint the comments box into a comments panel.\\n3. A single click in the comments panel will create a comment related to a point, while clicking\\nand dragging will assign the comment to an area. The comments settings window will open\\nwith a new comment inserted, enter the comment text and click Apply . Clicking on an\\nexisting comment will open it for editing.\\n4. Repeat the process until you have the desired number of comment boxes.\\nWhen you double-click in the comment box that you have just drawn in the Comment log , it will\\nopen the Settings for your Comment log . Define the text you want your log to have. You can\\nadd additional comment boxes in different depths.The background and text color can be specified\\nindividually; otherwise, the defaults on the style page will be used.\\nThe Comment log is stored in the Well section template settings as it is linked to the comment\\nlog defined in the Input pane on the Definition tab\\nThe comment log is displayed in a separate track in the Well section window.\\nBitmap logs\\nBitmaps of scanned logs, core photos, or any other relevant information can be imported and tied\\nto specific MD values along the well path for display purposes. Once imported, images can be\\nmoved and specific points on the bitmap can be tied to specific points on the well using control\\npoints. Between these points, Petrel will ensure that there are a constant number of pixels per\\nunit distance along the well in MD.\\nTo activate the editing of control points, you must activate Create/edit image control points\\n. The top and base of the image are control points by default, but can be moved. To add new\\ncontrol points, click on the bitmap log track at the desired point, then click on the new control\\npoint and drag it to the required MD value. The adjacent sections of the bitmap will be stretched\\nand squeezed respectively to accommodate the moved control point.\\nPress SHIFT while moving a control point to split the bitmap at that point. Dragging two bitmaps\\ntogether will join them.\\nTo import bitmaps onto a well path, right-click on the well and select Import (on\\nselection). Next, select one of the bitmap log formats, and import a bitmap file.\"},\n",
       " {'header': 'Grouped Track Panels ',\n",
       "  'content': 'Two or more logs can be displayed in the same track panel. By default, each log is plotted on its\\nown scale. However, minimum and maximum values for the log curve scale can be set in the\\nStyle tab under the Well section template settings for each log curve displayed in the same\\ntrack. The scale can be set to the same values for all the logs in one track.\\nColor fill can be inserted between two logs in the same track panel through the Curve filling tab\\navailable for any track panel under the Well section template settings .\\nThe resulting grouped logs can be visualized in the Well section window\\nHow to create a grouped track panel\\n1. Open the Settings for a Well section template.\\n2. Select any of the already displayed log curves and move them up or down to the track\\n3.\\n1.\\n2.\\nwhere you wish to place your log. Click Apply to visualize the log curves in the Well section\\nwindow.\\n3. Go to the Info tab of the new grouped track and give it a new name. Delete the empty\\ntracks.\\nIf you need the original log there for comparison or for different scale settings, simply make\\na copy of the log first (ctrl-c/ctrl-v), then move the copy into the grouped track folder. It is also a\\ngood idea to rename the grouped track folder into something explanatory.\\nCurve fill in a group track panel\\n1. Open the Settings for the Well section template.\\n2. In the Well section template settings , highlight the track panel for which you wish to\\ncreate the curve filling.\\n3. Go to the Curve filling tab and append a new color fill by pressing the Append row icon\\n.\\n4. Specify the Depth interval .\\n5. Under Fill edge , select, for instance, from curve to curve. Then, specify which log that\\nshould define the left and the right side of the curve fill.\\n6. Select the color and the pattern for each color fill.\\n7. Click Apply or OK .\\nGenerate a chronostratigraphic column in a\\nwell section window\\n1. Make sure a Well correlation process is active.\\n2. Press the Paint discrete log class button in the tool bar (right-hand side of Petrel\\nwindow). New icons will become active after pressing this icon.\\n3. Next, press the Create new discrete log button in the same tool bar.\\n4. A window will pop-up asking to select the template for the new discrete log. Choose Time\\nStratigraphy as the template and click OK.\\n5. A new discrete log has been created under the Global well logs in the input pane called\\nTime stratigraphy.\\n6. Display the new discrete log in the well section.\\n7. Insert (paint) some discrete time intervals into the log panel by using the Paint discrete\\nlog class option.\\n8. To choose between different time intervals, move the cursor over the new discrete log in\\nthe well section and right-click on it. A drop-down list will show the different time intervals.\\nSelect one and keep on painting.\\nCreate a zone log from your stratigraphic well\\ntops\\nA zone log will help you visualize the zones defined between your interpreted stratigraphic well\\ntops. The log can be used later while building the structural 3D grid and during the depth\\nconversion process to guide zonation along well bores.\\nRight-click on any Well tops folder in the Input pane and select Insert/update zone log. A new\\nzone log linked to the selected Well tops folder will be created in the Global well logs folder in\\nthe Input pane. You can now visualize the log on a Well section window or along the well path\\nin a 3D window.\\nCreate a zone log from zones of a 3D grid\\nYou can create a synthetic zone log from the main zones of the active 3D grid in your Models\\npane. The zone log is a log with integer numbers from the upper zone, increasing downwards.\\n1. To create the log, open the Settings of the Wells folder in the Input pane.\\n2. Go to the Make logs tab.\\n3. Select the From zones sub-tab and choose any of the existing options. The log is added to\\nthe Global well logs folder in the Input pane.\\nSummation track\\nThe Summation track is designed to support visualization of a type of petrophysical analysis that\\ncalculates the fractional makeup of the formation. It comprises a set of curves where each\\nrepresents a different fraction of the formation. They are visualized by adding one curve to the\\nnext and shading between them.\\nSupport for ELAN petrophysical volumes has been reworked:\\nPetrel loaders will no longer have a hardcoded behavior when ELAN mnemonics are\\ndetected. Existing ELAN volumes folders will be replaced with general log subfolders when\\nthe project is opened in Petrel 2010.1 for the first time.\\nThe ELAN volumes track has been replaced with a general Summation track. This does not\\nhave any product-specific behavior: fill colors and patterns are now user-defined.\\nOther data\\nFluid logs from Contact Sets\\nIt is possible to create a log representing the fluid column in the wells as defined by a Contact Set\\nin a 3D model.\\nHow to create a Fluid Log\\n1. Go to the Models pane, expand a 3D model and select to display a Contact set in the Well\\nsection window.\\n2. Right-click on the Contact Set and select Insert/update fluids log. This creates a discrete\\nzone log stored at the bottom of the Global well Logs folder.\\n3. Select to display the Fluids (Contact Set) from the Global Well logs folder.\\n3.\\nProperties in the well panel\\nProperties from the 3D grid can be displayed in the Well section window as:\\n1. A synthetic log along the well path.\\n2. Directly by toggling the Property in the Models pane. Model property values are extracted\\nalong the length of the well and displayed as a normal log. These values can then be edited\\ninteractively by choosing the Create/edit continuous curve icon and dragging the\\ncurve to the correct value. This is an excellent way to QC upscaling without creating a\\nsynthetic log.\\nA porosity log and its corresponding model property.\\nCreate a property log from the properties of a\\n3D grid\\nYou can create a synthetic property log from any of the generated properties in the active 3D grid\\nin the Models pane. The log values will be sampled from the values of the cells penetrated by the\\nwell.\\n1. To create the log, open the Settings of the Wells folder in the Input pane.\\n2. Go to the Make logs tab.\\n3. Select the From property sub-tab and choose any of the Properties available in your 3D\\ngrid. The log is added to the Global well logs folder in the Input pane. You can select\\nmultiple properties at the same time.\\nWell display in 2D or 3D\\nWell section fence\\nThe Well section fence is a vertical intersection between wells. Petrel automatically creates a\\nwell section fence everytime you create a Well section window. The path of the plane follows\\nthe order of the chosen wells. To display a well section outline in a 2D-, Map-, or 3D- window,\\nselect the check box in front of the Well Section fence.\\nHow to create an Intersection Fence between wells\\nAn intersection fence is built up of vertical intersection planes drawn between the wells. The\\nalignment is made either from the top-, mid-, or base point of the well paths or from a well top.\\nIn addition to, for example, a top alignment, it is possible to tie the plane to the base of the well.\\nThe well fence is controlled from the Well Section in the Windows pane. The well fence can be\\ndisplayed in 3D-, Intersection- and Map view.\\n1. Insert a new well section from the Window menu. Select the wells of interest.\\nAlternatively, do this in 3D, with the Well correlation process active.\\n2. Once the wells are selected, double-click on the Well Section Fence under the active Well\\nSection in the Windows tab. This will take you to the Wells tab under the Settings for\\nthe fence.\\n3. Select to align fence to top, middle, bottom, or well top. Tie to point bottom if you have\\ndeviated or horizontal wells.\\n4. To close a fence (join the two ends), select the Close fence option.\\n5. Click OK.\\nTo change the visitation order, go to the Settings of the Well section window, and in the\\nDefinition tab select any well and move them up and down. The Well section fence visits the\\nwells in the order established here.\\nBy default, the wells in a new Well section fence are aligned at the bottom of the wells. Go to\\nthe Wells tab under the Settings for the Well section fence to align the wells at top, middle or\\nbottom - or on a Well top. The Well Top is inserted from the Well Tops stratigraphy folder. A\\nsecondary tie point at the well bottom can be added.\\nVertical well intersection\\nThe Vertical well intersection follows the well path. Once inserted it is fixed and cannot be moved.\\nHow to create a Vertical Wells Intersection from a\\nwell path\\nVertical intersections can be created along any well path imported or designed in Petrel. The\\nintersections can be created as a combined intersection for all wells or as separate ones for each\\nsingle well.\\n1. Right-click on the Wells folder (to make a combined intersection for all wells) or right-click\\non a single well (to make a single well intersection).\\n2. Select Create vertical well intersection from the menu.\\n3. An intersection along the well path(s) will be created and placed at the bottom of the Wells\\nfolder.\\nThe Extend start and Extend end for the plane can be set in the Style tab under the Settings\\nfor the vertical Well intersection. These will extend the plane by the specified amount beyond the\\nend of the well path in horizontal distance (in project units). If the end of the well is near vertical,\\nthis can result in extrapolation in an unexpected direction.\\nLog signatures\\nThis functionality is introduced in Petrel 2010.1. It enables efficient well data display in a map\\nwindow.\\nA Log signature is a small well section window which contains data from one well and is\\ndisplayed close to that well in the map view.\\nWell data displayed in log signature, as well as its style, is controlled by the selected well section\\ntemplate. To add a log signature you have to:\\n1. Make sure that you are displaying a Map window.\\n2. Open the Settings of the main Wells folder in the Input pane\\n3. Go to the Style tab and select the Log signatures sub-tab.\\n4. Add a new log signature (1). It will always have the name of the original forder as a suffix.\\nDifferent Log signatures should have different names.\\n5. Choose the Well section template you want to use from a drop-down list (2). The Well\\nsection template attached defines logs to be displayed and their style.\\n6. You can limit the wells to which the Log signature is applied to, by selecting Saved search\\nand selecting one from the list.\\n7. The position of the log signatures can be defined relative to the well path, top/base of\\ndisplayed depth interval or interactively adjusted in the Map window.\\n7.\\nIt is also possible to define a set of wells which will have log signatures attached and/or to define\\ndifferent signatures and quickly switch between them.\\nCombined well logs\\nIf you want to display data from more than one log at a time, there is an option to generate a\\ncombined log. It is possible to combine up to five logs into one and map the values to different\\nattributes of disks. The disks will be presented along the well trace in the 3D window, with an\\noption to display every nth disk (depends on re-sampling interval). The attributes are color, dip\\nangle, dip azimuth, size, and transparency.\\n1. Go to the Global well logs folder in the Input pane, right-click and select Insert global\\ncombined log. The Settings dialog for the combined log opens up.\\n2. Open the Operations tab.\\n3. Select Color; pick a log template to use as the color. The color log is mandatory.\\n4. Enter a Dip angle; pick the log that defines the dip angle (the dip angle is the gradient of\\nthe steepness of the disk). Only logs with appropriate values (0-90 degrees) should be used\\nas the dip angle.\\n5. Enter Dip azimuth; select the log that should define the dip azimuth (the dip azimuth is\\nthe direction of the disks dip). Only logs with appropriate values (0-360 degrees) should be\\nused for the dip azimuth.\\n6. Set Size; select the log that will define the maximal radius on the discs. The largest value\\nin the log represents the maximum radius and 0 (zero) is the smallest (minimum).\\n7. Select Transparency; pick a log template to set the transparency from. Transparency is\\n0% for the largest value in the log, and 100% for the smallest.\\n8. Select Resampling intervals from; Choose one of the logs, with the preferred interval, to\\nuse for the resampling procedure.\\nNote that a continuous log will normally create many disks due to the dense sampling\\ninterval; therefore, the filter for every nth disk should be used from the Style tab. On the\\ncontrary, discrete logs tend to create fewer disks.\\n9. Click the Update button and Apply or OK to generate the new combined log.\\nThe combined log is listed under the Global well logs folder. Select the check box in front of the\\ncombined log to visualize in a 3D window. The combined log will only be present where data from\\nall the logs used in the combined log occur.\\nPre Petrel 2010.1 well section windows\\nThe first time a project is opened in Petrel 2010.1, the well section windows will be scanned and\\nconverted to well section templates. This is what Petrel will do on project load:\\n1. Scan all well section windows and convert the tracks, data, and styles into a template\\n2. Merge templates that are identical\\n3. Organize the resulting templates into a folder for each window\\nOur priority was to preserve the way the Well section windows look ; greater subtlety\\nincreases the risk of losing valuable information. Therefore, the convertor works in a very literal\\nway: 2 well section wells are considered identical if:\\nThey have the same number of tracks, and\\nThe tracks have the same number of children, and\\nThe children are of the same type and have the same property templates, and\\nThe tracks and their children are in the same order and have the same style settings\\nIn spite of our best efforts, some features of existing windows may not be preserved, so you are\\nadvised to inspect the Well section templates created by Petrel. For example, data that was\\niconized on the Well section window tree and subsequently hidden, will be included and\\nvisualized.\\nThe chief downside of using a simple convertor is that we may create a large number of\\ntemplates. There are ways to rationalize these templates:\\nIf one well section template was applied to multiple windows, other copies may be deleted.\\nIf one well section template was applied to multiple windows, other copies may be deleted.\\nIf the well section window tree looks like the illustration below, Petrel will create more than\\none to reproduce the window. This can be replaced with a single template that includes all\\ncandidates for the non-unique measurement type.\\n1. In Petrel 2009.2, the 3 wells have different data visible.\\n2. Petrel recognizes that SGR is equivalent to GR so only 2 templates are needed to reproduce\\nthe window.\\n3. The definition of the Gamma ray curve includes both candidates. As long as GR is at the\\ntop, it can also be used for G16.\\n4. The wells are all set to use the same template. Once done, the spare template can be\\ndeleted.\\nSharing Well section templates between\\nprojects\\nBecause each object in the template can be referred to by using only a property template, the\\nWell section template can be exchanged between projects. Petrel will populate the template\\nwith data using the same mechanism as described above. There are two ways to exchange\\ntemplates:\\n1. Through the Reference project tool.\\n2. By exporting in xml format. Styles and candidates, if any, will be exported.\\nInteractive visualization\\nThis section covers the different ways to organize your well data without duplicating it. Several\\ntypes of search criteria and filters will allow you to visualize your well data.\\nSaved searches\\nA saved search functionality exists for well data, allowing users to display/access wells based on\\nspecified search criteria. The functionality is introduced to help organize well data into different\\nplace holders without duplicating data. The functionality is restricted to well data. Several types of\\nsearch criteria can be applied, and each search can be used in isolation or in combination with\\nother searches.'},\n",
       " {'header': 'Procedure ',\n",
       "  'content': 'When a project containing a wells folder is opened, a new sub folder, named saved searches, is\\nautomatically introduced to the wells tree. This serves as the place holder for all saved searches.\\n1. You can add a new search criteria by rigth click on the Saved search folder and select\\nCreate new search.\\n2. The following window will open, there you can select wich Filter type to be use.\\n2.\\nThe following Filter types can be selected:\\nMatch primary well identifier: search by primary well identifier. When using this search\\ncriteria you will have different options to specify how to make the search:\\nExamples: Assume we have 5 well with names C1, C2, C7, ABC and Cantarell.\\n- Start with: option will search for all the wells that have a primary well identifier (well\\nname/UWI) starting with the specific character(in this case \"C\" letter), as result wells C1, C2, C7\\nand Cantarell will be shown.\\n- Contains: this option will search for all the wells that contains the specific character in any part\\nof the name, in this example C1, C2, C7, ABC and Cantarell will be shown.\\n- Wildcard: it can be used either the * or ? wildcard. Using a * wildcard before or after a\\ncharacter will search for names that include the character. Examples:\\n*C* will show all wells that contains a letter C anywhere in the well name/UWI : C1, C2, C7, ABC\\nand Cantarell.\\n*C will show all wells where letter C is the last character in the well name/UWI: only ABC will be\\nshown.\\nC* will show all wells where letter C is the first character in the well name/UWI (C1,C2, C7 and'},\n",
       " {'header': 'Cantarell). ',\n",
       "  'content': 'Use ? wildcard before or after a character to search for names that include the character with any\\nsingle character adjacent. Examples:\\nC? will show the wells with name C1, C2, C7\\n??C will show the well ABC\\nWell log data: searches for all wells that have the logs or completions specified.\\nWell attributes: searches for wells that have the attributes within the range specified.\\nSeveral attribute filters can be specified in the same search.\\nWell Tops: search for wells with particular well tops.\\nUser specified well list: use this search for custom lists. It is possible to generate the\\nsearch from the wells displayed in the active view.\\nWithin boundary: searches for all wells whose trace lies within a specified polygon or\\npolygon set.\\nHow to use multiple saved searches in combination\\nUsing searches in combination is a useful feature; for instance, you may be interested in making a\\nsaved search for horizontal wells having a completion log associated with them in the Petrel\\nproject. In order to do this, it is first essential to make the individual searches and then apply\\nthem.\\nExample search 1- Make a search for horizontal wells:\\n1. Right-click on \\'Saved searches\\' folder under Wells.\\n2. Select \\'Create new search\\' using the criteria \\'well attributes\\'.\\n3. Select to use the \"Max Inc\" attribute and set the filter to the desired range. For example, if\\nyou are interested in wells that go beyond the horizontal well, set the filter to Min = 90.\\n4. Click on Apply.\\n4.\\nExample search 2 - Make a saved search for completions:\\n1. Create a new saved search using the criteria well log data.\\n2. From the right list box, select the \\'Well completions\\' checkbox.\\n3. Click on Apply.\\n2.\\n3.\\nNow select both saved searches on in the tree to apply the filters.\\nSaved searches can also be used directly in processes and calculations. For instance, a\\nsaved search can be set to upscale the well logs for a desired property. When the search is\\napplied in the wells tree, the filtered list will be shown in the Scale Up-Scale Well Logs process\\ndialog box. Only the wells meeting the search criteria will then be used in the processing.\\nSaved searches can also be applied in the Well tops spreadsheets, Well tops attributes\\noperations and the Well tops calculator.'},\n",
       " {'header': 'Well Filters ',\n",
       "  'content': 'In the Wells folder, there is a folder called Well Filters. In this folder filters used for visualization\\ncan be stored. The filters can be used with Map windows, Intersection windows and Well section\\nwindows to limit the range of the logs/traces. For more information on Well filters and how to\\ncreate a new Well filter, See Well Logs filter.\\nThere is an option under the Wells folder to insert one or more Well filters. This will limit\\nvisualization to particular sections of a log/well path in Well Section, Map and Intersection'},\n",
       " {'header': 'Windows. ',\n",
       "  'content': 'Filters can be created based on absolute Z value or based on Well Tops or Surfaces.\\nThey include an optional blanking region above and below the chosen subject.\\nMissing Top logic is included so that if a well misses a selected top then the system will try\\nto use the next available top or the top or bottom of the well (Zone logic)\\nThe filter can be applied to all or a selection of wells.\\nFilters are additive so more than one range can be filtered.\\nFilters replace the Simplification option on wells.\\nTo Create a well filter:\\n1. Go to the Wells folder in the Input pane.\\n2. Right-click on the Well filter folder and select New well filter from the menu.\\n3. Select Wells to apply the filter on.\\n4. Toggle on the TopZ and BaseZ depth to apply the filter on trace/logs on.\\n5. Select either a Constant (type in depth) or From subject (drop in well tops). Apply an\\noffset if applicable in project units. The filter will keep the data between the TopZ and\\nBaseZ and reject data outside.\\n6. Open a Map, Intersection or for example a Well Section window. Toggle on the Well filter\\nunder Wells for it to take effect.\\nBoolean logs from user defined filters\\nBoolean logs have only two possible values - true or false, and are commonly used as an indicator\\nof a particular zone, interval with specific properties, etc. In Petrel 2010.1, it is now possible to\\ncreate Boolean logs from user defined filter.\\nHow to create an interactive boolean log\\nRight-click in any of the filters stored under the Filters folder in the Input pane and select\\nConvert to boolean log . The new log will be stored under the Global well logs folder in the\\nInput pane.\\nInteractively Boolean logs from filters can be updated in real-time once you change the\\nfilter criteria. These logs can be used as any other well log - visualized in windows, upscaled in the\\ngrid, etc.\\nFilter well top attributes using boolean log\\nA new option in Petrel 2010.1 allows you to filter well tops attributes calculation using Boolean\\nlogs.\\n1. Right-click on the Attributes folder for any Well tops folder and Insert new attribute.\\n2. In the Settings dialog for the Attribute, go to the Attribute operations tab.\\n3. Choose the log to be used.\\n4. Filter using boolean log.\\nEditing and interpreting well data\\nThere are different tools to edit and interpret well data. We can classify them according to the\\nkind of logs they can be used for:\\n1. Tools for continuous logs\\nLog editor - performs multi point operations, such as smoothing or blocking on logs or\\nsections of logs.\\nTrain estimation model - Estimation\\n2. Tools for discrete logs\\nInteractive log interpretation - Allows you to interpret using a discrete template.\\nTrain estimation model - Classification\\n3. General tools (both for discrete and continuous)\\nMake well logs - Creates logs based on an estimation model generated in the Train\\nestimation model process.\\nLog estimator - uses standard formulas to recreate damaged or missing sections of\\nlogs from other logs.\\nDerived logs - merges log data on single/multiple wells without physically merging\\nthem\\nWell log calculator - performs operations on or in between logs'},\n",
       " {'header': 'Log Editor ',\n",
       "  'content': 'The Log editor allows you to perform operations on specific sections of the log at the well level.\\nEach line in the table represents a section of the log upon which the action is to be performed.\\nThe sections can be defined interactively in the log panel or by entering the values into the dialog\\nmanually. Choosing Entire log applies the change to the entire length of the log.\\nThe last column in the table is a list of actions you can perform on the log section. Choose the\\naction and then edit the settings below. Several actions can be performed on the same section in\\na single interval. To add more actions, click the Append a column in the table icon .\\nHow to edit a log using Log Editor\\n1. Expand the Well logs folder for a specific well.\\n2. Right-click one of the logs and select Log editor.\\n3. Append rows and columns according to how many Actions and Zones you need to perform\\nthe required operations.\\n4. Click Run and Apply or OK to save the edits.'},\n",
       " {'header': 'Log Editor Dialog Control ',\n",
       "  'content': 'The following tools are available on the log editor dialog.\\nInsert new action zone above the active zone.\\nInsert new action zone at the base of the zone list.\\nInsert a new action zone below the active zone.\\nRemove the active action zone.\\nAdd an additional action column to the dialog.\\nRemove the active action column from the dialog\\nBlock. Create blocking action zones based on the variation in the well log.\\nCopy the action zones from another log.\\nCopy the settings of the active action zone.\\nPaste the settings into the active action zone.\\nOnce the actions have been defined, they can be applied by clicking Run. The settings can be\\nedited. Clicking Run again will undo the initial edits and apply the revised settings. Actions can be\\nundone by pressing Undo (one level). Clear will remove all the actions from the dialog.\\nClick Apply or OK to apply the settings to the well section. Click Cancel to exit the dialog.\\nLog editor actions\\nActions available include:\\nArithmetic operations\\nPerform addition, subtraction, multiplication or division on a section of the log curve, or assign a\\nconstant value directly. Choose the operation and type in the Operand.'},\n",
       " {'header': 'Clip ',\n",
       "  'content': 'Removes sections of the log with values above and/or below the specified values. Check Clip\\nAbove or Clip Below as appropriate and either type in the value the clip should be set at, or\\nmove the clip values interactively in the well section window. Clipped values can be dealt with in 4\\nways:\\nEliminate - removes the log entry.\\nTruncate - sets the log entry to the clip value.\\nSet Undefined - sets the log entry to undefined (it can later be dealt with using the\\nremove undefined action)\\nInterpolate - interpolates linearly between adjacent values.'},\n",
       " {'header': 'Block ',\n",
       "  'content': 'Replaces the log values with an average.\\nChoose the method by which the average should be calculated see Averaging Methods for a\\ndescription of these algorithms. To define the block values manually, uncheck Calculate Block\\nValue and enter the value to be used.'},\n",
       " {'header': 'Smooth ',\n",
       "  'content': \"Smooths the log with the specified filter. For each point in the log, Petrel will get the points before\\nand after (Filter Length) and average them (Filter Method) according to the user specified\\nweighting (Filter Shape) to find the new value for that point.\\nShape - controls the weighting given to each value in the filter. Box will weight all values\\nequally, while Triangular will weight the center values more than the extreme values. The\\nfirst point will have a weight of 1, the second 2, etc. until the center point is reached, then\\nthe weights will decrease.\\nMethod - is the method used to calculate each point's value from the points in the filter\\nwidth. See Averaging Methods for a description of these algorithms.\\nFilter length - defines the interval where a log value is replaced with the average log\\nvalue.\"},\n",
       " {'header': 'Despike ',\n",
       "  'content': 'Removes spikes from the log based on the selected filter and the distribution of the data points at\\nthe filter locations. The user defines a filter width and a standard deviation (as in the Smooth\\naction), Petrel then calculates the mean and standard deviation of the points within the filter and\\nif the log value falls outside the specified standard deviation, it will be removed. The options for\\ndealing with removed values are the same as for clipping, see above.'},\n",
       " {'header': 'Draw ',\n",
       "  'content': 'Digitizes a new straight section to the log curve.\\nInput the values of the curve at the top and the bottom of the defined zone directly in the dialog\\nor click in the log panel to define them interactively. To digitize consecutive zones use the shift\\nbutton while clicking.'},\n",
       " {'header': 'Change Undef ',\n",
       "  'content': 'There are three options for removing undefined log values:\\nEliminate - the value will be removed from the log.\\nInterpolate - the log value will be interpolated linearly from its two closest neighbors. This\\nhas the advantage that the log will still have a constant sample interval and the same\\nnumber of points.\\nCopy From input log - this will copy data from a second log e.g. an estimated log, to\\nreplace the undefined values. The sampling for these replacement values can be taken from\\nthe original log or the log to be copied from.\\nAutomatic blocking of the well logs\\nAutomatic blocking of well logs\\nLog sections can be inserted automatically based on variations in the characteristics of the log and\\na minimum layer thickness. Actions can then be performed within each section. This can be useful\\nfor reducing the resolution of the log to a coarser seismic resolution, prior to generating synthetic\\nseismograms. To do the blocking, press the button in the well log editor. There is only\\none Undo, so the user is encouraged to make a copy of the log first. Otherwise, the original data\\nis lost.\\nThe log sections will be larger than the Minimum Thickness and the contrast between two\\nadjacent blocks will be larger than the Minimum Contrast. The contrast is calculated as the\\ndifference between the averaged values of the two blocks divided by the average of the total.\\nBlocking can be done in MD or TVD.\\nOnce the log sections have been created, they will be given the specified blocking action.'},\n",
       " {'header': 'Copying Action Zones ',\n",
       "  'content': 'When blocking logs, it is preferable to use the same action zones on several logs, even if the\\nzones were created based on a particular log. To copy the zone setup from one log to another,\\npress the copy button and select the log to copy the action zones from. Only logs with\\ndefined zones will be listed.\\nLog editor interactive controls\\nLog Editor interactive controls\\nWith the log editor active, a number of actions can be performed interactively in the log panel in\\nthe well section window.\\nClick and drag in the log panel - changes the start and stop depth of the action zone in\\nthe dialog to the selected interval (deselect Entire well first).\\nShift and click - inserts a new row in the log editor dialog with a start depth at the\\nprevious point and a stop depth at the selected point. The new row will have the same\\nsettings as the last row inserted.\\nN - inserts a new row in the dialog so that a new action zone can be digitized.\\nClick and drag log section - the action zone can be moved up or down by clicking on it\\nand dragging it.\\nClick and resize - hovering the mouse over the upper or lower boundaries of a defined\\nsection will cause the mouse pointer to change to a resize cursor. Clicking and dragging will\\nnow resize the defined log section.\\nDrag clip boundary - with Clip defined as the action the clip boundaries can be dragged\\ninteractively in the well log panel.\\nDrag block value - with Block defined as the action, the blocked value can be edited\\ninteractively (the Calculate Block Value checkbox will automatically be toggled off).\\nDrag draw values - with Draw defined as the action, the start and stop log values for\\ndrawing can be edited interactively.'},\n",
       " {'header': 'Log Estimator ',\n",
       "  'content': 'The Log estimator allows the user to generate logs from other logs using standard formulas.\\nThis is useful for replacing damaged or missing sections of logs, particularly sonic logs where a\\ncomplete log is required for the synthetics process. Estimated logs can be created as new logs or\\nused to replace sections of existing logs (this will delete that section of the original log). The\\ntemplate of the new log is set automatically, but the name must be specified in the Log Estimator\\ndialog.\\nEach line in the table represents a section of the log and the action to be performed. The default\\nis Entire Log which means that the action will be performed on all the data points in the well.\\nThe sections can be defined interactively in the log panel or by writing the values into the dialog\\nmanually.\\nThe log estimator can be performed at the well level or at the Global well logs level.\\nLog estimation depends on the log units being used. Ensure that the global well log template\\nhas the correct units for the log data before starting the process. See Units.\\nLog estimator actions\\nThere are a number of standard equations that can be used to estimate the log:\\nDensity to/ from Sonic - the action will use Gardners Approximation:\\nDensity = C.Sonic x\\nWhere C and x are constants\\nDensity to/ from Porosity - the action will use the following equation:'},\n",
       " {'header': 'Density = (1-F). +F. ', 'content': 'm f'},\n",
       " {'header': 'Where: ',\n",
       "  'content': 'F = porosity\\n= matrix density\\nm\\n= fluid density\\nf\\nSonic from Resistivity - the action will use the Faust relationship:\\nSonic = C.(TVD.R) x'},\n",
       " {'header': 'Where: ',\n",
       "  'content': 'C = constant\\nTVD = true vertical depth\\nR = resistivity\\nX = constant\\nVelocity to/ from Sonic - the action will create velocity as the inverse of the sonic.\\nCopy - the action will copy a section of another log.\\nLog estimator replacing missing logs for a\\nspecific well\\n1. Ensure that the global well log template assigned to the log has the correct units for the log\\ndata.\\n2. Open the Log Estimator and select the input log. Right-click on a well and select Create\\nNew Estimated Log . It applies the operation to a specific depth interval of that well.\\n3. Choose the action for creating the log under Action#1 .\\n4. Define the area where the log is to be generated by un-checking Entire log and clicking\\nand dragging in the log panel, or write the interval directly in the dialog.\\n5. Adjust the settings as required and press Apply .\\n6. Press to insert additional depth intervals and repeat 3 and 4 as required.\\n7. Press OK\\nThe following tools are available on the log estimator dialog:\\nInsert new action zone above the active zone.\\nInsert new action zone at the base of the zone list.\\nInsert a new action zone below the active zone.\\nRemove the active action zone.\\nCopy the action zones from another log.\\nCopy the settings of the active action zone.\\nPaste the settings into the active action zone.\\nIf the log replaces missing sections of an existing log, you can create a grouped track panel\\nfor comparing the original and estimated logs. You should have a copy of the log panel outside the\\ntrack panel where you can interactively define the sections.\\nLog estimator replacing missing logs for all\\nwells\\n1. Ensure that the global well log template assigned to the log has the correct units for the log\\ndata.\\n2. Open the Log Estimator and select the input log. Right-click in the Global Well Logs\\nfolder in the Input pane and select Insert estimated global Log. It applies the operation\\nto the entire log for all wells.\\n3. Choose the action for creating the log under Action#1 .\\n4. Adjust the settings as required and press Apply or OK .\\nThe following tools are available on the log estimator dialog:\\nCopy the action zones from another log.\\nCopy the settings of the active action zone.\\nPaste the settings into the active action zone.\\nIf the log replaces missing sections of an existing log, you can create a grouped track\\npanel for comparing the original and estimated logs. You should have a copy of the log\\npanel outside the track panel where you can interactively define the sections.'},\n",
       " {'header': 'Make Well Log ',\n",
       "  'content': 'Make well log is available under Stratigraphic Modeling . The Make Logs process allows the\\nuser to use an estimation model to generate well logs in several wells. The estimation model must\\nbe created first, using the Train Estimation Model process.\\nMake Well Log settings\\nMake Well log can be used to create new logs or overwrite existing logs (1). If a new log is\\ncreated, then it will be given the same name and template as the log created in the Train\\nEstimation Model process.\\nThere are two tabs on the dialog:'},\n",
       " {'header': 'Well Log Tab ',\n",
       "  'content': 'Drop in an estimation model from the Input pane, using the blue arrow (2). If the Estimation\\nmodel performs a classification, you will have the option to Output Probabilities. This will create\\nlogs of the probabilities of each of the facies. Press the button to output the probabilities.\\nWith the estimation model in place, a table is created showing the logs used as input to the\\nestimation model and the equivalent logs in the global well logs folder. These are matched using\\nname and template. If the mapping is not correct, then different Global well logs can be dropped\\ninto the table using the blue arrow.'},\n",
       " {'header': 'Well Tab ',\n",
       "  'content': 'The wells tab allows the user to choose which wells to create the log for (3). Wells without the\\nspecified log will be grayed out and are not selectable. Create a new estimation model based on a\\ndifferent set of logs to create the log for these wells.'},\n",
       " {'header': 'Derived Logs ',\n",
       "  'content': \"Derived log is a very easy method to merge log data on single/multiple wells without physically\\nmerging them. For example; let's assume we have a set of Porosity logs that we want to display,\\nbut they do not have the same name. First, we want to know which logs of the same\\nmeasurement type exists in the project (for instance, all porosity logs having porosity templates).\\nThis can be done using the Well Manager. In addition, we want to make a common dynamic log\\nthat can incorporate the various logs (which have different names but same measurement type).\\nThis is called a Derived log and exists as an independent log. The values are derived from another\\nlog. The advantage is that we can edit the Derived log without merging physically the logs.\\nCreate a continuous derived log\\nHow to create a continuous Derived log\\n1. Right-click on the Global well log folder and select Insert new derived continuous log .\\n2. Go to the Settings , Derived tab for the new log. Notice that Petrel creates a log with the\\nsame template as the one assigned to the upper most log in the Global well logs folder. Make sure\\nthat any of the logs with the template you wish to create is at the top of the Global well logs\\nfolder list.\\n3. Select the Measurement type.\\n4. Select the logs that should be part of the new derived log, move to the top of the priority list\\n(blue arrow).\\n5. Lock the log, it is dynamic (changeable) by default. Right-click the log in the Input pane and\\nselect Make log(s) static.\\nThe new derived log will be assigned a name depending on which of the available logs have\\nbeen used for each well (priority list). The log template for the Derived log is also linked to the log\\nthat was used for each well (priority list).\"},\n",
       " {'header': 'Example: ',\n",
       "  'content': 'You have a set of gamma ray logs: GR, GR_10, GR_20, and GR_30, all of them have the same\\nmeasurement type but different names. You also have two wells: Apatite and Diamond. In the\\nwell Apatite GR_10 and GR_20 are missing, and in well Diamond GR_10 and GR_30 are missing.\\nWe want to create a Derived Gamma log using all available logs.\\n1. Right-click the Global well log folder and select insert new derived continuous log. A new\\nDerived log will be created at the bottom of the Global well logs.\\n2. Go to the settings for the new Derived log, Derived tab and select the measurement type\\nAPIGammaRay , toggle on the logs you want to use and organize them in the priority you want\\nthem to be used using the blue arrows. Click OK .\\nAs a result, GR_30 will be used for well Apatite and GR_20 will be used for well Diamond. If you\\nexpand well Apatite and Diamond, you will see that the Derived log for each well has the name\\naccording to the log that was used for each well. For Apatite the log is named GR_30[Derived]1\\nand for Diamond is called GR_20[Derived]1. The Global Derived gamma log will get the name of\\nthe log that is on top of the priority list.\\nThe settings for the new Derived log are linked to the log where it originated. For example, if\\nyou wish to change the color of the derived log curve, you first have to specify the color in the\\nsettings for the log where the derived log came from, and then go back to the settings of the\\nDerived log, Style tab , 2D log sub-tab, and select to use log curve color as Specified.\\nSettings for original curve (GR_30).\\nSettings for Derived log (GR_30[Derived]1).\\nWhen displaying both curves in the same track, changing style settings for one of the curves\\n(log curve color, log scale) will affect both (Derived log curve and original log curve). If you want\\nto have different scales and colors, it is preferable to display them in different tracks. Then each\\nof the curves will respect its own style settings.\\nCreate a discrete derived log\\nHow to create a continuous Derived log\\n1. Right-click on the Global well log folder and select Insert new derived discrete log .\\n2. Go to the Settings of the new log in the Input pane,and slect the Derived tab. Notice that\\nPetrel creates a log with the same template as the one assigned to the upper most log in the\\nGlobal well logs folder. Make sure that any of the logs with the template you wish to create is at\\nthe top of the Global well logs folder list.\\n3. Select the Measurement type.\\n4. Select the logs that should be part of the new derived log; move to the top of the priority list\\n(blue arrow).\\n5. Lock the log; it is dynamic (changeable) by default. Right-click the log in the Input pane and\\nselect Make log(s) static.\\nInteractive log interpretation\\nDiscrete logs can be interpreted from other information by painting directly in an existing discrete\\nlog panel. You will have to follow these steps:\\n1. Activate one of the discrete log editing toggles .\\n2. Press Create new discrete log.\\n3. Choose the appropriate template for the new log from the pop-up dialog.\\n4. Browse to the Global Well Logs folder and display the new (empty) log.\\nWhen the Well correlation process is active you will be able to choose any of the tools available in\\nthe function bar:\\nPaint discrete log class - Activates painting of the selected facies class into the log\\nand editing existing class intervals.\\nCreate new discrete log - Creates a new discrete log - one of the facies editing tools\\nmust be active before this button is visible.\\nPick up discrete log class - Pick a log class from an existing log by clicking.\\nFlood fill discrete log class - Flood fills a previously defined interval with the selected\\nclass.\\nWhen interpreting new discrete logs the user must first choose the facies class to interpret. There\\nare a number of ways to do this:\\n1. Right-click on the panel and select the required class from the list.\\n2. Shift and right-click on an existing class in the log.\\n3. Press and click on an existing class in the log.\\nEditing discrete log values\\nHow to edit discrete log values\\n1. Display a discrete well log in a log panel by toggling it on from the Global well logs folder.\\n2. Click the Paint discrete log class icon in the Function bar.\\n3. Right-click on the discrete log panel.\\n4. Select one of the available discrete values (if additional values are needed, this can be\\nadded in the well log template).\\n5. Start drawing the selected value in the log panel by holding down the left mouse button.\\n6. Do the same for other discrete values to fill up the discrete log to cover the depth range of\\ninterest.\\n7. Alternatively, if the discrete log blocks are filled and you only need to change the color, use\\nthe Flood fill discrete log class icon. Right-click first to select the color, and then click\\nonce in the discrete log to change the color.\\n8. Another option is to use the Pick up discrete log class value icon; first pick\\ninteractively a color in the discrete log panel. Once picked, the color can be filled in an\\nexisting log class (block) by clicking once more.'},\n",
       " {'header': 'Well Log Calculator ',\n",
       "  'content': 'The log calculator can be used to edit imported well logs. It can also be used to make new well\\nlogs based on existing well logs.\\nThe log calculator can be opened from the:\\n1. Global well logs icon - calculations will affect logs in all of the wells attached to that global\\nlog.\\n2. Specific well log icon - calculations will just affect the local log.\\nIf the calculator is used to edit an existing log, it will not change the sampling points on the log\\nunless Resample Existing is selected. There are 3 options for re-sampling:\\nSpecified (in feet) - input the sample interval for the log in feet (it will be automatically\\nconverted into the project Z units).\\nSpecified (in meters) - As above but in meters.\\nFrom log - the sampling interval will be taken from the chosen log. Discrete logs interpreted\\ninteractively in Petrel will have relatively few sample points (only at picked points), so using\\nthese logs to define the interval may result in a strange log.\\nIf two logs with different sampling intervals are used in a calculation, the sample values will\\nbe interpolated between sampling points. Continuous logs will be interpolated linearly between\\nsampling points. Discrete logs will keep their value until the next sampling point. The resulting\\nnumber of sampling points will be the union of the input.\\nFor more information see Calculator functions and syntax'},\n",
       " {'header': 'Synthetics ',\n",
       "  'content': \"The Synthetics process found under Stratigraphic modeling in the Processes pane is one out\\nof two approaches to generating synthetic seismograms in Petrel. This process already existed in\\npre-Petrel 2009.1.1 versions as compared to the Seismic well tie process introduced in Petrel\\n2009.1.1.\\nIn the Synthetics process, a 3D seismic cube can be sampled along the well path and displayed\\nnext to the synthetic seismic to obtain a correlation between the two. Also 2D lines can be used\\nfor correlating seismic data to the synthetic trace.\\nAny changes to the time depth relationship can be made and seismic horizons can be correlated\\nwith the stratigraphic boundaries identified in the well logs.\\nVelocity panel, reflection coefficients, synthetic seismogram and sampled seismic for a well log\\nSynthetics process dialog\\nThe Synthetics process dialog is designed to lead you through the process of generating\\nsynthetic seismograms from your well data, and simplify the display of the data you need to use\\nalong the way. It can be opened from the Process pane by choosing Synthetics under\\nStratigraphic modeling.\\nIn the top section, the user chooses the well(s) to create the synthetics for, and the well section\\nto display the logs and the synthetic seismic in. If the well section icon is toggled on, tick boxes\\nwill pop up next to the selection menus in all of the tabs of the synthetics dialog window. These\\ntick boxes give the user the option to toggle on/off the display of the logs and the seismic for the\\nwell section selected.\\nBegin at the top of the dialog, selecting the appropriate data and settings at each stage. There\\nare three types of buttons on the dialog:\\nCreates a new object of the appropriate type (displayed if no relevant object is\\navailable).\\nOpens the settings for the selected object.\\nOpens the spreadsheet for the selected object where appropriate.\\nAt each stage the user can choose the relevant input data from a list of all the appropriate data in\\nthe project for that well ('appropriate' data will be identified by means of the object type and the\\nattached log template).\\nThe synthetics process dialog consists of four main tabs; Wells, Sonic and time, Seismogram and\"},\n",
       " {'header': 'Well Seismic ',\n",
       "  'content': 'Making seismograms globally or locally\\nBefore generating the synthetic seismograms in a project, it can be beneficial to start working\\nwith all the wells with a common input in the project at the same time. By choosing Wells in the\\ntop section and concentrating on a single, fairly standard well, reasonable defaults will be in place\\nwhen you start to work on subsequent wells. Only the wells with relevant data will be processed\\nand not all the wells need to be displayed. Alternatively, choose the wells with a common input\\nfrom the Wells selection tab.\\nWell selection tab in the Synthetics process dialog\\nNote that the wells selection in the top section and the wells tab work in conjunction with\\neach other. If you specify a well to work with from the top section, the Wells tab will be\\ninaccessible (grayed out).\\nWhen subsequently working on individual wells, the settings will initially be grayed out, and an\\nadditional checkbox will be available. Override global settings will disable the global settings in\\nthe chosen well and subsequent settings will be applied only for that well. Toggling the checkbox\\nwill reveal the settings applied globally, while toggling off the checkbox will reapply those settings.\\nOn the global log settings, the wells with settings defined locally will be listed and those settings\\ncan be displayed or deleted.\\nLocally defined settings for sonic calibration\\nLog editing\\nBefore using the input logs in the Synthetics process, it is good practice to quality check and do\\nany neccessary log editing on them. The usage and functionality is further described in the Log\\neditor topic.\\nLog estimation\\nIf a well is missing one of the inputs logs (i.e. sonic or density) to the Synthetics process, it is in\\nmany cases possible to estimate the log based on another existing log. This is further described in\\nthe Log estimator topic.'},\n",
       " {'header': 'Sonic Calibration ',\n",
       "  'content': 'Sonic logs give a very detailed picture of the variation in velocity along the borehole; however\\nthey must be integrated to give a depth time relationship. This integration amplifies any\\ninaccuracies in the log and can cause a significant drift from the true time depth relationship along\\nthe length of the borehole. For this reason, checkshots are used to create a new calibrated sonic\\nlog that minimizes this drift. Import and handling of checkshots are further described under\\nImport checkshots and Checkshot editing.\\nInput required includes:\\nA sonic log\\nCheck shots\\nAlgorithm and settings for calculating the calibration curve.\\nSnapshot of the Synthetic dialog box showing the Sonic and time tab with the Calibration\\ntick box and list boxes for Check shots and Sonic correction.\\nIt is important to edit out errors in the sonic log before using it as input to the synthetics\\nprocess.\\nThe sonic calibration dialog\\nSettings for the calibration curve\\nThe calibration curve is calculated by first calculating the residual between the time calculated,\\nusing the uncorrected integrated sonic log, and the time at the checkshot. The Drift then\\ndetermines a best fit line through these points - the Fit curve. From these the Sonic\\nadjustment is calculated and applied to give the calibrated sonic and the Residual drift i.e. the\\ndrift which the curve was not able to correct for, is calculated. These curves can be displayed in\\nthe well section window by inserting a Delta Time panel in the well section, or by turning on the\\ndelta time option in the synthetics dialog.\\nThere are two options for calculating the drift curve.\\nLeast Squares Polynomial - a simple polynomial line through the points. The order of the\\npolynomial is specified using the Degree list box. As a general rule of thumb, this value\\nshould not exceed one half of the number of checkshot points. In some cases this method\\nmay not be able to find a solution to the equation, and a drift curve will not be drawn.\\nDecrease the order and press Apply.\\nCubic spline - This is a standard method for creating a smooth line through sporadic\\npoints.\\nAfter the calibration is performed, a new log will be created along with all the intermediate curves\\nused to create the calibration.\\nNote! The linear Least squares polynomial is calculated using singular value decomposition,\\ninterpolation (but not exactly matching) the drift values of each checkshot. Large gaps in the\\ncheckshot data will result in large undulations in the approximation polynomial. It is therefore\\nrecommended not to have gaps in the area of interest.\\nTime section\\nThis section gives the user the option of overriding the (existing) time depth relationship for the\\nwells, that is selecting a source for making time logs and the posibility to do manual adjustment\\nof the relationship. Toggle the tick box Overwrite global time log(s) to activate the Global time\\nand Manual adjustment selection that will take effect when generating the synthetic seismogram.\\nTime section of the Sonic and time tab.\\nThe Global time selection in the dialog will only be used if Overwrite global time log(s) is\\ntickmarked, and it will only effect the wells selected in the Synthetics dialog when the Synthetic\\nseismogram is generated (i.e. clicking Apply or OK in the dialog). To check the Global time source,\\nclick on the Global time settings icon, which is accessible whether the Overwrite global time\\nlog(s) is activated or not. This will open the Time tab on the settings for the wells folder. The\\ndesired source for time/depth relation should be moved to the top with help of the blue arrows on\\nthe left hand side and toggled on with a green tickmark (ex Corrected sonic 1 object in example\\nbelow).\\nIt is advisable to correlate and edit the manual adjustments before selecting to use it in the\\ntime depth relationship. If you are making adjustments while you are editing, the updates will be\\ndifficult to follow and editing will be slow.'},\n",
       " {'header': 'Acoustic Impedance ',\n",
       "  'content': \"Acoustic impedance is calculated from existing density and/or sonic logs.\\nFirst, create a new acoustic impedance log by right-clicking Global well logs. Then open the\\nAcoustic impedance tab on its settings dialog. Select the logs to use from the list box and press\\nOK (see image below).\\nPetrel will display a list of all the logs attached to the sonic, density and velocity templates. The\\nlog is a link to the input logs, so edits to the input logs are automatically incorporated.\\nAcoustic impedance is a measure of the ease at which the seismic waves can pass through the\\nearth. It is calculated as the density of the formation multiplied by its velocity. If only one of these\\ntwo is present, the second may be estimated using Gardner's equation and impedance calculated\\nusing this:\\n= C.vx\"},\n",
       " {'header': 'Where: = Density ',\n",
       "  'content': \"C = Gardner's constant (0.230 for imperial sonic logs, 309.5 for metric sonic logs)\\nv = Velocity (1/sonic)\"},\n",
       " {'header': 'X = 0.25 ',\n",
       "  'content': 'Reflection coefficient\\nReflection coefficients are calculated from an existing acoustic impedance log.\\nFirst, insert a new Reflection coefficient log by right/clicking Global well logs. Then open the\\nReflection coefficients tab on its settings dialog. Select the Acoustic impedance log to use in\\nthe list box.\\nPetrel will display a list of all the logs attached to the acoustic impedance template. The log is a\\nlink to the input logs so edits to the input logs are automatically incorporated.\\nReflection coefficient is a differential of the acoustic impedance and defines the strength of the\\nreflection at various geological boundaries. Sharp changes in the acoustic impedance create\\nstrong reflectors. The reflection coefficient is calculated at regular intervals defined by the\\nSample rate (the sample interval for the acoustic impedance log) using the formula:'},\n",
       " {'header': 'RC = (AC -AC )/(AC +AC ) ', 'content': '2 1 2 1'},\n",
       " {'header': 'Where: ',\n",
       "  'content': 'RC = Reflection Coefficient\\nAC = Acoustic Impedance\\nDefining the wavelet\\nWavelets can be defined via the Synthetics process dialog by clicking on the settings dialog icon\\nbeside the list box. The wavelets parameters are defined on the settings tab of its settings dialog\\nand the adjacent windows show the effects of any changes.\\nThe type of wavelet will control the parameters that are displayed on the panel, choose between:\\nSynthetic wavelets\\nExtracted wavelets\\nFrom file wavelets\\nWavelet displays\\nThere are 3 displays for the wavelet. The graphs show the shape of the wavelet and its\\ncorresponding frequency and phase spectrum plots. The user can display the effect of changing\\nany of the parameters describing the wavelet on the three windows and QC the shape and\\nfrequency response of the wavelet operator. The shape of the wavelet has a direct influence over\\nthe signature of the resulting Synthetic seismogram and needs to be adjusted carefully to match\\nthe signature of the processed seismic data.\\nLower left hand: Time domain wavelet displayed in Amplitude Vs Time\\nUpper right hand: Phase spectrum of the wavelet displayed in Phase (rad) Vs Freq (Hz)\\nLower right hand: Frequency spectrum of the wavelet displayed in Amplitude Vs Freq (Hz)\\nImported wavelets\\nExternal wavelets can be imported into Petrel and used in the Synthetics Process.\\nThe input format is a text file consisting of a header, which ends with an end header flag (EOH)\\nand two columns with time (default ms) and amplitude.\\nIt is also possible to export a wavelet to disk, see below.\\nHow to import a wavelet\\n1.\\n2.\\n1. Click on File in the main menu and select to Import File.\\n2. Locate the ASCII file in the browser and select Format: Wavelet (ASCII)(*.*).\\n3. Change the time unit in the Import wavelet dialog if required.\\n4. Press OK in both import dialog boxes.\\n5. The loaded wavelet is now available for selection in the Synthetics process dialog.\\nHow to export a wavelet\\n1. Right-click on an existing wavelet in the Input pane.'},\n",
       " {'header': '2. Select Export. ',\n",
       "  'content': '3. Give it a name and make sure Save as type is set to Wavelet (ASCII)(*.*).\\n4. Click Save to output the wavelet.\\nSynthetic wavelets\\nThere are four types of analytical wavelets to choose from:'},\n",
       " {'header': 'Ricker Ormsby Klauder Butterworth ',\n",
       "  'content': 'These are described in detail along with their specific parameters in Wavelets.\\nIn addition, there are some settings that apply to all the wavelets:\\nSample rate -Sampling rate of the points describing the wavelet\\nLength - The overall operator length of the wavelet in time\\nConstant phase - Phase shift applied to the wavelet operator\\nMinimum phase - Changes the phase characteristic of the wavelet to be of type\\n\"minimum-delay\". The main energy is concentrated in the front-end of the lobe.\\nPrewhitening - A way of making spectral density more constant. Applies only for'},\n",
       " {'header': 'Minimum-Phase Wavelets. ',\n",
       "  'content': 'SEG polarity norm - Toggle between normal and reverse polarity (Note: Petrel uses a\\nEuropean standard for a Zero phase wavelet).\\nExtracted wavelets\\nThere are many factors that affect the quality of a wavelet, but the quality of the seismic and the\\nlogs being used are the main factor. Therefore, the user must invest some time in this process.\\nBefore attempting any extraction, it is important to do both of the following:\\nProperly Quality Checked logs\\nProperly calibrated sonic log\\nThe workflow process for the wavelet extraction involves trying several combinations of extraction\\nparameters, recording the results, and trying different boreholes in order to gain a better\\nunderstanding of the nature of the seismic data.\\nExtracted wavelets (Settings)\\nThere are a number of standard settings referring to the phase and sampling of the wave to be\\ngenerated:\\nSample rate -Sampling rate of the points describing the wavelet\\nLength - The overall operator length of the wavelet in time\\nConstant phase - Phase shift applied to the wavelet operator\\nMinimum phase - Changes the phase characteristic of the wavelet to be of type\\n\"minimum-delay\". The main energy is concentrated in the front-end of the lobe.\\nPrewhitening - A way of making spectral density more constant. Applies only for'},\n",
       " {'header': 'Minimum-Phase Wavelets. ',\n",
       "  'content': 'SEG polarity norm - Toggle between normal and reverse polarity.\\nIn addition, the user must select the seismic to sample the wave from, where to sample the wave\\nand what method to use:\\nSeismic - Selects seismic data for the statistical extraction\\nWell - Selects the well\\nNeighborhood - Selects the number of traces for the statistical calculation\\nAuto pos - Lets software define automatically the position of the extraction\\nManual - Defines position and range manually\\nTaper - Selects the type of taper window to be applied, see below.'},\n",
       " {'header': 'Taper Window ',\n",
       "  'content': 'The taper window is essentially a function of time that is multiplied by a data segment. It is\\nmainly used before computing the FFT (Fast Fourier Transform) spectrum of the data segment.\\nIts purpose is to smooth or shape the resulting spectrum.\\nHanning - Smooths with weights 0.23, 0.54, 0.23.\\nHamming - Smooths with weights 0.25, 0.50, 0.25.\\nCosine - 10% Cosine taper'},\n",
       " {'header': 'Bartlett - ',\n",
       "  'content': 'Papoulis - The default taper used in Petrel'},\n",
       " {'header': 'Creating Synthetic Seismograms ',\n",
       "  'content': 'Synthetic seismic is created by convolving the reflection coefficient log with a defined wavelet. The\\nwavelet will be added at each point in the RC log with an amplitude equivalent to the size of the\\nreflection. These are then summed to give the synthetic seismogram.\\nFirst, insert a new synthetic seismic log by right-clicking on the Global well logs or through the\\nSynthetics process dialog. Open its settings panel and browse to the Synthetic seismogram\\ntab. There are 3 sets of input required to build the Synthetic Seismogram:'},\n",
       " {'header': 'Reflection Coefficient Wavelet Sample Rate ',\n",
       "  'content': 'Underneath this is a table describing the standard properties of the wavelet used and giving an\\noption to override these.\\nNumber of traces allows the user to define additional traces with slightly different wavelet\\nproperties.\\nThe seismic can be displayed as wiggles or as a filled bitmap, these settings are found on\\nthe Style tab.\\nThe synthetic seismogram settings dialog (Synthetic seismogram tab)\\nIt is also possible to load a synthetic trace (indexed in TVD or TWT) from an ASCII or SEGY\\nfile, see below.\\nGenerating multiple traces\\nIf Number of traces is set to a number greater than 1, then a range of traces can be created in\\nthe same panel with slightly different wave properties. This provides an excellent method for\\ntesting the sensitivity of the seismogram to the various wave properties, and for comparing these\\nto the sampled seismic to get a good match.\\nThere are 4 options for setting each of the properties of the wavelet:\\nDefault - use the settings as they are in the wavelets settings.\\nFixed - over ride the default settings for all the traces in the synthetic.\\nRange - specify an initial and a final value and let Petrel fill in the intermediates.\\nSequence - manually specify the parameter for each trace.\\nWhen the synthetic seismogram is displayed, the bitmap will vary gradually showing the values\\nfrom the first trace on the left and the last trace on the right. When wiggles are displayed, 4\\ntraces will be shown for each set of settings.\\nFive traces with increasing low cut and pass frequencies\\nHow to display the synthetic seismogram in the 3D window\\nWhen a synthetic seismogram has been generated it can be displayed in the 3D window and in\\nthe interpretation window. When any of these windows are active, toggle the synthetic\\nseismogram in the input tree to display.\\nHow to export a synthetic seismogram to file\\nA generated synthetic seismogram can be exported out as an ASCII or SEG-Y file;\\n1. Right-click on a Synthetics object in the Input pane and select Export.\\n2. Give a file name and make sure that Save as type is set to Seismogram logs (ASCII, SEG-'},\n",
       " {'header': 'Y)(*.*). Click Save. ',\n",
       "  'content': '3. Select SEGY or ASCII in the Export domain index well log dialog.\\n4. Complete the dialog with Realization quality, Data sample scaling and Sample value\\nformat if using SEGY before clicking OK.\\n5.\\n3.\\n4.\\n5. If using ASCII, just click OK.\\nHow to import a synthetic seismogram from file\\nA synthetic seismogram generated outside of Petrel can be loaded in and used to tie to real\\nseismic data;\\n1. Right-click on a well where the synthetics seismogram should be loaded and select Import\\n(on selection).\\n2. Navigate to the file and and make sure that File of type is set to Seismogram logs (ASCII,\\nSEG-Y)(*.*). Click Open.\\n3. The Input data parameters must be matched to the file info found under SEGY header\\ninfo or Header info (depends on the type of input file) at the bottom of the Import\\ndomain index well logs dialog.\\n4. Set the domain and Elevation reference to complete the dialog.\\n4.\\n5. If needed, go to the Units tab to change the selection before importing the synthetic\\nseismogram.'},\n",
       " {'header': 'Well Seismic ',\n",
       "  'content': 'Seismic data can be sampled from wells and compared to the synthetic seismic created. Either\\nright/click on the seismic volume and choose Create well seismic, or select well seismic tab\\nfrom the Synthetics process dialog.\\nThere are two options for sampling from 3D volumes:\\nRadial extraction - sample along a radius to the well path at the given azimuth and at the\\ngiven distances from the well.\\nOrbital extraction - sample in a cone around the well at the specified radius and from the\\nspecified start azimuth to the specified end azimuth.\\nThere are also two options for sampling from 2D lines:\\nAutomatically find closest 2D seismic trace - calculates the closest position between\\nwell(s) and the seismic line.\\nManual set position - Line and trace must be specified.\\nSet the number of traces used in extraction for both cases.\\nA new seismic log icon will appear under global well logs and the seismic will be sampled next\\ntime it is displayed in a well section window or 3D window.\\nOrbital and radial extraction of seismic around a well path.\\nThe well seismic extraction dialog.\\nManual adjustment of time depth curves\\nOnce a reasonable synthetic seismogram has been created and it can be correlated with the\\nsampled seismic, it may be useful to make minor manual adjustments to the time / depth\\nrelationship to ensure that log values are matched as well as possible to the seismic trace. This is\\ndone by correlating points between time and depth and picking them. These points can be stored\\nas well tops or as a new checkshot group and then used as a manual adjustment.\\nWith Make/Edit Well Tops active, use Show Well Top Time to display tops in time (dotted\\nline) and Edit well Top Time to edit it. See Editing Well Top Time for a description of the\\nprocess.\\nPetrel will interpolate linearly between the picked points and stretch or squeeze the relationship\\naccordingly. These edits will not affect the sonic curve directly, but will be applied on top of the\\nexisting relationship.\\nIt is advisable NOT to apply the manual correction while you are editing the points, as the curves\\nwill be updated interactively making it difficult to drag points.\\nAs the relationship changes, so will the position of the well in time which will in turn result in\\nthe seismic being resampled and perhaps shifting in the well panel (i.e. moving the event you are\\ntying to).'},\n",
       " {'header': 'Geophysics ',\n",
       "  'content': \"Under the Geophysics topic you will find all the information available in the Online-help which\\nbelongs to Geophysical processes in Petrel.\\nCovered topics:\\nSeismic basic and visualization\\nReference datums\\nSynthetic seismogram\\nAttribute generation\\nGenetic inversion\\nAnt tracking workflow\\nHorizon interpretation\\nAutomatic Fault extraction and manual interpretation\\nGeobody extraction\\nVelocity modeling\\nDomian conversion\\nSeismic Basic and Visualization\\nIn the Seismic module, you can import large data volumes of 3D seismic cubes in SEG-Y or ZGY\\nformat. SEG-Y files are often very large - usually too large to load into the PC's RAM in their\\nentirety. Petrel avoids this by reading the parts necessary for visualization or processing directly\\nfrom the file, or by accessing a back-end seismic server (i.e., Linux cluster). On a stand-alone\\ncomputer, Petrel offers some important methods of reducing the amount of data and optimizing\\nthe data for specific tasks. These are:\\nCropping: for defining a virtual seismic volume that is a spatial sub-volume of the original.\\nRealization: for making a physical representation (a ZGY file) of a virtual volume, or for\\nmaking a new physical representation optimized for specific usage.\\nCropping of the seismic cube allows rapid viewing of 3D data even on standard PCs. Real-time\\nrendering of seismic data can be used for superior quality control of fault planes and surfaces.\\nPetrel also provides scalability for seismic operations through the Seismic server (accessing large\\namount of memory [RAM] and great computing powers from a Linux cluster).\\nHorizons and faults can be interpreted in 3D, which makes it easy to quality control the\\ninterpretation.\\nWhen the interpretation is complete, the 3D grid can be depth converted. It is recommended to\\nbuild the 3D grid in time and use the depth conversion process in Petrel to generate the depth\\nmodel. A virtual link from the seismic time attributes to the depth domain enables the seismic\\nattributes to be visualized in depth. You can then continue with the property modeling and also\\ncreate seismic properties.\\nFor information on the settings for seismic objects see Seismic Data (Settings).\\nSeismic in Petrel.\"},\n",
       " {'header': 'Data Management ',\n",
       "  'content': 'During a Petrel seismic project, the data-tree can grow to such a size that handling the data\\nbecomes quite difficult. Therefore, it is important to manage the data properly. Petrel can handle\\nlarge amounts of seismic data in the form of 2D and 3D surveys and can be accessed through\\nloading from file, from a database using Open Spirit or connecting to a seismic server (3D cubes\\nas ZGY only).\\nThere are two options for storing data on the Seismic Server:\\nProject-specific ZGY file:\\nThe advantage of having projects with specific ZGY files is that they are easy to administrate and\\nideal for a server with few projects. The disadvantage is that the content of a ZGY file can be\\nduplicated several times while it is in use by different projects. Nevertheless, different projects\\ncan contain non-overlapping subsets from one ZGY file.\\nA ZGY file can be dropped into a project from any External Directory (or Working Directory)\\nfolder. When the External Directory (source) and project (target) are located on different servers,\\nthe seismic server copies the ZGY file to the External-Directory on the target server. If there is no\\nExternal Directory on the target server, the ZGY file is copied to the target project directory.\\nShared ZGY file:\\nThe advantage of sharing the ZGY files on an External Data directory is that the files used in\\nseveral projects are not duplicated. This is ideal for a cluster with several users. This solution also\\nrequires more careful data administration and cleanup.\\nTo share a ZGY, drag to the External Data directory. This copies the file physically to the External\\nData directory.\\nSeismic data - Memory management\\nThe BASE system has been created to enable superior memory management for Petrel\\'s\\ngeophysical applications. The better handling of the data and memory access, the better the\\napplication performs for you. In an ideal world, all data should be instantly read into the memory,\\nbut as of today this not the case. Large data volumes take time to read into a fairly limited\\namount of RAM. The smart utilization of this RAM is critical for your Petrel user experience.\\nWhen using the geophysics modules in pre-Petrel 2007.1 versions, the software required large\\namounts of data resided directly in your PC\\'s RAM. As you view larger and larger amounts of data,\\nyour RAM runs out and Petrel either starts to respond sluggishly or, in extreme cases, crashes.\\nThe BASE system enables the seismic modules to have a single \\'chunk\\' of controlled memory,\\ncoupled with an intelligent use of a local disk cache (known as a pagefile). This pagefile is\\nessentially memory mapped data that has been temporarily swapped out of memory, and is\\ncurrently available for seismic interpretation only. For the user, this means better performance\\nand improved stability.\\nWhen running on a 32-bit OS, Petrel can utilize up to 2Gbyte RAM. This can be used up very\\nquickly, especially when displaying lengthy seismic sections in the Interpretation window - either\\n2D or 3D data (because the Interpretation window displays full resolution data, every sample\\nneeds to reside in memory); or when working with modeling modules.\\nThe BASE system starts to allocate memory as the seismic data/interpretation is either displayed\\nor edited. It does not pre-allocate its memory, but will start to fill up from 0 to the set variable\\nlimit (this can be manually set, see Seismic (System settings)). Once the BASE RAM variable limit\\nhas been reached, any \"stale\" interpretation data that is not being actively used can be passed\\nout of RAM and onto the local pagefile, in a format that enables Petrel to rapidly reaccess this\\ninformation if needed. Actually, the BASE system aims to only use 90% of its allocation,\\nmaintaining 10% as spare in case of sudden need. The \"Free Memory\" command will empty the\\nmemory of stale data.\\nZGY is now the standard format for optimized 3D seismic performance. The BASE system\\nrequests the relevant resolution of data for display in a Petrel window. (ZGY data is a multi-\\nresolution format - with data at 7 levels of detail) Only the required data for display is stored in\\nmemory. Once the BASE RAM variable limit has been reached, seismic data is thrown out of\\nmemory - if needed again it is reread from the disk. To speed up the reading of the bulk data\\nfrom the disk, the BASE system uses a multi-threaded approach - using every CPU on your local\\nworkstation to gather the required data for display. When ZGY data resides in RAM, that same\\nRAM-resident data can be used by multiple windows if they are displaying the same data. By\\nallowing different windows to \\'share\\' this data, geophysical processes make very efficient use of\\nmemory. In contrast, for Petrel 2005 seismic interpretation and bulk data, everything needed to\\nreside in memory. Additionally, the toolkit used for rendering seismic in the 3D window also had\\nits own RAM requirements.\\nWhen you save your project, the data in memory plus that in the pagefile will be saved. Note that\\nthe Petrel temporary pagefile will not be deleted upon EXIT - they are removed at the next\\nstartup.\\nUpon startup of Petrel, any windows that are iconized will only call for the data they require when\\nthey are opened.\\nZGY data is read in bricks - each brick is 64*64*64 samples. For 8-bit data, a brick occupies\\napprox 262 Kbytes or 0.2 Mbytes. A brick is the smallest unit that can be read into or thrown out\\nof memory. In the image below, to display an inline (401) requires 12 bricks to be read into\\nmemory. Changing to inline (402) will not require any new bricks to be reread because they are\\nalready in cache, making this a quick process.\\nThe ZGY display option Tile overlap doubles the memory required to display ZGY data. The\\nmemory requirement to store all 7 levels of detail (LODs) will add about 30% to the memory\\nusage.\\nPossible error messages from the seismic BASE\\nsystem.\\nThe most common error messages coming from the BASE system are those related to memory\\nallocation failure. The memory allocation will typically fail if the computer memory is too low or\\nvery fragmented. The Free memory command (Menu bar - Tools - Free memory) can help\\nresolve some of these issues/workflows, but will probably not work for all workflows and\\ninterpretation combinations.\\nSome other error messages related to memory allocation failures are:\\n\"Failed to allocate XX MB memory: std::bad_alloc exception in Shared Buffer\"\\nThe system has failed to find XX of continuous available memory.\\n\"Failed to allocate 256 KB memory: std::bad_alloc exception in cache\"\\n\"std::runtime_error: [ZGYBulkAccessor::accessBrickData] ReadData failed - unable to allocate\\nmemory\"\\nThere are several measures you could try to avoid this.\\nFree memory\\nClose windows\\nTurn off displayed objects. (E.g. Volume rendering and seismic data)\\nTry to reduce the seismic cache size (in Seismic (System settings)).\\nSEG-Y Utility\\nA large portion of available 2D surveys in SEG-Y format that have been acquired and processed in\\nthe past do not contain the proper information related to the navigation or positioning of the lines\\nin the header. The navigation information is provided on separate files in UKOOA format.\\nThe SEG-Y Utility will read disk files with 2D lines in SEG-Y format and the corresponding UKOOA\\nnavigation files. It will also use either CDP number, shotpoint number or trace number stored in\\nthe SEG-Y trace headers to determine the missing x and y coordinates. Those will be written into\\nthe SEG-Y trace headers of each respective 2D line. The results can be saved as new versions\\nwith updated trace headers. These files can be imported to Petrel.\\nIn the upper part of the image below, the UKOOA navigation file is selected. Based on line\\nselection (SEG-Y files), a match is made with line names found in the UKOOA file. The trace\\nlocation can be determined using CDP number, shotpoint number or trace number found in the\\nSEG-Y trace header. The position of the items in the SEG-Y file must be specified. The defaults are\\naccording to standard.\\nUKOOA Navigation File\\nClicking on the Select File button opens a browser where you can locate and select the UKOOA\\nnavigation file to be used for determinning x/y coordinates. Clicking on the List button will show\\nthe first 500 records of the navigation file.\\nUKOOA File Format\\nThe utility will accept navigation files in:\\nstandard UKOOA format\\nUKOOA P1/84 format\\nUKOOA P1/90 format\\nThe format must be specified before the line can be selected from the navigation file.\\nSee also the Society of Exploration Geophysicists (SEG) tech standards:\\nhttp://seg.org/publications/tech-stand/ and UKOOA publications:\\nhttp://www.oilandgas.org.uk/ukooa/newpublications/srchResults.cfm\\nStandard UKOOA format:\\n4 Header records at the top of the file.\\nThen records of the format Columns (length) and Field Description:\\n1-16 (16) Line Name (left adjusted)\\n17-24 (8) Shotpoint number (numeric)\\n45-52 (8) X-coordinate Easting (numeric)\\n53-60 (8) Y-coordinate Northing (numeric)\\n1984 UKOOA format\\nColumns (length) and Field Description:\\n1 (1) Data record ID character (Value S=shotpoint, G, Q, A)\\n2-17 (16) Line Name (left adjusted)\\n18-25 (8) Shotpoint number (numeric)\\n26-35 (10) Latitude DDMMSS.FFN (or S) (Ignored)\\n36-46 (11) Longitude DDDMMSS.FFE (or W) (Ignored)\\n47-55 (9) X-coordinate Easting (numeric)\\n56-64 (9) Y-coordinate Northing (numeric)\\n65-70 (6) Water depth/Elevation (Ignored)\\n71-73 (3) Day of year (Ignored)\\n74-79 (6) Time HHMMSS (Ignored)\\n80 (1) (Not used)\\n1990 UKOOA format\\nColumns (length) and Field Description:\\n1 (1) Data record ID character (Value S=shotpoint, G, Q, A)\\n2-13 (12) Line Name (left adjusted)\\n20-25 (6) Shotpoint number (numeric)\\n47-55 (9) X-coordinate Easting (numeric)\\n56-64 (9) Y-coordinate Northing (numeric)'},\n",
       " {'header': 'Line Selection ',\n",
       "  'content': 'Clicking on the Line Selection button opens a spreadsheet where you can locate and select your\\nSEG-Y in the disk. Here, you will match the SEG-Y files with line selection from the UKOOA\\nNavigation file.'},\n",
       " {'header': 'Trace Location ',\n",
       "  'content': 'The trace location can be specified by:\\nCDP number\\nShotpoint number\\nTrace number\\nDefault positions are according to standard. They can be modified if required.\\nLocation of X Coordinate / Location of Y Coordinate\\nX and Y coordinates, as determined from the navigation file, will be stored in the new SEG-Y file\\nat the positions indicated in the dialog. The defaults are according to standard and these positions\\ncan be changed if required.\\nSEG-Y Output\\nBy default, X and Y coordinates will be written into the SEG-Y file to be processed. By default, the\\noriginal SEG-Y file will be overwritten, but a new directory or file extension can be selected to\\npreserve the original input.\\nHow to merge 2D SEG-Y lines with UKOOA Navigation\\n1. Click on the Tool option in the menu bar and select Launch SEG -Y Utility from the menu.\\nA new dialog called \"UKOOA Navigation to SEG-Y header utility\" will open.\\n2. Click on the Select file button to select the UKOOA Navigation File.\\n3. Locate and select the navigation file using the appearing browser.\\n4. If needed, click on List to list the 500 first records in the navigation file.\\n5. The file format for the UKOOA file should normally be picked up by the application, if not,\\nselect the appropriate format from the drop-down menu or select User defined .\\n6. Click on the Line Selection button to open a table where SEG-Y trace files can be assigned\\nto UKOOA navigation lines.\\n6.\\n7. Use the Directory browser and Filter to locate the files if needed. Right-click inside the\\nLines column and select List Line table from the menu that opens.\\n8. Match the lines found in the navigation file with the SEG-Y files. Drag and drop line table\\ninto the SEG-Y trace file assignment table.\\n9. Select the trace location in the file, the options are CDP, shotpoint or trace number. The\\ndefault is CDP at 21-24 bytes; this can be changed if needed.\\n10. You can specify the position of the X and Y coordinates in the output file, the defaults listed\\nare according to standard.\\n11. In the SEG -Y Output field, select whether to overwrite, set a new file extension or put the\\nresult in a new folder. Note that the default selection will overwrite the original SEG-Y file.\\n12.\\n13.\\n11.\\n12. Press Start to start the process.\\n13. When the new file has been generated, it can be imported into Petrel using the normal\\nSEG-Y import format.'},\n",
       " {'header': 'Seismic Data Import ',\n",
       "  'content': 'Two different formats can be imported and used in Petrel; SEG-Y and ZGY (bricked) format. When\\na seismic file is imported, the intersections in the cube are generated automatically. Any seismic\\ndata must be imported into predefined folders, a seismic main folder that contains all seismic\\nrelated data and seismic survey folders for the various surveys.\\nSeismic main folder\\nThe seismic main folder is a predefined folder reserved for seismic data in Petrel. It contains all\\nseismic bulk data like seismic surveys with corresponding vintages, interpretation folders for\\nhorizon/fault interpretations and filters for easy handling of data contained in the main folder.\\nOnly one seismic main folder can exist for a given project. In earlier Petrel versions (pre-Petrel\\n2007.1), there was no seismic main folder. Any pre-Petrel 2007.1 projects must be converted to\\nmeet this standard, which is an automatic process. Both seismic data and interpretation is\\nautomatically converted to the new standard, but interpretation needs user interaction before any\\nfurther interpreting can take place (see How to convert pre-Petrel 2007.1 interpretation).\\nHow to insert a seismic main folder:\\n1. Make sure the Input pane is activated.\\n2. Click on Insert in the Menu bar and select New seismic main folder.\\n3. A seismic main folder will open in the Input pane with predefined sub-folders and filters.\\nAlternatively: Open up a new Petrel project.\\n1. Go to File in the Menu bar and select Open project.\\n2. Find and select the pre-2007.1 project and click Open.\\n3. Alternatively, use the window explorer to find and double-click on the Petrel *.pet file.\\nPetrel will automatically create a seismic main folder and place seismic related objects in it.\\nA seismic cube report can be made containing information about all seismic volumes in the\\nproject. Right-click on the Seismic main folder and select Make seismic cube report... The\\nPetrel message log opens, containing extensive information about the volumes in the project.\\nSeismic survey folder\\nThe seismic survey folder is a placeholder for seismic data belonging to a survey. Vintages, or\\nversions of the same survey will reside under the same folder. The survey folder can be used to\\ndo operations, such as mis-tie corrections, for all data in the folder and control the display of the\\nbasemap annotation. If data is imported directly from the File menu, a new survey folder will be\\ncreated for the imported seismic; however, it is possible to insert a survey folder or import\\nseismic into existing survey folders. Sub folders can be created by right-clicking on the folder and\\nselecting Insert Folder. Seismic data can be placed into the sub folders.\\nHow to insert a survey folder and import seismic data into it:\\n1. Make sure the Input pane is activated.\\n2. Click on Insert in the Menu bar and select New seismic survey.\\n3. Alternatively, right-click on the main seismic folder and select Insert seismic survey. A\\nnew survey folder will open up under the seismic main folder.\\n4. Right-click on the newly created survey folder and select Import (on selection).\\n5. Select the seismic file and format to be imported.\\nAlternatively: Import several surveys in one go (works only for SEG-Y seismic data).\\n1. Make sure the Input pane is activated.\\n2. Right-click on the main seismic folder and select Load multiple surveys.\\n3. Select the main folder where all seismic data files are stored in its sub folders and click OK.\\n4. Also, click OK in the box that opens (the seismic data will be loaded using default loading\\nparameters).\\n5. The different surveys will be loaded and sorted into separate survey folders adopting to the\\nfolder structure on the disk.\\nIf seismic data is already loaded with preset loading parameters, you can choose to use\\nthese or default parameters in the dialog box that opens.\\nSeismic surveys can be grouped under sub folders of the Seismic folder.'},\n",
       " {'header': 'Seismic Survey Definition ',\n",
       "  'content': 'The geometry of a 3D survey can be defined prior to loading a 3D volume. The definition can be\\nbased on an existing object and then optionally modified, or based on 3 corner points.\\nSettings in the Survey folder geometry supports 3 main workflow:\\n1. Allow loading of interpretation data into a project with no seismic volumes.\\nWorkflow - Create a new survey based on the desired geometry. Select this survey when\\nloading ASCII data.\\n2. Allow definition of a survey to be independent of SEGY positional information\\nAfter a survey is defined the inline and xline numbers from the SEGY file will be used to\\nposition subsequently loaded volumes .\\n3. Allow the inline/xline extent to be adjusted to enable multiple SEGY files to be loaded into a\\nsingle survey.\\nWorkflow - load a seismic volume, adjust survey geometry to increase inline, xline range,\\nload additional SEGY volumes.\\nNote once the 3d Survey contains a seismic volume certain parameters cannot be edited.\\nOnce the survey contains a seismic horizon the extent can no longer be edited.\\n4. Allow generation of empty \"dummy\" seismic volumes\\nThe Create empty cube option allows the user to generate a seismic volume based on the\\nsurvey geometry. The seismic volume will be a ZGY contained in the Petrel .ptd folder. The\\nZGY file has uniform amplitude values of 0 and will occupy very little disk space due to the\\nway the ZGY format deals with constant value bricks. When an intersection from the\\nvolume is viewed in Petrel, it will occupy more memory as each sample has to be displayed.\\nMerging seismic cubes\\nIn order to merge seismic cubes, you can select two or more volumes under a survey and use the\\nthe right-click menu to Merge seismic volumes. This will create a 32-bit ZGY file of the\\ncombined data. This is typically used to combine multiple SEGY files into a single ZGY file.\\nGeneration of empty \"dummy\" seismic\\nvolumes\\nThe Create empty cube option allows you to generate a seismic volume based on the survey\\ngeometry. The seismic volume will be a ZGY file from the Petrel .ptd folder. The ZGY file has\\nuniform amplitude values of 0 and will occupy very little disk space due to the way the ZGY\\nformat deals with constant value bricks. When an intersection from the volume is viewed in Petrel,\\nit will occupy more memory as each sample has to be displayed.\\nThe dummy seismic volume can be useful in the following workflows:\\nFor displaying and QCing the outline of the survey in 3D-, 2D-, or Map window.\\nTo enable composite lines to be made between seismic intersections that do not intersect\\neach other.\\nAllowing seismic sections or interpretations to be viewed using the \"blue button\" option.\\nTo allow interpretation between wells - intersections from empty volumes can be\\ninterpreted on using the seismic interpretation tools.\\nTo extend the seismic interpretation above or below available seismic volumes. This can be\\nuseful during basin modeling exercises.\\nSeismic vintages\\nSeismic vintages were introduced in Petrel (version 2007.1 and onwards) to allow the user to\\nswitch between different seismic attributes contained within a single survey. For example, in the\\ninterpretation window it can be useful to switch between normally migrated and variance seismic\\nfor fault interpretation. Petrel allows the user to use multiple seismic vintages, by switching\\nbetween them rather than having multiple windows open.\\nSeismic vintages are created upon the initial loading of the seismic into a Petrel project. Initially, if\\na seismic cube is loaded into a blank project, a default vintage is given to the seismic or a vintage\\nselection input from the user is required.\\nThe default vintage in a blank project is Seismic Time 1 and can found under the Vintages folder.\\nIf a survey folder already contains a seismic vintage for \"Seismic Time 1\" and another volume is\\nloaded or generated in the same survey, a new vintage will be created. The new vintage is then\\nby default called \"Seismic Time 2\" as the vintage names increases sequentially by the number.\\nNevertheless, vintages can be renamed at any time. If a new volume is loaded into a second\\nsurvey folder, an already existing vintage can be used (that is, the definition of the volume is\\ndifferent since it is a different survey). The vintage of a seismic object can be set after loading in\\nthe Settings dialog, Info tab.\\nGenerating seismic attributes from seismic data will create additional vintages, as will the creation\\nof a mis-tie set. All vintages can be managed in the Survey Manager, alternatively from the\\nVintages folder.\\nIf any unused vintages exist in the project, they can be removed by right-clicking on the Vintages\\nfolder and select Remove unused vintages.\\nSEG-Y Data Import\\nSeismic 3D cubes can be imported as either SEG-Y or ZGY format. Seismic 2D lines can be\\nimported in SEG-Y format. The files will be stored in survey folders. The survey is created when\\ndata is imported, unless the data has been imported directly into an existing survey folder. There\\nare two different SEG-Y import options in Petrel; SEG-Y seismic data and SEG-Y import with\\npreset parameters. Petrel will automatically try to find the correct byte locations for x,y-\\ncoordinates, and so on, using the SEG-Y seismic data format. If you use the SEG-Y Import\\nwith preset parameters option, you have to specify the correct byte locations and you also\\nhave the possibility to scan the file.\\nIt is recommended to follow normal usage of filenames and use the extension to describe\\nfile types. The name of the imported seismic object in Petrel is created from the name of the file,\\nbut ignores the extension. If multiple dots are used in the file name, only that which comes after\\nthe last dot is regarded as the extension. As an example, file SurveyA.FullFold.SEGY.line1 will\\nbe imported as SurveyA.FullFold.SEGY and can lead to multiple objects having the same file\\nname.\\nSEG-Y seismic data\\nPetrel will auto detect whether the input file is 2D or 3D seismic. SEG-Y files detected as having\\nonly one line will be assumed to be 2D seismic.\\nThe SEG-Y reader will use sx, sy for coordinates. If not present, gx, gy will be used.\\nWhenever a new realization of the seismic cube is created within Petrel, the new seismic volume\\nwill be stored in ZGY format.\\nNote that this method uses industry standards for Inline/Crossline number byte locations. If\\nthe automatic line detection method uses the wrong byte position for the parameters, in many\\ncases, Petrel will still import the file. The SEG-Y volume can be used and, in most cases, will\\nbehave correctly. After realizing the volume to a bricked seismic format (ZGY), the new volume\\ncan be sluggish and hard to handle due to the wrong settings. The original SEG-Y file then needs\\nto be re-imported using the SEG-Y Import with preset parameters (recommended).\\nSEG-Y Import with preset parameters\\nIf using the SEG-Y Import with the preset parameters option (recommended), you have to specify\\nthe correct byte locations and you can also scan the file. It is possible to ignore traces with zero\\ncoordinates. SEG-Y loading parameters can be specified automatically from an already loaded\\nSEG-Y file using the blue arrow in the uppermost part in the SEG-Y Import box.\\nThe SEGY headers from first file area of the dialog gives you access to the ASCII header,\\nbinary header and trace header information to identify byte location parameters.\\nThe file can be scanned to check inline and crossline numbers as well as x and y coordinates. A\\nspecified number of traces can be scanned.\\nThe stair-step pattern of the inlines and sawtooth pattern of the crosslines is the expected\\nbehavior of the SEG-Y Scan.\\n2D lines specifics\\nImport of 2D SEG-Y files will gives you an option to specify parameters to correctly define\\ntrace, CDP, and shotpoint numbering.\\n2D seismic lines can be cropped and realized.\\n2D lines can be exported. See section about SEG-Y export.\\nAttributes can be extracted from 2D seismic.\\nReconnect seismic files\\nThe original seismic file is not saved in the Petrel project folder - only a link to the file. Therefore, if you\\nmove the project, the seismic file cannot be found unless its path from the project\\'s new location is\\nunchanged. If the file is not found, its icon changes into a cross to mark it as unreadable like this:\\nTo re-establish the link, move the seismic file to an accessible directory. Open the Settings window for\\nthe seismic cube in the Petrel project and, on the Info tab, type in or browse to the new directory and\\nfile name of the seismic file. Alternatively, you can right-click on the Seismic main folder or a survey\\nfolder (or sub folders) and select the option to Reconnect missing files... . Use the browser to point\\nto the folder where the seismic file(s) are located and click OK . There is also the option to re-import\\nthe files.\\nFig. 1 Right-click menu Reconnect missing files...\\nThe top half of the window list folders where the system is expecting to find seismic data. Beneath this\\nare 3 sub-tabs with different options for the seismic data to be reconnected:\\nSearch in folder structure : You can set the number of folder levels lateral and vertical to\\nsearch within and validate before reconnecting strating from the Initial folder\\nThe option Minimum number of folders in path enables you to control how many\\ndirectories above the file must match to allow the connection to take place.\\nFor example, if the original file location was listed in Petrel as ..\\\\My\\nFiles\\\\Petrel\\\\Seismic\\\\Survey 1\\\\Migrated.zgy\\nSetting the parameter to 0 and starting the search at D:\\\\My Files\\\\Petrel\\\\ would find\\nsuitable a file in the directories\\nD:\\\\My Files\\\\Petrel\\\\Seismic\\\\Survey 1\\\\Migrated.zgy\\nD:\\\\My Files\\\\Petrel\\\\Seismic\\\\Survey 2\\\\Migrated.zgy\\nD:\\\\My Files\\\\Petrel\\\\Temp\\\\datasets\\\\Migrated.zgy\\nThis is because the match is only being made based on the file name. Changing the Minimum\\nnumber of folders in path setting to 1 would require a match with the folder above, and would\\nonly match\\nD:\\\\My Files\\\\Petrel\\\\Seismic\\\\Survey 1\\\\Migrated.zgy\\nNote: By default the first file found is reconnected. If the Advanced selection of files\\noption is used, a new window appears showing how many versions of each file have been found\\nand the file that will be\\nreconnected by default. This can be changed to reconnect to a different file or the user can\\namend the search criteria (paths, folders in path etc) to ensure the correct files are reconnected.\\nFig. 2 Advanced selection of files dialog.\\nSearch in paths - The search id made based on defined paths, these can be set at a corporate\\nlevel.\\nIf data management team wants to move seismic bulk files round the system, they have no way of\\nknowing which Petrel projects are using the files and, therefore, informing users where to find the\\nmoved files. The Seismic Reconnect option allows the creation of disk lists. They can be at a project,\\nsystem, or corporate level and are searched in this order to reconnect to seismic volumes.\\nProject and system disks are set up in Petrel , while corporate disks are read from a text file whose\\nlocation is given via the \"Corporate paths file\".\\nFig. 3 Search in paths tab\\nRe-parent paths - Is very useful when working with USB disks where drive letters change.\\nFiles can be re-parented to locations that do not exist. The option Force re-parent will update the\\nlocation of the seismic to the new parent path even if this location is not accessible on the current\\nmachine. This enables projects to be created with disk paths that are perhaps only visible in a remote\\noffice, or to update seismic file locations before the physical file has been copied there.\\nFig. 4 Re-parent paths tab.\\nThe results of reconnect missing files can be written to the output sheet, providing a record of what\\nhas been done.\\nNote that the original seismic files should never be moved to the project .ptd file. These files are\\ninternal to the Petrel project, and other files in this directory will be deleted by Petrel.\\nZGY Data Import\\nSeismic 3D cubes in ZGY format can be imported and will be stored in survey folders.\\nIf the link to the ZGY file is lost, you will need to re-establish the link. Move the ZGY file to an\\naccessible directory, open the Settings window for the seismic data and, in the Info tab, enter\\nthe new directory and file name of the ZGY file, or browse and select the ZGY file from this tab.\\nAlternatively, you can re-import the file.\\nThe ZGY format is a seismic file where the seismic representation is changed to a bricked format\\nfor rapid display of the seismic (inlines, crosslines, timeslices and cropped volumes). The ZGY files\\ncontain a pre-computed \"level of detail\", which means that the bricks exist with full resolution and\\nlow resolution. When the ZGY file is displayed, only the necessary bricks are loaded into memory.\\nBig bricks with low resolution are loaded into memory first, after which the program will start\\nloading smaller bricks with a higher resolution. The user will perceive the seismic as coarse\\nresolution, but, it will be refined as the program is given time to load smaller bricks into the\\nmemory. The benefits are that large seismic bricked data can be rendered in the 3D window, and\\nuser interactions are always available. The loading of the bricks is stopped if the user moves a\\nseismic line.\\nSee also How to import seismic data into a survey folder .\\nThe benefit of using ZGY bricked seismic data is that large seismic volumes, which are much\\nbigger than the computer\\'s memory, are easily displayed and handled in Petrel.\\nReuse of pre-Petrel 2008.1 projects\\nOnly one seismic volume geometry can exist in a survey folder in Petrel. In pre-petrel 2007.1\\nversions, survey folders could contain multiple geometry volumes and even a combination of 2D\\nand 3D. If such a project is converted to this version of Petrel, it will move all, except the first\\nvolume in each survey folder, into new folders. The new survey folders will be named Converted\\nseismic 1 or Converted 2D seismic dependent on type of seismic that is stored in each folder.\\nSeveral converted survey folders can exist in a converted project.\\nHow to open a pre-Petrel 2007.1 project\\n1. Open the latest version of Petrel.\\n2. In the Menu bar, go to File and select Open project...\\n3. Find the pre-Petrel 2007.1 project and open it. The project will start loading and converting\\nthe seismic data to the new standard. The Petrel message log will open, listing the various\\nconversion steps.\\n4. When the loading is finished, check the log for information.\\n5. Find any pre-existing interpretation folders containing padlocked interpretation. They can\\nbe converted to a survey consistent interpretation if needed.\\n6. Find the seismic data stored in survey folders, alternatively in newly created converted\\nseismic folders. These can all be found under the seismic main folder.\\nWhen realizing seismic data in Petrel 2005 and earlier versions, the following formats were\\nincluded for selection:\\nInteger 64-bit\\nFloating point 64-bit\\nInteger 4-bit\\nInteger 2-bit\\nInteger 1-bit\\nThese value formats are no longer supported in Petrel. When upgrading a pre-Petrel 2007.1\\nproject that contains realized seismic data in any of the above formats, an error message opens\\nand the seismic object is deleted. The source volume or line needs to be reloaded from disk or\\nthrough OpenSpirit.\\nWhen upgrading a P2007.1 project to P2008.1 or later, any existing seismic 2D multilines (i.e.\\nseismic data imported from one SEG-Y file containing multiple 2D lines) are split into separate\\nsingle lines. This has some implications when it comes to the display of already existing composite\\nlines containing parts from the original multiline.\\nBest practice when upgrading pre-Petrel 2007 projects:\\nSave the project in the new version of Petrel, close and load it again. This will free up some\\nmemory.\\nHow to re-display composite lines created from multi 2D lines in Petrel\\n2007.1\\nAny composite line that was created with the use of multi 2D lines in Petrel 2007.1, will not\\ndisplay correctly when upgraded to Petrel 2008.1. This is due to the upgrade procedure that splits\\nthe multiline into single lines. So the source for parts of the composite has changed and needs to\\nbe redirected. The following simple workaround will correct the display problem:\\n1.\\n2.\\n1. After upgrading the project to Petrel 2008.1, find the composite line in the Input pane.\\n2. Click the display of the composite line off in the active window, then redisplay it.\\n3. Alternatively, expand the composite line, find the part(s) coming from the multiline and\\ndeselect before re-selecting it.\\nRecommended byte positions for importing'},\n",
       " {'header': 'SEG-Y ',\n",
       "  'content': 'The following are recommended byte positions for importing SEG-Y volumes into Petrel:\\n5-8 (\"tracr\")integer inline number\\n21-24 (\"cdp\")integer cdp/crossline number\\n73-76 (\"sx\")X coordinate\\n77-80 (\"sy\")Y coordinate\\n105-106 (\"ms\")trace start time depth\\n115-116 (\"ns\")number of samples\\n117-118 (\"dt\")sample interval in microseconds\\n169-170 (\"trwf\")trace weighting factor (optional, usually zero), applied as 1^2^trwf on\\neach sample. Every sample is scaled by a factor 2.0 raised to the power of minus trwf:\\nsample value = sample value * (2^-trwf)\\nPetrel auto detects integer and IBM or IEEE floating point values for the X and Y coordinates. All\\nother values are integers. The loader will also auto detect if data is stored as little or big endian.\\nBig-endian means that within the bytes that make up a number, the most significant byte\\n(containing the sign bit) is written closest to the beginning of the file, and the least significant\\nbyte is written closest to the end of the file. ns and dt must have the same value for all traces.\\nFor inline and crossline numbers, Petrel supports the use of almost all standard trace header\\nfields, so the two fields listed above are merely suggestions. Petrel will automatically try to find\\nthe correct byte locations for Inlines, Crosslines, x,y-coordinates, etc. using the SEG-Y seismic\\ndata format. The automatic line detection algorithm does a good job of locating the most likely\\ncandidates.\\nThe following fields in the binary SEG-Y header (after the EBCDIC header and before the first\\ntrace header) must equal the corresponding ns and dt fields in the trace headers:\\n21-22 (\"hns\")number of samples\\n17-18 (\"hdt\")sample interval in microseconds\\nThe following field in the binary SEG-Y header determines the sample format used:\\n25-26 (\"format\")sample format\\nThe supported values are:\\nIBM floating point\\n32-bit fixed point (treated as integer by Petrel)\\n16-bit fixed point (treated as integer by Petrel)\\nIEEE floating point\\n8-bit (non-standard)\\nAppending SEG-Y volumes\\nAppending SEG-Y volumes is possible by using the Windows DOS copy command. One\\nprerequisite is that the volumes to be appended are adjacent to each other (inlines or crosslines\\nneed to be consecutively numbered).\\nHow to use windows DOS command to append two adjacent volumes\\n1. Open up a Microsoft Windows XP DOS window and locate the files to be appended (cd to\\ndirectory). For example, the mig_north.sgy and mig_south.sgy to be appended into\\ncomb_mig.sgy file in the C\\\\temp directory:\\n2. Enter the following command on the C\\\\temp drive: copy /b mig_north.sgy +\\nmig_south.sgy comb_mig.sgy (where the /b signifies binary files).\\n3. Import the comb_mig.sgy file as normal for a 3D volume.\\nFor more information on the DOS Copy commands see the following link to Microsoft Windows XP'},\n",
       " {'header': 'DOS: ',\n",
       "  'content': 'http://www.microsoft.com/resources/documentation/windows/xp/all/proddocs/en-us/copy.mspx'},\n",
       " {'header': 'CDP/SP ',\n",
       "  'content': 'For 2D seismic, there is also a CDP and Shotpoint numbering header field under the SEG-Y\\nImport dialog box.\\nLine detection method\\nEditing of the SEG-Y settings is done from the SEG-Y Import with preset parameters window.\\nHere, you can change some of the input parameters found in the headers of the SEG-Y file. The\\ninformation in the headers is not always precise (or even correct) when received from seismic\\ncontractors, and often, it is necessary for the user to adjust or change some of these SEG-Y\\nsettings. The SEG-Y seismic cube must be placed in the correct UTM position with correct inline\\nand crossline numbers.\\nThe inline and crossline numbering fields can be corrected by using the Trace header fields\\nmethod (shown in the image below). You can then select the correct byte locations. The SEG-Y\\nImport with preset parameters format can be used to specify the correct inline and crossline byte\\nlocations before importing the file. The Automatic method will analyze the trace headers and\\nselect the most likely line/inline and trace/crossline headers. If not found, gaps in the X/Y\\ncoordinates will be used. When this method is set, scanning will not be available because the\\nheaders are undetermined until the SEG-Y file is read. This method corresponds to loading SEG-Y\\nfiles without setting any loading parameters. X,Y coordinate gap will break up the lines\\nwhenever there is a significant gap in the trace coordinates. EBCDIC and/or binary header will\\nbreak up the lines whenever a SEG-Y header is found in the file. This is appropriate when a file\\ncontains concatenated SEG-Y files.\\nSEG-Y Import with preset parameters dialog box illustrating Line detection method activated as\\nTrace header fields.'},\n",
       " {'header': 'Trace Format ',\n",
       "  'content': 'There is an option to override the auto-detection of some variables like Sample format,\\nSamples per trace and Sample interval. The program will try to find this information in the\\nSEG-Y headers, but it is not always present. These options require that you know the correct\\nvalues.\\nSEG-Y import with the preset parameters dialog box, illustrating Trace format manipulation.\\nLateral and vertical geometries of 3D cubes\\nTo define the seismic data area, only 3 points are needed: The origin (the first point of the first\\ninline and the first crossline), the last point of the first inline, and the last point of the first\\ncrossline. Together, these three points span a rectangle in the X-Y plane. When loading a SEG-Y\\nfile, X-Y positions of all traces are read from file. If, for some reason, these are incorrect, the user\\ncan edit them here. If no horizon interpretation exists for the survey and if a Line detection\\nmethod other than Automatic is used, the geometry (lateral and vertical) can be edited if the\\nsurvey contains one single cube. If the x and y coordinates are wrong or non-existing, it is\\npossible to click on the Ignore SEG-Y coordinates and then specify three corner points in the\\nGeometry tab of the Settings of the imported seismic (see below).\\nHow to edit geometry\\n1. Go to the Settings for the imported seismic file and go to the Geometry tab.\\n2. Change either the x,y coordinates for the first inline and crossline points, or change the\\nintervals between the lines. As the coordinates are updated, the inline and crossline spacing\\nwill be updated. If the intervals are edited, the origin will stay fixed while the end points of\\nthe inline and crossline will be moved according to the changes in the intervals.\\n3. It is also possible to rotate the end of either an inline or crossline around its origin to make\\nit perpendicular to the crossing direction.\\n4. Click either the OK or the Apply button to see the updates (for example, in a map).\\n4.\\nSettings menu, Geometry tab for the seismic 3D volume.\\nAppending SEG-Y 2D lines'},\n",
       " {'header': 'CDP/SP ',\n",
       "  'content': 'For 2D seismic, there is also a CDP and Shotpoint numbering header field under the SEG-Y\\nimport dialog box.\\nSEG-Y import dialog box. SP/CDP.'},\n",
       " {'header': 'Data Preparation ',\n",
       "  'content': \"SEG-Y files are often very large - usually too large to load into the PC's RAM in their entirety.\\nNevertheless, in Petrel this is unnecessary as the data required for visualization or processing can\\nbe extracted directly from the file. Petrel offers some important methods of optimizing the data\\nfor specific tasks. These are:\\nCropping: for defining a virtual seismic volume that is a spatial subvolume of the original.\\nRealization: for making a physical representation (a file) of a virtual volume or for making\\na new physical representation optimized for certain usage.\\nPrefetch to cache: loading the entire seismic volume or a 2D line into (RAM) memory.\"},\n",
       " {'header': 'Cropping ',\n",
       "  'content': \"Cropping is the operation of cutting away parts of the volume, leaving a smaller volume that is\\nusually faster and more convenient to work with. Cropping can also be thought of as defining a\\nregion of interest (ROI). The cropping can be performed on both 3D and 2D seismic.\\nFig. 1 The Cropping tab in the Settings window.\\nCropping tab\\nThe inserted virtual cropped volume or virtual cropped 2D line is a virtual mapping of the original\\nseismic. The icon with the cropped seismic will be given a name based on the original grid\\nfollowed by (Crop). This name can be overwritten from the Info tab of the Settings window and\\nreset by stating a blank. The new data set can be cropped (reduced) to contain fewer lines or\\ntraces than the original.\\n3D seismic\\nIn Inline range and Crossline range, the range of data can be set: From: First line to include\\nin the subset. To: Last line to include in the subset. Skip: How many lines to skip.\\nIn Vertical range, the time range can be specified with a From and a To value. Time values\\ncannot be skipped.\\nHow to crop a seismic volume\\nThe cropping can be performed in two different ways through the Cropping tab:\\n1. Right-click on the icon for your seismic volume, and select Insert virtual cropped\\n1.\\nvolume from the menu. A new icon with the same name as the original followed by [Crop]\\n1 opens below your original icon (the number behind [Crop] denotes the sequence of\\ncropped volumes generated from the parent cube).\\n2. Open the Settings window for the cropped volume by double-clicking on its icon, and\\nselect the Cropping tab. See figure 1.\\n3. Select the inline and crossline ranges, as well as the time range that you want your new\\nsubvolume to cover. The Skip options can be used to create a subvolume that has only\\nevery second inline from the original, etc.\\n4. Alternatively, this can be done by dragging the corners of the cube manually:\\n5. Right-click on the icon for your seismic volume, and select Insert virtual cropped\\nvolume from the menu. A new icon with the same name as the original, followed by\\n[Crop] 1 appears below your original icon.\\n6. Display the cropped volume. Click on the Select/pick mode icon.\\n7. Click on one of the corner points of the cube and drag along one of the axes to move the\\nlimit. When resizing a virtual cropped volume, the amount of memory required to hold that\\nvolume is displayed in the seismic readout (lower right corner\\nof Petrel).\\n8. Using the Select/pick mode icon on the outlined walls of the cropped cube will move the\\nwhole cropped volume.\\nThe default name can be overwritten from the Info tab of the Settings window and reverted to\\nthe default by leaving the name field blank.\\n2D seismic\\nIn traces, CDP's or SP, the range of data can be set: From: First line to include in the subset.\\nTo: Last line to include in the subset. Skip trace: How many traces to skip between each trace\\nthat has been included in the subset.\\nIn Time, the time range can be specified with a from and a to value. Time values cannot be\\nskipped.\\nHow to crop a seismic 2D line\\nThe cropping can only be performed in the Cropping tab:\\n1. Right-click on the icon for your seismic 2D line, and select Insert Virtual Cropped 2D\\nline from the menu. A new icon with the same name as the original, followed by [Crop] 1,\\nopens below your original icon.\\n2. Double-click on the icon to open the settings window for the cropped 2D line, and select the\\nCropping tab. See figure 2.\\n3. Select the trace range that you would like your new 2D line to cover, CDP and SP\\nnumbering are updated accordingly. The Skip trace option can be used to create a cropped\\n2D line that only includes every second, third, etc., trace. Also, specify the vertical range\\nkeeping in mind that numbers below MSL are negative.\\n4. Click Apply to preview the result, or OK to perform the operation and close the settings\\nwindow.\\n4.\"},\n",
       " {'header': 'Fig. 2 ',\n",
       "  'content': 'The default name can be overwritten from the Info tab of the Settings window and reverted to\\nthe default by leaving the name field blank.\\nIf your 2D line consists of more than one line, you will have to crop each line separately.\\nNote that the cropped volume/line is not created as a physical file on your hard disk. Rather,\\nit provides a mapping to the original volume. To create a physical representation (i.e., a file) of a\\nvirtual volume, see Realization.'},\n",
       " {'header': 'Realization ',\n",
       "  'content': \"Realization is the process of creating a physical copy of any seismic volume or 2D line. The\\noriginal seismic can be an imported SEG-Y or ZGY file, a virtual file (for example, a cropped\\nvolume or a cropped 2D line) or even a previously realized volume or 2D line. The output from the\\nrealization process is seismic in ZGY format (3D) or a Petrel raw format (2D). Realization serves\\nthe following important purposes:\\nPurpose 1: Realization creates a physical\\nrepresentation\\nCropping (see Cropping) is a useful operation in itself, but creating a new physical representation\\nof this virtual region of interest can yield yet another performance boost.\\nA realized seismic file is created in ZGY format (3D volumes) or an internal Petrel raw format (2D\\nlines). Also, ZGY files can be imported into other Petrel projects or exported as SEG-Y or ZGY (see\\nSEG-Y and ZGY export).\\nSeismic files realized to ZGY format are noticeably faster in use compared to the original SEG-Y\\nfile.\\nRealization is also useful when you want to compute a complex attribute. Some attributes are\\nexpensive to compute (for example, structural smoothing and chaos). As long as only single\\nsections of a cube will be used, it is beneficial to keep the attribute as a virtual volume to save\\ndisk space. When the attributes are in virtual mode, the attributes displayed in a slice are\\ncalculated, on-the-fly, for each trace. Quick slicing and volume rendering are expensive:\\ntherefore, it is useful to create a physical representation to speed up the visualization. You decide\\nwhat is acceptable. Virtual attributes save disk space when they are calculated on, but the quality\\ncan suffer when you move the slices. Realized attributes utilize quick slicing and volume\\nrendering, but will create a new file in the project and will use more disk space.\\nPurpose 2: Realization can change value resolution\\nMany SEG-Y files use 32-bit floating-point format for the trace amplitude values. This kind of\\nresolution is often unnecessary and adds a certain overhead to all operations on the volume.\\nVolumes and 2D lines realized in Petrel can be given a value resolution of 16-bit or even 8-bit\\nintegers, yielding a gain in available storage space by 50 or 75 percent, respectively. Often, this\\nloss of resolution will not impose any noticeable loss of quality or perceptible information.\\nNote that the original value range is kept, for example, converting a floating point cube to 8-bit\\nwill retain the value range from the original cube, and not use the 8-bit value range (-128 to\\n+127).\\nPurpose 3: Realization changes the data format to\\nZGY bricked format\\nZGY format is a new brick representation of the seismic volume. Using the bricked format, the\\nseismic is stored in bricks of various resolutions (LODs, Level Of Detail) rather then the traditional\\ntrace format. When seismic is displayed, only the bricks needed are loaded into memory. Big\\nbricks with low resolution are loaded into memory first. The program will then start loading the\\nsmaller bricks with high resolution. The seismic appears to be of coarse resolution, but it will\\nrefine as the program is given time to load the smaller bricks into memory. The benefit is that\\nlarge seismic bricked data can be rendered in the 3D window, and user interactions are always\\navailable since the loading of the bricks is stopped if you move a seismic line. Another advantage\\nis that when you are working with very large seismic volumes, rather than reading and\\nattempting to display every seismic sample, only the required resolution of data will be read and\\ndisplayed. Access to ZGY data has been multi-threaded which means that every available CPU on\\nthe computer will be used to grab data as quickly as possible. Hence, the improved access speed\\nas opposed to large SEG-Y files.\\nThe ZGY file can be realized in 8-bit, 16-bit or 32- bit.\\nThe bricked format (ZGY) supports rapid intersection access and volume rendering of large data\\nfiles.\\nRealization guidelines\\nImportant guidelines for Realization\\nRealization is potentially a time-consuming process, and uses a lot of disk space.\\nIt is strongly recommended that your project is saved to a specific location before realizing\\nlarge seismic volumes. If not, the system's temporary directory (for example, C:\\\\TEMP) will\\nbe used for the generated volume file. Subsequently, when you finally do save your project,\\nthe entire realized volume will be moved to the project's location, which can be time-\\nconsuming if this location is on a different file system.\\nIt is strongly recommended that projects with realized volumes be saved to a local hard\\ndisk. Working with volumes is very I/O intensive, so your local area network might not be\\nable to provide the required throughput.\\nIt is strongly recommended that the disk used for realization be defragmented. If the\\nrealized file becomes heavily fragmented, this can severely impact processing and\\nvisualization performance.\\nWhen realizing to ZGY format it is critical to scale the data properly, especially when moving\\nfrom 32-bit SEG-Y to an 8-bit ZGY file. This is because many SEG-Y files contain spikes or\\nerroneous data that, when scaled, will make the data look washed out.\\nFig. 1 The Realize subtab under the Operations tab in the Settings dialog of the seismic\\nvolume.\\nUnder the Operations tab for seismic data, in the Realize subtab, the amplitude range for the\\nrealized seismic data is specified by the user as defined by the Set from source..../User\\ndefined buttons. The Source amplitude range values specifies the range of values currently\\ndefined. A ~ (tilde) in front of the values means that the range is estimated and clicking the Scan\\nbutton will calculate the entire value range. If you select User defined, the value range can be\\nset when realizing the data (that is, clipping seismic), but the Source amplitude range is\\nunaltered. In the Amplitude subtab, you can manually set the value range but that will also\\nchange the Source amplitude range. If this is not wanted, click on the Rescan button and the\\nfull value range is recalculated.\\nIn addition, in the Realize subtab, there is a Zero centric option that ensures that if data is\\nrealized to a lower resolution (8- or 16-bit), the readout of the original amplitude 0.000000 in the\\n32-bit float seismic will stay 0.000000 when realized to 8- or 16-bit data. To get a correct\\nscale/offset value, the minimum amplitude value has to increase to some extent if min/max is not\\nalready a module of the 8- or 16-bit limits.\\nFurther down on the Realize subtab, there is now a histogram display. This histogram can be\\nused to QC data before realization. Note that any changes to the histogram display will not affect\\nthe data, only the displayed histogram. ONLY through/after the Realization process are any\\nchanges applied to the data. The histogram tool has a filter option that excludes the maximum\\nspike in the histogram (for conventional seismic this means crossover (null) values). The\\nhistogram tool also includes the ability to send histogram information to the Petrel message log\\nthat details exactly what data range will be stored in which bin. The message log content can be\\ncopied and pasted into other applications as needed.\\nRealize a 3D seismic volume\\nHow to realize a seismic 3D volume\\n1. Open the Settings dialog from the imported seismic cube and go to the Realize subtab\\nunder the Operations tab.\\n2. Choose to scan the dataset for QC (creates a histogram representation of the amplitude\\ndistribution) and to obtain exact amplitude ranges by selecting one of the available\\nmethods and click the Scan button.\\n3. Alternatively, set the precise amplitude range under the Amplitude tab.\\n4. Select the desired Realization quality and select the proper Output file name.\\n5. Clear the Use default check box to drop in an existing vintage (must be a vintage not\\nalready used by the survey) or leave it selected to create a new vintage.\\n6. Click on Realize (a new seismic icon will then appear in the Petrel Explorer pane containing\\nthe realized volume). It is stored in the ZGY (bricked) format.\\n7. Close the Settings window.\\n6.\\n7.\\nFig. 1 The new and realized ZGY file generated is stored on the disk, and can be shared with\\nother projects by using the import option in Petrel.\\nRealize a 2D seismic line\\nHow to create a realized 2D line\\n1. Open the Settings dialog of the imported 2D seismic line or the cropped 2D seismic line\\nand go to the realization submenu under the Operations tab.\\n2. Select the Realization quality, Output file name and exact amplitude range as we did for\\na 3D volume. Realize a 3D seismic volume\\n3. Leave the check box Use default selected to create a new vintage or clear itt and select an\\nexisting vintage from the Vintage folder.\\n4. Click on Realize (a new seismic icon will then open in the Petrel Explorer pane). It is stored\\nin an internal Petrel RAW format.\\n5. Close the Settings window.\\n5.\\nFig. 1 The Realize subtab under the Operations tab in the Settings dialog of the seismic line.\\nPrefetch to Cache\\nInteractively browsing through huge seismic cubes and 2D lines in an exploration scenario\\nrequires quick access to the data. Data read speed from disk can reach 100 MB per second.\\nHowever, in some cases this is not sufficient. With the emerging 64-bit operating systems, it is\\npossible to store data in RAM - Petrel includes an option to prefetch seismic data to cache.\\nSeismic volumes with a size that can reside in the computers memory is possible to Prefetch to\\ncache (independent of operating system, that is, 32-/64-bit). Both SEG-Y and ZGY volumes or\\n2D lines have this option that loads the entire seismic data into memory. This operation will run\\nas a multi-threaded asynchronous task. For users familiar with pre-Petrel 2007 releases, this\\noption is similar to the old Load into memory option.\\nHow to prefetch to cache a seismic data\\nRight-click on a seismic data object; 3D volume or 2D line, either a SEG-Y or ZGY cube, and\\nselect Prefetch to cache from the drop-down menu.\\nDepending on the format of the seismic cube (SEG-Y or ZGY) that is prefetched to cache,\\nthe following will happen:\\nSEG-Y: The task manager opens up (if not already open) below the graphic display area of\\nPetrel and a counter updates until it reaches 100 %. At this point the volume is successfully\\nloaded into cache.\\nZGY: The Petrel message log pops up and reports the Levels of detail (LOD) that is\\nprefetched to cache. When Level 0 (highest level of detail) is completed, the volume is\\nsuccessfully loaded into cache.\\nIf the seismic volume is too large to fit into the cache of your computer, an error message opens\\nup.\\nThe seismic cache size for Petrel can be changed in the System settings, Seismic tab.\\nAlternatively, you can crop down the seismic volume before you try to Prefetch to cache again.\"},\n",
       " {'header': 'Seismic Server Introduction ',\n",
       "  'content': \"The seismic server provides scalability for seismic operations through the access to large amounts\\nof memory (RAM) and great computing powers through a Linux cluster. The benefit of having\\naccess to a seismic server is most significant when you are working with large seismic data sets\\n(20 Gbytes+). The server works as a large shared seismic data storage, where resource\\ndemanding attribute computations can be performed in the background. The seismic server only\\nworks on 3D seismic. Note that some volume attributes are not supported for running on the\\nseismic server. This includes general depth conversion, graphic equalizer, neural net, relative\\nacoustic impedance and velocity cube (see also Attributes available in Petrel (alphabetically)). In\\naddition, the seismic calculator is not available on the server; it will become a local calculator that\\nis dependent upon network access.\\nPSS 2010 is only supported on RedHat 5.3 or CentOS 5.3. So you will need to upgrade your\\nclusters. The PSS will not work on RedHat/CentOS 4.x. As for the 5.x series, it has only been\\ntested on 5.3.\\nPSS 2010 requires a different version of the Intel MPI runtime (3.2.2.006), so you will need to\\ninstall this\\nHow to set up and configure a seismic server (Linux cluster)\\nSetting up and configuring a Linux cluster is typically a system administrators job. The\\nprocedures for this are further described in the documentation found on the Petrel installer CD.\\nThe PSS installer is now command line based instead of using a GUI. This makes it much simpler\\nto install the server on clusters because you don't need a graphical login screen. I.e. you don't\\nneed X running on the cluster.\\n1. From the main toolbar, select View from the Menu bar, Main project and Seismic Server\\nexplorer. This will open the Seismic Server Explorer window at the bottom of the Petrel\\nwindow.\\n2. Click on Connect...,\\n3. You can either give the host name of the cluster or IP address. Type in port, user name and\\npassword.\\n4. It is also possible to have a list of Seismic Servers in the pull-down menu configured (see\\nHow to configure a list of seismic servers).\\n5. Once connected, the server name and projects that you have access to will be listed.\\n6. The current load on the server is shown as percentages and is also indicated by the color of\\nthe disk icon. Available space shows how much available disk space there is for you on the\\nserver. It also shows how many clients are connected to the server.\\nUser access is controlled from the separate Seismic Server Administrator application.\\nGreyed out projects are not loaded into memory on the server and are, thus, unavailable. The\\nprojects can be reloaded using the Seismic Server Administrator.\\nOnly seismic cubes are stored on the server. The small s annotated to the object tells that it\\nis a server object. The pre-Petrel 2010.1 possibility to interpret and store interpretation grids on\\nthe seismic server is removed.\\nHow to configure a list of seismic servers\\n1. Find the petrel.exe.config file on disk (located in the same directory as the petrel\\n2.\\n3.\\n1.\\nexecutable).\\n2. Make a copy of it.\\n3. Edit the following section in the file where you add server name or ip address and the port\\nto connect to the server. Example marked in bold below for clarity.\\n-----------------------------snip--------------------------------\\n<!-- The following section defines information needed to identify and connect to SeismicServer\\nclusters-->\\n<SeismicServerConfigSettings>\"},\n",
       " {'header': '<Servers> ',\n",
       "  'content': '<!-Examples of SeismicServer identification (host and port are mandatory attributes): <Server\\nhost=\"seismicserverhostname\" port=\"4445\" defaultuser=\"gigaviz\" defaultpwd=\"somepwd\" /-->\\n<Server host=\"TheFastSeismicServer\" port=\"4445\" />\\n<Server host=\"TheEvenFasterSeismicServer\" port=\"4446\" />'},\n",
       " {'header': '</Servers> ',\n",
       "  'content': '</SesimicServerConfigSettings>\\n-----------------------------snip--------------------------------\\n1. Save the file and restart Petrel.\\n2. A list of servers will now be available from the Seismic server pull-down menu in the\\nConnect to a seismic server dialog.\\nIf Petrel does not start, you have made a syntax error in the file you edited. Correct it and\\nrestart Petrel. If you still get an error, please revert to the original file you copied at the beginning\\nof the project.\\nHow to access data on server from Petrel\\n1. In the Seismic Server explorer, expand the project, expand the Seismic Volumes folder,\\nright-click on the seismic volume and select Copy.\\n2. In the Petrel Input pane, right-click and select Paste link to seismic server data. This\\nwill create a link between the Petrel project and the server project. In the data tree, the\\nseismic volume will be denoted with a small \"s\". That tells you that the volume resides on\\nthe server.\\n3. When a seismic section is turned on in the 3D window, the seismic image will gradually be\\nbuilt up from a low level of detail to a full level of detail. The speed of this process is\\ndependent upon data size and network performance.\\n4. The links between data objects in Petrel and the server need to be reestablished by\\nconnecting to the server if you exit Petrel.\\n5. Seismic server volumes can be cropped, realized and saved in Petrel in the same way as\\nnon-server volumes. Cropped volumes are attached to the mother cube, and are shown as\\nan object in the Petrel Input pane and not on the Seismic Server explorer. Volume\\nattributes of the cropped cubes are stored on the server. Realized volumes are not stored\\non the seismic server.\\nHow to upgrade to 2010.1\\nIf you already had the Petrel 2009.2 Seismic server, you need to do the following to upgrade the\\nserver:\\n1.\\n1. Copy the horizon which are on the Petrel seismic server 2009.2 to a local Petrel project\\n(2009.2) and save the project.\\n2. Make a backup of the Petrel Seismic Server project (can take a copy of the Linux project\\ndirectory).\\n3. Upgrade to a Linux 5.3 and install in all nodes IMPI.\\n4. Upgrade the server to PSS2010.\\n5. Copy the vvuseracl.lst from PSS2009.2 to PSS2010.\\n6. Start the server.\\n7. Open Petrel 2010 and open the project which was saved in step 2.\\n8. Connect to the server and reload the Seismic Server projects.'},\n",
       " {'header': 'Survey Manager ',\n",
       "  'content': 'This section covers how to use the Survey manager to visualize and administrate multiple 2D\\nseismic lines and 3D surveys.\\nYou can open the Survey manager in Petrel by right-clicking on the main Seismi c folder (top\\nfolder), or by right-clicking directly on the survey folders (either 2D or 3D survey folders) and\\nselecting Survey manager . The Survey manager is a tool used for filtering, sorting, realizing\\nand otherwise managing the seismic data in Petrel. For 2D lines you can control parameters, like\\nCDPs, SPs, Trace number, Templates, Vintages and sorting and moving of data into folders,etc.\\nThe Survey manager also allows you to time shift, amplitude scan and change vintage on\\nselected data. The Survey manager can also be used to toggle visualizations on/off for any\\ndesired data.\\nSettings for the Survey Manager\\nSorting is done by double-clicking on the column name. Columns can be made wider or narrower\\nby simply dragging the column boundaries. Clicking on the top left corner of the spreadsheet will\\nselect data for the possibility of copying the entire spreadsheet. Selecting seismic in the\\nspreadsheet is done by clicking in the first column of the spreadsheet (with index numbers) or by\\nclicking and dragging over selected datasets.\\nInformation in the Survey Manager\\nData in the survey manager\\nVisible turns on and off seismic in the active window.\\nName lists the name of the seismic file. The name can be edited.\\nSurvey lists the name of the survey folder in which the seismic data is placed.\\nVintage lists the name of the vintage/version the seismic data belongs to.\\nSubfolder lists the subfolder the seismic is stored in.\\nDomain lists the domain of the seismic file (time or depth, etc).\\nType lists the type of the file (2D or 3D).\\nTemplate lists the color table attached to the seismic data.\\nDirection lists the main direction of the 2D line (not valid for 3D cubes). Direction is calculated\\nbased on the position of the first and last trace in a line. If it is a multi-line, the direction is taken\\nfrom the first line.\\n#Lines lists the number of lines in the seismic file.\\n#Traces lists the number of traces in the seismic file.\\n#Samples lists the number of samples in the seismic file.\\nSample interval lists the sample interval for the seismic file.\\nFirst SP lists the first shot point in the seismic file.\\nLast SP lists the last shot point in the seismic file.\\nFirst CDP lists the first common depth point in the seismic file.\\nLast CDP lists the last common depth point number in the seismic file.\\nX Min lists the minimum x coordinate.\\nX Max lists the maximum x coordinate.\\nY Min lists the minimum y coordinate.\\nY Max lists the maximum y coordinate.\\nZ Min lists the minimum z coordinate.\\nZ Max lists the maximum z coordinate.\\nFormat lists the volume value format (Floating point, Integer, etc).\\nFile size lists the size of the files in bytes.\\nStorage lists OK if the link to the original file is valid. If the storage is bad, then double-click on\\nthe specific file in the Survey manager or in the Input Data to open settings to reestablish the\\nlink to the original data.\\nNote that the #Lines, #Traces, SP and CDP can be changed in SEG-Y settings.\\nMin amplitude lists the minimum real amplitude of the seismic data (Reports Undef until needed\\nfor the first time, typically when displayed).\\nMax amplitude lists the maximum real amplitude of the seismic data (Reports Undef until\\nneeded for the first time, typically when displayed) .\\nStorage type lists the file format or server (SEG-Y, ZGY, Internal Petrel format (if imported from\\nprevious versions) etc). This parameter also contains information about whether the seismic\\nvolume is virtual or not.\\nFile path this parameter lists the full path to where the seismic is stored on disk.\\nAttribute lists the attribute of the seismic data.\\nTemplate lock lists the type of template lock (Global, Standalone or Survey/Vintage) used for\\nthe seismic data.\\nSeismic Line identifier used to distinguish lines that are vintages of each other. In this case the\\nseismic line identifier is identical.\\nGeometry line identifier can be used to show lines sharing geometry.\\nOpen and sort the data in the Survey manager\\nOpen the Survey manager by right-clicking on the Seismic main folder (top folder), or by right-\\nclicking directly on the survey folders (either 2D or 3D survey folders) and selecting Survey\\nmanager.\\nHow to select/deselect columns displayed in the Survey manager\\n1. Click on the select columns icon in the Survey manager.\\n2. In Column selection dialog box, select which columns to display (green checkmark) and\\nnot to display (no checkmark).\\n1.\\n2.\\n3. The order of columns can be reorganized by selecting an entry and clicking the up and\\ndown arrows .\\n4. The Set all columns visible and Set all columns invisible buttons make selection\\neasier. The Reset column settings to default button sets the displayed columns and\\ntheir order back to default.\\nVisualizing and moving seismic data from the'},\n",
       " {'header': 'Survey Manager ',\n",
       "  'content': 'How to visualize seismic data using the Survey Manager\\nSeismic data can also be toggled and visualized from the Survey manager. The sorting\\nmechanisms in the Survey Manager can make it easier to find the relative data and visualize\\nthem.\\n1. Toggle on view of selected seismic icon is used to visualize the selected seismic data\\nin the active window. Keep in mind that visualizing a large number of 2D lines in the 3D\\nwindow can stress the graphic card.\\n2. Toggle off view of selected seismic icon will remove the visualization of the selected\\nseismic files in the active window.\\n3. Toggle (invert) view of selected seismic icon will invert the view for the selected\\nseismic data.\\nHow to move seismic data into folders\\nSubfolders in the survey folders can be created by right-clicking on the survey folder and selecting\\nInsert new folder. Seismic data from the input data can be dragged and dropped into the\\nfolders.\\nThe data can also be moved into folders in the survey manager.\\n1. Open the Survey manager. Make a selection of seismic data. Click on the Move selected\\nseismic to another subfolder icon on top of the survey manager spreadsheet.\\n2. A new window will appear where you can select a folder to move the data into.\\n3. If no subfolder exists, there is an option to create a new sub folder from this window.\\nHow to find and remove erroneous data\\nThe Survey manager is an excellent tool for finding incorrect coordinates in the imported files.\\nOnce identified, the data can easily be cropped out using the cropping feature, and a new\\nrealization can be created without the erroneous points created.\\n1. In the Survey manager, locate the incorrect coordinates for the file. For example, in many\\ncases the 2D line consists of two or multiple portions, which can be validated in the #Lines\\ncolumn and the incorrect coordinates for XMin and YMin, which will then be 0,0. When this\\nline is displayed in a 3D window and the user selects a tool to view all, the canvas will\\ndisplay all the coordinates associated with the file and this result in a view of a very large\\narea. The seismic data will only be shown as a small dot in the 3D window.\\n2. To remove the wrong coordinates, create a new cropped 2D line and open the cropping tab,\\nas described under the cropping section.\\n3. Use the cropping option to crop out the erroneous coordinates, by removing the unwanted\\ntraces. The incorrect coordinates are removed in the virtual cropped 2D line.\\n4. To create a new representation of the line, select to realize the cropped line or export it as'},\n",
       " {'header': 'SEG-Y. ',\n",
       "  'content': 'Search for seismic data in the Survey Manager\\n1. Click on the search tool Search in survey manager , this will open up the search\\nengine.\\n2. The complete name or parts of a name can be entered in the Find next or Select all field.\\n3. If none of the options on the left is toggled, the search engine will search for words\\ncontaining the specifications in the field. The search will start from the top of the survey\\nmanager.\\n4. When match case is selected, the search engine takes into account both lower and\\nuppercase letters and will try to match the names in the list.\\n5. Match whole name will search for the full name of the file.\\n6. When both Match case and Match whole name are selected, the name being searched\\nfor must be matched 100%.\\n7. Search up, will start the search from the bottom of the listed names in the server manager\\nand search upwards. If search up is not toggled, the search engine will start from the top of\\nthe survey manager.\\n8. Find next will highlight the next name in the survey manager list that fits the search\\ncriteria.\\n9. Select all will select all names in the survey manager that fit the search criteria.\\n10. Close will close the window.\\nNote that the search will only be valid for the items visualized in the Survey Manager. If the\\ncontent filter is applied, only the seismic data within the spreadsheet will be part of the search.\\nHow to select data in the Survey manager\\nSelection of data is used in the following operations within the Survey manager: display, delete,\\nmove to folder, scan amplitude, set vintage, and set new template.\\nThere are several ways to select data for these tasks:\\nTo select only one seismic data file, click on the corresponding row/line in the survey\\nmanager, the row will be marked light grey.\\nTo select several seismic files at once; select one line + press Shift, then select another\\nline. All seismic data between the selections will be highlighted.\\nTo select specific files; select one line + press Ctrl, then select another line. Both the\\nselections will be highlighted.\\nClick on one of the header columns to select all files.\\nHow to filter items in the Survey manager\\nIn projects with large amounts of seismic data (a long list of seismic objects in the survey\\nmanager), finding and retrieving subsets of the data can be time consuming. The best way to sort\\nout this issue is to use the available content filter.\\nIt is possible to filter on survey, survey subfolders, vintage or a combination of these.\\n1. Open the content filter in the Survey manager.\\n2. Select items to filter on.\\n3. Select appropriate surveys, survey subfolders and vintages from the pull-down menus.\\n1.\\n2.\\n3.\\nRealize seismic data in the Survey Manager\\n1. Select the seismic to be realized in the Survey manager.\\n2. Click on the Realize icon.\\n3. In the Realize selected seismic dialog box, enter the desired parameters for the\\nrealization process and click OK. Petrel will realize the selection into the specified folder.\\nNote: When realizing 3D seismic, the default settings will be used for realization.\\nHow to visualize seismic data using the Survey manager\\nSeismic data can also be toggled on/off and visualized from the Survey manager. The sorting\\nmechanisms in the Survey manager can make it easier to find the relative data and visualize\\nthem.\\n1. Toggle on view of selected seismic icon is used to visualize the selected seismic data\\nin the active window. Keep in mind that visualizing a large number of 2D lines in the 3D\\nwindow can stress the graphic card.\\n2. Toggle off view of selected seismic icon will remove the visualization of the selected\\nseismic files in the active window.\\n3. Toggle (invert) view of selected seismic icon will invert the view for the selected\\nseismic data.\\nRename seismic data in the Survey Manager\\nThe name of the seismic file can be changed in the settings window (Info tab) for the file or\\nsimply by clicking on the name and typing the new name in the \"Seismic\" column in the Survey'},\n",
       " {'header': 'Manager. ',\n",
       "  'content': 'How to change multiple names of seismic data using the Survey\\nManager/Excel spreadsheet\\nA typical problem while loading 2D seismic data is that the line names do not match. If you have\\nseveral hundred or maybe thousands of lines in a survey, it can be very tedious to manually\\nrename all of the lines. The following workflow uses \"Find and Replace\" in Microsoft Excel to do\\nthe job.\\n1. Open the Survey Manager on the survey that contains the lines to be renamed.\\n2. Select all the line names in the \"Seismic\" column. Left-click and drag over the selection or\\nleft-click on the \"Seismic\" header.\\n3. Use Ctrl+c to copy the selected line names.\\n4. Open Miscrosoft Excel and paste the line names into a column (Ctrl+v).\\n5. Go to Edit in the menu bar and select Replace from the menu that opens. To change the\\nline names, for example, to remove \" [Realized]\" from lines names, enter \" [Realized]\" into\\nthe \"Find what\" field and nothing into the \"Replace with\" field.\\n6. When you are satisfied with the new line names, select all of them. Be sure to select only\\nthe Excel cells that contain the line names.\\n7. Copy them from Excel using Ctrl+c.\\n8. Select the cell in the Survey Manager that contains the first line name that should be\\nrenamed, use Ctrl+v to paste in the new line names.\\n9. Press Apply in the Survey Manager and you will see that the names are updated in the\\nPetrel input tree.\\nNote that you can use a text editor instead of Excel. For example, if you have an editor that\\nworks with columns (like UltraEdit), it can make the edits easier.\\nIcons for the survey manager\\nShow settings dialog for selected seismic icon will open the settings for the selected\\nseismic. The settings for a seismic line or volume can also be opened by double-clicking on the\\nindex number (the first column in the spreadsheet).\\nSearch for seismic in the survey manager will open the search engine for the survey\\nmanager.\\nTurn on the selected seismic in the current window icon is used to visualize the selected\\nseismic data in the active window.\\nTurn off the selected seismic in the current window icon will remove the visualization of\\nthe selected seismic data in the active window.\\nToggle visible of the selected seismic in the current window icon will invert the\\nvisualization of the selected seismic data in the active window.\\nDelete the selected seismic icon will delete the selected seismic from the project.\\nFilter content in spreadsheet on survey, sub-folder and vintage icon will open up a\\nfilter selection box.\\nClear filter setting icon will clear any filter setting used in the spreadsheet.\\nMove selected seismic to another sub-folder icon will move the selection of seismic data\\nto another user specified sub-folder.\\nRealize selected seismic icon will open up the Realize selected seismic dialog box.\\nVertical shift selected seismic icon will vertically shift the selection either to or with the\\nuser defined value.\\nSet vintage on selected seismic icon will open up the Select vintage dialog box. The user\\ncan also create a new vintage for the selected data.\\nSet template (color table) on selected seismic icon will open up the Set template dialog\\nbox. The user can select a new template for the seismic from a full pull down list.\\nScan or set min and max amplitude on selected seismic icon will open up the Set\\namplitude on selected seismic dialog box. The user can also create a new vintage for the selected\\ndata.\\nVertically crop and decimate traces of selected 2D seismic icon will open a menu where\\nthe selected seismic 2D lines can be cropped.\\nSelect Columns to display in Survey manager icon will open a menu that will aid in\\nselecting which columns to display in the spreadsheet.\\nSEG-Y Data Export\\nSeismic 3D cubes, seismic 2D lines, seismic intersections, individual inline/xline/random from a\\n3D cube, and composite lines can be exported in the standard SEG Rev1 SEG-Y format. In\\naddition, 3D cubes can be exported in ZGY format.\\nHere are the default byte locations used by Petrel (this is written into the SEGY header when\\nexporting from Petrel):\\nBinary header locations:\\nThe following are the exported byte positions for SEG-Y from Petrel:\\n17-18 (dt) sample interval in microseconds\\n21-22 (ns) number of samples per trace\\n25-26 () trace date format\\nTrace header locations\\n5-8 (tracr) integer inline number for 3D volumes\\n17-208 (SP) SP number\\n21-24 (cdp) integer cdp/crossline number\\n73-76 (sx) X coordinate\\n77-80 (sy) Y coordinate\\n105-106 (ms) trace start time depth\\n115-116 (ns) number of samples per trace\\n117-118 (dt) sample interval in microseconds\\nNote: If the exported volume is cropped, you might have to adjust the start time for the cube\\nwhen you re-import the volume.\\nHow to export seismic in SEG-Y format\\n1. Find the seismic cube or 2D line you want to export on the Input pane.\\n2. Right-click on the seismic file and select Export from the menu.\\n3. Use the browser to locate the directory where the seismic will stored and give the SEG-Y\\nfile a name.\\n4. Select SEG-Y Seismic Format (*.*) as file type.'},\n",
       " {'header': '5. Click Save. ',\n",
       "  'content': '6. In the SEG-Y Export dialog, select Coordinate scale factor and Sample value format\\nand click OK.\\nZGY Data Export\\nSeismic 3D cubes can be exported in ZGY format.\\nNote: Only seismic cubes can be exported in ZGY format.\\nHow to export a seismic cube in ZGY format\\n1. Find the seismic cube you want to export on the Input pane.\\n2. Right-click on the seismic file and select Export from the menu.\\n3. Use the browser to locate the directory where the seismic should be stored and enter a file\\nname.\\n4. Select Seismic data in ZGY bricked format (*.zgy) from the Save as type pull-down menu.'},\n",
       " {'header': '5. Click Save. ',\n",
       "  'content': '6. In the ZGY Export window, specify how to set the amplitude range and realization quality.\\n7. Use the default vintage or select an existing one if needed.\\n8. Click OK to store the seismic volume.\\nFig. 1 The ZGY Export dialog for seismic 3D volumes.\\nDisplay of Seismic Data\\nAfter you have imported the seismic data, it is easy to display; either as a cube or through\\nintersections. For volumes, the classic seismic sections are inline, crossline, timeslices, and\\nrandomline. In addition, Petrel allows specific seismic sections to be extracted along any given\\npolygon or along any well path. Volumes can also be rendered using filters for extracting the\\npreferred attribute values. This makes a very good visualization tool, as you can play with the\\ntransparency effects and search for objects of interest with known attribute values.\\nThere are two settings in particular in Petrel which allow you to optimize the way the data is\\ndisplayed, depending on the task at hand. The data can be stored in a bricked format called ZGY\\nfor speedy 3D rendering (See Realization), and it can be cropped so that only the area of interest\\nis displayed (see Cropping).\\nVolume Visualization in 3D\\nVolume rendering is controlled from the Settings window of any seismic ZGY format volume (not\\nSEG-Y). This is done by defining the settings in the Style - ZGY style sub-tab, and by setting the\\nopacity curve of the Colors tab. For details about the settings window in general, see Seismic\\nData (Settings), where the settings window is described in its entirety.\\nTo open the settings window for the seismic volume, right-click on the seismic ZGY volume and\\nselect Settings.\\nThe Style tab contains a sub-tab called Volume visualization, which contains the settings\\ndescribing what is to be displayed, that is; Volume walls and Volume render. The color filter\\nused for extracting the preferred amplitude values can be edited under the Colors tab.\\nNote: When looking at 3D volumes, it is often useful to select/deselect the Orthogonal\\non/off icon. If this is on, and you zoom out slightly and then deselect the orthogonal view, the\\nbox will have increased the perspective. The further you move the seismic cube away before\\ndeselecting the orthogonal view, the greater this effect will be.'},\n",
       " {'header': 'Volume Walls ',\n",
       "  'content': 'The walls of a ZGY seismic volume can be visualized explicitly. This makes it easy to construct\\nvirtually any seismic cube.\\nThere are two options for the Volume walls settings: Normal and Inside .\\nFig. 1 The Volume visualization on the Style tab of the Settings window for a seismic volume.\\nWhen walls are showing, you have the option of Enabling transparency for walls . If this\\ncheck box is not selected, the walls will always be visible with no transparency. If you want to\\ndisplay the walls with the same level of transparency as that described under the Colors tab,\\nselect the Enabling transparency for walls check box.'},\n",
       " {'header': 'Volume Walls-Normal ',\n",
       "  'content': 'The visible sides of a seismic ZGY volume will be visualized and the volume will appear as a box.'},\n",
       " {'header': 'Volume Walls-Inside ',\n",
       "  'content': 'The view will be like looking inside a box, with the outer sides stripped off. This option displays\\nonly the distal walls and will not show any objects hidden inside the box. This can, for instance, be\\ncombined with volume rendering.\\nA Seismic volume shown with Normal Volume Walls. -----------------------------------------------\\n-------- A Seismic volume shown with Inside Volume Walls.\\nDisplay several volumes\\nIf you only display one seismic volume, it should either be displayed as normal or inside.\\nWhen visualizing two different seismic volumes, the following combinations will be valid:\\nNormal + Normal will show both volumes as two boxes. See figure 1 below.\\nNormal + Inside will show one of the volumes as a box (normal) and the other one will\\nonly have displayed the distal walls (that is, the facing wall will not be showing). See figure\\n2 below.\\nInside + Inside will only show the distal walls of both seismic volumes. You can view both\\nvolumes from the inside. See figure 3 below.\\nFigure 1 shows the combination Normal + Normal, that is, two partly overlapping cubes displayed\\nwith normal walls.\\nFigure 2 shows the combination Normal + Inside: The black & white cube is displayed with\\nnormal walls while the red-white-blue cube is displayed with inside walls.\\nFigure 3 shows the combination Inside + Inside. Two cubes displayed with three walls each, that\\nis, the two distal walls and the bottom.\\nHow to display several seismic volume cubes together\\n1. Create several cropped volumes that overlap each other.\\n2. Open the Style tab under the Settings window and select Volume Walls and Normal or\\nInside for each cube depending on the desired result.\\n3. Also, there is an Enable transparency for walls option that will allow you to make sides\\nof the cubes transparent for better display.\\nVisualize seismic annotation\\nAnnotation of seismic lines in a 3D window is controlled from the seismic cube settings under the\\nStyle tab. Multiple intersections can be annotated at the same time. The annotation is not\\ndependent on having the seismic interpretation process active.'},\n",
       " {'header': 'Volume Rendering ',\n",
       "  'content': 'The Volume rendering process is, unlike volume walls, a display of all data within a seismic\\nvolume at the same time. By rendering a seismic volume, making it partly opaque (high\\namplitudes) and partly transparent (crossover amplitudes), you can identify hidden structural or\\ndepositional features. Only seismic in ZGY format can be volume rendered, implying that input\\nSEG-Y volumes must be realized to ZGY format before the data can be volume rendered. The\\nseismic volume can also be cropped down prior to realization to focus on more local (smaller)\\nfeatures. See Cropping for details about cropping a volume and Realization for converting your\\nseismic to ZGY format.\\nCheck the Volume render checkbox to turn on the volume rendering feature.\\nPetrel geobody interpretation provides another method of visualizing objects within a seismic\\ncube.\\nThe bricked ZGY format allows you to volume render large seismic cubes.\\nHow to use the Inside display of walls in combination with volume\\nrendering\\n1. Visualize the outline of a seismic (cropped) ZGY volume.\\n2. Open the Settings window for the seismic volume by right-clicking on it.\\n3. Enter the Style tab and the Volume visualization subtab.\\n4. Turn on Volume walls , then Inside and make sure the Enable transparency for walls\\nis not checked. This will show only the side walls of the cube, seen from inside.\\n5. Left-click on the seismic volume in the Input pane, press Ctrl+C and then Ctrl+V. This\\nproduces a copy of the original volume.\\n6. Open settings for the copy of ... volume. Go to the Style tab, Volume visualization\\nsubtab.\\n7. Click off Volume walls and on the Volume render checkbox.\\n8. Enter the Colors tab .\\n9. Play with the opacity curve to filter out preferred attribute values for the 3D volume. As\\nlong as the Enable transparency for walls is not checked, the walls will be showing.\\nHide frame/annotations in viewing mode gives you the choice between showing the frame or\\nannotations.\\nBy clicking on a cropped volume with the select/pick mode arrow, the entire cropped volume\\ncan be moved.\\nFigure showing the Volume rendering of a seismic volume in combination with the use of the\\nVolume walls Inside option. Only values with high attribute values are displayed in the volume\\ncube while all attribute values are displayed on the walls.\\nDisplay of 3D Seismic\\nFor volume visualization of 3D seismic, please see Volume Visualization in 3D. This chapter\\ndiscusses display in 3D with the help of various types of intersections.'},\n",
       " {'header': 'Seismic Intersections ',\n",
       "  'content': 'There are a number of different intersections that can be used to display seismic data. These are\\nessentially based on the standard intersections in Petrel (see General Intersection for more\\ninformation), and can be used to display virtually any data, not just seismic. Similarly, any\\ngeneral intersection can be used to display seismic and much of the functionality described here is\\napplicable to general intersections. These intersections differ from a general intersection because\\nthey are aligned along the seismic lines so that the data can be optimized for rapid redrawing.\\nThe different options are:\\nInlines, Crosslines and Timeslices: These are intersections aligned to one of the three\\nprincipal directions in the seismic data and cannot be rotated. They can, however, be\\noptimized for rapid redrawing, etc.\\nRandom lines (General intersections): Intersections that can be orientated in any\\ndirection using the Manipulate Plane icon and pressing Shift. (Includes tilting of the\\nplane when making sure there is no alignment restriction set in the player).\\nVertical intersection: A vertical intersection generated from a drawn polygon. Moving the\\npolygon will move the intersection. Nevertheless, this process is much slower than with\\ninlines crosslines and timeslices.\\nVertical Well Path or Sections: A vertical intersection plane generated from a well or well\\nsection can be used to display seismic. This section cannot be moved in any direction.\\nArbitrary polyline intersections: A vertically and arbitrary aligned intersection where\\ndirections are guided by the use of polygons drawn on a timeslice.\\nSeismic aligned polyline intersections: A vertically and inline/crossline aligned\\nintersection where directions are guided by the use of polygons and inline/crossline\\ndirections (drawn on a timeslice).\\nSeismic composite lines: Lines composed of multiple 2D or 3D lines or combinations of\\n2D and 3D (see Seismic Composite Lines).\\nHow to play through multiple intersections\\nIf more than one seismic intersection has been inserted from any seismic cube, the player can be\\nused to play through all lines in the file.\\nHow to generate and visualize a Seismic intersection plane\\n1. Open a 3D window\\n2. From your seismic volume, right-click and select Insert seismic intersection.\\n3. Use the Tool bar to align the plane (one option).\\n4. Or click on the Manipulate plane icon to be able to move the intersection freely.\\n5. Move the cursor in one direction (forward/backward).\\n6. By pressing the SHIFT + left mouse button, you will be able to rotate the seismic line.\\n7. By pressing the SHIFT + left mouse button and making sure there is no alignment\\nrestriction toggled in the player, (like shown here: ) you can tilt the seismic\\n6.\\n7.\\nline.\\nAn alternative way of selecting a certain seismic line is to use the function, Snap intersection\\nplane, to one, two, or three points. These functions are shown on the right-hand side in the\\nFunction bar above.\\nHow to snap manually inline, crossline or time slice to a specific point, well\\nor well top\\n1. Display the seismic cube together with a seismic intersection.\\n2. Select the icon Snap Intersection plane to 1 point .\\n3. Move the pointer over the top of the cube (note the dotted line shown for each\\ninline/crossline) and click where you want the intersection to snap.\\nHow to visualize time slices\\n1. From the Input Petrel Explorer, right-click on the seismic data icon.\\n2. From the pull-down menu, select Insert time slice intersection.\\nHow to assign mnemonics to seismic intersections\\n1. From the Input pane, right-click on a seismic intersection.\\n2. From the menu that opens, select Assign mnemonic, this adds a shortcut key to the\\nselection (e.g., A: in front of the intersection name).\\n3. Redo the same steps for all wanted intersections.\\n4. Pressing the assigned letter on the keyboard, with the Input pane active, will find and\\nhighlight the wanted intersection.\\nMnemonics can be assigned to inlines, crosslines, randomlines, timeslices and 2D lines.\\nTo assign mnemonic to a 2D line, expand the line (+ in front of the line name) and right-\\nclick on Seismic 2D line.\\nGenerate a dip slice in a ZGY cube\\n1. Insert a seismic intersection on your ZGY cube in a 3D window.\\n2. Click on the Align plane vertically option of the player. Note that the name of Random line\\nchanged to Arbitrary intersection under the realized seismic volume.\\n3. Click on the Manipulate plane button to move the dip slice if needed.\\n4. By keep pressing CTRL and SHIFT and the left mouse button together, the dip angle of the dip\\nslice can be manipulated.\\nWhen the desired angle has been reached, the line can be moved by using the left mouse button.\\nExtract vertical intersections along polygon\\n1. From a 3D window, digitize a polygon using Make/edit polygon in the Processes pane.\\n2. Select and activate the polygon from the Input data window. Right-click and select Create\\nvertical intersection. A file called Vertical Intersection Polygon has been created and\\ncan be found at the bottom of the Input pane.\\n3. Toggle the Visualization on plane icon (lower left corner of your main Petrel Explorer\\nwindow) .\\n4. Select the seismic volume on which to create a vertical intersection.\\nNote that you can use the Basemap tools to create composite lines. Read more about it in\\n2D window/Base map window.\\nCreate a seismic random line along a well path\\n1. Right-click on a selected well from the Input pane\\n2. Create a vertical intersection plane\\n3. Click on the Visualization on plane icon\\n4. Select the seismic volume on which to create a vertical intersection.\\nCreate and visualize a Well section fence\\n1. From the Window menu, select New well section window. From the Input pane,\\nWells folder, select the wells of interest.\\n2. Go to the Windows tab, locate and expand the newly created well section. Open the\\nsettings for the Well section fence, and if the Volume Rendering requires more RAM than\\nyour computer can provide, choose how to align the fence to wells under the wells tab (top,\\nmiddle, bottom, etc).\\n3. Activate a 3D window and display the well section fence in it.\\n4. Select the plane and Toggle visualization on plane icon (found in the lower left corner of'},\n",
       " {'header': 'Petrel) . ',\n",
       "  'content': '5. Select your seismic volume on which to create a vertical intersection, click on the light blue\\ncheck box in front of it and the seismic will be displayed on the fence (as shown below\\nbetween two wells).\\nSelection and Manipulation of the seismic\\nsection\\nThe selection of seismic intersections can be done in several ways. To select a specific crossline,\\ninline or timeslice, enter the required number in the Function bar below the Display window and\\npress ENTER:\\nOther ways of selecting and displaying seismic sections are described in 2D window/Base map\\nwindow.\\nUse of the Intersection mode for interpretation data\\nTo hide interpretations in front of the plane, deselect the interpretation in normal mode (white\\ncheck boxes). Turn on the interpretation by activating the blue mode (see details in How to use\\nthe General Intersection). In this mode the interpretation in the plane will become highlighted\\nwith a dimming of the interpretation out from the plane.\\nHow to hide interpretation outside plane by use of the Intersection mode\\n1. Turn off any interpretation visualized in the normal mode (white boxes)\\n2. Ensure that the visible plane is active (bold).\\n3. Activate the Toggle visualization on plane (in the lower left corner).\\n4. Select the blue colored check boxes in front of the interpretation data you want to visualize.\\nTo view interpreted lines within a specific distance of the Seismic Intersection, go to the Settings\\ndialog of the intersection plane and, in the Style tab, specify a Ghost limit.\\nDisplay of 2D seismic\\n2D seismic lines are imported the same way as 3D seismic, and Petrel detects the 2D template\\nautomatically.\\nHow to import one or multiple 2D seismic lines\\n1. Create a new survey folder on the Input pane by right-clicking a Seismic main folder and\\nselecting Insert seismic survey folder.\\n2. Right-click on the new survey folder and select Import (on selection).\\n3. Import one 2D line or select several lines using the SEG-Y seismic data format. Select the\\ndesired vintage to store the data in.\\n4. In the Input data dialog, select the domain of the data (Time or Depth) and attach a color'},\n",
       " {'header': 'Template. ',\n",
       "  'content': '5. Click OK or OK for all.\\nFig. 1 Input data dialog\\nUse SEG-Y Import with preset parameters to better control how the 2D lines are loaded\\nbased on trace and binary header information.\\nImporting lines will not trigger a display refresh.\\n2D Seismic Drag and Drop in the Petrel Input pane:\\nTo prevent issues with seismic interpretation corruption when working with reference projects, 2D\\nseismic lines can no longer be moved between seismic surveys. Lines can still be moved between\\nsurvey subfolders. To move a seismic line from one survey to another, you need to copy and\\npaste the line and then delete the original line (note that this will also delete any interpretation\\nthat has been done on the removed line).\\nVisualize multiple 2D seismic lines\\n1. After importing 2D lines, you can toggle to visualize on one 2D line or all of them if desired.\\n2. Toggle the survey folder to visualize all. A new slice renderer introduced in the 2009.1\\nrelease makes it possible to display large amounts of 2D seismic data in a 3D window.\\nUsing 3D windows for 2D basemap display adds usability to multi 2D line handling.\\n3. Seismic data can also be visualized from the Survey manager. See survey manager.\\nOn-the-fly level of details decimation of seismic 2D lines was introduced in the Petrel 2009.1\\nrelease. In previous releases, displaying a high number of 2D lines would fill up the texture\\nmemory of the graphics card and could lead to system instability. The new method reduces the\\nstress on the graphics card and will improve stability and performance.\\nThe new slice renderer is not available if it is part of a composite line or when using trace\\nskipping.\\nCreate 2D seismic attributes\\n1. Right-click on one 2D seismic line and select Volume attributes. The process for volume\\nattributes will open. Note that the 2D line you clicked on is used as input for the process but\\ncan be changed.\\n2. Select the attribute to be created and run it in virtual mode.\\n3. Under the original 2D line in the Input pane, you will find a virtual representation of the 2D\\nline. Click on it to display the attribute you created.\\n4. For more details about attributes see Attribute Generation Process.'},\n",
       " {'header': 'Seismic Composite Lines ',\n",
       "  'content': 'It is possible to create composites within a seismic survey or between crossing seismic surveys in\\nPetrel. This means that you can create composites on 3D lines within a 3D survey, lines that are\\nspanning across multiple 3D surveys, lines spanning over 2D and 3D lines, but also along 2D lines\\nonly. Composite lines can also be created using any type of seismic (any attribute) that rests on\\nthe Petrel project.\\nCreating composite lines\\nBefore you can create any composite line, the Seismic interpretation process must be active\\nunder Geophysics on the Processes pane. Depending on the active display window used,\\nactivating the Seismic interpretation process will open up different compose icons in the\\nfunction bar for 3D, 2D, and interpretation windows. Using 3D and 2D windows activate three\\nicons at the bottom of the function bar: Select composite section , Draw arbitrary\\ncomposite sections , and Draw aligned composite sections . With an active\\ninterpretation window, four icons are available at the bottom of the function bar: Compose with\\nintersecting line , Compose with inline , Compose with crossline , and Clip and\\nextend composite .\\nWhen you create a composite line for the first time, if you use any of the composite section\\nicons from the function bar, a new composite folder will automatically be placed in the Input\\npane. In the figure below, you can see that if a composite contains multiple parts, each individual\\npart will be listed along with a tick box in the hierarchy below the actual composite name. This\\nmeans that it is possible to turn off and on individual parts of the composite.\\nThe figure shows the Seismic Composite folder 1 containing a total of three composite lines of\\nwhich the Composite line 3 has three parts consisting of a 3D crossline, and two 2D lines.\\nThe display of composite lines in 3D windows has not implemented the new slice renderer as\\nused for 2D lines and intersections from SEGY 3D volumes. This means that the parts of the\\ncomposite derived from SEGY (2D and 3D) seismic will not have the level of details decimation\\nand the possibility to do smooth interpolation available (defaults to Bilinear interpolation).\\nYou can create empty \"dummy\" seismic cube in order to create composite lines with no\\noverlapping.\\nIcons for making Composite lines\\nIn a 3D or 2D window:\\nSelect composite section , this icon is used to select the 2D line components of the\\ncomposite lines.\\nSelect arbitrary composite sections , this icon is used to select randomly directed lines\\nfrom 3D cubes (not necessary aligned with inline or crossline directions).\\nSelect arbitrary composite sections , this icon is used to select seismic aligned lines from\\n3D cubes.\\nWhile creating the composite line, pressing Delete on your keyboard deselects the last section of\\nthe composite (before it is created by double-clicking).\\nIn an interpretation window:\\nCompose with intersecting line , this icon is used to compose with already displayed seismic\\nlines (2D and 3D).\\nCompose with inline , this icon is used to compose with any intersecting inline.\\nCompose with crossline , this icon is used to compose with any intersecting crossline.\\nClip and extend composite , this icon is used to clip and extend already existing composite\\nlines.\\nComposite line using only 2D seismic\\nHow to create composite line using only 2D seismic\\n1. Visualize the 2D lines you want to make the composite lines from. Next, click the Select\\ncomposite section icon on the right-hand side (of the Function bar).\\n2. Move the cursor over the 2D line from which you wish to start the composite. The seismic\\nline should be highlighted in a white color (rubberband). To start the composite, click once\\non the 2D line. To move to the next 2D line, move the cursor over the next 2D line that you\\nwant to select. Tthis next line will also be highlighted in white. Continue this operation for\\nas many parts you would like to include.\\n3. End the selection of composite parts by double-clicking the left mouse button or by pressing\\nthe letter N (shortcut key for Start new line).\\n4. A new composite will be created in the Composite folder as seen in the example below\\nwhere Composite line 1 consists of four 2D lines.\\n5. The final composite line can be viewed in a 3D window (as image below) or as a base map\\nview in 2D.\\nNote that the rubberband (line selection highlighted in white) is still displayed in a 3D\\nwindow if breaking the construction of the composite line by pressing ESC or another hotkey.\\nActivating another editing tool removes the selection rubberband.\\nComposite line using only 3D seismic data\\nHow to create composite line using only 3D seismic\\nUsing only 3D for a composite is very much the same as drawing a random line. However, the\\ncomposite icons give you control over whether the lines follow crosslines or inlines, are created\\narbitrarily or are a mixture of both.\\n1. Select either the , or the icon depending on what result you want.\\n2. Start drawing the composite line, either within the limits of one 3D volume, or span the\\nselections to another active 3D survey.\\nNote: By default, the aligned direction for a composite is set to inline (as Petrel works\\nprimarily in the inline direction with seismic). To set the initial aligned direction to crossline, hold\\nthe Ctrl key and move the mouse. You can now select an crossline.\\nNote: The composite sections derived from 3D seismic can be edited and manipulated using\\nthe Intersection player or Manipulate plane icon. This means that inline, crossline and\\nrandomline parts of the composite can be repositioned inside the composite. Random lines can be\\nrotated and the intersections converted from aligned (inlines and crosslines) to unaligned\\n(randomlines) using the alignment icons, just like ordinary 3D seismic intersections.\\nNote: By default, once a composite has been created in the 2D window, it will be displayed\\nin either a 3D or intersection window, if they exist. Depending on which window was last accessed\\n(either a 3D window or Intersection window), it will be displayed in that window.\\nComposite line using 2D and 3D seismic data\\nHow to create composite line using 2D and 3D seismic data combined\\nThere are two options when you create a composite in 2D and 3D combined; you can to start with\\nthe 2D data or the 3D data.\\n1. If you start with the 2D lines, you start off in exactly the same way as for creating a\\ncomposite line only for 2D data.( Composite line using only 2D seismic ) Select the\\ncomposite section . When you reach a point where you wish to traverse from the 2D\\nseismic into the 3D cube, you can use either the arbitrary or aligned icons ( , or ). Click\\non any of these icons (activate the 3D survey if they are grayed out), and continue to\\ntraverse through the 3D volume. End the composition by double-clicking the left mouse\\nbutton or by pressing the letter N (shortcut key for Start new line).\\n2. If you start with the 3D volume: Activate the 3D volume on the Seismic input pane. Click\\nany of the two icons , or to compose 3D line parts of the composite. When\\napproaching the 2D lines to include, click the icon and continue to select the 2D lines of\\ninterest.\\nNote: It is important to select which end of the 2D seismic line you want to start the\\ncomposite with. If you select the undesired end of the 2D seismic line, the procedure for flipping\\nthe line to the opposite end includes inserting the composite in an Interpretation window where\\nthe Clip and extend composite icon can be used. Alternatively, delete the composite and start\\nover again.\\nMake a composite line transparent\\nHow to make a composite line transparent\\nA composite line displayed in a 3D window can be made transparent in the same way as any\\nother seismic intersections, with one exception: Each segment of the composite line is made\\ntransparent from the source of that segment, rather than setting transparency for the entire\\ncomposite.\\n1. Open the the settings for the various sources of the composite line.\\n2. Under the Style tab, select the Enable transparency for intersections check box. If\\nmultiple 2D lines are used, activate the Apply setting to all similar objects icon or\\nApply to all similar objects in folder icon and click Apply.\\n3. On the Colors tab, adjust the opacity curve to your liking.\\n4. Make sure to enable transparency and change the opacity curve for all segments of the\\ncomposite line.\\nNote: The opacity curve is set for a template which the seismic object is attached to, not the\\nobject itself. Therefore, the same opacity curve is used for all seismic intersections using the\\nsame template (both 2D and 3D).\\nNote: Under settings for the composite line, Style tab and Plane settings, the plane itself\\ncan be displayed (in one color), alternatively with a transparency.\\nComposite lines in an Interpretation window\\nHow to create and handle composite lines in an Interpretation window\\n1. Activate an interpretation window containing seismic data.\\n2. Select the appropriate icon to make a composed line. By using the Compose with\\nintersecting line icon, only intersection lines marked as small triangles above the\\ndisplayed seismic are accessible (both 2D and 3D seismic intersections). The four following\\nsteps describe how an intersecting line is composed with a current selected seismic line.\\nTo compose to the right and use the part of the intersecting line away from you, left-\\nclick on a possible compose location.\\nTo compose to the left and use the part of the intersecting line away from you, press\\nCTRL and left-click on a possible compose location.\\nTo compose to the right and use the part of the intersecting line towards you, press\\nSHIFT and left-click on a possible compose location.\\nTo compose to the left and use the part of the intersecting line towards you, press\\nSHIFT and CTRL and left-click on a possible compose location.\\n3. Using Compose with inline or Compose with crossline , any intersecting 3D line\\nwill be accessible.\\n4. Continue creating the composed line using the different icons.\\n5. To edit on the selected lines comprising the composed line, use the Clip and extend\\ncomposite icon. Its use is explained in the following steps.\\nTo clip out parts of the composed line to the right and extend it from that point on,\\nleft-click where the clip/extend should take place.\\nTo clip out parts of the composed line to the left and extend it from that point on,\\npress CTRL and left click where the clip/extend should take place.\\nTo clip out parts of the composed line to the right without extending it, press SHIFT\\nand left-click where to clip and end the composed line.\\nTo clip out parts of the composed line to the left without extending it, press CTRL and\\nSHIFT and left-click where to clip and end the composed line.\\nNote: The best way of handling and visualizing these steps is to tile your windows (2D, 3D\\nand Interpretation window) and orientate the seismic data in the same direction. It is good\\npractice to copy and paste your composite lines before editing them.\\nFlatten a composite line\\nA composite line displayed in an interpretation window can be flattened on a horizon as any other\\nseismic intersection, with the added functionality to only flatten the part belonging to a specified\\nsurvey.\\n1. Display the interpreted horizon in an Interpretation window containing the composite line.\\n2. Expand the interpreted horizon object in the Input pane. It will contain one survey filter\\nobject for each survey that has been interpreted.\\n3. Right-click on a survey filter and select Flatten horizon.\\n4. Right-click on the next survey filter and flatten that one too. Observe that the first flattened\\nsection of the composite is unflattened.\\n5. Right-click on the seismic horizon to flatten the entire composite line.\\nNote: Composite sections can be converted into 2D lines to allow them to be used in\\nattribute computations and mis-tie analysis.'},\n",
       " {'header': 'Color Manipulation ',\n",
       "  'content': 'The default color template used for seismic data in Petrel is red, white and blue with yellow and\\nturquoise for extreme values. Positive amplitudes are displayed as red color and negative\\namplitudes as blue color. Petrel will, by default, estimate the minimum and maximum amplitudes\\nfor the visualized seismic. The colors can easily be modified in the Color tab in the Settings\\nwindow or the Color table toolbar inserted from the View menu.\\nThe color templates can also be changed in the Templates pane in the Petrel Explorer. For\\ndetails of the Templates pane, see Templates and Color Tables.\\nSeveral predefined color templates exist for seismic data in Petrel. These are:\\nColor bars can be imported from and exported to files. Right-click on the Seismic color tables\\nfolder and select Import (on selection)... from the menu that opens. There are four types of\\nfiles accepted to import from and examples of them are given in the lower part of the import\\ndialog box when selected.\\nTo export a color bar, right-click on it in the Templates pane and select export from the menu\\nthat opens. Color bars can only be exported as *.alut files.\\nIt is possible to lock a color template to a local 2D line or to the entire 2D survey/vintage. This\\nfunctionality is controlled from the Settings dialog -> Colors tab of a seismic 2D line or from the\\nSurvey manager.\\nGlobal color table: any change to the color template of the 2D line will be applied to all\\nseismic data using to the same template.\\nLocal color table: any change to the color template of the 2D line will only be applied to\\nthe 2D line itself.\\nSurvey and vintage color table: any change to the color template of the 2D line will be\\napplied to all lines in the same survey/vintage.\\nCompress Colors using Color tab\\nSeismic data often covers large amplitude ranges and the color templates have to be modified for\\neach project. To avoid problems with extreme amplitude values in the seismic data, a compressed\\ncolor template can be made in two different ways. Below is a description of how to use the Colors\\ntab on the Settings window for the seismic object.\\nBy default, the \"auto\" button (Use automatic min and max in the color table button ) is\\nactivated in the Colors tab of the Settings window. Figure 1 shows the Colors tab. When the\\n\"auto\" button is activated, the system will try to adjust the color scale according to the estimated\\nrange in amplitudes. When the Auto button is turned off, values for min and max amplitudes can\\nbe adjusted manually (visible by two blue arrows indicated at the top and bottom respectively).\\nHow to compress colors in Petrel using the colors tab\\n1. Open the Settings window from the seismic data volume icon, and go to the Info tab.\\n2. Select the appropriate (color) template, for example, red, white and blue.\\n3. Go to the Colors tab.\\n4. Deactivate the Use automatic min and max in the color table button . This activates\\nthe Get min and max value from the data buttons .\\n5. Pick the top arrow corresponding to the red/yellow color.\\n6. Move the arrow downwards until satisfied with the selection.\\n7. Pick the bottom arrow corresponding to the blue/turquoise color.\\n8. Move the arrow upwards to where you want it.'},\n",
       " {'header': '9. Click Apply. ',\n",
       "  'content': '8.\\n9.\\nFig. 1 Color settings for seismic data.\\nAdding more colors to a color table\\nIf the colors need additional colors or compressing, the following procedure can be used:\\n1. Insert a new arrow in the color template just below the yellow arrow by clicking next to the\\ncolor bar itself.\\n2. Pick the yellow color.\\n3. Move this arrow just above the red arrow.\\n4. Insert a new arrow in the color template just above the turquoise arrow.\\n5. Pick the turquoise color.\\n6. Move this arrow just below the blue arrow.\\n7. Apply the new settings.\\n6.\\n7.\\nColor table toolbar\\nA Color table toolbar can be opened from the View menu. It will appear at the bottom of the\\nPetrel window.\\nThis toolbar allows you to, on the fly, change color templates for the seismic specified in the\\ntoolbar, reverse, rotate, and compress the colors.\\nThe color table toolbar displayed is taken from the last selected intersection in the active\\nwindow. The seismic volume or line name is shown in the Color table toolbar for reference. By\\nmoving the cursor over the color bar, a continuous readout of the (amplitude) values is obtained.\\nHow to compress colors in Petrel using the color table toolbar\\n1. Open the Color table toolbar from the View menu.\\n2. Use the handles in the outer rim of the colorbar to compress the colors.\\n3. Left-click on one of the handles to compress the color bar one-sided.\\n4. Press SHIFT and left-click on one of the handles to compress the color bar symmetrical\\naround zero.\\n5. Click on the triangles on the left and right-hand side of the color bar to rotate the colors.\\nThe Colors tab in the Settings dialog and the Color table toolbar can be used in combination.\\nColor filtering techniques\\nAnother useful function is to filter the seismic 2D or 3D data using an opacity curve accessed\\nthrough the Colors tab, Opacity tab, or the Color table toolbar, see the image below. Specific\\namplitudes can be highlighted to look at particular seismic events, which is useful in detecting\\nsand-bodies with a characteristic amplitude range.\\nColor filtering using Settings dialog\\nColor filtering of 2D lines and seismic intersections from 3D volumes can be controlled in the\\nSettings dialog of the seismic object. There are two options that basically do the same thing and\\nare found on the Colors and Opacity tabs.\\nThe opacity curve in the Colors tab can be edited by using the two lowermost icons. New points\\ncan be added to the curve by left-clicking somewhere on the curve. The active point on the line\\n(highlighted color) can be moved by dragging the points. By changing from the Select Edit Point\\nmode to the Line mode , the whole curve can be moved.\\nClicking on the Reverse Color template icon will invert the color template. If changes have\\nbeen made to the color template, you can click on the Reset color template to default icon\\nto get back to the original template.\\nThe opacity curve in the Opacity tab can be edited by simply clicking inside the graphic area and\\ndragging the area over to make it transparent.\\nNote that the Min/Max values in the Colors tab and histogram distribution in the Opacity\\ntab are defined by how the (amplitude) values are defined. Updating the value distribution is done\\nin the Operations tab of the seismic object. The histogram distribution in the Opacity tab has a\\ncontinous readout of values when moving the cursor over the area. The same readout\\nfunctionality exists for the Color table toolbar.\\nColor filtering using color table tool bar\\nIf the seismic has been scanned (using the scan function under the Seismic -> Settings ->\\nOperations tab -> Realize sub-tab), an opacity histogram can be brought up for the colorbar by\\nright-clicking on the color bar itself. This activates further functionality to set transparency for the\\nseismic.\\nHow to apply transparency on seismic intersections using the color table\\ntoolbar\\n1. Open the Settings window from the seismic data icon.\\n2. Select Enable transparency for intersections on the Style tab -> SEG-Y or ZGY style\\nsub-tabs.\\n3. Make sure the amplitude range has been scanned in the Operations tab. Alternatively, re-\\nscan under the Amplitude sub-tab.\\n4. Insert the color table toolbar from the View menu.\\n5. Richt-click in the color bar in the lower part of the Petrel window.\\n6. Click and drag to update the opacity curve while observing the intersection displayed.\\nTransparency set in the Color table toolbar.\\nTransparency on seismic intersection\\nHow to apply transparency on seismic intersections using the settings\\ndialog\\n1. Open the Settings window from the seismic data icon.\\n2. Select Enable transparency for intersections on the Style tab -> SEG-Y or ZGY style\\nsub-tabs.\\n3. On the Colors tab, click on the Line mode button and move the line in the opacity ruler\\nto the left.\\n4. Apply the new setting. Note that the intersection plane is now transparent.\\n5. Go to the Opacity tab. The grayed out area at the top of the graphic display is adopted\\nfrom the Colors tab settings.\\n6. Click and drag to update the opacity curve (observe how the colors tab has changed) while\\nobserving the intersection displayed.\\nAny changes to the opacity curve under the Color s tab must be applied to take effect,\\nwhile under the Opacity tab any changes are made \"on-the-fly\".\\nFig. 1 Transparency of a Seismic Intersection plane.\\nHighlight a specific amplitude range\\nThe easiest way to highlight a given amplitude range is to use the Colors tab as described below.\\n1. Ensure that an intersection is visible.\\n2. Open the Settings window from the seismic data icon.\\n3. On the Color tab, click on the Line mode button and move the line in the opacity ruler\\nto the left.\\n4. Apply the new setting. Note that the intersection plane is now transparent.\\n5. Activate the Select edit point mode .\\n6. Insert four new points and make a square to filter out a certain amplitude range, see figure\\nbelow.\\n7. Apply the new settings - note that only those amplitudes within the filtered range are\\nvisualized.\\nThis action does not affect the walls of the seismic cube unless the Enable transparency\\nfor walls check box is selected.\\nBy moving the line in the opacity ruler to the center, the intersection will be partly\\ntransparent.\\nMis-tie Analysis\\nMis-tie analysis allows you to extract and apply mis-tie value corrections for 2D seismic\\nsurveys. All lines contained inside a Seismic survey folder or a sub-folder will be used when a\\nMis-tie set is created.\\nA simple, but effective algorithm based upon weighting value assignments using a variance\\ncriterion has been used. It assumes mis-tie values to be random variables. The algorithm satisfies\\nthe following requirements:\\nThe mis-ties should be reduced to a minimum after the error adjustment.\\nThe method should be applicable to any survey configuration.\\nThere should be a way to define a weighting factor to good lines (reference lines) in\\ncomparison to lines showing data of poor quality.\\nThe method should be easily manageable within the current workflow.\\nThe algorithm should be fast and require minimal iteration.\\nMis-tie manager\\nThe Mis-tie manager is an interactive tool for managing the mis-ties in Petrel. You can calculate\\nor specify corrections, select reference lines, deselect lines not to be used for mis-tie analysis, and\\nalso toggle to display 2D lines in the active window.\\nTo generate a Mis-tie set, right-click on a Seismic survey folder (in\\nthis case called \"2D lines for MIS-TIE\") or sub-folder and choose Insert mis-tie set from the\\nmenu. The new mis-tie set is located in a new folder called \"Mis-ties\", under the survey folder that\\nit was created from.\\nWhen a mis-tie set is created, Petrel will extract all crossing points for the 2D lines in the survey\\nfolder and build a color-coded spreadsheet showing all 2D lines and their corresponding\\nintersecting lines. The table looks very similar to the Survey manager, but it has additional\\nfunctionality to work with mis-tie values. It is called Mis-tie manager.\\nThe Mis-tie manager is opened by right-clicking on the Mis-tie set object on the tree and\\nselecting Mis-tie manager.\\nSeveral Mis-tie sets can be defined independently for a 2D Seismic survey. This allows you\\nto analyze mis-ties for different zones in the survey (for example, lower formations and upper\\nformations might need different Mis-tie sets).\\nA new entry is created in the tree under the Mis-ties folder, where all mis-tie sets are kept.\\nA bold display indicates the active Mis-tie set.\\nData in the Mis-tie Manager\\nLine lists the name of the 2D lines.\\nShotpoint lists the crossing Shotpoint number for the lines.\\nCDP lists the crossing CDP number for the lines.\\nTrace lists the crossing trace number for the lines.\\nVertical mis-tie lists the calculated mis-tie for a line and an intersecting line.\\nCorrelation factor lists the calculated correlation factor for a line and an intersecting line.\\nVertical correction lists the estimated vertical correction for the line and the intersecting\\nline.\\nTurn visible indicates what lines are toggled and displayed in the active window. You\\ncan toggle on and off the display for the lines in this spreadsheet, instead of entering the\\nPetrel Input pane. The first column visualizes the original line; the second column\\nvisualizes the mis-tie corrected line.\\nIntersecting line lists the corresponding intersecting line for the line displayed in the Line\\ncolumn.\\nThe Use column allows you to decide to use or to reject a line during the mis-tie process.\\nYou can define which lines are going to be used as reference lines. These lines will not be affected\\nby the mis-tie correction procedure at all. Reference lines are defined dependant upon the survey\\ngeometry, the orientation of certain geological features like faults, etc. In order to set a reference\\nline, toggle on the column with the Lock icon for the corresponding line. Locked lines are not\\ninfluenced by the mis-tie corrections and will appear in bold in the Mis-tie manager .\\nInformation can be sorted on the Mis-tie manager . Double-click on the Line header for\\nexample to sort the table by lines.\\nSettings for the Mis-tie Manager\\nEvery 2D line in the Mis-tie manager is identified by a different color to ease the visualization.\\nThe table provides information for each line regarding the position of the intersecting traces (CDP,\\nTrace number and X,Y coordinates).\\nMis-tie manager functionality toolbar\\nGain - Enable mis-tie corrections for gain (amplitude balancing).\\nVertical - Enable vertical mis-tie corrections. By Default this is enabled.\\nPhase - Enable mis-tie phase corrections.\\nStart , End - Define the top and bottom vertical range value for the corrections\\nestimations. Only one window can be defined at a time. Default range is -250 ms and -2500\\nms.\\nCompute mis-ties - Calculate mis-tie estimate values from the seismic data.\\nConstant, Variable - Select method for calculating the mis-tie corrections.\\nCompute corrections - Calculate mis-tie corrections.\\nRealize - permanently realize mis-tie corrected sections on disk.\\nScroll to top - Scroll to the top of the table.\\nScroll to bottom - Scroll to the bottom of the table.\\nThe gain mis-tie and gain corrections are expressed as a difference to 1.0. For example, a\\ngain mis-tie of 1 means no mis-tie and a gain correction of 0.001 will give the factor 1.001. A gain\\ncorrection of -0.2 will give the factor 0.8.\\nVisualize and Realize Mis-tie corrected lines\\nHow to visualize and control mis-ties on intersecting lines\\n1. Mis-tie values can be easily be visualized for quality control in the 3D window. Use the Mis-\\ntie manager, turn on the visibility of the mis-tie corrected line by toggling the second\\nvisibility column. Do the same operation for any of the intersecting lines.\\n2. To see the effect of the mis-tie correction, change the toggle between the original line and\\nthe mis-tie corrected line and look for the subtle changes when the line shifts.\\n3. You can manually override the computed correction values. Simply enter the desired value\\ndirectly in the corresponding cell on the Mis-tie manager spreadsheet.\\nThe Mis-tie manager window can be dragged outside the Petrel window. This is especially\\nuseful when working with dual-monitor workstations.\\nHow to realize mis-tie corrected lines\\nMis-tie values are applied \"on-the-fly\", generating a virtual mis-tie corrected 2D line that is\\ndisplayed. The system will store the computed values and reapply them every time the line is\\nused for display. This allows you to work on a Mis-tie set interactively while analyzing mis-tie\\ncorrections. It can also save disk space. However, a Mis-tie set can be stored permanently and\\nused separately for later steps in interpretation. For this purpose, it is possible to permanently\\nrealize mis-tie corrected lines on disk. This provides the advantage to generate independent\\nrealized mis-tie-corrected surveys. For more information about realization of seismic data see'},\n",
       " {'header': 'Realization. ',\n",
       "  'content': '1. Click on the Realize button on the Mis-tie manager toolbar. This will prompt the system\\n2.\\n1.\\nto generate a new survey using the current mis-tie computed values.\\n2. Petrel will prompt you with a confirmation box called Realize mis-tie corrected seismic\\nasking for the realization quality, vintage name and amplitude settings. When this\\ninformation has been provided, click the OK button.\\n3. You have the option to control the amplitude settings with three options available:\\n4. Petrel will realize all lines and store them under the defined sub-folder. The mis-tie\\ncomputed values are also applied to the survey in the realization step.\\nMis-tie Computation Correction\\nHow to generate mis-tie values\\n1. Enable or disable the type of mis-tie correction to be generated (Gain, Vertical, Phase)\\n2. Define the window for the mis-tie corrections (default is -250 to -2500 ms)\\n3. Optionally, define which lines are going to be reference lines by using the Lock column\\non each of those lines.\\n4. Select the method for the mis-tie corrections (Constant or Variable). Constant is the\\ndefault setting and it will generate a single constant mis-tie value for each line and will\\ncompute the corrections so that the mean shift for all lines will be zero. Variable will\\ngenerate a floating mis-tie correction function for each line.\\n5. Click on the Compute mis-ties button: This will calculate the mis-tie estimates from the\\nseismic data and fill the values in the Mis-tie Manager table.\\n6. Click on the Compute corrections button: This will calculate the mis-tie corrections\\naccording to the settings and it will fill the values in the Mis-tie Manager table.\\nExample using Constant correction: Line slb1 will be corrected using a -0.3 ms vertical shift.\\nExample using Variable correction: Line slb1 will be corrected using a variable correction function\\nthat interpolates the values between every single intersection.\\nThe Correlation factor column indicates the \"quality\" of the correlation between traces at\\nan intersection. Values close to 1.0 and displayed in green, indicate good correlation between\\ntraces; values with lower correlation will be indicated in yellow or red. In such cases, you should\\ncheck the reason for the poor correlation (noise, missing information, end of a line) and take\\nappropriate action, such as avoiding to use this line in the mis-tie process.\\nMapping mis-tie computed values\\nIn order to estimate the distribution of the extracted and computed mis-tie values, it is possible to\\nconvert them to points. These points can be posted on the 2D window or used as input for the\\nMake/edit surface process. When converting to points, the first point found at a crossing will be\\ninserted to the point set.\\n1. To convert a Mis-tie set to points, right-click on the Mis-tie set object in the tree and select the\\nConvert to points... option. A new point folder will be created under the active Mis-tie set.\\n2. The created point set contains all the extracted values as attributes. These can be used as input\\nfor posting or mapping. The example below shows the attribute Vertical correction points\\nposted on the 2D window.\\n3.\\n2.\\n3. The computed mis-tie values can be contoured using the Make/edit surface process under\\nUtilities in the Processes pane.\\n4. Drop the points set as the main input, using the blue arrow, to the Make/edit surface\\ninterface and select the point attribute you want to map.\\nUse the Kriging Interpolation algorithm to generate a contour map that honors single extracted\\npoints, as shown in the figure below.\\nCorrect interpretation using mis-ties\\nAlready interpreted horizons can be corrected with the mis-tie values created in the Mis-tie set.\\nYou have the option to add or subtract the mis-tie correction.\\n1. Activate the mis-tie set to be used for the correction.\\n2. Expand the horizon interpretation object and right-click on the 2D survey tied\\ninterpretation.\\n3. Select Add mis-tie correction or Subtract mis-tie correction from the menu.\\nAdding or subtracting mis-tie corrections on horizon interpretation is purely a vertical\\ncorrection. Gain and phase correction is not used in this operation.\\nReferences and Reading\\nMittal, P.K., Algorithm for error adjustment of potential field data along a survey\\nnetwork, In Society of Exploration Geophysicists, 1984\\nWindows for Seismic Display\\nSeismic data and the resulting interpretation can be displayed in several different windows:\\n3D window\\n2D window or Base map window\\nInterpretation window\\nIntersection window\\nMap window (Not Timeslices)\\nThese windows can be displayed one by one, two by two, on dual screens or all together as a\\nmulti-frame composition.\\nNotice that in most of these windows, other types of data that are available in the project can also\\nbe visualized, such as well data, logs, well tops, model data- such as horizons, zones, property\\ngrids, fluid contacts, simulation grids, etc.\\n2D window/Base map window\\nA 2D window will serve as a base map when the seismic interpretation process is activated.\\nWithin a 2D window or a Base map window, you can display:\\nThe frame of the seismic cube with annotations\\nThe outline of 2D seismic lines with annotations\\nSelected inlines, crosslines, time slices\\nInterpretations of horizons or faults\\nOther data such as wells, surfaces, etc.\\nBase map display for 2D lines\\nSettings for display of 2D seismic lines\\nThe 2D line annotations sub-tab controls the display and annotations of 2D lines in the survey\\nfolder. If there are no 2D lines in the folder, the tab will be grayed out.\\nBasemap style- Only enabled for 3D windows\\nZ level - Only enabled for 3D windows\\nColor - Enables you to set the color of the lines\\nShow lines - Enables you to change the draw style of the line.\\nShow name - Enables you to specify how the name of the line should be drawn.\\nEvery \"userdefined\" trace - Lets you specify the annotation of the CDP/SP/Traces for every\\n\"user defined\" trace.\\nBase map display for 3D cubes\\nSettings for display of 3D seismic volumes\\nColor - Enables you to set the color of the lines.\\n\"Base map\" annotation - Enables you to set the annotations of the existing lines in the 3D\\nvolume.\\nIntersections - Enables you to change the draw style of intersections.\\nNote the annotations settings are also valid for 3D windows.\\nThe Base map is also a very efficient tool for selecting seismic sections, moving or snapping\\nthem to a specific point, and visualizing in a 3D or an Interpretation window.\\nCreate arbitrary polyline intersection in the\\nbase map\\n1. From the Window menu on the main Petrel window, select a new interpretation window\\nand a new 2D window.\\n2. On the Input pane, select the seismic cube to display it in the base map.\\n3. Click on the Create arbitrary polyline intersection icon in the Function bar.\\n4. Use the pointer to digitize the intersection in the base map and double-click to end the line.\\n5. The arbitrary line will be displayed in the interpretation window.\\nNote that the current cube, inline, crossline, and xyz coordinates are updated in the Status\\nbar.\\nCreate seismic aligned polyline intersection in\\na base map\\n1. From the Window menu on the main Petrel window, select a new interpretation window\\nand a new 2D window.\\n2. From the Input pane, select your seismic cube to display it in the base map.\\n3. Click on the Create seismic aligned polyline intersection icon in the Function bar.\\n4. Use the pointer to digitize the intersection in the basemap and double-click to end the line.\\n5. The intersection inline will be displayed in the interpretation window.\\nCreate a combined arbitrary and aligned\\nintersection in a base map\\n1. From the Window menu on the main Petrel window, select a new interpretation window\\nand a new 2D window.\\n2. From the Input pane, select your seismic cube to display it in the base map.\\n3. Click on the Create arbitrary polyline intersection icon on the Function bar.\\n4. Use the pointer to digitize the intersection in the base map.\\n5. If CTRL is pressed while digitizing, the intersection line is restricted to the 3D cube\\nalignment.\\n6. The intersection line will be displayed in the interpretation window.\\nNote: Intersections can only be generated within the same 3D volume.\\nSelecting seismic line from a base map\\nHow to select lines using Manipulate Plane in 3D window\\n1. On the Window menu on the main Petrel window, select a new 3D window.\\n2. On the Input pane, select the Inline/crossline to display.\\n3. Click on the Manipulate plane button on the Function bar.\\n4. Use the pointer on the displayed Inline/Crossline and drag it to the desired position.\\nHow to select lines in the base map window\\n1. On the Window menu on the main Petrel window, select new 2D window.\\n2. On the Input pane, select your seismic volume\\n3. Select the inline to display in a base map and activate the selected line (make it bold). The\\nselected Inline will be represented in the base map by a dotted line.\\n4. Select the crossline to display in base map. The crossline will be shown by a dotted line.\\n5. Click on Manipulate Plane button on the Function bar.\\n6. Use the pointer in the base Map window and place it on the Inline/Crossline and drag it to\\nthe desired position.\\nHow to select lines using snap intersection plane to point\\n1. On the Input pane, activate the section you want to move (in bold).\\n2. Select the Snap intersection plane to point button.\\n3. In the Base Map window, move the cursor to the desired position and click to snap that\\nline to the specific position.\\nHow to select lines using General Intersection Player toolbar\\n1. Set your increment by setting the plane step increment on the General Intersection\\nplayer toolbar and change it to, for example,10.\\n2. Use the step plane forward or step plane backwards to display the line.\\nMultiframe display for seismic\\nUsing multiframe with Petrel is easy.\\nOpen windows can be arranged using the options under the Windows pull-down menu.\\nBy displaying the same piece of data in several windows, edits made in one view will be\\nautomatically updated in the others in real time. If windows are set up like the example below,\\nthe yellow line indicates the extent of the seismic displayed in the interpretation window. When\\nthe seismic is moved in the interpretation window, the yellow line will update in all of the other\\nwindows.\\nHow to remove the yellow line that indicates the portion of seismic\\ndisplayed in interpretation window\\n1.\\n2.\\n3.\\n1. On the Windows pane, locate the 2D or 3D window to be updated.\\n2. Expand the 2D (3D) window folder and locate an object called Interpretation window .\\n3. Clear the check box in front of this object.\\n4. The yellow line will no longer be visible in the 2D or 3D window.\\n5. The yellow line has its own draw style. It can, however, be customized by color, thickness,\\nsolid vs. dotted, and transparency. You can also tell if the yellow line should represent the\\nlast active interpretation window, if it should be shown only if an interpretation window is\\nactive, or only when scrolling in the Interpretation window . After a few seconds of\\ninactivity, the yellow line will fade out in a 3D window.\\nSynchronize two different windows\\nHow to synchronize two windows to visualize progressing interpretation\\nIt is possible to view a 2D map of a seismic interpretation while interpreting on an inline or\\ncrossline in 3D.\\nTo do this:\\n1. Ensure you have one 2D and one 3D window open.\\n2. From the Windows pull-down menu, select Tile vertical, so that both the 2D and the 3D\\nwindows are visible in the display area.\\n3. Activate the 3D window and view the seismic data you wish to interpret and any other data\\nyou want to view in that window.\\n4. Activate the 2D window and display any data you wish to view (for example, maps, etc).\\n5. Once an interpretation has begun, the resultant horizon can be turned on in the 2D window.\\nAny further interpretation on that horizon will appear in both windows simultaneously.\\nWhen you start interpreting in the 3D window, the interpretation will be added to the active\\ninterpretation object in the Petrel Explorer. Activate the 2D window and click on the interpretation\\nto display it as you progress.\\nCursor tracking\\nHow to activate the Cursor tracking between two windows\\n1. Open a 2D, 3D or Interpretation window and make it active.\\n2. Open the Windows pane.\\n3. Turn on the Cursor tracking (top of the list in the Window pane) for both windows\\nHow to change the shape and size of the Cursor tracking\\n1. Open the Windows pane.\\n2. Double-click on Cursor tracking to open the settings.\\nDepending on which window is active, the Settings for the cursor is different (that is, cursor\\ntracking in an Interpretation window has an unchangable size).\\nSeismic Interpretation window\\nThe seismic interpretation window gives you a classic 2D view of the seismic data. Inline, crossline,\\ncomposite lines and any type of random lines, can be displayed in the interpretation window. All\\ninterpretation tools are available in this window and the view can be zoomed, stretched and squeezed\\nin either direction. In addition, a number of shortcut keys are available to make the interpretation\\ntools as easy to use as possible. See Shortcuts For Seismic Interpretation .\\nHow to create a new interpretation window\\n1. Open a new Interpretation window from the Window pull down menu\\n2. Identify the seismic data of interest in the Input pane\\n3. Select the 2D line, inline, crossline or randomline to be visualized\\nHow to create a new interpretation window directly from an intersection\\nRight-click on the 2D line, Inline, Crossline or Random line icon from the Input pane.\\nFrom the pull down menu, select Create interpretation window .\\nAnnotations and symbols of the Interpretation window\\nThe title bar displays the name of the seismic volume, the vintage it belongs to and an indication of\\nthe kind of intersection is being viewed.\\nIf a 3D or a random line is displayed, the Inline and crossline number (CDP) are shown at the top of\\nthe Interpretation window. For a composite line, \"Composite line\" will be shown on the title bar. For\\nany form of 2D seismic lines, Line and Trace numbering are displayed by default. They can however be\\ncustomized to annotate CDP and SP.\\nThe time/depth scale will show the time or depth in accordance with the project unit settings. It will\\ndisplay time seismic in seconds or milliseconds, and meters or feet for seismic in the depth domain.\\nHow to select a crossing intersection from the interpretation window\\nLine Ties or Crossing sections are indicated by their shorthand ID and a downwards-pointing triangle.\\nYou can click on the triangle to immediately display that particular section.\\nInterpolation of Seismic samples in\\nInterpretation window\\nInterpolation method\\nThe three different interpolation methods have an effect on both bitmap and wiggle displays in an\\ninterpretation window.\\nNone - voxels will be rendered as original values for the bitmap. Wiggle traces will have\\nlinear interpolation.\\nBilinear - voxels will be rendered by bilinear interpolation for the bitmap, honoring the\\noriginal values. Wiggle traces will have linear interpolation.\\nSmooth - voxels will be rendered by squared distance weighting for the bitmap, smoothing\\nthe original values. Wiggle traces will be interpolated by a sync function.\\nZooming/Scroll bars and pan images in the\\nInterpretation window\\nYou can pan the image freely by using the left mouse button when operating in the View mode\\n.\\nThere are several ways to zoom in/out or scroll your display:\\nThe white bars to the right and below the intersection act as any standard scroll bar in windows.\\nClick and drag these to scroll in either direction, click above or below the bar to jump one full\\nscreen. The white area is proportional to the amount of data currently in view, that is, if the\\nintersection is twice as high as the area currently visible, then the vertical scroll bar will be half\\nwhite and half grey.\\nDragging the ends of the white bars will zoom in and out, while dragging the ends of the bars\\nwhile holding down the SHIFT key will stretch or squeeze the window in that direction.\\nPressing CTRL + SHIFT and moving the mouse up or down will zoom out or in when in View\\nmode, doing the same and moving from one side to the other will stretch or squeeze the view\\nvertically.\\nYou can also zoom in and out by pressing the + and - keys.\\nYou can specify an area to zoom in on using the magnifying glass. Clicking on the intersection will\\ndraw a square, giving a regular zoom. Pressing SHIFT at the same time will allow you to select a\\nrectangle so that the zoom action will change the vertical to horizontal ratio of the intersection.\\nFinally, in Viewport settings you can specify the XY-Scale and Z-scale for the vertical and\\nhorizontal ratio of the interpretation window.\\nTo move along the section while interpreting, the keyboard arrows can be used to pan the section\\nhorizontally and vertically.\\nYou can set a deterministic scale in the Viewport Settings.\\nDisplay wiggle traces in interpretation window\\nWhen displaying seismic intersections in an interpretation window, you have the option to display\\nWiggle traces . This option is accessed through the Style tab in the Settings dialog for the\\nseismic when an interpretation window is displayed. Options to fill negative and/or positive side of\\nthe traces, increase the gain (x scale) of the wiggles, and determine the number of traces shown\\nare all available. Wiggles traces are only available in the Interpretation window and in Well\\nsection window (Synthetic seismograms). The wiggle trace display will be interpolated.\\nInterpolation method - Interpolation options for bitmap and wiggle displays\\nShow bitmap - Enables you to view the seismic\\nShow Wiggle - Enables you to display in wiggle traces\\nFill positive - Fill the positive amplitude values. The right side is the positive and the left\\nside the negative amplitude.\\nFill negative - Fill the negative amplitude values.\\nInterval - Shows every n\\'th trace for display\\nManual gain - The maximum width of the trace. The traces overlap more if the setting is\\nhigh. Given in dB.\\nPosting data in an interpretation window\\nYou can display data objects in an Interpretation window from both the Input pane and the\\nModels pane. Examples of data objects you can display are well paths and logs, well tops,\\nhorizons and faults, 3D grid properties and zonation. The display style for objects is controlled\\nfrom the Settings dialog for the different seismic sections when an Interpretation window is\\nactive .\\nHow to set a distance limit for posted objects in an interpretation window\\nWhen posting objects like well data in an interpretation window, it is beneficial to limit the\\ndistance out to the data to be be displayed. It is only objects in the Input pane that can use a\\ndistance limit. 3D grid objects will be displayed where it intersects with the seismic section.\\n1. With a seismic section displayed in an interpretation window (and posted data like well\\ntops, paths and logs displayed), open the settings for the section. For 3D volumes, go to\\nthe settings for the Inline, Crossline, or Random line. For 2D lines, expand the seismic line\\nobject and open settings for the \"plane\" sub-folder (typically called Seismic 2D line 1).\\n2. Go to the Style tab, Input settings sub-tab.\\n3. Set the appropriate distance limit (in project units).\\n4. Click Apply to change the settings.\\nDisplay horizon interpretation in an\\nInterpretation window\\nAny interpreted points, either generated by interpreting the displayed seismic or on intersecting\\nseismic sections, can be displayed by selecting the interpretation object in the Input pane. The\\ndisplay style of the interpretation is controlled from the object\\'s Settings window.\\n1. Select the interpretation of interest from the Input pane. Select the check box in front of\\nthe name of the object.\\n2. Open the settings for the displayed interpretation. Go to the Style tab.\\n3. Under the 2D and 3D interpretation section, change between Points and Lines and set\\nsuitable parameters if it is interpreted on the displayed seismic object.\\n4. Complete the style settings, depending on what you want to display and if the\\ninterpretation is just intersecting the displayed seismic line, see the following how-tos.\\nThe display of a horizon interpretation in Interpretation windows is also controlled from the\\nInterp survey inclusion filters . This filter folder is found under the Seismic main folder and\\ncontains a Survey of seismic object that only works for Interpretation and Intersection windows\\n(it will be unavailable if a 3D or 2D window is active). The Survey of seismic filter ensures that\\nthe interpretation corresponding to the seismic survey displayed in the window is posted.\\nVisualize previous and next interpretation while\\ninterpreting\\nThe interpretation from neighboring lines can be projected onto the interpretation window while\\ninterpreting. The previous and next projections use the increment set in the General intersection\\nplayer.\\n1. Open the Settings window for the interpretation to be displayed.\\n2. Select to display the previous and/or the next interpretation in the Style tab under Neighbor\\nsections (3D only).\\n3. Adjust the plane step increment in the General intersection player, if needed.\\nHighlight points interpreted on intersecting\\nseismic sections\\nThe crossing points interpreted on intersecting sections are displayed in the interpretation window\\ndependent of type. 2D line interpretation is set differently from 3D cube interpretation which is\\nagain different from horizon interpretation performed on the displayed seismic itself. This is to\\ndifferentiate between the various sources of interpretation.\\n1. Open the settings window for the interpretation to be displayed. Make sure that the horizon\\nconsists of points intersecting the seismic section that is displayed in the Interpretation\\nwindow.\\n2. Select and set desired parameters under the section Crossing points in the Style tab.\\n2D: there are several options for display representation, size and color for crossing\\n2D line interpretation.\\n3D: there are also several options for line type and width for interpretation originated\\nfrom intersecting 3D surveys. The color display will follow the selection set under 2D\\nand 3D interpretation in the dialog.\\nAnnotate Horizon Interpretation in\\nInterpretation window\\nAnnotation for horizon interpretation is set for individual objects. There will be one single object per\\nhorizon and be left aligned to where the visible interpretation exists.\\n1. Open the settings window for the interpretation to annotate. Go to the Style tab.\\n2. In the Annotation section, select the Name check box and set the desired parameters.\\nOnly local interpretation is annotated (cross-posted interpretation is ignored). Annotation for new\\nhorizons is by default off.\\nTo set annotation for all horizon interpretations in the Petrel project, click and click the Apply\\nsettings to all similar objects icon.\\nDisplay grid lines (Time lines) in Interpretation\\nwindow\\nGrid lines to aid the interpreter can either be displayed as vertical and horizontal lines or crosses\\nin the Interpretation window. When displayed, grid lines will be layered on top of all regular\\ngraphics.\\n1. Navigate to the active Interpretation window in the Windows pane.\\n2. Expand the Interpretation window folder and the Interpretation 1 sub-folder.\\n3. Select the Grid lines check box.\\n4. To change the appearance of the grid, right-click on Grid lines and select Settings . Go to\\nthe Style tab.\\n5. Select to display Lines or Crosses and set the appropriate parameters for the selection.\\nIntervals between each grid line can either be set as ticks or fixed in project units.\\nGrid lines are supported for horizon flattening and will be distorted in accordance with the\\namount of flattening of the seismic.\\nDisplay Scale bar in an Interpretation window\\nThe scale bar can be switched on/off from the Windows pane by selecting/clearing the check\\nbox.\\nDisplay cultural data as curtain intersections in\\nInterpretation window\\nCultural data in the form of polygon lines can be drawn as intersections in X/Y as vertical lines\\n(that is, ignoring z-values of the polygon). It is supported for vertical interection planes only, and\\ncan be used for intersection windows as well.\\n1. Display the cultural data polygon in the active Interpretation window.\\n2. Open settings for the polygon and go to the Style tab.\\n3. Tick-mark Show vertical curtain intersections only under th Lines section.\\n4. Set the appropriate parameters and Apply the selection.\\n3.\\n4.\\nBy using Show vertical curtain intersections only , standard line/point projection is\\nexcluded.\\nStandard domain rules apply if the polygons are attached to a domain-specific template (that\\nis, the domain of the polygon must be in Elevation time if displayed on conventional time\\nmigrated seismic).\\nAnnotate CDP/SP for 2D lines in Interpretation\\nwindow\\nWhen displaying a seismic 2D line in an interpretation window, the line and trace numbering is\\nused by default. This can be customized to display CDP and/or SP numbering.\\n1. Open settings for Interpretation 1 under the active Interpretation window (Windows\\npane in the Petrel Explorer). Go to the Style tab.\\n2. Set SP and CDP independently for the upper and lower numbering pull down menus.\\n3. Click Apply to change the annotation in the active window.\\nDisplay and annotate Fault Interpretation in an\\nInterpretation window\\nDisplay and annotation of fault interpretation is very similar to horizon interpretation. There will\\nbe one single label per fault object, even if multiple segments are visible. The annotation will be\\ncentered above the visible top of the segment.\\n1. Tick mark the fault to display with an Interpretation window active. Make sure the fault is\\ninterpreted or intersecting the triangulated fault plane.\\n2. Open settings window for the fault interpretation to annotate. Go to the Style tab.\\n3. Select the Show check box and select the desired settings under the section Name .\\nFault interpretation is annotated as points, lines or surface intersections. Annotation for new\\nfaults is by default off.\\nTo set annotation for all fault interpretations in the Petrel project, click and apply the Apply\\nsettings to all similar objects icon.\\nProject Fault Interpretation in Interpretation\\nwindow\\nThe fault interpretation from the neighboring lines can be projected onto the Interpretation\\nwindow while interpreting. The projection use the increment set in the General intersection\\nplayer.\\n1. Open the settings window for the fault interpretation to annotate. Go to the Style tab.\\n2. Select the Show check box in the Line projections section and set the desired\\nparameters.\\n3. Adjust the plane step increment in the General intersection player, if needed.\\nFlip a seismic section in Interpretation window\\nWhen you are in an Interpretation window, do the following to flip a displayed seismic section 180\\ndegrees:\\n1. Click on the Align camera with plane/flip window icon to redisplay the section in\\nthe opposite direction.\\n2. Click one more time on the same icon to display the seismic section in its original direction.\\nSynchronize two interpretation windows\\nHow to synchronize two interpretation windows for zoom and pan\\nWith two (or more) Interpretation windows displayed in Petrel, they can be synchronized for\\nzooming and panning. The different Interpretation windows can display inlines, crosslines, random\\nlines and 2D lines from different surveys and still behave in a synchronized way.\\n1. Display more than one Interpretation window.\\n2. Identify the Interpretation windows to synchronize in the Windows pane. Expand each\\nInterpretation window folder and open the settings for the Interpretation 1 sub-\\nfolders.\\n3. Go to the Settings tab for each window.\\n4. In the Linked to coordinate group pull down menu, select a common group for all\\nwindows (e.g. First) and apply the changes.\\n5. Display the Interpretation windows side by side and pan, zoom or strech/squeeze the\\nseismic inside one of the windows.\\nHow to synchronize two interpretation windows for scrolling\\nWith two (or more) Interpretation windows displayed in Petrel, they can be synchronized for\\nscrolling. The different interpretation windows can display inlines, crosslines and random lines\\nfrom the same survey, the prerequisite is that the line to be displayed and used for scrolling must\\nexist in two (or more) vintages of the seismic volume.\\n1. Display more than one Interpretation window.\\n2. Display the same (in-, cross- or random-) line in all windows, zoom and pan the windows\\nso they look similar.\\n3.\\n4.\\n1.\\n2.\\n3. Activate the second (and third, etc.) interpretation window and click on the vintage of\\npreference (for example, an attribute version of the original volume) to display.\\n4. Display the interpretation windows side by side and scroll through the seismic in one of the\\nwindows.'},\n",
       " {'header': 'Ghost ',\n",
       "  'content': \"The Ghost curve is used to create a small bitmap of reflector events on a seismic line from the\\nsame seismic display or from a different seismic volume showing different attributes. The area\\ncan be moved to other parts of the same seismic line (or other seismic lines) to compare signal\\npatterns and identify the same horizons across a fault. For example, when a ghost is created it\\nwill be located in the seismic interpretation window folder in the Windows pane.\\nThe seismic in the interpretation window and the ghost, share the interpretation window display.\\nIf you click on the ghost in the interpretation window, you will notice that the ghost is activated in\\nthe Windows pane. If you click on the seismic displayed in the interpretation window, you will\\nnotice that the Interpretation 1 in the Interpretation window is activated. In practice, this\\nmeans that you can have different settings for the ghost and the seismic in the interpretation\\nwindow. For example, the ghost can be displayed with wiggles or another attribute, while the\\nseismic in the interpretation window is displayed in a conventional mode.\\nIn the Windows pane, you can toggle the ghost on or off, delete ghosts and access the\\nsettings for the ghost. Note that you can have as many ghosts as you like.\\nHow to create a ghost correlation tool\\n1. While in an interpretation window, click on the Ghost icon in the function bar to activate\\nthe tool.\\n2. Use the mouse in the interpretation window to drag the area where the ghost is generated.\\n3. The ghost is situated under the Interpretation window in the Windows pane.\\nHow to move and update a ghost\\n1. The size of the ghost can be changed by dragging the borders using the single arrow mode\\n(move mouse over the edge of the ghost).\\n2. The ghost is moved by using the crossed arrow mode (point with the mouse over the ghost\\nitself).\\n3. To rotate the ghost, press CTRL and SHIFT at the same time as you click with the mouse\\nbutton and move the mouse inside the ghost display.\\n4. Move the mouse inside the ghost area in the interpretation window and click with the right\\nbutton.\\n5. The image inside the ghost is updated with the seismic beneath it.\\n5.\\nDisplay ghost with wiggles\\nIt is possible to only change the display of the ghost, while not influencing the seismic in the\\nInterpretation window.\\n1. In the Windows pane, locate the ghost under the seismic Interpretation window and\\nclick on it to activate.\\n2. In this mode, the display settings you choose are only influencing the ghost and not the\\nunderlying seismic display.\\n3. Open the settings for the seismic displayed by double-clicking on the seismic that is toggled\\nto be displayed in Input pane (crossline/inline for a 3D volume, or a 2D line in any 2D\\nseismic folder).\\n4. Go to the Style tab for the seismic and select to display wiggles. See wiggle trace display\\nfor more info.\\nHow to display interpretation with annotation in a ghost correlation tool\\n1. With the ghost active, tick-mark any horizon interpretation and fault interpretation that\\nintersects the ghost.\\n2. To annotate a horizon and fault interpretation, open the object's respective settings dialogs.\\nGo to the Style tab and activate the annotation.\\nDisplay ghost with a different attribute\\nIt is possible to only change the display of the ghost, showing a different attribute such as RMS\\namplitude or velocity cube.\\n1. In the Windows pane, locate the ghost under the seismic Interpretation window and\\nclick on it to activate (make it bold ).\\n2. In this mode, the display settings you choose are only influencing the ghost and not the\\nunderlying seismic display.\\n3. Display the attribute cube you have from the Input pane by toggling on the icon in front of\\nan Inline or Xline.\\nIntersection window used for seismic display\\nThe Intersection window can be used to display seismic data. The normal display window for\\n2D seismic intersections is the Interpretation window, but in many ways the Intersection\\nwindow behaves very similar but with some major exceptions.\\nThe display style for the seismic object displayed is comparable to the same object displayed in an\\nInterpretation window. But no interpretation of the seismic can be done and crossing seismic\\nintersections cannot be selected from the intersection window. Another difference is that any\\ndisplayed seismic can be deselected by clicking off the mother seismic object (for example, the\\nseismic volume if an inline or a crossline from the volume is displayed as the intersection). In this\\ncase, the general intersection is used (void of seismic data) and objects displayed on it is still\\nseen.\\n3D window for seismic visualization and\\ninterpretation\\n3D windows are a convenient way to visualize and interpret seismic data in any direction and are\\nan essential tool for quality control of the interpretation. For example, inline, crossline, time slice\\nand random lines (vertical intersection) of specific attributes can be displayed to detect and\\nvisualize certain substructures.\\nWith Petrel, you can also force the view of the plane to be true 2D in a 3D window.\\nThe appearance of seismic 3D volumes and 2D lines, and the parameters that controls it, is\\ndescribed under Seismic data (Settings).\\nHow to use a 3D window for 2D basemap\\ndisplay\\nA basemap view of 2D seismic lines can be displayed in 3D windows.\\n1. Display all 2D lines under a survey folder in the active 3D window.\\n2. Open settings for the survey folder, go to the style tab.\\n3. Make sure Basemap style and Z level are tick marked.\\n4. With the Seismic interpretation process active, use the Select line to display in\\ncurrent or last 3D/Interp window icon and click on any of the lines representing the\\nbasemap view of the 2D seismic lines.\\n5. If multiple vintages (e.g. mis-tie corrected versions) exists, the order and active selection\\nin the Vintages folder is used when displaying a 2D line.\\n6. With the seismic 2D line displayed, click on the seismic intersection again using the same\\nicon to remove it from view.\\n7. To select the line to display in the last used 3D/Interpretation window, press Shift on the\\nkeyboard and left-click while using the Select line to display in current or last\\n3D/Interp window icon.\\n8. In the style tab, give in another Z level value (e.g. -1000) and see the vertical position of\\nthe lines change.\\n8.\\nBy deselecting the Basemap style, the 2D lines will appear as empty sections showing the\\nvertical extent of the lines (instead of only the line trace). Display/undisplay of the sections still\\nworks as described above. To display all 2D lines in a folder, right click on the Survey folder and\\nselect View seismic from the appearing menu.\\nHow to visualize the seismic lines in 2D view\\nwithin a 3D window\\nThe Align camera with plane icon, when toggled on, the camera is moved to directly face\\nthe currently active intersection. The camera will then remain locked to the plane: Attempting to\\nrotate the view will result in panning, and moving the plane will result in a corresponding move of\\nthe camera.\\nTo avoid perspective distortion of Seismic Intersections:\\n1. Turn on the Clip in front of plane or Clip behind plane.\\n2. Click on Orthogonal on/off in the upper Tool bar.\\nHow to clip the 3D seismic display for\\ninterpretation\\nTo avoid disturbance of interpreted data on intersection planes behind or in front of the actual\\nplane the following functions will help:\\nClip behind plane .\\nClip in front of plane .\\nReference Datums for Onshore Data\\nPetrel will support a seismic reference datum (SRD) different from mean sea level (MSL). This\\nmeans that Petrel now can import more checkshot data through OpenSpirit than previous\\nversions.\\nFor Datum settings in Petrel, see also Units and coordinates tab (project settings).\"},\n",
       " {'header': 'Acronyms ',\n",
       "  'content': 'PRD: Project reference datum\\nSRD: Seismic reference datum (used by Petrel)\\nMSL: Mean sea level (used by Petrel)\\nCDD: Checkshot depth datum\\nCRD: Checkshot reference datum (used by Petrel)\\nKB: Kelly bushing (used by Petrel)\\nETZ: Elevation at time zero\\nV2SD: Velocity to seismic reference datum\\ndTWT: Time shift between SRD and ETZ\\nTDR: Time depth relationship\\nGF: GeoFrame\\nOW: OpenWorks\\nOSP: OpenSpirit\\nDifferent Reference datums\\nMSL - In Petrel the project reference datum is always MSL, while e.g. in GeoFrame, the project\\ndatum can be defined by the user, but is normally MSL.\\nPRD - The project reference datum is the fundamental elevation reference for all data in a\\nproject. In addition, other convenient reference datums can be used, but they will all be defined\\nas the elevation (vertical measurement) from the project reference datum.\\nSRD - for offshore projects it is normally MSL, but as illustrated below, MSL may not be an\\noptimal reference for onshore data with an altitude high above MSL. Worldwide, there are also a\\nfew areas where SRD can be below MSL.\\nFigure 1. SRD and MSL\\nWhen checkshot data is acquired (and processed), there are two important reference datums to\\nbe aware of:\\nCDD - Checkshot depth datum, defines the reference level for the checkshot depth values.\\nIn GeoFrame it is important to be aware that all depth values for the checkshot data are\\nreferenced to the given CDD value and not to KB (or another working datum).\\nETZ - Elevation at time zero; in theory, this is the elevation of the seismic source used in\\nthe checkshot survey (the seismic travel time to a receiver at this level is zero), but during\\nprocessing the checkshot time values may have been converted to another specified level.\\nThese two datums may be equal to KB, but can generally be different. It is critical that you\\nknow how the checkshot data has been acquired and processed before loading any checkshot\\ndata into Petrel or GeoFrame.\\nFigures 2 a and b illustrate two situations where CDD and ETZ are above and below the SRD. It is\\nimportant to understand that while CDD and ETZ represent physical datums for the checkshot\\nmeasurements, the SRD is an \"artificial\" processing datum.\\nFigure 2. CDD, ETZ and SRD\\nIn OpenWorks the checkshot depth datum and the elevation at time zero is one common datum\\n(meaning that CDD=ETZ).\\nIn GeoFrame the SRD is a project setting that can be changed after the checkshot data has been\\nloaded and it is completely independent of the checkshot data itself.\\nOpenWorks does not contain a SRD since this value is defined in the actual SeisWorks project\\n(several SeisWorks projects can be connected to the same OpenWorks project). However, it is\\nrequired that all time depth tables (checkshots) must reference a single time datum. This means\\nthat for OpenWorks/SeisWorks projects the seismic reference datum (SRD), the checkshot depth\\ndatum (CDD) and the checkshot time datum (ETZ) must all be equal!\\nIn Petrel the SRD setting must be defined before checkshot data is imported since the actual\\nSRD value will be used during the checkshot import. By changing the SRD value after the import\\nof checkshot data, the time-depth relationship for existing wells will not be changed. This means\\nthat the TDR will not match the new SRD!\\nConversion between reference levels\\nWhen handling wells in Petrel, the SRD value will only affect the checkshot time values; all depth\\nvalues will always be referenced to MSL.\\nIt is also important to be aware of the following differences between GeoFrame and Petrel:\\nPetrel will apply the depth and time conversions during import (as opposed to GeoFrame\\nwhere the conversions are applied on the fly)\\nIf the SRD is changed in Petrel, it will only affect the data imported after the change. This\\nmeans that all checkshot data loaded before the change is no longer correct and should be\\nre-imported!\\nFor OpenWorks/SeisWorks data all the reference levels are assumed to be identical, meaning that\\nno depth or time conversion is necessary (assuming that Petrel SRD equals SW SRD).\\nConversion of time values\\nIf SRD is not equal to ETZ, the checkshot time values must be converted from the ETZ level to\\nthe SRD level. This means that a constant time shift must be applied to the checkshot time\\nvalues.\\nGeoFrame (and Petrel) will estimate this time shift differently depending on whether ETZ is\\nabove or below SRD.\\nOpenSpirit will not perform any shift of the checkshot time data; meaning that ETZ will always be\\nthe reference datum for the checkshot time values. Petrel will receive the GeoFrame replacement\\nvelocity (V2SD) from OpenSpirit.\\nPetrel has implemented the same logic as GeoFrame and will, if necessary, convert the checkshot\\ntime values to the Petrel SRD.\\nPlease note that in general, the SRD in the original datastore and Petrel do not need to be\\nequal. However, if they are different, the replacement velocities used in the GeoFrame project\\nmay not be optimal. In this case you may want to import the checkshot data from ASCII files\\nsince the replacement velocities can then be re-defined.\\nIn OpenWorks it is possible to define a time shift value associated with the checkshot data (time\\ndepth table). Petrel will read and can optionally apply this time shift. By default, the time shift is\\nnot applied, but this can be changed in the OpenSpiritMapping.xml file (must be done before\\nstarting Petrel).\\nPlease be aware that if the Petrel SRD is different from the SeisWorks SRD, the\\ncheckshot time data will be shifted according to the rules described in the next section.'},\n",
       " {'header': 'ETZ > SRD ',\n",
       "  'content': 'This situation is illustrated in figure 2.a and normally, since checkshot data will exist below SRD, it\\nis possible - based only on the checkshot data itself - to calculate the time shift between ETZ and'},\n",
       " {'header': 'SRD. ',\n",
       "  'content': 'The time shift (dTWT) can be calculated as:\\ndTWT = - TWT(i) - 2*[TVDSS(i)-SRD]/Vint\\nwhere:\\ni = the first checkshot above SRD\\nVint = the interval velocity between checkshot i and i+1(if no checkshots above SRD, Vint is\\ncalculated from ETZ, where TWT = 0))'},\n",
       " {'header': 'ETZ < SRD ',\n",
       "  'content': \"This situation is illustrated in figure 2.b and in this case, additional information must be supplied\\nin order to estimate the time shift. In GeoFrame this additional information is given as the\\nVelocity to Seismic datum (V2SD) parameter.\\nThe time shift (dTWT) can then be calculated as:\\ndTWT = 2*[SRD-ETZ]/V2SD\\nIn Petrel, if the V2SD value from OpenSpirit is zero (or not defined), a pop-up will appear and you\\ncan manually enter a replacement velocity.\\nConversion of depth values\\nThe conversion of the checkshot depth values from CDD to any other reference datum is given\\nby the difference between the CCD value and the reference datum.\\nOpenSpirit will shift the checkshot depth values to the ETZ level (if CDD not equal to ETZ).\\nPetrel will always shift the checkshot depth values to MSL (if ETZ not equal to MSL).\\nPetrel (current version) versus pre-Petrel\\n2007.1\\nPre-Petrel 2007.1 (i.e. Petrel 2005 and earlier versions) has not implemented the functionality to\\nperform any depth or time shifts of the checkshot data. This means that checkshot data with\\nETZ=0 cannot be treated properly, so pre-Petrel 2007.1 will not import such checkshot data (they\\nwill be blocked and a warning will be given).\\nCheckshot data in GeoFrame can contain both TVD and MD values. Petrel will use the checkshot\\nTVD values as is, but will use the well's deviation data to re-calculate the corresponding MD\\nvalues.\\nIn Petrel, the OpenWorks time shift value can be applied during import. To enable this option,\\nyou must change a setting in the OpenSpiritMapping.xml file before starting Petrel.\\nP2005 regression issue\\nIn Petrel 2005 build 21 December 2006 the same logic as in Petrel 2007.1 and newer versions has\\nbeen implemented.\\nTime-depth relationship\\nIf a checkshot with no information at the MSL was imported into Petrel 2005, an artificial depth\\ntime pair was inserted at MSL (TWT=0) . This logic (which was implemented only for OpenSpirit\\nimport) has been changed in Petrel 2007.1 and later versions, where an artificial depth time pair\\nis inserted in the General time log at the SRD (if not existing in the checkshot data).\\nASCII loaded checkshot data\\nIn Petrel, the checkshot data imported through OpenSpirit is handled similarly to checkshot data\\nimported from ASCII files, than in previous versions of Petrel. This means that if a user imports\\ncheckshot data from files - containing the same CDD, ETZ, V2SD and checkshot data as in\\nGeoFrame, the result in Petrel should be exactly the same as if the data were imported through\\nOpenSpirit.\\nThe only exception is that the file import dialog will always require the user to supply either a time\\nshift or a replacement velocity. Since GeoFrame doesn't require this information when ETZ >\\nSRD, the checkshot data imported through OpenSpirit will follow the same logic as in GeoFrame.\\nExport of checkshot data\\nWhen checkshot data are exported from Petrel to GeoFrame or OpenWorks (through OpenSpirit)\\nthe following datum settings will be used:\\nIf exporting back to an existing checkshot, the checkshot data will be converted back to the\\noriginal CDD and ETZ datums.\\nIf exporting to a new checkshot in:\\nGeoFrame: the CDD will always be zero, but ETZ will be set to the original ETZ value\\n(if imported through OpenSpirit)\\nOpenWorks: the datum will be set to the original datum value (if imported through\\nOpenSpirit)\\nDefining CRD\\nThe Checkshots Reference Datum (CRD) cannot be pre-defined in Petrel. It is a well specific\\ndatum and has different values from well to well. It is defined if/when check shot data is imported\\nand datums are specified based on CRD.\\nNote that CRD is well specific and has no editable entries under its Settings.\\nDefining SRD\\nIn Petrel the Seismic Reference Datum (SRD) can be set at the start of a project, much the\\nsame way as units and coordinates. The distance from MSL can be set in the Datum settings of\\nthe SRD. All pre-definded datums are found under the Datums folder in the Templates pane\\n(see fig. 1).\\nFig. 1 Datums folder in the Templates pane\\nOpen the settings for SRD and enter the depth shift from MSL (depending on the units set in the\\nProject settings).\\nNote that SRD is a regional datum and only one common seismic reference datum can exist\\nin a Petrel project.\\nAlso note that only Z from MSL can be edited. This is the seismic starting point, meaning\\nthat zero time for all surveys will coinside with the SRD. If not, the vertical geometry of the\\nvarious surveys must be edited. See Geometry tab (Seismic data) for more information.\\nDefining a user specified datum\\nYou have an option to make one (or more) user defined datums if none of the pre-defined datums\\nare sufficient. Right-click on the Datums folder in the Template pane and select Insert new\\ndatum.\\nSpecify the type of datum and enter the parameters. It can be renamed under the Info tab to a\\nmore suitable name if needed.\\nIf Time datum is selected for input, it can either be given as TWT from SRD or as\\nReplacement velocity .\\nUsage of datum while importing checkshots\\nWhen you import checkshots, you can select SRD (Seismic reference datum) or CRD (Checkshot\\nreference datum) as Time datum and Depth datum in the import dialog.\\nIf you select SRD for either datums, Petrel will use the value as specified under the settings for\\nSRD (returned in the greyed out fields in the dialog).\\nIf you select CRD for either datums, the input fields will be activated for manual editing (opens\\nwhite fields in the dialog box).\\nFor Depth datum, other options are also available (MSL, KB, and user defined).\\nDatums used when creating a velocity model\\nWhen you create a new velocity model, you can select the relevant datum input. The default\\ndatum in the Make velocity model process is Time datum using SRD (as defined in SRD\\nsettings). If a user defined datum exists, it can be selected as Time datum in the pull-down\\nmenu. If you select Other as datum , user interaction is required.\"},\n",
       " {'header': 'Synthetic Seismograms ',\n",
       "  'content': 'Synthetic seismograms are the bridges between geological information (well data in depth) and\\ngeophysical information (seismic in time). This essentially involves a two-step process:\\n1. Time converting the wells by means of check shot data and sonic logs, establishing\\ntime-depth relationships for the wells.\\n2. Generating synthetic seismograms from density logs, sonic logs and a seismic wavelet\\nby calculating acoustic impedance and reflection coefficients, which are then convolved\\nusing a wavelet.\\nAny changes to the time-depth relationship can be made and seismic horizons can be correlated\\nwith the stratigraphic boundaries identified in the well logs.\\nPetrel offers two different processes to essentially achieve the same goal; generating synthetic\\nseismograms that can be used as a starting point for seismic interpretation. The pre-Petrel\\n2009.1.1 Synthetics process (found under the Stratigraphic modeling processes) is continued\\nin this version and exists side-by-side with the new Seismic well tie process (found under the\\nGeophysics processes).\\nSeismic well tie\\nThe Seismic well tie process, found under Geophysics in the Processes pane, is one out of\\ntwo approaches to generating synthetic seismograms in Petrel. This new process was introduced\\nin Petrel 2009.1.1, however, the pre-Petrel 2009.1.1 Synthetics process still exists in the current\\nversion.\\nIn the Seismic well tie process, interactive sonic calibration, wavelet extraction and building, as\\nwell as interactive stretch and squeeze of time-depth curves can be performed.\\nAny object made in the Seismic well tie process can be saved back to the Input pane.\\nVelocity panel, reflection coefficients, synthetic seismogram, and sampled seismic for a well log .\\nLog editing for input into synthetic\\nseismograms\\nBuilding synthetic seismograms requires continuous and reliable log data along the entire length\\nof the borehole. Damaged logs will create errors in the time depth relationship or artificial\\nresponses in the synthetic seismogram. In the majority of cases, logs will require some\\nconsiderable editing before they can be used to create synthetic seismograms. It is advisable to\\ncreate a copy of the original log, and then edit the damaged areas and interpolate missing areas\\non the copied version. A copy of the log is easily made using the calculator (right-click and select\\nCalculator on the appropriate log). See image below.\\nFig. 1 Well log calculator\\nProblems with the sonic log are perhaps the most critical as the log will be integrated to create a\\ntime depth relationship for the well. Any errors in the log will be propagated throughout the time\\ndepth relationship (at least to the next checkshot). One commonly required edit with regards to\\nsonic logs is despiking. Despiking is achieved using the Log editor (right-click on the log to be\\ndespiked and select Log editor). Choose Despike under the Action #1 column, and set the\\nparameters for the despiking (Standard Deviation and Length).\\nFig. 2 Well log editor - despiking a sonic log\\nLog editing must be done properly. Poor editing will result in an inconsistent time depth\\nrelationship and artificial responses in the synthetic which make an accurate correlation\\nimpossible.\\nWhat causes problems in the sonic log\\nProblems in the sonic log can be caused by:\\nLow transmitter strength - Results in low amplitude responses at the receiver and under\\nextreme conditions, cycle-skipping. This in turn causes generally poor quality and noisy logs. How\\nsuch problems are repaired depends very much on the specific effect.\\nRoad noise - High frequency noise generated by the tool moving along the borehole. This results\\nin random spikes of varying amplitude which must be either clipped or removed manually.\\nAttenuation - Reduced amplitude of the compressional acoustic wave. This is probably the major\\ncause of poor logs and is caused by:\\n1. Low formation velocity - energy is continually refracted back to the borehole during the\\nwave\\'s transit, longer travel times mean more attenuation.\\n2. High porosity - poor grain-grain connections in high porosity layers means that energy is\\ntransmitted to the much slower fluid. This effect is most common at shallow depths.\\n3.\\n4.\\n2.\\n3. Shale content - In laboratory experiments a substantial decrease in signal amplitude has\\nbeen noticed with the addition of small amounts of clay to the formation.\\n4. Thin beds - Reflection and refraction of the wave at bed boundaries attenuates the signal.\\n5. Near borehole alteration - Drilling fluids can cause alteration close to the borehole, reducing\\nthe formation velocity and resulting in refraction and reflection of the wave as it passes in\\nand out of the altered section.\\n6. Non-centered tool - Receiver readings diminish with distance to the formation, so a non-\\ncentered tool can significantly affect the response.\\n7. Borehole rugosity - Energy is lost as the wave is constantly diffracted on the rough borehole\\nwalls. This results in a much longer effective transmitter-receiver spacing, resulting in a loss\\nof signal strength. This rugosity is often caused by alteration of the drilling mud, resulting in\\na number of the other factors listed above.\\n8. Fractures - Acoustic waves meeting fluid filled fractures are transmitted into the fluid phase\\nand then back again. Reflection at both of these boundaries results in considerable loss of\\nenergy.\\n9. Hydrocarbons - gas in high porosity formations causes considerable attenuation of the sonic\\nwave, resulting in anomalously high transit times.\\nWith the amplitude of the wave much smaller, the threshold amplitude for the receiver to register\\nthe arrival is reached much later. This in turn means that velocity is underestimated, resulting in\\n\\'dt-stretch\\', which can be up to 6 usec/ft, as well as an overestimation of porosity of up to 0.05%.\\nIn severe cases, the compressional wave may not be registered at all and the shear wave will\\nappear as the first arrival. This appears on the log as the familiar and easily recognized cycle-\\nskips, where the transit time is obviously much too high, and often has a \"spiky\" appearance.\\nWhat to look for\\nThere are a number of things to look for when QC\\'ing a sonic log for use in generating synthetic\\nseismograms.\\nNever use a raw sonic log - this is unlikely to give useful results.\\nCompare the log with reference logs such as calipers and gamma ray. Areas of \"washout\"\\nwill require editing. Changes due to geology should be correlatable between logs.\\nLook for spikes and abrupt changes in the log. These may be errors and will have a\\nsignificant impact on the resultant seismogram.\\nReplace undefined areas with interpolation from other logs or average values, alternatively\\nuse Neural Nets to generate log values from other wells.\\nCheck the log statistics for extraneous values, typical sonic should lie within 40 to 140 us/ft.\\nCheckshot editing\\nOnce checkshots have been imported (see Import checkshots ) they can be displayed using the\\nSpreadsheet icon , and edited manually.\\nThis is done either by clicking on a cell in the depth or time columns and updating the value, or by\\nmarking the entire row before deleting the entry.\\nMultiple checkshots objects can be merged using the Append points with attribute\\noperation , found in the settings dialog of the checkshots data.\\nAn even better way of displaying and editing the checkshots is to open a new Function window,\\ncrossplot attributes (for example, Z vs. Vint) from the checkshot object and try to identify outliers\\nor abrupt changes in the data set. Use the Select and edit/add points icon (Short cut key E\\n) and click on any point of interest in the function window. The selected entry will be marked in\\nthe spreadsheet and is easy to delete.\\nNote that checkshot data is hard facts, so you need good reasons before you do any\\nextensive editing of the data.\\nWhen the quality check and edit is finalized, the checkshots can further be used in calibrating\\nsonic logs or to directly establish time depth relationships in wells.\\nCreate a log set\\nThe log input used in the Seismic well tie process is not individual logs, but a log set that is\\ncreated well-by-well. Basically, this means that seismic well ties are done for individual wells.\\nA log set can contain all of the logs in a well, independent of type (that is, resistivity, gamma ray,\\nspontaneous potential, etc.). However, only sonic and density logs will be used as input into the\\nSeismic well tie process. All other log types can be displayed in auxiliary log tracks.\\nHow to create a log set\\n1. Right-click on the well of interest, select Insert new log set from the menu.\\n2. Open the settings for the newly created Log Set 1.\\n3. Go to the Components tab, select logs from the Available Logs list and click Add to put\\nthem in the Selected Logs list. Click OK.\\n2.\\n3.\\nSeismic well tie process dialog\\nThe Seismic well tie process is a plug-in that comes with the Petrel installer. The process is\\naccessed from the Geophysics folder on the Processes pane.\\nLaunching the process will open the Seismic well tie process dialog and give you access to the\\nfollowing workflows, each sorted under its own tab:\\nSonic calibration\\nWavelet extraction\\nWavelet viewer\\nWavelet builder\\nEach tab contains a graphical explanation of the workflow and has a button to launch a new\\nworkflow window at the bottom.\\nThe same workflow windows can be accessed by using the available icons in the Function bar\\nwhen the Seismic well tie process is active. Dependent on what window is open, a set of icons\\nto handle the display is available.\\nNote the Seismic well tie process dialog will not be displayed if the Function bar icons are\\nused to open the workflow windows.\\nSonic calibration\\nThe sonic calibration workflow used in the Seismic well tie process, includes the ability to edit a\\nknee curve based on time-depth information (typically checkshots data), interactively do sonic\\ncalibration and view the resulting calibrated sonic log while editing. It is also possible to redefine\\nthe datum (datuming) in the process and specify the output after calibration.\\nUsers who are familiar with the Synthetics process in Petrel will experience expanded\\nfunctionality in controlling the calibration process.\\nYou can access the Sonic calibration window from the Seismic well tie process dialog and\\nclicking on the button on the Sonic calibration tab. If the Sonic\\nwell tie window is not open, it can be directly accessed by using the Sonic calibaration icon\\nin the Function bar (given that the Seismic well tie process is active).\\nSonic calibration workflow\\nThe Sonic calibration workflow is graphically described in the display area of the Seismic well tie\\ndialog, under the Sonic calibration tab.\\nOpen a Sonic calibration window to perform this workflow. You can eiter use the icon on the\\nFunction bar or access it from the Seismic well tie process dialog. The window will be empty\\nuntil a Log set is selected to use. The log set is selected by selecting the check box or dragging it\\nfrom the Input pane.\\nNote that the windows used in the Seismic well tie process are not accessible after Petrel\\nis closed down. Make sure to finalize the workflow and output all needed results back to the\\nInput pane before closing down Petrel.\\nSonic calibration workflow\\nHow to perform sonic calibration using the Seismic well tie process\\nWith the Seismic well tie process active, do the following steps to produce a densely sampled\\ntime-depth curve for your well of interest:\\n1. Open a sonic calibration window.\\n2. Click one time on a well tops set (the name in bold text) to make it active.\\n3. Drag Log set 1 into the sonic calibration window.\\n4. Go to the Datuming tab, change the reference level if needed.\\n5. Go to the Knee picking tab. Make sure Move and add knees is selected.\\n6. Click on Create knees at checkshots.\\n7. The drift curve points (blue) will adopt to the checkshots (black).\\n8. Click on any of the blue points and move it to another position (observe that the calibrated\\nsonic log will update accordingly).\\n9. When satisfied with the result, go to the Output tab.\\n10. In the Depth/time field, select Continous and click on Output to store it back into the\\nInput pane.\\n11. Open the settings for the current well, go to the Time tab.\\n12. Click on Override global settings and select the newly created object as TDR for the well\\nSonic calibration input\\nWhen selecting an appropriate log set to use in the sonic calibration workflow, the window is\\npopulated with a sonic track and the checkshots/knee log track as well as any selected auxiliary\\nlog tracks. The Sonic calibration variables and settings dialog will open up.\\nIf multiple checkshot objects exist for the well, a selection dialog will open up and prompt\\nyou for a selection.\\nThe Input tab of the variables and settings dialog shows the current well name, any active well\\ntops as well as any log set and checkshot object used. All settings are initiated when you select\\nthe log set.'},\n",
       " {'header': 'Datuming ',\n",
       "  'content': 'On the Datuming tab, you can set the reference levels and datum for the input data. A drop-\\ndown menu gives you the option of specifying the current well to be onshore (Land ) or offshore\\n(Marine ). The graphic display example will change accordingly. By default, the Seismic well tie\\nprocess picks up the project datum, however, this can be changed here.\\nThe addition of multiple reference datums options to SRD as replacement velocities enable you to\\nwork with checkshots above the top of the log in a flexible manner. These added well attributes\\nand datums are persistent.'},\n",
       " {'header': 'Depth Time ',\n",
       "  'content': \"The Depth time tab gives you control when you are working with checkshots above the top of\\nthe log.\\nOptions for checkshots usage:\\nThese options define how far above the top of the log the checkshots will be used in order to\\ndefine the shallow interval velocity trend.\\nOnly use checkshots: The interval velocity trend to come entirly from the checkshot.\\nJust above shallowest checkshot: The interval velocity trend to come from checkshots\\njust above shallowest checkshot point then the values specified in the Datuming tab are\\nused.\\nUp to sea surface:The interval velocity trend to come from checkshots up to sea surface\\nin marine case, then he values specified in the Datuming tab are used.\\nUp to sea bed: The interval velocity trend to come from checkshots up to sea bed in\\nmarine case, then the values specified in the Datuming tab are used.\\nDon't use checkshots above TOL: The interval velocity values specified in the Datuming\\ntab are used regardless the checkshots.\\nUser: User defined threshold depth value to start using the values specified in the\\nDatuming tab.\\nInterpolation type above Top Of Log:\\nThe type of interpolation between the lowest datum layer and the top checkshot (or TOL) can be\\nset to Linear, Quadratic or Cubic spline.\\nIf you use Cubic spline as the interpolation type, you can choose to Use datuming velocity or\\nCalculate automatically for Velocity to use at start of interpolation and Interpolation\\nvelocity at top of log parameters.\\nKnee picking\\nKnee picking is the actual workflow where the sonic log is calibrated to the checkshots for the\\nwell. This is obtained by fitting the drift curve (the knee log) to the checkshot points and/or well\\ntops. The drift curve can interactively be changed to optimize the time-depth relationship or the\\ncalibrated sonic log.\\nInterpolation methods for both Knees and Reisdual drift are\"},\n",
       " {'header': 'Linear Cubic Spline ',\n",
       "  'content': 'Sonic calibration Display tab\\nThe log curve and data point appearance is handled from the Display tab. Also the density and\\nresidual drift can be shown.\\nSonic Calibration will display up to 6 logs that are part of the LogSet in the Input tab. Other logs\\nthat are part of the LogSet can be dropped in to the \"Other\" fields'},\n",
       " {'header': 'Auxiliary Log Tracks ',\n",
       "  'content': 'Any log tracks can be moved using the Track order on the Display tab. This gives you the\\nflexibility to set up the display as you like.\\nSpecific log tracks have been added;\\nInput Log track displays Sonic, RHOB and CSON\\nDrift and Residual Drift has its own dedicated track\\nDepth track displays depth/time curve and interval velocities\\nAuxiliary tracks can be used for displaying other logs\\nCALI, Sw and GR curves will be automatically displayed on selection in Wavelet Extraction if\\nthey are part of the LogSet\\nAn auxiliary log can be added to the logset in the same way as Sonic and Density logs are added.\\nThe display of auxiliary log tracks can be added or removed from the sonic calibration window.\\nRight-clicking on a track enables you to display additional logs that are part of the current LogSet.\\nSonic calibration Output tab\\nObjects made in the Sonic calibration workflow are not accessible from the Input pane until\\nthe results are output from the Seismic well tie process. The LogSet, Knee LogSet and\\nDepth/time relations can be obtained from the Output tab and will be stored on the Input\\npane under the Well logs folder. In addition, the Sonic log, Residual drift curve and Time\\nreference log can be saved from here. A typical output from this workflow is the final time-depth\\nrelationship that can be used for re-establishing the time log for the well used.\\nNote: Depth/time is saved as checkshot data although it is similar to a log. Also, it is\\nrecommended to select the All samples and Continuous output check boxes. If you are going\\nto use the output for velocity modeling, you should clear the All samples check box.\\nWavelet extraction\\nThe wavelet extraction workflow used in the Seismic well tie process, is a tool for performing\\ndeterministic wavelet extraction by selecting the seismic volume and input logs of interest. The\\nposition of the extraction location can be changed interactively based on predictability to optimize\\non the wavelet to use. Changing the extraction location automatically updates the extracted\\nwavelet with its corresponding power and phase spectra, as well as the resulting synthetic trace.\\nThe Wavelet extraction window is accessed from the Seismic well tie process dialog, Wavelet\\nextraction tab by clicking on the button. If the Sonic well tie\\nwindow is not open, it can be directly accessed by using the Wavelet extraction icon on the\\nFunction bar (given that the Seismic well tie process is active).\\nWavelet extraction workflow\\nThe Wavelet extraction workflow is graphically described in the display area of the Seismic well tie\\ndialog, under the Wavelet extraction tab.\\nOpen a Wavelet extraction window to perform this workflow. You can either use the icon from\\nthe Function bar or access it from the Seismic well tie process dialog. The window will be\\nempty until a Log set and a seismic volume are selected. The inputs are selected by selecting the\\ncheck box or dragging them from the Input pane.\\nNote that the windows used in the Seismic well tie process are not accessible after Petrel\\nis closed down. Make sure to finalize the workflow and output all needed results back to the\\nInput pane before you close Petrel.\\nWavelet extraction workflow\\nHow to extract wavelets using the Seismic well tie process\\nWith the Seismic well tie process active, follow the steps below to do a wavelet extraction for\\nyour well of interest:\\n1. Open a wavelet extraction window.\\n2. Drag Log set 1 into the wavelet extraction window.\\n3. Drag the seismic volume or 2D lines survey folder into the wavelet extraction window.\\n4. On the Position tab, click on the Deviated well location button (if you have a non-\\nvertical well).\\n5. Do a bulk time shift on theTime shift tab if needed.\\n6. On the Extract tab, set the parameters to your liking and click on the Extract button\\n7. When satisfied with the result, go to the Output tab. In the Depth/time field, click on\\nOutput for the Synthetic and Depth/time curve.\\n8. Open the settings for the current well, go to the Time tab.\\n9. Click on Override global settings and select the newly created object as TDR for the well.\\n10. Open a new Well section window, display the well of interest together with the synthetic\\ntrace you just created.\\nWavelet extraction input\\nWhen selecting an appropriate log set and seismic data (2D or 3D) to use in the wavelet extraction\\nworkflow, the window is populated with the selection. At the same time a Wavelet extraction\\nvariables and settings dialog will open up. It shows the seismic volume in the Input 1 tab and\\nthe log set used in Input 2 tab. If the current well does not have a valid time-depth relation, this\\nworkflow will not be possible to do. An already existing pilot wavelet can be dropped in here.\\nFor 2D seismic, the wells will be projected onto the seismic line using a closest trace approach.'},\n",
       " {'header': 'Position ',\n",
       "  'content': \"On the Position tab, the extraction position can be set at different locations. The number of\\nInlines and Crosslines around the location is specified for 3D seismic data. For 2D seismic data,\\nthe position will be defined by the center trace and number of traces on each side. Depending on\\nwhether the well is vertical or deviated, this can be incorporated into the wavelet extraction\\nalgorithm.\\nClick on the Deviated well location button to follow the well path of non-vertical wells. It is also\\npossible to interpolate seismic data to follow the trajectory. The extraction position can later be\\ninteractively changed based on predictability plots if the correct well trajectory is not obtained.\\nIn case of 2D line usage for extraction;\\nTime shift\\nA bulk shift can be applied to the entire seismic trace on the Time Shift tab. Any manual\\nadjustments between the seismic data and the synthetic trace are also controlled from here.\\nExtract a wavelet\\nExtraction of the wavelet can be done at any time using the Extract button at the bottom of the\\nWavelet extraction variables and settings -> Extract tab dialog. It will then use the settings\\nyou have specified. To better control the wavelet extraction, the Extract tab has some controlling\\nparameters, such as start and end time of the extraction window and offset to center of the scan\\nand length of the scan.\\nYou can decide whether to see the time shift or phase shift of the extracted wavelet in the\\npredictability display. This selection can be made through the options shown below;\\nDisplay time shift of best wavelet\\nCalculate and display phase of best wavelet\\nUpon extraction, two new windows will open; the Predictability display and the Extracted\\nwavelet display .\\nNote: You don't have to click Extract again to switch between Time of Maximum\\nPredictability graph to Phase of Maximum Wavelet\\nClicking in the graphic areas inside the Predictability display will update the extracted wavelet\\nwith associated Phase and Power spectra in the Extracted wavelet display dialog.\\nThe synthetic trace is also displayed in the Wavelet extraction window and will interactively\\nchange if the position is updated in the Predictability display .\"},\n",
       " {'header': 'Synthetic ',\n",
       "  'content': 'The usage of the wavelet is defined on the Synthetic tab. You can select which wavelet to use for\\ngenerating the synthetic seismogram:\\nThe raw extracted wavelet\\nThe extracted wavelet after some modification through tools in the Extracted wavelet\\ndisplaty\\nPilot wavelet that been defined under Input 1 tab\\nPilot wavelet modified by tools Pre-made wavelet\\nWavelet extraction output\\nObjects made in the Wavelet extraction workflow are not accessible on the Input pane until\\nthe results are output from the Seismic well tie process. Among other objects, the Modified\\nextracted wavelet, Synthetic (trace) and Depth/time curve (different from the output in the\\nSonic calibration workflow only if time shifts are applied) can be obtained from the Output tab\\nand will be stored on the Input pane under the Well logs folder. A typical output from this\\nworkflow is the updated time-depth relationship that can be used for re-establishing a more\\naccurate time log for the well used.\\nThe Method tab is used for specifying the extraction method. Here, only the Extended white\\nmethod is availabe but allows for the specification of the wavelet length. The Display tab is used\\nfor defining the log curve and seismic volume/trace display.\\nDisplay settings\\nYou can use the Display tab to display the synthetic trace and the real seismic traces by using\\nwiggles or interpolated density. This tab also allows you full control of the display and helps you to\\nenhance visibility. The fill colors can also be changed to match the variable density display.\\nWavelet viewer\\nThe Wavelet viewer workflow used in the Seismic well tie process, is a window designed to view\\nany premade, loaded or already generated wavelets with the corresponding power and phase spectra.\\nThe Wavelet viewer window is accessed from the Seismic well tie process dialog, Wavelet viewer\\ntab by clicking on the button. If the Sonic well tie window is not open, it can\\nbe directly accessed by using the Sonic calibaration icon in the Function bar (given that the\\nSeismic well tie process is active).\\nOpen a Wavelet viewer window to perform this workflow. Either use the icon from the Function bar\\nor access it from the Seismic well tie process dialog. The window will be empty until an already made\\nor loaded wavelet is selected to display. The input is selected by tick marking or dragging it from the\\nInput pane.\\nWavelet builder\\nThe wavelet builder workflow used in the Seismic well tie process, is a tool to build statistical\\nwavelets. The wavelets can be constructed as Ricker, Ormsby or Tapered sync types. The amplitude\\npolarity is specified here, either using the European or US standard, as well as the Phase polarity of\\nthe wavelet.\\nThe Wavelet builder window is accessed from the Seismic well tie process dialog, Wavelet builder\\ntab by clicking on the button. If the Sonic well tie window is not open, it can\\nbe directly accessed by using the Sonic calibaration icon in the Function bar (given that the\\nSeismic well tie process is active).\\nWavelet builder setup\\nIn the Name field, you can enter the wavelet name. From the Type drop-down menu, you can select\\namong; Ricker , Ormsby or Tapered sync type wavelets. The wavelet type specific parameters will be\\nactivated based on the selection. The parameters are entered as numerical values and will not take\\neffect until the Compute button is clicked. The Phase rotation can be set by using the slider or the\\nincrease/decrease value selector. Note that the Amplitude polarity can follow a SEG (UK) or SEG\\n(US) standard from the Positive amplitude option. Likewise, Phase polarity can follow a Petrel or\\nInverse standard. When you are satisfied with the result, click Save to store the wavelet to the Input\\npane.\\nNote that the parameter selection depends on the type of wavelet that is selected. Here a Ricker\\ntype wavelet is used as an example.\\nTime shift and manual adjustment\\nThe final synthetic trace made in the Seismic well tie process can be bulk shifted or stretched and\\nsqueezed to align it to the real seismic data. The alignment points can be set randomly on any\\nstrong event that needs to be adjusted and any updates are applied as soon as they are needed.\\nThe adjusted synthetic trace can be output back to the Input pane of Petrel with a different name\\nthan the original unadjusted trace for comparison and use.\\nTime shift and manual adjustment workflow\\nThe Wavelet extraction window is used for manual adjustment. The manually adjusted syntetic\\ntrace is updated interactively and is saved back to the Input pane for further use.\\nOpen the Wavelet extraction window to perform this workflow. You can either use the icon from\\nthe Function bar, access it from the Seismic well tie process dialog, or from the Windows pane if\\nPetrel has not been closed since the wavelet extraction workflow was done.\\nNote that the windows used in the Seismic well tie process are not accessible after Petrel is\\nclosed down. Make sure to finalize the workflow and output all needed results back to the Input\\npane before closing down Petrel.\\nVariable time shift alignment\\nControlling the variable time shift alignment is done from the Wavelet extraction variables and\\nsettings dialog, Time shift tab.\\nIf you select the Move and add alignment points button, any point can be set on the seismic\\n(preferably on a strong event/marker) and adjusted to the corresponding event on the synthetic\\ntrace.\\nThe difference in time picks can be collapsed by\\nselecting the Use variable time shift button .'},\n",
       " {'header': 'Attribute Generation ',\n",
       "  'content': 'Attribute generation in Petrel is split into two separate processes, the Volume attributes and\\nSurface attributes processes. They are similar in the sence that they both contain a library of\\ndifferent seismic attribute classes for display and use with the seismic interpretation workflow in\\nPetrel. Seismic attributes help to enhance information that might be subtle in conventional\\nseismic, leading to a better understanding and interpretation of the data.\\n- based on various properties of the analytical signal, it makes virtual or\\nrealized (physical) volumes of the input seismic.\\n- extracts seismic properties out of volumes based on analysis of the signal\\nshape. Surface based, that is, extraction is performed at a given level or between two levels and\\noutput as a surface.\\nSurface attributes\\nA surface attribute, also referred to as seismic attribute maps, is an extraction of data from a\\nseismic volume across a surface, within an interval or where interpretation intersects the volume.\\nTo create a surface attribute, double-click on the Surface attributes process under'},\n",
       " {'header': 'Geophysics. ',\n",
       "  'content': \"The surface attribute will be created as an attribute associated with a horizon interpretation or a\\nsurface. Any number of attributes can be assigned to the horizon interpretation/surface as\\nadditional attributes.\\nTo display the full resolution of the seismic cube, the surface or interpretation must have the\\nsame resolution as the seismic cube.\\nMake Surface attributes\\nIf a surface attribute based on a (continuous) surface is to display the full resolution of the\\nseismic cube, the surface must have the same resolution as the seismic cube. There are two ways\\nto do this:\\n1. Create a surface at the same resolution and rotation as the seismic cube using Make Edit\\nSurface. To do this, select the cube and press Get all settings from selected in the\\nMake Edit Surface dialog. All other settings should be specified normally. In the Surface\\nattribute process, use Add to surface and drop this surface into the dialog.\\n2. Choose Add to new surface in the Surface attributes process dialog. A new surface will\\nbe created at the seismic resolution if you use the gridded surface as input.\\nIf some loss of resolution is acceptable, then a surface at a non-seismic resolution can be used,\\ntogether with the Add to surface option.\\nIf additional attributes are to be sampled at the same location from cubes with the same\\nresolution, these new attributes can be added to the same surface with no loss of resolution.\\nChoose Add to surface in the Surface attribute process and a new attribute will be created.\\nIf using a horizon interpretation, it must be attached to the input seismic to be a valid selection.\\nThe surface attribute will have the same resolution as the seismic data.\\nThe Surface attribute process dialog\\nThe process dialog used to create Surface attributes is divided into five main areas; the Attribute\\nlibrary, Input/Output definition, the Window specification tab with Repeated windows section and\\nthe Parameters tabs. The Attribute library, Window specification and parameters are linked in the\\nsense that some attributes have a predefined window specification and/or parameters attached to\\nthem. Not all attributes need parameter input and the tab will then be unavailable. The dialog will\\nupdate based on the selection of surface attribute type.\\nThe horizon local attributes (loop asymmetry, loop kurtosis, lower loop area, lower loop\\nduration, upper loop area, upper loop duration, upper loop skewness) got another user interface\\nthan the other surface attributes. Instead of the normal Window specification tab, upon selection\\na loop specification tab will appear.\\nAttribute library\\nThe attribute library is split into different classes. They are the Amplitude, Statistical, Signal Shape\\nand Measurable Interval classes. Selecting 'All' activates an extensive list of more than 50\\nattributes that goes into the other four classes. A more detailed explanation of the surface\\nattribute algorithms is given in Surface attributes available in Petrel.\"},\n",
       " {'header': 'Input/Output Definition ',\n",
       "  'content': 'Defines the input seismic selection and where the output surface or horizon interpretation\\nattribute is placed.'},\n",
       " {'header': 'Parameters: ',\n",
       "  'content': 'If a surface attribute needs further parameter input from the user, it is defined in this tab. If no\\nparameters are needed, the tab is not available .\\nAll parameters and settings used to create a surface attribute is stored in the objects Settings\\ndialog, Info tab under the History sub-tab. The information includes:\\nSurface attribute name\\nInput seismic\\nVintage of input seismic\\nReference horizons (with parameters)\\nRepeated windows settings\\nParameter selection'},\n",
       " {'header': 'Window Specification ',\n",
       "  'content': 'The options available under window specification are Horizon - Horizon, Single Horizon or Z-Z.\\nThis selection defines at what level or interval the attribute will be extracted. In this context,\\nHorizon means surface or horizon interpretation, and Z means a constant depth or time.\\nTo use surfaces from the input pane. Check the Horizon - Horizon or Single Horizon\\noption, drop in surface(s) with the drop box(es). Change the other parameters to capture\\nappropriate events.\\nTo use horizon interpretations from the input pane. Check the Horizon - Horizon or\\nSingle Horizon option, drop in interpretation(s) with the drop box(es). Set the other\\nparameters.\\nTo use fixed constants. Check the Z - Z window specification. Type in the interval. To\\nextract a surface attribute at a fixed level, type in the same value for top and base interval.\\nA further refinement of which part of the signal extractionthat will take place, is based on the\\nparameter inputs Horizon selection, From event (described below), Search window and\\nHorizon offset.\\nThe From event selection can either be above (shown as example) or below and are as follows:\\nNone - no offset from the horizon\\nLargest peak - absolute largest peak within the search window\\nClosest peak - closest peak to the horizon\\nLargest trough - absolute largest trough within the search window\\nClosest trough - closest trough to the horizon\\nZero crossing +/- - crossover going from peak to trough\\nZero crossing -/+ - crossover going from trough to peak\\nRepeated windows\\nThe Repeated windows selection allows for multiple computation windows in the same\\ncomputation run. From the selection pull-down menu, None will obviously deselect this\\nfunctionality while the other two have the following features:\\nFixed; the Window of advance specifies how much the original search window advances for each\\nnumber of repeats.\\nProportional; the original search window is divided into the number of repeats (partitions).\\nThe output attributes are appended with the window advance or partition number, respectively.\\nThe use of repeated windows is shown as an example in the Multiple surface attribute ...\\nsection.'},\n",
       " {'header': 'Loop Specification ',\n",
       "  'content': 'If any of the horizon local attributes are selected in the attribute library, the normal Window\\nspecification tab will be substituted by a Loop specification tab. This tab contains only two\\nfields; the reference Horizon selection and Horizon local offset.\\nThe horizon local attributes in question are:\\nLoop asymmetry\\nLoop kurtosis\\nLower loop area\\nLower loop duration\\nUpper loop area\\nUpper loop duration\\nUpper loop skewness\\nSurface attribute based on a single horizon\\n1. Prepare a surface at which the seismic is to be sampled.\\n2. Double-click on the Surface attribute process to open the dialog.\\n3. Check Add to new surface. Type in an appropriate name.\\n4. Drop the seismic cube into the drop box.\\n5. Choose attribute to use (e.g. Maximum amplitude).\\n6. Use Single horizon as Window specification.\\n7. Drop in the surface as First horizon. Use 0 (zero) for search window and horizon offset.\\n8. Set the appropriate parameters for To event (e.g. Largest trough, below and 16 ms search\\nwindow).\\n9. Press OK\\nSurface attribute based on an interval\\n1. Prepare a surface and a horizon interpretation from which the interval attribute is to be\\nextracted.\\n2. Open the Surface attribute process dialog.\\n3. Select an attribute from the Attribute library (e.g. RMS).\\n4. Drop the seismic cube into the drop box.\\n5. Check Add to new surface. Type in an appropriate name.\\n6. Use Horizon-Horizon as Window specification.\\n7. Drop in the surface and horizon interpretation as first and second horizon in the drop\\nboxes. Leave the other options as default.\\n8. Press OK.\\nIf Add to new surface is selected as output definition, the position and resolution of the\\nresulting surface attribute is taken from First Horizon. When First horizon is a partly distributed\\ninterpretation, the surface attribute will only be defined where the interpretation exists. If First\\nhorizon is a continuous surface (and second horizon is the partly distributed interpretation), the\\nresult is continuous over the area, but with zero values where the interpretation does not exist.\\nExtract the amplitude value from a horizon\\ninterpretation\\n1. Use a horizon interpretation displayed as cell boxes (Settings>Style>3D interpretation).\\n2. Open the Surface attribute process dialog.\\n3. Select the Amplitude class from the Attribute library.\\n4. Use Extract value from the list. The Window Specification will automatically be set to Single\\nhorizon.\\n5. Drop the seismic cube into the drop box.\\n6. Choose Add to surface and drop in the interpretation into the drop box.\\n7. Also, drop in the interpretation into the First horizon drop box.\\n8. As the extraction should exactly follow the interpretation picks, use 0 (zero) for Search\\nwindow and Horizon offset. The above / below selection has no effect without any offset,\\nleave it as it is.\\n9. Apply to create the extraction.\\n10. Display the horizon interpretation in a 3D window, toggle between the TWT and Extract\\nvalue attributes.\\nMultiple surface attributes incrementally\\nthrough a 3D volume\\n1. Prepare a surface at which the seismic is to be sampled.\\n2. Double-click on the Surface attribute process to open the dialog.\\n3. Check Add to new surface. Type in an appropriate name.\\n4. Drop the seismic cube into the drop box.\\n5. Choose attribute to use (e.g. Extract value).\\n6. Note that Single horizon is the only available Window specification.\\n7. Drop in the surface as Reference horizon. Use 0 (zero) for search window and horizon\\noffset.\\n8. In the Repeated windows section, select Fixed, Number of repeats: 3 and Window of\\nadvance: -50 (the extraction will step 3 times downwards with an increment of 50\\nmilliseconds).'},\n",
       " {'header': '9. Press Apply. ',\n",
       "  'content': '10. Expand and view the resulting attribute surface in the Input pane.\\nTracking a surface attribute\\nHow to find input parameters and settings used to create a surface\\nattribute\\n1. Open settings for an already created surface attribute (e.g. in the How to... above, open\\nsettings for Extract value; -150).\\n2. Go to the Info tab and History sub-tab.\\n3. Place the cursor in the History information area and veiw the content of the pop-up list that\\nappears.\\nSurface attributes available in Petrel\\nThe following sections gives an overview of the available surface attributes in Petrel. They are\\nlisted alphabetically so you can easily find the attribute of interest.\\nArc length\\nArc length measures reflection heterogeneity, and can be used to quantify lateral changes in\\nreflection patterns. It is calculated using the following formula:\\nWhere Z is in milliseconds in time domain, or in feet or meters in depth domain.\\nArc length is a stratigraphic sequence indicator.\\nAverage duration of negative loops\\nGives the average duration of all negative loops in a given interval. It is undefined if there is no\\nloop that requires two zero crossings.\\nwhere di represents loops with negative amplitude and K is the number of negative loops.\\nAverage duration of positive loops\\nGives the average duration of positive loops in a given interval. It is undefined if there is no loop\\nwhich requires two zero crossings with positive amplitudes.\\nwhere di represents loops with positive amplitude and K is the number of positive loops.\\nAverage energy\\nThis is the squared RMS Amplitude. This attribute is a measure of reflectivity within a time or\\ndepth window and can be used to map direct hydrocarbon indicators in a zone.\\nAverage energy is computed using the following formula:\\nwhere k is the number of live samples.\\nAverage loop duration\\nAverage loop duration is defined as the average duration of all loops. It is undefined if there is no\\nloop (requires two zero crossings). Its reciprocal (e.g. 500/Dav if the sample rate is 4 ms), gives\\nan approximate average frequency of the seismic data within the extraction window.\\nwhere di represents loops with positive and negative amplitude and m is the number of loops.\\nAverage magnitude\\nThis operation measures the reflectivity within a time or depth window, but is less sensitive to\\nlarge numbers than RMS Amplitude.\\nAverage Magnitude is computed using the following formula:\\nwhere k is the number of live samples.\\nThis attribute can be used as a hydrocarbon indicator and well as isolated geologic features which\\nexpress themselves as anomalous amplitudes relative to background values.\\nAverage negative amplitude\\nGives the average of all negative amplitudes values within the analysis window.\\nThe amplitude range to be included in the calculation can be controlled with the parameter\\nselector. The data range to be included can be within the defined interval or outside the defined\\ninterval. By default, all data values will be used.\\nAverage negative trough value\\nMeasures the negative reflectivity within a time or depth window. Only trough values which are\\nnegative are included in the average. This allows discrimination of local minima in the positive\\nlobes of the seismic waveform.\\nAverage peak value\\nThis is the average of all peak values in a window. These peak values can be local maximums, in\\nwhich case negative peaks are also averaged in. This attribute can be a measure of the positive\\nreflectivity within a time/depth window.\\nLarge or small values can be used as a direct hydrocarbon indicator.\\nAverage peak value between zero crossings\\nThis operation is similar to the Average peak value, but instead of taking all peak values, only the\\nlargest peak between each pair of zero crossings is taken.\\nThe output can provide a better measure of reflectivity when tracking a single event.\\nAverage positive amplitude\\nGives the average of all positive amplitudes values within the analysis window.\\nThe amplitude range to be included in the calculation can be controlled with the parameter\\nselector. The data range to be included can be within the defined interval or outside the defined\\ninterval. By default, all data values will be used.\\nAverage positive peak value\\nThis operation is similar to Average peak value, but instead of taking all peak values, only the\\npeaks in the positive lobe of the seismic waveform are taken.\\nAverage trough value\\nThis operation measures the average of negative reflectivity within a time or depth window. Its\\nuses are similar to those of Average peak value.\\nAverage trough value between zero crossings\\nThis operation is similar to Average peak value, but instead of taking all peak values, only the\\nlargest negative peak between each pair of zero crossings is taken.\\nThis attribute can give a better measure of reflectivity when tracking a single event.\\nCipher attribute\\nCipher attributes are horizon local attributes. Cipher attributes measure the characteristic of one\\nof the three peaks or three troughs above and below the reference horizon. The measured\\ncharacteristics include time of the peaks/troughs below or above the reference horizon, amplitude\\nof the peaks/troughs, the isochron between the peaks/troughs and the reference horizon and the\\nnumber of peaks or troughs below or above the reference horizon within the specified window.\\nWith this in mind, there are forty attribute variants.\\nWhen clicking on Cipher Attribute in the Surface Attribute Selection list, the Cipher Attribute\\nparameters become available for selection of parameter values (see figure above).\\nCipher event\\n Peak/Trough, above/below, 1st/2nd/3rd/Number of: Toggle on the appropriate option to specify\\nthe number of peaks or troughs above or below the Reference Horizon that will be measured in\\nthe operation. You can specify that the Cipher attributes measure the characteristic of one of the\\nthree peaks or three troughs above and below the reference horizon. There are forty attribute\\nvariations.\\nCipher type'},\n",
       " {'header': 'Amplitude ',\n",
       "  'content': 'Toggle on to measure the amplitude of the peaks/troughs above or below the reference\\nhorizon'},\n",
       " {'header': 'Time ',\n",
       "  'content': 'Toggle on to measure the time of the peaks/troughs above or below the reference horizon.'},\n",
       " {'header': 'Isochron ',\n",
       "  'content': 'Toggle on to measure the isochron between the peaks/troughs and the reference horizon\\nwithin the specified window.\\nAmplitude limits'},\n",
       " {'header': 'Inside ',\n",
       "  'content': 'Select Inside from the drop down list to ignore amplitudes inside the specified range\\n(From/To) of Amplitude Limits'},\n",
       " {'header': 'Outside ',\n",
       "  'content': 'Choose from the drop down list to ignore amplitudes outside the specified range (From/To) of'},\n",
       " {'header': 'Amplitude. From ',\n",
       "  'content': 'specify time/depth for upper limit of Amplitude limits.'},\n",
       " {'header': 'To ',\n",
       "  'content': 'specify time/depth for lower limit of Amplitude limits\\nExtract value\\nExtract value is the utility to extract the input seismic value relative to a single horizon or an\\nexisting interpretation.\\nThis utility allows you to produce Surface attribute maps from seismic volumes created as Volume\\nattributes with methods not available directly as Surface attributes or from volumes created with\\nSeismic calculator options.\\nGeometric mean\\nThe geometric mean of a data set [a1, a2, ..., an] is given by:\\nWhere n is the number of data points used in the mean. The geometric mean will be smaller or\\nequal to the arithmetic mean, being related through a log-normal distribution. See also Averaging\\nmethods.\\nHalf energy\\nThis operation computes the time or depth required for the energy within a window to reach one-\\nhalf of the total energy within the entire window. Half Energy is computed using the following\\nformula:\\nHalf energy may indicate asymmetric changes in lithology or porosity within a specified zone.\\nHarmonic mean\\nThe harmonic mean H of the positive real numbers a1, ..., an is defined to be:\\nWhere n is the number of data points used in the mean. The harmonic mean is typically used with\\nthe averaging of rates (rates of change). The harmonic mean will be smaller than either the\\nGeometric mean or the Arithmetic mean (Mean Amplitude). See also Averaging methods.\\nInterval average\\nCalculates the average over an interval based on one of the following methods; Arithmetic,\\nHarmonic, Geometric, RMS, Summation, Minimum, Maximum, Most of or Median. Provides the\\nuser with the same interval averaging options that were available in pre-Petrel 2007.1\\nIsochron thickness\\nDefined as the time difference between two horizons. Measured in the units of the input horizons\\n(milliseconds in Time domain, feet or meters in Depth domain).\\nLoop asymmetry\\nLoop asymmetry measures the asymmetry of the loop that straddles the horizon. It is undefined\\nif there is no loop that requires two zero crossings. Loop asymmetry is the base 10 logarithm of\\nthe ratio of the area in the upper part of the loop to the area in the lower part. The upper and\\nlower parts of the loop are separated by either the peak or trough or, in the case of a doublet, the\\nsaddle (indentation) between the local peaks or troughs. Asymmetry >0 generally indicates that a\\nloop is top loaded, and Asymmetry <0 generally indicates that a loop is bottom loaded, but not\\nalways.\\nLoop kurtosis\\nLoop Kurtosis measures the peaked-ness of a statistical distribution (here the loop is considered\\nas a distribution). This representation treats time as the variant of interest and amplitude as\\nprobability. The trapezoid approximation is the series of lines that connect sample points.\\nFor the time value t, the amplitude is a(t), and the probability for the Kurtosis calculation is;\\nWhere a and s are defined by;\\nand where dt is the total time interval covered by the loop.\\nLower loop area\\nLower loop area is the sum of the areas of the trapezoids defined by the amplitudes in the lower\\nloop. The tail triangles are also in the sum when the zero crossings are defined by interpolation.\\nThe amplitude and time values are not scaled. The resulting area has units of amplitude multiplied\\nby milliseconds. Negative loops have negative areas. It is undefined if there is no lower loop\\n(requires one zero crossing below the upper loop) or if there is no upper loop.\\nWhere T1 and Tn are Ta, and Tb in upper loop duration and T2 to Tn-1 are times at integer\\nsamples in between Ta and Tb\\nLower loop duration\\nLower loop duration is the time separation between upper and lower zero crossings for the loop\\nbelow the loop that straddles the horizon. The upper zero crossing for lower loop duration is the\\nsame point as the lower zero crossing for upper loop duration. Loop duration is undefined if there\\nis no lower loop (requires one zero crossing below the upper loop) or if there is no upper loop. It\\nis defined as:\\nwhere Tc and Tb are determined by the presence of a zero amplitude sample or by linear\\ninterpolation between samples with amplitudes of opposite sign.'},\n",
       " {'header': 'Make Offset Horizon ',\n",
       "  'content': 'Make offset horizon creates a surface at each of the search windows specified in the surface\\nattribute process dialog. The offset horizons are created as two new interpretation objects in the\\nPetrel Input tree named Offset horizon 1 and Offset horizon 2.\\nMaximum amplitude\\nMeasures reflectivity within a time or depth window. Returns the maximum positive number in the\\ndefined window.\\nIt is used to detect positive direct hydrocarbon indicators such as bright spots.\\nMaximum loop duration\\nDefined as the maximum duration (longest half-cycle) of all loops, both positive and negative in\\nthe extraction window. It is undefined if there is no loop (requires two zero crossings).\\nMaximum magnitude\\nMeasures reflectivity within a time or depth window. Returns the maximum positive number in the\\ndefined window.\\nIt is used to detect positive direct hydrocarbon indicators such as bright spots.\\nMean amplitude\\nThis is the arithmetic mean of the amplitude and is a measure of trace bias. If the seismic trace\\nhas general bias, perhaps from the data processing, this can be removed from the seismic volume\\nusing the Graphic equalizer attribute and removing the zero hertz component. Mean Amplitude is\\ncomputed using the following formula:.\\nwhere k is the number of live samples.\\nPositive or negative bias may indicate the presence of bright spots.'},\n",
       " {'header': 'Median ',\n",
       "  'content': 'The Median of the analysis window can be found by arranging all the values from lowest to\\nhighest value and picking the middle one (i.e. 50% of the values in the window are below the\\nmedian value). The Median is less sensitive to extreme values (outliers) than the computation of\\nthe Mean. See also <Cross reference to Averaging methods>\\nMinimum amplitude\\nThis operation measures the reflectivity within a time or depth window. This is the maximum\\nnegative number in the defined window.\\nIt is used to detect negative direct hydrocarbon indicators such as bright spots.\\nMinimum loop duration\\nIt is defined as the minimum duration (shortest half-cycle) of all loops, both positive and negative\\nin the extraction window. It is undefined if there is no loop (requires two zero crossings).\\nMost of\\nThe Most of attribute captures the most commonly occurring data value within the analysis\\nwindow. A histogram is computed from the input window and the value from the bin with the\\nhighest count is output for each trace location. See also <Cross reference to Averaging methods>\\nNumber of negative zero crossings\\nThis operation results in a value representing a counter for the number of zero crossings\\nencountered within the analysis window that match the criteria of the sample values going from\\nnegative values to positive.\\nChanges in the number of zero crossings can be related to the complexity of the stratigraphy. A\\nhigh number of zero crossings generally indicates a greater degree of vertical lithologic\\ncomplexity.\\nNumber of positive zero crossings\\nThis operation results in a value representing a counter for the number of zero crossings\\nencountered within the analysis window that match the criteria of the sample values going from\\npositive values to negative.\\nChanges in the number of zero crossings can be related to the complexity of the stratigraphy. A\\nhigh number of zero crossings generally indicates a greater degree of vertical lithologic\\ncomplexity.\\nNumber of zero crossings\\nThis operation results in a value representing a counter for the number of zero crossings\\nencountered within the analysis window that match the criteria of the sample values going both\\nfrom positive values to negative ranges and from negative to positive ranges. See also Number of\\nnegative zero crossings.\\nPositive to negative ratio\\nRatio of positive to negative is the number of positive values in an interval, divided by the number\\nof negative values in the interval. If there are no negative values found in the interval to be used\\nas a divisor, the application returns a value of zero.\\nThis operation can be used to look for lateral changes in thickness and also lithology, such as a\\npinchout or a sand that is thickening within a shale sequence.\\nRMS Amplitude\\nRMS Amplitude is the square root of the sum of the squared amplitudes, divided by the number of\\nlive samples as shown in the following formula:\\nwhere k is the number of live samples. See also <Cross reference to Averaging methods>\\nRMS can map directly to hydrocarbon indications in the data and other geologic features which\\nare isolated from background features by amplitude response.\\nStandard deviation of amplitude\\nStandard deviation of amplitude measures the variability of the seismic amplitude values within\\nthe extraction window. It is undefined if n is less than 2.\\nWhere n is the number of samples in the extraction window and Aav is the average amplitude of\\nthe samples.\\nStandard deviation of loop durations\\nIt is the Standard Deviation of all loops, both positive and negative durations. It is undefined if\\nthere are not at least two loops (requires three zero crossings).\\nwhere Dav is the Average Duration and n is the number of loops.\\nSum of amplitudes\\nThis is the arithmetic mean of the amplitude, multiplied by the number of samples in the window.\\nThis operation provides a measure of brightness multiplied by the formation thickness (time or\\ndepth) and may be regarded as a measure of brightness volume. The Sum of Amplitudes over the\\ngiven window is calculated as follows:\\nA large value may indicate a high net sand ratio.\\nSum of magnitudes\\nThis operation measures the reflectivity within a time or depth window, but multiplied by the\\nnumber of samples in the window. The operation can be used in a similar way to Sum of\\nAmplitudes but is independent of amplitude sign. The Sum of Magnitudes over a given window is\\ncalculated as follows:\\nSum of negative amplitudes\\nThis is the arithmetic mean of the negative amplitudes, multiplied by the number of samples in\\nthe window. This operation provides a measure of brightness multiplied by the formation\\nthickness (time or depth) and can be regarded as a measure of brightness volume.\\nA large value may indicate a high net sand ratio.\\nSum of positive amplitudes\\nThis is the arithmetic mean of the positive amplitudes, multiplied by the number of samples in the\\nwindow. This operation provides a measure of brightness multiplied by the formation thickness\\n(time or depth) and may be regarded as a measure of brightness volume.\\nA large value may indicate a high net sand ratio.\\nThreshold value\\nThe threshold value attribute computes the percentage of samples that satisfy the Threshold\\nvalue parameter. Threshold value parameter: The threshold value is controlled by the data range\\nselected with the value parameter. You can select the threshold as greater than, less than, or\\nequal to the user defined data range value.\\nAmplitudes in the seismic data can be analyzed using the user-defined threshold values which\\nmay infer porosity or fluid changes, when amplitude driven.\\nTime at maximum amplitude\\nThis operation results in a z-value (time or depth) as the output attribute, where the z-value\\ncorresponds to the vertical position of the maximum amplitude within the analysis window.\\nTime at minimum amplitude\\nThis operation results in a z-value (time or depth) as the output attribute, where the z-value\\ncorresponds to the vertical position of the minimum amplitude within the analysis window.\\nUpper loop area\\nUpper loop area is the sum of the areas of the trapezoids defined by the amplitudes in the upper\\nloop. The tail triangles are also in the sum when the zero crossings are defined by interpolation.\\nThe amplitude and time values are not scaled. The resulting area has units of amplitude multiplied\\nby milliseconds. Negative loops have negative areas. It is undefined if there is no upper loop that\\nrequires two zero crossings within the extraction window: one zero crossing at or below the local\\nhorizon interpretation and one zero crossing above the local horizon.\\nwhere T1, Tn are Tb, Tc in lower loop duration and T2 to Tn-1 are times at integer samples in\\nbetween Tb and Tc.\\nUpper loop duration\\nUpper loop duration is the time separation between upper and lower zero crossings for the loop\\nthat straddles the horizon. Ud is undefined if there is no upper loop which requires two zero\\ncrossings within the extraction window: one zero crossing at or below the local horizon\\ninterpretation and one zero crossing above the local horizon.\\nwhere Tb and Ta are determined by the presence of a zero amplitude sample or by linear\\ninterpolation between samples with amplitudes of opposite sign.\\nUpper loop skewness\\nUpper Loop Skewness measures the symmetry of a statistical distribution (here the loop is\\nconsidered as a distribution). The formula is:\\nwhere a and s are defined as in the Kurtosis equation.\\nSkewness is zero for symmetrical loops; it is positive for loops that are top loaded and negative\\nfor those that are bottom loaded.\\nWindow length\\nThe output from this operation indicates bed travel time thickness above tuning when using peak\\nabove and trough below (or the reverse). Tapering does not affect this operation because the\\ntapers are centered at the start and end points of the window. Window Length is computed in\\nmilliseconds in the time domain, and in feet or meters in the depth domain.\\nVolume attributes\\nThe Volume attributes process is opened by double-clicking on it in the Process pane. The\\ndialog needs to be populated with input data, attribute selection and parameters from scratch. If\\nthe process is initiated by right-clicking on a seismic volume and selecting Volume attributes\\nfrom the appering menu, this volume is automatically instantiated as the Input under the\\nInput/Output tab.\\nThe volume attribute dialog is split into three areas:\\n1. The Attribute Library: this is at the top of the dialog. The available attributes have been\\ndivided into five collections for specific tasks:\\nSignal processing\\nComplex attributes\\nStructural methods\\nStratigraphic methods\\nDepth conversion methods\\nAdditionally, the entire suite of attributes is available in a single collection for your\\nconvenience.\\nFirst, choose the appropriate group from the pull down menu and then the appropriate\\nattribute from the list. A brief description of each attribute is given in the tool tip to the\\nright of the selection list. See Volume attributes available in Petrel for a description of the\\nvarious attributes.\\n2. Input/Output tab: Drop the input seismic into the dialog from the Petrel explorer. An\\noutput cube can also be specified and renamed if required. However, by default this is left\\nblank and a new cube will be created. It is possible to specify a vintage for the output cube.\\nVolume attributes can be output as Virtual volumes calculated on the fly from the original\\nor Realized volumes which are saved to disc independently. When using the last option, it\\nis possible to set realization quality and specify the file path and name.\\n3. Parameters tab: If the attribute has parameter controls then these will appear in a\\nseparate tab from the Input/Output tab. If no parameter input is required, this tab is not\\navailable. The parameter setup (volume attribute type and parameter values) can be\\ninherited from an already existing seismic volume by dropping it into the Output field with\\nthe blue arrow.\\nPress OK to create the attribute cube that will appear in the Input pane of the Petrel explorer.\\nDuring generation, other tasks can be performed in Petrel. Once created, the attribute library tab\\nwill be part of the settings dialog for the virtual cube and can be altered at any time.\\nIf you do not have the Multitrace attributes module, only the basic attributes will be\\navailable.\\nSeismic attributes can be created using the Workflow editor, allowing attributes to be\\ncreated in batch and enabling cascading workflows where the results of one process is used in the\\nnext.\\nPetrel is using an asynchronous tasks approach for several processes, so while the volume\\nattribute cube is generated in the background, you can resume to other tasks. The status of the\\ngeneration process can be found below the graphic area of Petrel.\\nThe Volume Attributes process dialogue.\\nVolume attributes available in Petrel\\nThis provides you with a brief description of each of the volume attributes available in Petrel with\\nsome information of their general use.'},\n",
       " {'header': '3D Curvature ',\n",
       "  'content': 'Curvature is a two-dimensional property of a curve and describes how bent a curve is at a\\nparticular point on the curve. That is, how much the curve deviates from a straight line at this\\npoint. For a particular point on a curve, its curvature is defined as the rate of change of direction\\nof a curve. Curvature is closely related to the second derivative of a curve. Often the second\\nderivative is used as a direct measure of curvature, however, it is only in the special case of zero\\ndip that this assumption is strictly valid. However, for small dip values it makes a close\\napproximation.\\nThe sign convention for curvature is shown below;\\nSign convention for curvature attributes. The grey arrows represent vectors, which are normal to\\nthe surface. Where these vectors are parallel on flat or planar dipping surfaces, the curvature is\\nzero. Where the vectors diverge over anticlines, the curvature is defined as positive and where\\nthey converge over synclines, the curvature is defined as negative.\\n13 different types of curvature volumes are available for calculation:'},\n",
       " {'header': 'Minimum Maximum Gaussian Mean Most Positive Most Negative ',\n",
       "  'content': 'Azimuth of Minimum\\nAzimith of Maximum'},\n",
       " {'header': 'Dip Strike Contour Extreme Directional ',\n",
       "  'content': 'Vertical radius\\nA vertical radius of 2-40 samples can be specified. The window size will be two times the vertical\\nradius plus 1.'},\n",
       " {'header': 'Minimum: 2.0 Maximum: 40.0 Default: 7.0 ',\n",
       "  'content': 'Inline/Xline radius\\nAn Inline/Xline range of 1-5 can be specified either side of the reference trace. A value of 1\\nchooses comparison between neighbor traces. Larger values compares the central trace to more\\ndistant traces.'},\n",
       " {'header': 'Minimum: 1.0 Maximum: 5.0 Default: 1.0 ',\n",
       "  'content': 'Interpolation method\\nInterpolation method used for the trace between samples calculation.'},\n",
       " {'header': 'Method 1: Linear Method 2: Spline Default: Linear ',\n",
       "  'content': 'In comparison to variance, the 3D curvature volumes (in the image below Directional curvature)\\ncan highlight areas that are not easily discernable on variance.\\n3D curvature can be used to bring out stratigraphic features in sedimentary environments, karst\\nfeatures or structural discontinuities.\\nAnt tracking\\nAnt tracking is used to extract faults from a pre-processed seismic volume. The pre-processing\\ncould be variance or chaos combined with structural smoothing. Currently, only realized volumes\\ncan be calculated. The Ant tracking attribute and pre-processing is extencively described in the\\nant tracking workflow .\\nApparent polarity\\nThe polarity of instantaneous phase, calculated at the local amplitude extreme. The apparent\\npolarity reveals the sign of the reflection coefficient and therefore indicates features that would\\nchange it, e.g. unconformities. It is useful for checking the lateral variation of polarity along a\\nreflection layer.\\nA window length parameter is available (default: 33).\\nOn a noisy seismic section, event continuity can be clearer on the apparent polarity than the\\noriginal seismic section. This attribute reveals reflection details without the waveform effects and\\ncan help detect thick beds when the data is of good quality (less noise).'},\n",
       " {'header': 'Chaos ',\n",
       "  'content': 'The chaotic signal pattern contained within seismic data is a measure of the \"lack of\\norganization\" in the dip and azimuth estimation method. Chaos in the signal can be affected by\\ngas migration paths, salt body intrusions, and for seismic classification of chaotic texture. The\\nchaos attribute is scaled from 0-1.\\nSigmaX, SigmaY and SigmaZ: X, Y, Z directional sigmas are enabled for the user to specify the\\nwindow radius for calculating the \"chaoticness\" of the seismic data. The larger the sigma, the\\nsmoother the result.\\nChaos in the signal can be used to illuminate faults and discontinuities and for seismic\\nclassification of chaotic texture. Chaos can be related to local geologic features as it will be\\naffected by gas migration paths, salt body intrusions, reef textures, channel infill, etc.\\nCosine of phase\\nThe cosine of the instantaneous phase, cos( ), also known as \\'Normalized Amplitude\\', can help\\nto enhance the definition of structural delineations. Used together with Instantaneous phase for\\ncomparison.\\nA window length parameter is available (default: 33).\\nCosine of phase is commonly used for guiding interpretation in areas poorly resolved on the\\namplitude or to enhance definition of structural delineation. Used together with Instantaneous\\nphase for comparison.'},\n",
       " {'header': 'Dip Deviation ',\n",
       "  'content': 'The difference between the dip trend and the instantaneous dip. By tracking rapid changes in\\nthe orientation field, edges and subtle truncations become visible. This edge attribute has been\\nfound to work successfully for low-angle fault illumination.\\nThreshold angle (degrees)\\nThis parameter eliminates computed dip deviation below this threshold angle. It has the effect of\\nenhancing large deviations, as one would expect when encountering a fault displacement in the\\ndata.'},\n",
       " {'header': 'Minimum: 0 Maximum: 90 Default: 0 ',\n",
       "  'content': 'The dip deviation method can be effective for softer rocks in passive margins, where the\\ndownthrown side of a fault typically shows significant dip into the fault.\\nDix conversion\\nUses an existing velocity cube and solves the Dix conversion system to calculate an average\\nvelocity or interval velocity volume, alternatively a domain converted copy of the input volume.\\nVelocity conversion: Select Average velocity, Interval velocity or None (makes a domain\\nconverted copy of the input volume). For average and interval velocity conversion, choose\\nbetween domain convert result (tick marked) or keep the result in the input volumes domain (not\\ntick marked).\\nDatum: Set the starting point (datum) for the volume, as Time datum or Other input (can be\\nconstant values or as surfaces).\\nNote that this method of calculating velocities assumes that Vrms ~= Vstack. This\\nassumption is only strictly valid for non-dipping geology, hence the method must be used with\\ncaution, and always calibrated to well velocity data before it is used in domain conversion.\\nDominant frequency\\nDominant frequency, calculated as the hypotenuse between instantaneous frequency and\\ninstantaneous bandwidth. This attribute in combination with Instantaneous bandwidth, serves as\\na supplement to the Instantaneous frequency, as the three attributes reveal the time varying\\nspectral properties of seismic data.\\nA window length parameter is available (default: 33).\\nDominant frequency, with instantaneous bandwidth and instantaneous frequency help in the\\nsearch for low frequency shadows.'},\n",
       " {'header': 'Envelope ',\n",
       "  'content': 'The total instantaneous energy of the analytic signal (the complex trace), independent of\\nphase. Also known as \\'Instantaneous Amplitude\\', \\'Magnitude\\' or \\'Reflection strength\\'.\\nThe f and g are the \"real\" and \"imaginary\" components of the seismic trace. So, if f is the real\\npart, which are just the original seismic trace samples, g will be the samples from the Hilbert\\ntransform (also called quadrature amplitude) of the seismic trace.\\nA window length parameter is available (default: 33).\\nThe envelope attribute is of importance detecting bright spots caused by gas accumulations,\\ndetecting major lithological changes that are caused by strong energy reflections and sequence\\nboundaries. The attribute clearly shows subtle lithological changes that may not be apparent on\\nthe seismic data.\\nEnvelope can be used to help recognize phase differences between seismic versions. The peak\\nenergy should align independent of the phase of the data.'},\n",
       " {'header': 'Frequency Filter ',\n",
       "  'content': \"The Frequency fiilter attribute enables the user to to specify frequency filtering on a time\\nvarying basis applied on the input seismic volume. Multiple time gates can be defined with a taper\\nsetting to control the overlap. It is possible to specify different filter and taper types:\\nFilter types: Butterwoth, Ormsby, Low pass, High pass, Ricker and Klauder\\nTaper types: Available for Ormsby based tapers (Ormsby, Low and High pass filter types):\\nCosine, Hanning, Hamming, Bartlett and Papoulis\\nFilters and Tapers can be combined in order to highlight areas or features of interest.\\nThe left image belongs to the original seismic and the right one has filtered out lower frequencies\\nbetween 0-12 Hz.\\nThe Frequency Filter attribute is useful for enhancing particular seismic events or to reduce\\nunwanted noice in the data. This can improve on the accuracy of interpretation.\\nNOTE: is not possible to use Depth seismic cubes or 2D lines as input for this process.\\nFirst derivative\\nThe first time derivative of the input seismic volume. The combination of original amplitude,\\nfirst derivative, and second derivative allow you to express seismic interpretation in relationship to\\nmaximum, minimums, greatest descents, and descent polarity.\\nNo parameters required.\\nThe First Derivative is useful for stratigraphic analysis, facies estimation, and horizontal well\\nplacement since the phase of a zero-phase seismic cube will be rotated into something more\\nclosely mimicking a well log.\\nGeneral depth conversion\\nUses an existing velocity model to domain convert a seismic cube.\\nVelocity model: Drop in a generated velocity model from the Models tab.\\nInterpolation: None, Linear and Smooth (Default). Use None or Linear when domain converting\\nnon-seismic data (e.g. discrete facies, impedance, etc.)\\nDirection: Forward or backward domain conversion (relative to the velocity models defined\\ndirection).\\nGeneric inversion\\nA simple and fast method to produce inverted cubes from post-stack seismic amplitude\\ndatasets and selected property well logs. This process uses a neural network and genetic\\nalgorithm in order to provide an accurate seismic property cube. It is further described the\\nGenetic Inversion section .\\nGradient magnitude\\nThe magnitude of the instantaneous gradient computed in three-dimensions of the sample\\nneighborhood.\\nNo parameters required.\\nThere are no user parameters for Gradient Magnitude, but color table range limiting can help\\nilluminate different aspects of the results.\\nGraphic equalizer\\nA virtual instrument to enhance or reduce the selected frequency component of the input\\nsignal. Can be used to apply high, low or band-pass filters to the input volume.\\nFrequency sliders (Hertz)\\nThe frequency sliders set a control point in frequency at ten hertz increments. Each slider allows\\nfrequency scaling from zero (eliminate) to two (boost), at steps of 10 percent (0, 0.1, 0.2, ...\\n2.0).\\nUp position: Boost frequency (factor of 2)\\nCenter position: No frequency adjustment\\nDown position: Eliminate frequency\\nThe slider icons can be used to reset all sliders to up , down , or center positions .\\nBand pass filtering can be used for guiding interpretation in ambiguous situations such as\\nonlapping locations, truncations, unconformities etc. by highlighting reflectors that are consistent\\nat different bandwidth.\\nNOTE: is not possible to use Depth seismic cubes or 2D lines as input for this process.\\nInstantaneous bandwidth\\nThe absolute value of the time derivative of the envelope, or the measure of the rate of\\nrelative amplitude change.\\nA window length parameter is available (default: 33).\\nThe unit is given in Hertz (Hz). This attribute represents the standard deviation of the\\ninstantaneous power spectrum about its mean.\\nInstantaneous frequency\\nThe time derivative of phase, w=d(phase)/dt. The time derivative of instantaneous frequency\\nis often referred to as 'Phase Acceleration'. It is calculated from the temporal rate of change of\\nthe instantaneous phase (it's time derivative). Instantaneous Frequency is not the same as, and\\nshould not be confused with, the frequency of the wavelet. It is often used to estimate seismic\\nattenuation. Oil and gas reservoirs usually cause drop-off of high frequency components. It helps\\nto measure cyclicity of geological intervals and can be useful for cross-correlation across faults. It\\ncould also identify contacts between gas and water or gas and oil. Instantaneous frequency tends\\nto be unstable in the presence of noise and is sometimes difficult to interpret.\\nA window length parameter is available (default: 33).\\nInstantaneous frequency is independent of phase and amplitude, and is useful in indicating\\nreservoir rock properties such as hydrocarbon, fracture zones detection, and change in thickness\\nand lateral changes in lithology. Oil and gas reservoirs usually cause drop-off of high frequency\\ncomponents. This attribute helps to measure cyclicity of geological intervals and can be useful for\\ncross-correlation across faults. It could also identify contacts between gas and water or gas and\\noil.\\nInstantaneous phase\\nThe argument of the analytic signal, phase=arctan(g/f). The attribute is calculated on a sample\\nby sample basis without regard of the waveform. The attribute provides an amplitude\\nindependent display which is especially useful for revealing continuatively of reflectors which vary\\ngreatly in their amplitude. It is commonly used to find continuity of weak events and to\\ndistinguish small faults and dipping events. The attribute tends to enhance weak intra-reservoir\\nevents, but also enhance noise. Used together with Cosine of phase.\\nA window length parameter is available (default: 33).\\nInstantaneous phase is a good indicator of continuities, faults, pinch-outs, bed interfaces,\\nsequence boundaries, and regions of on-lap patterns. The Cosine of instantaneous phase is\\ngenerally used due to the amplitude invariant nature of the attribute.\\nInstantaneous quality\\nThe instantaneous quality factor is the ratio of instantaneous frequency to twice the\\ninstantaneous bandwidth.\\nA window length parameter is available (default: 33).\\nInstantaneous quality may indicate fluid content and absorption characteristics of reservoir. This\\nattribute can be used to highlight subtle gas reservoirs or for fracture detection.\\nIso-frequency component\\nThe contribution of individual frequencies to the make-up of the input seismic signal. Useful for\\nisolating frequency dependant changes in the signal, such as stratigraphic thinning and fluid\\neffects. The output volume is the local contribution of the selected frequency at each sample\\nposition.\\nDesired frequency (Hertz)\\nThe desired frequency is the isolated frequency component to extract from the input seismic\\nvolume.\"},\n",
       " {'header': 'Minimum: 0 ',\n",
       "  'content': 'Maximum: 125 (250 if High-band tick box is selected)'},\n",
       " {'header': 'Default: 45 ',\n",
       "  'content': 'Number of cycles (cycles per second)\\nThe length of the analysis window to extract the contribution of the selected frequency is\\ndetermined by this parameter. The analysis window length will be longer for lower frequencies and\\nshorter for higher frequencies for a defined number of cycles. A value between 1.0 and 2.0 is\\ngenerally recommended.'},\n",
       " {'header': 'Minimum: 0 Maximum: 5.0 Default: 1.0 ',\n",
       "  'content': 'Spectral normalization\\nIf selected, an average trace spectrum is computed. The output frequency is scaled by the\\ninverse of the average spectral value for the frequency.\\nNOTE: is not possible to use Depth seismic cubes or 2D lines as input for this process.\\nLocal flatness\\nThe variance of the orientation field to identify the uniformity of the signal within the\\norientation estimation range. This can be an excellent attribute for both structural and\\nstratigraphic workflows for feature isolation.\\nOrientation Filter size (Orientation sigma X, Y and Z)\\nThe filter size controls the number of traces horizontally and samples vertically to use for\\nestimating flatness. The value represents the standard deviation for the Gaussian filter (see\\nReferences). The larger the value, the larger the number of traces and samples will be used. In\\nterms of the number of traces, it is approximately twice the value on either side of the current\\npoint (a standard deviation of 1.5 would use 3 traces on either side of the central point for a total\\nof 7 traces in each direction).'},\n",
       " {'header': 'Minimum: 1.0 Maximum: 2.5 Default: 1.5 ',\n",
       "  'content': 'Orientation Filter Variance (Variance sigma X, Y and Z)\\nThe size of the local variance estimate window can be defined independently for each orientation.'},\n",
       " {'header': 'Minimum: 1.0 Maximum: 2.5 Default: 2.0 ',\n",
       "  'content': \"Below are images showing the effects on increasing the variance and orientation sigma's.\\nThe Local Flatness can be computed on an amplitude invariant input volume by using the Cosine\\nof Phase attribute volume as an initial step.\\nLocal structural azimuth\\nThe estimation of local azimuth from the seismic data, containing three options:\\nEvent: the downslope azimuth [0, 360] of the estimated event. The gradient is assumed to\\nbe perpendicular to the event.\\nGradient: the azimuth [0, 360] of the instantaneous gradient of the sample neighborhood.\\nPrinciple Component: local azimuth estimate from principal component analysis of\\ngradient covariance matrix (Randen, 2000).\"},\n",
       " {'header': 'Event Azimuth Gradient Azimuth Principle Component Azimuth ',\n",
       "  'content': 'For the Principle Component calculations sigma\\'s values can be used in the X, Y and Z directions\\nto specify the window radius when calculating the \"chaoticness\".\\nThe results of changing the sigma\\'s can be seen below. The larger the sigma, the smoother the\\nresut.\\nThe local structural dip (see below) and azimuth attributes are powerful both for capturing\\nproperties of the seismic data, i.e. as attributes, and as a basis for compensating for the dip and\\nazimuth.\\nLocal structural Dip\\nThe estimation of local dip from the seismic data, containing three options:\\nEvent: the downslope dip (0..90) of the estimated event. The gradient is assumed to be\\nperpendicular to the event.\\nGradient: the dip (-90..90) of the instantaneous gradient of the sample neighborhood.\\nPrinciple Component: local dip estimate from principal component analysis of gradient\\ncovariance matrix (Randen, 2000).\\nThe same sigma\\'s values for the calculation of Principle Component as for the Local structural\\nazimuth applies here.'},\n",
       " {'header': 'Event Dip Gradient Dip Principle Component Dip ',\n",
       "  'content': 'Neural net (Estimation model)\\nAttribute volume generated based on other seismic attributes by applying a neural net model\\nthat has been trained on existing data.\\nEstimation model: Neural net model trained on existing data.\\nOriginal amplitude\\nThe real part of the analytical signal, f(t). This is the original seismic trace.\\nPhase shift\\nA selectable phase rotation of the input signal.\\nPhase shift (degrees): The desired phase angle to rotate the input seismic data.'},\n",
       " {'header': 'Minimum: -180 Maximum: 180 ',\n",
       "  'content': 'Default: 180 (polarity reversal)\\nPhase rotation is commonly applied to improve the match between different versions of seismic\\ndata. A phase rotation of 180 will produce a reverse polarity version of the input trace, while a\\n+90 or -90 degree rotation will alter the seismic trace in such a way that a peak or trough on the\\ninput trace will become a zero-crossing on the output trace, and vice-versa.\\nPhase rotation can be used to tie seismic polarity to lithology and to improve amplitude-porosity\\ncorrelation.\\nQuadrature amplitude\\nThe imaginary part, g(t), of the analytic signal, calculated by phase shifting the original trace\\nby 90 degrees. An analytic signal is constructed from the real seismic amplitude and the\\nimaginary quadrature amplitude. This signal is complex, and cannot be visualized directly.\\nA window length parameter is available (default: 33).\\nReflection intensity\\nReflection intensity is the average amplitude over a specified window (default 9 samples)\\nmultiplied with the sample interval.\\nNo parameters are required.\\nReflection Intensity is useful for the delineation of amplitude features while retaining the\\nfrequency appearance of the original seismic data.\\nRelative acoustic impedance\\nRelative acoustic impedance is a running sum of regularly sampled amplitude values.\\nCalculated by integrating the seismic trace, passing the result through a high-pass Butterworth\\nfilter, with a hard-coded cut-off at (10*sample rate) Hz.\\nNo parameters are required.\\nThis attribute shows apparent acoustic contrast, indicates sequence boundaries, unconformity\\nsurfaces and discontinuities. It can also indicate porosity or fluid content in the reservoir.\\nNote: RAI attribute has been reworked as an asynchronous attribute for Petrel 2010.1 This\\nenables virtual on virtual calculations using virtual RAI cubes as input. On the other hand, the\\nButterworth filter mentioned above is now applied as a low-cut filter with no scaling. Hence the\\nresultant value range will be larger and more pronounced than in previous versions of Petrel.'},\n",
       " {'header': 'Remove Bias ',\n",
       "  'content': 'Remove Bias tries to remove deconvolution bias from the seimsic traces. A bias is a constant\\nthat has been added or substracted from the data samples. DC bias occurs when the average of\\nthe trace values departs from zero and may be caused by processing artifacts and/or geological\\nfactors.\\nNo parameters are required.\\nThe left image shows the original seismic amplitude volume and the right shows where the DC\\nbias has been removed.\\nRemove bias can be used when an inversion cube is biased by the starting velocity or acoustic\\nimpedance.\\nRMS Amplitude\\nRMS Amplitude computes Root Mean Squares on instantaneous trace samples over a specified\\nwindow.\\nA window length parameter is defined by the number of samples (default: 9 samples).'},\n",
       " {'header': 'Second Derivative ',\n",
       "  'content': 'The second time derivative of the input seismic volume. The combination of the original\\namplitude, first derivative, and second derivative allow you to express seismic interpretation in\\nrelationship to maximum, minimums, greatest descents, and descent polarity.\\nNo parameters required.\\nSecond derivative can be used to help guide the pick by providing continuity in areas of where\\nreflections are poorly resolved on the raw amplitude. Lateral amplitude variations are visibly\\ndiminished, which will make auto-tracking regional events more difficult.'},\n",
       " {'header': 'Structural Smoothing ',\n",
       "  'content': 'Smoothing of the input signal guided by the local structure to increase the continuity of the\\nseismic reflectors(Randen, 2002). Principal component dip and azimuth computation are used to\\ndetermine the local structure. Gaussian smoothing is then applied parallel to the orientation of\\nthis structure.\\nDip guiding (checkbox)\\nOption to determine if smoothing will be performed parallel to local structural orientation\\nestimate.\\nUnchecked: Perform traditional 3D Gaussian smoothing\\nChecked: Perform structurally guided Gaussian smoothing\\nEdge enhancement (checkbox)\\nOption to enhance the presence of edges detected with the Dip guiding option.\\nUnchecked: Do not enhance detected edges\\nChecked: Enhance detected edges\\nFilter size (Inline, Crossline, Vertical)\\nThe filter size controls the number of traces horizontally and samples vertically to use for\\nestimating structural smoothing. The value represents the standard deviation for the Gaussian\\nfilter (see References). The larger the value, the larger number of traces and samples will be\\nused. In terms of the number of traces or samples, it is approximately twice the value on either\\nside of the current point (a standard deviation of 1.5 would use 3 traces on either side of the\\ncentral point for a total of 7 traces in each direction).'},\n",
       " {'header': 'Minimum: 0 Maximum: 10.0 Default: 1.5 ',\n",
       "  'content': 'The Structural smoothing attribute can also be used to illuminate flat spots within the seismic\\nvolume. By running the smoothing operation without Dip guiding, horizontal features such as fluid\\ncontacts can be emphasized.\\nStructural smoothing is an extremely valuable operation to run before auto-tracking as it can\\nstabilize the results. The results could be snapped back to the original data, or used as a smooth\\ninterpretation of regional surfaces.'},\n",
       " {'header': 'Sweetness ',\n",
       "  'content': 'Sweetness is the implementation of two combined attributes (Envelope and Instantaneous\\nFrequency) and is used for the identifacation of features where the overall energy signatures\\nchange in the seismic data.\\nSweetness is defined by the formula: Sweetness=Envelope/SQRT(Inst. Frequency)\\nBelow is an exmaple of sweetness to highlight a progressing channel sequence.\\nt* Attenuation\\nThe differential loss of high frequencies relative to low frequencies as measured above and\\nbelow the point of interest. It can be used to identify fracture zones and fluid movement.\\nLower frequency (Hertz)\\nThe lower frequency comparison point is presumed to be less effected by attenuation. This value\\nshould be high enough to contain a measurable signal above the background noise.'},\n",
       " {'header': 'Minimum: 0 ', 'content': 'Maximum: Higher frequency setting'},\n",
       " {'header': 'Default: 18 ',\n",
       "  'content': 'Higher frequency (Hertz)\\nThe higher frequency comparison point is presumed to be more effected by attenuation. This\\nvalue should be low enough to contain a measurable signal above the background noise but\\nseparated from the lower frequency by as much as the signal bandwidth will allow.\\nMinimum: Lower frequency setting\\nMaximum: 125 (250 if High-band tick box is selected)'},\n",
       " {'header': 'Default: 36 ',\n",
       "  'content': 'Number of cycles (cycles per second)\\nThe length of the analysis window to extract the contribution of the selected frequency is\\ndetermined by this parameter. The analysis window length will be longer for lower frequencies and\\nshorter for higher frequencies for a defined number of cycles. A value between 1.0 and 2.0 is\\ngenerally recommended.'},\n",
       " {'header': 'Minimum: 0 Maximum: 5.0 Default: 1.5 ',\n",
       "  'content': 't* Attenuation is a patented seismic attribute for indicating open fractures within the seismic\\nvolume based on windowed frequency attenuation. The attenuation is tied to the fracture density\\nand the vertical thickness of the fractured zone.\\nNOTE: is not possible to use Depth seismic cubes or 2D lines as input for this process.\\nTime gain\\nScales the trace amplitudes with (1+t)*G, where G is a constant specified by the user.\\nTime gain (exponent): The desired exponent to scale the input seismic data.'},\n",
       " {'header': 'Minimum: 0 Maximum: 10.0 Default: 1.5 ',\n",
       "  'content': 'Trace AGC\\nTrace AGC scales the instantaneous amplitude value with the normalized RMS amplitude over\\na specified window (by default 9 samples).\\nRMS window input.\\nThe attribute is useful for boosting weak events for improved interpretability. It will also have the\\neffect of boosting noise which could be eliminated using the Structural Smoothing attribute.\\nTrace gradient\\nTrace gradient computes the gradient along a trace (default 5 samples). It gives the amplitude\\ndifference across the output time sample and will have the highest value at points having the\\ngreatest rate of change.\\nNo parameters are required.\\nGradient illumination effects can be produced with the semi-transparent rendering of the Trace\\nGradient attribute superimposed on the original seismic data.\\nVariance (Edge method)\\nThe estimation of local variance in the signal. You can apply optional vertical smoothing for\\nnoise reduction. It is useful for edge detection.\\nFilter length (Inline, Crossline range)\\nThe filter size controls which number of traces horizontally to use for estimating horizontal\\nvariance. The larger the value, the larger the number of traces will be used. Normally, the inline\\nand crossline filter length will be set the same.'},\n",
       " {'header': 'Minimum: 1 Maximum: 11 Default: 3 ',\n",
       "  'content': 'Vertical smooth (milliseconds)\\nThe filter size controls what tapered vertical smoothing to apply to the variance computation.\\nLarger values (greater than 80 ms) reduce noise effectively but also \"smear\" the sharpness of the\\ndetected edges. The optimum length is data and objective dependent, but 32 - 64 milliseconds is\\na good starting point.'},\n",
       " {'header': 'Minimum: 0 Maximum: 200 Default: 15 ',\n",
       "  'content': 'Note: Attribute Examples from WestCam Survey - Xline 380, Inline 231-367, Time 872-2132\\nDip correction (Inline, Crossline, Vertical scale)\\nDirectional parameters can be added to the variance attribute. This uses a principle component\\nanalysis (PCA) and the primary component of that PCA as a dip estimation method. A larger filter\\nsize gives a smoother result.'},\n",
       " {'header': 'Minimum: 0 Maximum: 5 Default: 1.5 ',\n",
       "  'content': 'Plane confidence threshold\\nThe dip-guided algorithm computes variance along a dip plane with a corresponding measure of\\nthe dip estimate confidence. Areas where the computed confidence is above the selected\\nconfidence threshold will apply dip-guiding. Areas where the confidence is below the threshold will\\nrevert to standard horizontal variance.'},\n",
       " {'header': 'Minimum: 0 Maximum: 1 Default: 0.6 ',\n",
       "  'content': 'Below are images showing the effects on modifying direction and confidence threshold.\\nThe Variance attribute that can be used to isolate edges from the input data set. By edge, this\\nmeans discontinuities in the horizontal continuity of amplitude.\\nVariance is applicable as a stratigraphic attribute. If run with a short window, it can bring out\\ndepositional features, including reefs, channels, splays, etc.\\nDip guided variance is useful for accentuating structural features like faults. For stratigraphic\\nfeatures (i.e. channels), variance without dip-guidance is a better choice.\\nVelocity cube\\nVelocity type (instantaneous or interval vs. average velocity) and domain (time vs. depth) is\\nread from the property template associated with the input seismic velocity cube. Velocity type and\\ndomain for the conversion output cube must be chosen.\\nConvert cube to\\nVelocity type: velocity or average velocity\\nDomain convert result: Keep in the same domain as the input volume or domain convert the\\noutput volume.'},\n",
       " {'header': 'Datum ',\n",
       "  'content': 'Time datum SRD.\\nOther: Constant or surface.\\nCreate Volume attributes\\nHow to create a Seismic Volume Attribute\\n1. On a seismic volume, open the right mouse button pull-down menu.\\n2. Select Volume attributes... from the menu. The Volume attributes process dialogue will\\nappear with the selected seismic volume defined as the Input seismic volume.\\n3. A Virtual volume or a Realized volume can be generated. When the operation is\\ncomplete, the new seismic attribute volume will be instantiated in the Petrel Explorer. A\\nRealized volume cannot be changed, only used as an input for additional operations. A\\nVirtual volume can be changed to a different attribute.\\nHow to change a Virtual Seismic Volume Attribute\\n1. On a virtual seismic attribute volume, open the right mouse button pull-down menu and\\nclick Settings, or double-click on the cube.\\n2. The Attribute Library tab on the Settings dialogue allows you to change which attribute\\nto generate, but does not allow you to change the Input seismic or the Output seismic\\ndefinitions.\\n3. Press the right mouse button on the attribute object in the Petrel Explorer and Insert\\nInline/crossline /seismic intersection.\\n4. The color table for an attribute can be changed under the Info tab, and the scale settings\\nfor color may be changed under the Colors or Opacity tabs.\\n5. A realized version of the virtual seismic attribute volume can be created under the\\nOperations tab. The virtual seismic attribute volume will not be affected. A new realized\\nvolume will be created and appear in the Petrel Explorer.\\nHow to view an Attribute\\n1. To view the attribute, click on the toggle box in front of the default Inline or Crossline\\nIntersections. Alternatively, select the Insert inline, crossline, time slice or seismic\\nintersection from the (right mouse button) pull-down menu of the attribute object in the\\nPetrel Explorer. Display the intersections in an Interpretation Window, a 2D window or a 3D'},\n",
       " {'header': 'Window. ',\n",
       "  'content': '2. Use the other icons in the Function bar below the Display window to maneuver the\\nintersection.\\nCreate Volume attributes using the Workflow\\neditor\\nThe dialog for creating seismic attributes in the Workflow editor is identical to that used in a normal\\nPetrel workflow, however within the Workflow editor object variables can be used to use the results of\\none process as input to another.\\n1. Drop the volume attributes process into the workflow.\\n2. Double-click on the process in the workflow tro open it.\\n3. Fill in the settings for the first attribute as normal.\\n4. Drop in a second attribute generation process and fill in the appropriate settings\\n5. To use the results of the first attribute as the input to the second process, drop from\\nthe variables folder on the workflows tab into the input box.\\n6. To use the results of the first run in several runs assign to another object variable and\\nuse that. See Referring to objects (Workflow editor) .\\n6.\\nSeismic attribute workflows\\nThis section is intended to stimulate thought on possible workflows that can be achieved by using\\nthe Volume attributes process. Additional functionality is described in the Surface attributes\\ndocument, and the creation of Seismic Properties in a 3D Grid .\\nSeismic attributes can be created using the Workflow editor, allowing attributes to be\\ncreated in batch and enabling cascading workflows where the results of one process are used in\\nthe next.\\nImproving horizon auto-tracking on noisy data\\nStructural smoothing can be an effective tool to reduce background noise and improve the\\nspatial continuity of seismic signal for horizon auto-tracking.\\n1. Apply strong structural smoothing (filter size 2.0 -3.0) to the input seismic volume.\\n2. Auto-track regional marker events\\n3. Apply a milder structural smoothing (filter size 1.0 - 1.5) to the input seismic volume\\n(not the strongly smoothed one).\\n4. Auto-track, or manually interpret reservoir level events.\\nOther suggestions for difficult noise data are to use simple filtering via the graphic equalizer to\\nenhance the continuity of events or to consider tracking from a more continuous attribute, for\\nexample: cosine of phase, envelope, or second derivative attributes.\\nHorizon auto-tracking on Apparent polarity\\nThe apparent polarity attribute reduces the seismic volume to estimates of the maximum peak\\nand trough contributions. This is a useful attribute to perform auto-tracking on.\\n1. Optionally, apply structural smoothing (filter size 1.0 - 3.0) to the input seismic volume\\nto reduce noise.\\n2. Generate the apparent polarity attribute using the structural smoothing result as the\\ninput.\\n3. Auto-track the desired events on the apparent polarity volume.\\n3.\\nEnhancing fault appearance on edge detection\\nvolumes\\nSeveral attributes are available which are capable of highlighting fault features. Variance is an\\nexcellent starting point to capture fault expression in the data. The visualization of faults is best\\nseen in timeslice orientation.\\n1. Apply structural smoothing (filter size 1.0 - 3.0) to the input seismic volume to reduce\\nnoise.\\n2. Generate the variance attribute using the structural smoothing result as the input.\\n3. Adjust color table range to emphasize important features in the data.\\nDiscrimination of Stratigraphic features\\nA single attribute may not be capable of distinguishing subtle stratigraphic events. A combination\\nof different attributes can detect different expressions of the feature, and can then be combined\\nfor a more complete picture. Shown in the example below are: seismic amplitude to detect\\nanomalous amplitude relative to background signal, variance to identify sharp edges causes by\\nthe feature, and iso-frequency to capture the frequency expression relative to background.\\n1. Once a target area is identified, realize a cropped volume to reduce the amount of\\nunnecessary computation of attributes.\\n2. Generate a virtual attribute of interest from the cropped volume.\\n3. Select Insert timeslice intersection. Once displayed, the other icons in the Function bar\\naround the Display window can be used to maneuver the intersection.\\n4. Additional virtual attributes can be generated in the same fashion.\\nIntroduction to Genetic Inversion\\nA new approach to derive an Acoustic Impedance Inversion volume is proposed in Petrel. Multi\\nlayer neural networks as well as genetic algorithm are combined together in order to provide a\\nrobust and straight forward seismic inversion.\\nThe estimation of rock properties using seismic data and derived attributes has always been a\\nvery important but challenging task. There are several different methods for achieving this goal.\\nAll of them are based on strong and constraining a priori information. The required knowledge of\\nan initial model (cf. for the stochastic inversions), or source wavelet (cf. Colored-, Sparse Spike\\nInversion), is in several cases hard to acquire, if not impossible. Moreover, the result of this kind\\nof inversion is often biased by the input initial model itself.\\nIn the case of Genetic Inversion, the required inputs are limited to the seismic amplitude, and the\\nAcoustic Impedance well logs used as training data. Indeed no single unique wavelet, neither\\ninitial property modeling are needed as inputs prior to run the inversion. A genetic algorithm\\nback-propagates the error in order to update the weights for the neural networks.\\nThe advantage of this new method of generating a property estimation, is that the genetic\\nalgorithm constrains the convergence of the inversion in a way that the chance of achieving a\\nglobal minimum error is much greater than in other previous neural network based inversions.\\nThus, success is quasi absolute. In addition, another advantage of this process is that it is not\\nonly restricted to conventional Acoustic/Elastic impedance inversion, but it can be extended to any\\nkind of petro-physical attribute/parameter, which is linked in a meaningful, and straightforward\\nway to the seismic amplitude or derived attribute data. To be more explicit, all the parameters\\ncontained in the wave-equation are possible candidates (e.g. velocity, density, porosity, bulk\\nmodulus...).\\nThe methodology has been proven valid in a real case study across the Shtokman gas field,\\nRussia. The result was published in Geophysics, vol. 74 (2009), Nonlinear multitrace genetic\\ninversion applied on seismic data across the Shtokman field, offshore northern Russia\\nby Paul C. H. Veeken et al. External link to article: http://dx.doi.org/10.1190/1.3223314\\nParent topics: Neural Networks Background, Background to Creating Estimation Models\\nGenetic Inversion: Brief explanation of Neural\\nNetworks ang Genetic Algorithms.\\nBasics concepts of Neural networks are described in the \"Neural Network background\" part of the\\nOnline help.\\nThus the theory may not be as detailed as within this part. For further details you may want to\\nlook into existing standard literature (see References) Figure 1 gives you a schematic view of the\\nworkflow of the Genetic inversion behind the user interface.\\nFigure 1: Genetic inversion workflow scheme.\\nThe Neural network used is a common Multi-layer network, with one hidden layer in the case of\\nthe Genetic Inversion (GI) module. The characteristics of the Neuronal workflow are as follows:\\nActivation function (sigmoid function):\\nInput/hidden layer relationship:\\nThe bias of the input layer, and the one of the hidden layer are respectively represented by:\\nThe difference is locate in the fact that the weights update is not done in a classical way.\\nTraditionally, Neuronal processes use a Gradient descendent method (or more elaborated ones\\nlike \"Conjugate gradient\", \"Newton\"...) and back propagate the error in order to converge\\nhopefully to the global minimum.\\nThe introduction of a Genetic Algorithm into the Neural Network common workflow, represents a\\nstep forward with respect to the convergence risk which takes into account local minima as well\\nas the computation time aspect.\\nInitially, what is called population in figure 1, represents a set of 50 input weight combinations\\n(randomly selected), which are all going through the neural network first iteration. The output\\nresult is then compared with the observed datasets (cf. the well logs) by calculating an error\\nfunction. As soon as an error value is computed for each of the 50 input weight combinations, the\\nprocess enters into the Genetic part of the algorithm (see illustration in figure 2):\\nSelection : in analogy to the natural selection hypothesis of C. Darwin which favors only\\nthe best adapted individuals to survive; in this case the survival criteria is given by the\\nindividual with the smallest error.\\nCross-over : during that step \"chromosomes\" (here a \"chromosome\" will be one weight\\ncombination) are exchanging \"genes\" (a \"gene\" is here associated to a single weight, within\\none combination) between each other (the number of genes exchanged can be singular or\\nmultiple). This cross-over phenomenon is occurring with a given probability after and within\\neach iteration.\\nMutation : Again, like in the natural evolution theory, genes are going to be replaced\\nrandomly within chromosomes. This is insuring for the process not to converge to a local\\nminimum. The probability of occurrence is here as well a function of the iteration step itself,\\ne.g. mutation is more likely to happen as soon as the evolution of the error function is\\nreaching a plateau. Nevertheless, in most cases it is much lower than the cross-over\\nprobability.\\nIt is important to note that the population at each iteration of the inversion has a constant\\nnumber (cf. 50). Therefore, even if the selection is reducing the number of the population, by\\ntaking, for example the 10 best ones; applying \"cross-over\" and \"mutation\" to those selected\\ncombinations of weights will recreate a full set of 50 \"chromosomes\" into the population.\\nThe output of this workflow is a non-linear multi-trace operator which will be applied to the whole\\nseismic dataset, and will transform it into the property described by the logs used during the\\ntraining phase. This filter makes the parallel with the wavelet used in common Acoustic\\nImpedance inversions. The derivation of the operator is supported by creating many shifted\\nvolumes of the original seismic cube and feeding them into the neural network engine to power\\nthe genetic inversion (cf.Genetic Inversion parameters ). Vertical shifts in the seismic volume are\\naccounting for vertical mismatch of the non-linear operator, while lateral shifts compensate for\\nlateral dissipation of energy (cf. the operator will take into account the geological structure\\ncharacterized by the continuity of the seismic amplitudes).\\nFigure 2: Schematic explanation on how cross-over and mutation is working.\\nGenetic Inversion parameters\\nThis section explanes the different settings and details on the a priori information needed for\\ngenetic inversion.\\nThe Genetic Inversion module is located within the Volume Attribute library under the\\n\"Stratigraphic methods\" class. As for the other volume attributes, the Input/output tab defines\\nwhat input volume is used and how the result is stored. The Parameters tab defines how the\\nneural network and genetic algorithm learns and handles the result for each iteration.\\nThe latter tab is divided into three sub-titles (see figure 1):\\n1. Learning inputs'},\n",
       " {'header': '2. Settings ',\n",
       "  'content': '3. Advanced options\\nEach part organizing a given set of parameters\\nLearning inputs:\\nAll the inputs for the Genetic inversion will be located in the Input pane (cf. Ctrl+T) of Petrel.\\nSeismic cube : You have to drop in the 3D volume you want to use for the learning step\\n(see \"Genetic Inversion: Brief explanation of Neural Networks ang Genetic Algorithms. \"),\\nas well as for the inversion itself. You can choose all types of 3D cubes as input (e.g.\\ncropped volume, seismic attributes, SEG-Y or ZGY format...). For performance reasons, it is\\nrecommended to use bricked volumes (ZGY format).\\nWell folder : Select the global well folder or any sub-folder, containing the wells which will\\nbe used for the learning process.\\nGlobal well log : Select one of the logs listed within the \"Global well log\" folder. It must be\\ncontinuous, and have some explicit (linear or not) relationship with the Seismic cube.\\nQC well folder :Select the global well folder or any sub-folder, containing the wells which\\nwill be used as the \"Blind\" wells. The relationship determined by Neural Network during the\\nlearning step will be computed at those wells so you can cross-validate the computed\\nproperty and the observed one.\\nFigure 1 : Paramters tab of the Genetic inversion attribute.'},\n",
       " {'header': 'Settings: ',\n",
       "  'content': 'Vertical range : vertical extension of the seismic sub-volume (see figure 5). Set to 50 by\\ndefault (depends on the resolution of the seismic).\\nInline half-range : horizontal half extension of the seismic sub-volume, with respect to\\nthe inline direction. Set to 1 (cf. number of inline interval) by default (depends on the lateral\\ncontinuity of the structures with respect to the inline direction).\\nCrossline half-range : horizontal half extension of the seismic sub-volume, with respect\\nto the crossline direction. Set to 1 (cf. number of cross-line interval) by default (depends on\\nthe lateral continuity of the structures with respect to the crossline direction).\\nResample parameter : defines the sample increment within the seismic around the well\\nsample in order to create the input vector containing the seismic amplitudes for which the\\nlearning process is computed. Set to 3 by default (depends on the sampling rate and the\\nresolution of the seismic). In conclusion, the higher the Resample parameter, the more\\nimportant the concentration of samples per volume unit (this parameter is driven by the\\nfrequency content of the seismic). Figure 2 sums up schematically this option.\\nTop surface/marker : select a \"regular surface\" for the upper limit where the learning\\nprocess is computed. You can also use well-top markers.\\nBottom surface/marker : select a \"regular surface\" for the lower limit where the learning\\nprocess is computed.\\nFigure 2 : Seismic resampling prior to learning phase. Crosses represent the \"jumped\" samples\\n(not included into the learning phase).\\nFigure 3 : Seismic resampling prior to learning phase. 3D representation\\nAdvanced options:\\nMaximum iterations : defines the maximum number of runs allowed for computing the\\nNeural Network derived operator with respect to the Correlation threshold. Set to 1000 by\\ndefault.\\nCorrelation threshold : Converging criteria. Set to 0.85 by default.\\nIf the latter one is reached before the maximum number of iteration, the learning process will\\nstop. In the opposite case, if the maximum threshold is reached before the converging criteria,\\nthe learning process will stop as well. As the two previous parameters are strongly linked\\ntogether, one should be aware that they are affecting each other.\\nNodes in hidden layer : number of cells in the hidden layer used for computing the\\ninversion operator. Set to 3 by default (has a drastic impact on the computation time).\\nLinear : toggled OFF by default. Once chosen, this option deactivates the Neural Network\\nand tries to find a linear combination of the inputs (e.g. amplitudes in the sub-volume : see\\nfigure 5) instead of using the combination of sigmoid functions (see \"Genetic Inversion:\\nBrief explanation of Neural Networks ang Genetic Algorithms. \"). The Hidden Layer (cf.\\nfigure 4), is removed from the process.\\nFigure 4 : Schematic approach of the link between seismic traces and property logs, through'},\n",
       " {'header': 'Neural Nets. ',\n",
       "  'content': 'Computation of the derived Neural Network operator (see figure 5) is made step by step from\\n\"Top surface\" down to the \"Bottom surface\", each step being equal to the seismic sample interval\\n(e.g. 1 to 4 ms).\\nFigure 5 : Illustration of the sub-volume used for the Neural Network.\\nWeight decay: Neural network smoother and overfitting prevention parameter. Once this\\nparameter is set larger than 0, it will constrain the neural network fitting process. The result\\nis smoother output data. Correlation on training data will generally decrease when\\nincreasing the weight decay parameter, but correlation on QC wells might increase as a\\nresult of less overfitting on the training data\\nData gathering and pre-processing\\nThe following describes how the input data should be pre-conditioned in order to improve the\\nsuccess of the inversion.\\nAs you can see in the parameters tab (cf. \"Genetic Inversion parameters \" part), no a priori model\\nand no input wavelet is required for the inversion. In fact, the Genetic Inversion algorithm is not\\ngoing through any forward modeling step, by computing synthetic dataset in order to estimate\\nthe error function. The process itself is trying to build a function directly in order to go from the\\nSeismic cube vector space into the property space.\\nA conventional inversion scheme is doing everything at once within each iteration (modeling, error\\nfunction computation, back-propagation, model re-estimation...), whereas within the Neural\\nnetwork process the modeling part is done once for all at the end of the learning phase.\\nGenetic Inversion requires only the essentials regarding the inputs. Nevertheless, this does not\\nmean that the input data used does not need any pre-conditioning in order to increase the\\nprobability of success of the process.\\nThe main input data is as follows:\\nSeismic cube.\\nProperty logs.\\nUpper/Lower limit for the training.\\nFrom a strict mathematical view the seismic cube itself does not need any particular pre-\\nprocessing (e.g. like zero-phasing the seismic trace, which is sometimes required in Sparse Spike\\nInversion). Nevertheless in order for the inversion result to match properly the property which is\\ntried to be recovered, by the modeling step; the seismic cube in use should have true amplitudes\\n(no AGC...) a phase signature matching the response to the Acoustic Impedance log and of\\ncourse as less noise as possible. The Well logs must go through a much more elaborated\\nprocessing.\\nFurthermore, the generation of a solid well-tie relationship between wells sampled in depth and\\ntwo-way-traveltime seismic is essential before attempting any Inversion process. Petrel offers a\\ncomprehensive tool to generate Synthetic seismograms for this purpose. Since the Acoustic\\nImpedance logs used as input will have a major role in training the Neural network, a poor well-\\ntie situation will lead to poor or wrong results.\\nA weak point with Genetic Inversion compared to classical methods, where an initial model based\\non the well logs is required, is that the final resolution is less important. The classical methods are\\nusing the higher frequency bandwidth of the well logs (see figure 1), in order to increase the one\\nof the Inverted cube, compared to the Initial seismic input. For the neural network training to\\nsuccess in the creation of an operator which will link the seismic to the property log, both of them\\nshould look \"alike\" in a way (note: Neural Nets, can build a relationship between carrots and\\napples but reality is different).\\nThus, the well logs used for the learning phase, should additionally go through a prior low pass\\nfiltering (with a cutting frequency defined by the seismic spectrum) process. Nevertheless the low\\nfrequency content does not have any negative impact on the Neural nets learning process; so,\\none could even expect to have a noticeable increase in the inverted cube\\'s resolution due to the\\nwell log contribution (cf. seismic cubes have usually a lower threshold in their spectrum range\\nwhich is around 6Hz, for marine acquisition).\\nFigure 1 : Acoustic impedance log (in red), filtered acoustic impedance log (in black, overlaid to\\nthe red). Seismic around the wells (wiggle).\\nFinally the Upper and the Lower limit defined by the \"Top surface/marker\", and \" Bottom\\nsurface/marker\" input parameters, are the only requirement defining kind of a structural\\nboundary for the learning area. Indeed it is recommended to keep this interval (defined by the\\ntop and base surfaces) relatively close in order to get a derived operator which is defined within a\\nstructurally stable area (cf. not taking into account the vertical low wave-number behavior of the\\nsedimentation due to compaction).\\nThe Genetic Inversion process, once it has established the non-linear multi-trace operator linking\\nthe Seismic cube amplitude and the rock property, will then model the latter property all over the\\ncube; even if this filter was only derived within the interval defined by the top and base surfaces.\\nThus one should not take into account the results produced outside the area of interest.\\nGenetic Inversion workflow\\nThe following examples describes the best practices when doing genetic inversion.\\nThe Petrel Inversion module is not restricted to pure Acoustic impedance inversion, but can be\\nextended to any property with some inherent link with respect to the input seismic cube.\\nThree examples will be shown:\\nGenetic Inversion workflow 1: Acoustic Impedance computation\\nGenetic Inversion workflow 2: Porosity cube computation\\nGenetic Inversion workflow 3 : Check for consistent well calibration\\nFigure 1 : General workflow for genetic inversion in Petrel.\\nGenetic Inversion workflow 1: Acoustic\\nImpedance computation\\nFor this specific attribute (Acoustic Impedance), the Genetic Inversion is not the only required\\nmodule to get the inputs you need. In fact, to fulfill all the desired input parameters you should\\nhave a seismic cube. The calibrated AI logs are however a main input a priori parameter.\\nVelocity (Vp, Vs...) and density logs (RhoB...) are can be found within the global well logs list. You\\nhave to derive (using the Well calculator) the Impedance from them (Impedance=Velocity x\\nDensity). Alternatively, you can use a more complex workflow from either \"Synthetics\" in Petrel,\\nor the MMRD module (see. MMRD, Synthetics). The latter ones are not going to be described in\\ndetails in this section.\\nGenerally, the acoustic impedance and other types of reservoir properties are not interesting if\\nthey are computed outside the reservoir limits. You therefore have to specify the Top and Base\\nsurfaces of the area you want to use. Alternatively, you can select a specific area of the global\\nseismic cube by using a cropped volume and running the inversion on the latter one (as Top and\\nBase surfaces are not mandatory inputs).\\nIn order to get the Impedance cube, you have to follow the Workflow described in Genetic\\nInversion workflow . As clearly described in the workflow above, the most important parameter\\nused for the inversion is the set of wells. There are limits to the amount of logs you can use for\\nthe learning phase. A set made of too many wells will cause the inversion to fail because the\\nnumber of unknown parameters will make the whole process unstable. The recommended\\nnumber is around 10. Another important parameter is the spatial distribution of the boreholes\\nwith respects to the geological repartition of the facies. If you take these two facts into account,\\nyou will increase the chance that the derived operator is efficiently characterizing the relationship\\nbetween the seismic and the property.\\nFigure 1 : Impedance cube generated by Genetic Inversion displayed with acoustic impedance\\nlogs.\\nGenetic Inversion workflow 2: Porosity cube\\ncomputation\\nThe initial steps here are the same as for the Acoustic impedance inversion. However, you cannot\\nmanually compute any Porosity logs ( Phi) and instead you have to use the logs obtained from\\nwell measurements. The Genetic Inversion itself works in exactly the same way; it is an operator\\nlinking the seismic impedance (or any type of attribute you want to use) to the Porosity and is\\nderived by using a combination of Neural Network and Genetic Algorithms.\\nBy following the general workflow in Genetic Inversion workflow you can do iterations over the\\nreservoir zones in order to have a derived distribution with respect to a specific sedimentation\\nprocess. This means that you will have to run the inversion for each zone (for example, porosity is\\ndifferent from a shore-face depositional system, to a channel one) specify top and base surface\\nfor each layer and finally use the seismic calculator to get the right property cube (figure 1).\\nFigure 1 : Final property cube with a well displayed on one of the inlines.\\nNote that in figure 2 , the porosity logs displayed are not low-pass filtered. The display is just\\nmade to show that the inversion process, despite the fact that the frequency content of both input\\nparameters, is very robust. This can be verified by applying the \"Blind-well method\" using a set of\\nwells which will not be part of the learning process, but where you will QC that the operator is\\nstable and robust enough to model the input property correctly, even far away from the wells\\nused in the learning process.\\nArriving at this step, you have to populate the geological model, using the inverted cube, and the\\nre-sampling process (Geometrical modeling process -> Seismic resampling).\\nThis specific workflow can be applied to any type of reservoir or rock property which has an\\nexplicit (linear or not) relationship with the seismic amplitude (good examples: Porosity, Density,\\nVelocity, Poisson\\'s coefficient...; bad examples: Permeability, Resistivity...).\\nFigure 3 and 4 allow you to QC the property population by upscaling the Genetic Inverted cube,\\nagainst the traditional Kriging method. Statistics from up-scaled porosity logs compared to the\\nstatistics from the upscaled property cube (highlighted in red within figure 1), give very close\\nresults.\\nFigure 2 : Well section of some of the wells used for the Genetic Inversion. Seismic well section of\\nthe porosity cube, inverted porosity log (in black) with original porosity log (in red) overlaid.\\nIn conclusion, this way of building your geological model can for some reservoir properties be\\nvery interesting ibecause it is a faster way. In addition, the structural repartition of a given\\nproperty will be much more accurate compared to models build using kriging derived methods.\\nFigure 3 : Comparision between statistics from the upscaled porosity logs and the upscaled\\nporosity cube.\\nFigure 4 : Porosity model populated in the 3D grid.\\nGenetic Inversion workflow 3 : Check for\\nconsistent well calibration\\nYou can use the Genetic Inversion as a QC to validate that the well calibration process was done\\ncorrectly prior to any interpretations. Therefore, use the best calibrated one as the input well for\\nthe Neural Network learning phase, and all the other wells as QC wells.\\nNote that the input log is of no importance here as the result does not have any modeling\\npurposes. You can therefore choose between porosity, density, sonic, and so on as the input log\\nfor the inversion.\\nAfter running the process, you can display this in a single well section window: First, the well used\\nfor the training, the initial inputted log overlaying the modeled one to verify that they do match\\ncorrectly. Next, you can display all the QC wells with the same well section template (compare the\\ntwo overlaid curves) in order to QC that there is a correct match between the modeled and the\\ntrue logs. A mismatch does not necessarily mean the inversion failed. Look again at the QC\\nmodeled well log and see if the global shape of the curves match but are shifted up or down\\ncompared to the original logs. This means that the derived operator is good, but the well tying is\\nwrong.\\nYou now have a qualitative and quantitative estimation of the errors made during the well-tie\\nstep.'},\n",
       " {'header': 'Ant Tracking Workflow ',\n",
       "  'content': 'The patent pending Ant Tracking algorithm automatically extracts fault surfaces from fault\\nattributes. The algorithm uses the principles from ant colony systems to extract surfaces\\nappearing like trends in very noisy data. Intelligent software agents (\"ants\") will try to extract\\nfeatures in the attribute corresponding to the expectations about the behavior of the faults. True\\nfault information in the attribute should fulfill these expectations and be extracted by many ants,\\nwhereas noise and remains of reflectors should be extracted by no ants or by only single ants (in\\nwhich case they will be deleted). The approach is fully 3D and can take advantage of surface\\ninformation in the surrounding voxels. This makes it possible to derive detailed information from\\nthe attribute. By writing the extracted surfaces back to a volume, we get what is referred to as an\\nenhanced attribute, or ant track cube. This cube contains only what is likely to be true fault\\ninformation.\\nThe process can be divided into four main activities: (1) seismic conditioning, (2) edge detection,\\n(3) edge enhancement, and (4) interactive interpretation (surface extraction). A collection of\\nsurface segments, fault patches, can be extracted after the generation of the ant-track attribute.\\nThis is a volume of fault surface \"pieces\" having a high confidence of connectedness, which can be\\ninteractively merged into complete fault surfaces using the Automatic Fault Extraction process .\\nFig. 1 Ant Track workflow for the creation of an ant-track attribute volume and for the generation\\nof Fault Patches extracted after the Ant tracking process.\\nBy using this new workflow, the interpretation to create fault surfaces can be done in several\\nways. The traditional approach for interpreting on the seismic sections can be done at any time.\\nIn addition, manual interpretation can be performed on a processed seismic attribute volume,\\nsuch as the ant-track enhanced edge volume. And interpretation of fault systems can be done\\nbased on spatial filtering of fault patches. See Automatic Fault Extraction process'},\n",
       " {'header': 'Fig. 2 ',\n",
       "  'content': 'Manual Fault Interpretation can be performed on any of the edge detected or edge enhanced\\nseismic volumes.'},\n",
       " {'header': 'Fig. 3 ',\n",
       "  'content': 'Patch-based Fault Interpretation, using the settings on the extracted fault patches functionality\\ncan be performed on the output patch collection from the ant-track algorithm. Examples to this\\nare shown in the figures below. The image on the left shows a Variance time slice, while the\\nimage on the right shows the corresponding Ant-tracked slice. Note that the enhanced resolution\\nof major faults and the additional information inside the fault blocks show several smaller faults.\\nThe chaotic (bottom right area) responses have not been extracted as they do not fulfill the\\nexpected fault properties, whereas detailed fault information has been derived from the\\nsurrounding volume.\\nVariance attribute Ant Tracking attribute'},\n",
       " {'header': 'Ant Tracking ',\n",
       "  'content': 'This unique algorithm is part of an innovative workflow that introduces a new paradigm in fault\\ninterpretation. The procedure consists of four steps. The first step is to condition the seismic data\\nby reducing noise in the signal. The second step enhances the spatial discontinuities in the seismic\\ndata (fault attribute generation, edge detection). The third step, which generates the Ant track\\nvolume, significantly improves the fault attributes by suppressing noise and remains of non-\\nfaulting events. This is achieved by emulating the behavior of ant colonies in nature and how they\\nuse foramens to mark their paths in order to optimize the search for food. Similarly, \"artificial\\nants\" are put as seeds on a seismic discontinuity volume to look for fault zones. Virtual\\npheromones deployed by the ants capture information related to the fault zones in the volume.\\nThe result is an attribute volume that shows fault zones very sharp and detailed.\\n3D fault patches or planes of discontinuity can then be extracted from the ant-track cube,\\nAutomatic Fault Extraction Process. The faults can be split into different non-intersecting sub-\\nsystems. These sub-systems ease the extraction of fault surfaces in the final step of the process.\\nThe input for the ant attribute is an edge enhanced volume, like variance or chaos. See Enhancing\\nFault Appearance on Edge Detection Volumesand the Ant Tracking workflow.\\nAnt Tracking is a CPU-intensive process. It is advisable to use a small-cropped volume first\\nto test the parameters before attempting to calculate larger areas. As a rule of thumb, account for\\n20 min. of calculation for a 100 Mbyte volume using a machine with 2 Gbyte of RAM and 1.7 GHz\\nof CPU-clock.\\nThe time it takes to generate a volume will depend heavily on the amount of discontinuities\\nthat are present in the input volume and on the mode you are running the Ant tracking.\\nAnt tracking can only be run in Realized mode.\\nAnt Tracking Attribute parameters\\nA coherent signal tracker based on \"swarm intelligence\" to find optimal connectivity for fault\\nfeatures within an edge detected volume. The results are the basis for interpretation automation\\nand allow the unique capability for orientation filtering.\\nParameters for the Ant tracking are shown in the figure below.\\nAs a first step in the Ant-track algorithm, each agent makes an initial estimate of the orientation\\nfor the identified local maximum within the agent\\'s territory (Ant boundary parameter). This\\norientation estimate will define the tracking direction for that agent. Within the program, the\\nagents are restricted to a maximum of 15% deviation from this original orientation estimate.\\nAlso, the movement of the ant agents is performed in steps (Ant step size), a step is defined in\\nvoxels.\\nThe different user defined parameters will be described below.\\nTwo different \"predefined\" settings are provided with the method: passive or aggressive.'},\n",
       " {'header': 'Passive Ants (Default) ',\n",
       "  'content': 'Passive ants refer to a set of parameters where the swarm behavior is conservative, the\\nartificial ants require a strong signal to advance further in the volume. Use this mode to extract\\nonly major regional fault zones in the data.'},\n",
       " {'header': 'Aggressive Ants ',\n",
       "  'content': 'The Aggressive ants option allows the ant agents more freedom to explore and detects more\\nsubtle connections. Use this mode to extract major and subtle fault zones in the data. The list of\\nsingle parameters is adjusted accordingly.\\nYou can overwrite these settings to condition the behavior of the ants.\\nInitial ant boundary (number of voxels)\\nThe Initial ant boundary parameter defines the initial distribution of agents, being a territorial\\nradius around each ant, defined in number of voxels, see figure below. This parameter has a huge\\nimpact on the execution time of the algorithm, as it defines the total number of agents that are\\npropagated through the volume.\\nFor the objective of extracting large regional faults, this distribution can be fairly coarse (5-7\\nvoxels). For detail work, and the mapping of small faults and fractures, a closer distribution is\\nrecommended (3-4 voxels). Generally, using a radius smaller than 3 voxels has no benefits as the\\nagents will track the same events and not add new information content to the results. This\\nparameter does not imply that the agents are homogeneously distributed throughout the volume.\\nThe parameter means that no agent will be placed within this radius of another agent as each one\\nsearches for a local maximum in the data.\\nAnt boundaries are defined by a radius, in voxels for the distribution of the ant agents. If the\\nagent is unable to identify a local maximum or make an orientation estimate within this radius,\\nthe agent will be exterminated.\\nParameter settings:'},\n",
       " {'header': 'Minimum:1 Maximum:30 ',\n",
       "  'content': 'Default:7 in \"passive\" mode and 5 in \"aggressive\" mode\\nAnt track deviation\\nAnt track deviation controls the maximum allowed deviation from a local maximum while\\ntracking. The agents assume a planar shape, and can only deviate 15 degrees from the initial\\norientation. The method allows the agent to accept local maximum one voxel on either side of the\\npredicted position as legal. If the maximum is outside this ant track step range, the track\\ndeviation parameter comes into play.\\nIf a local maximum deviate much from a plane, the agent are not able to track them for long.\\nThis parameter will allow the agents to deviate from local maximum and they are able to follow\\nthe structure longer.\\nA value of 1 would allow the agent to deviate by one voxel in either direction from the legal\\npositions to search for a local maximum. If a maximum is not found, this would be recorded as an\\nillegal step. If a maximum is found, the legal position closest to this maximum would be used as\\nthe legal step. See figure 1.'},\n",
       " {'header': 'Fig. 1 ',\n",
       "  'content': 'The Ant track deviation parameter controls the possible voxels the agent can search away from\\nthe legal positions to find a local maximum. If a maximum is found, the closest legal position is\\nused.\\nParameter settings:'},\n",
       " {'header': 'Minimum: 0 Maximum: 3 Default: 2 ',\n",
       "  'content': 'Ant step size (number of voxels)\\nThis parameter defines the amount of voxels an Ant agent advances for each increment within its\\nsearching step. Increasing this value will allow an Ant agent to search further, but it will lower the\\nresolution of the result.\\nParameter settings:'},\n",
       " {'header': 'Minimum: 2 Maximum: 10 Default: 3 ',\n",
       "  'content': 'The Ant Step Size parameter decides how far an ant agent can search for a local maximum in a\\nsingle step.\\nIllegal steps allowed\\nIllegal steps allowed defines how far (as measured in steps) that an agent\\'s track can continue\\nwithout finding an acceptable edge value. (An acceptable edge value means that a local maximum\\nis found.) See figure below.\\nFor example, if the agent currently resides on a valid position and advances one step where it\\ndoes not detect an edge, this would count as an illegal step. Using the initial orientation estimate,\\nthe agent would advance to the next step. If it does not find an edge here, this would constitute a\\nsecond illegal step. If the parameter was set to 1, the agent would terminate the search in this\\norientation. If a valid voxel is found, then the agent\\'s recorded path will include both this valid\\nposition and the \"illegal\" position (if the Legal Steps criteria is satisfied, see Legal steps required).\\nIllegal steps are only counted after the Legal steps have been recorded.\\nAnt Track Illegal Steps parameter decides how many steps an agent can go without finding a local\\nmaximum.\\nParameter settings:'},\n",
       " {'header': 'Minimum: 0 Maximum: 3 ',\n",
       "  'content': 'Default: 1 for \"passive\" mode and 2 for \"aggressive\" mode\\nLegal steps required\\nLegal steps required controls how \"connected\" a detected edge must be to help distinguish an\\nedge from un-oriented noise. This parameter is used in combination with the Illegal step\\nallowed parameter. It is expressed in terms of the number of steps that must contain a valid\\nedge value for the agent to continue. See figure below.\\nAs the agent advances and encounters a valid edge, this represents 1 legal step. When the agent\\nadvances again and encounters another valid edge value, this would represent a 2nd legal step. If\\nyou have set the legal steps parameter to 2, this track will be considered legitimate and can be\\nrecorded. If you have set the legal steps parameter to 3, and on the next advance of the agent,\\nan edge is not encountered, then since only 2 legal steps is found, this track will not be considered\\na real fault, and will not be recorded in the output collection.\\nThe Ant Track Legal Steps parameter decides the number of steps that contains an edge value\\n(maximum) for the agent to continue.\\nParameter settings:'},\n",
       " {'header': 'Minimum: 0 Maximum: 3 ',\n",
       "  'content': 'Default: 3 for \"passive\" mode and 2 for \"aggressive\" mode\\nStop criteria\\nThe Stop criteria refers to the percentage of illegal steps allowed throughout a single agent\\'s life\\n(entire search space). The parameter will come into play as the agent advances, finds an illegal\\nstep, progresses again finding a legal step and continues in this fashion, while gradually\\naccumulating illegal steps until they represent a significant portion of the agent\\'s search area.\\nWhen this value becomes too large, we are no longer sure that it is legitimate fault geometry we\\nare tracking, the stop criteria percentage therefore allows us to terminate this track. See figure\\nbelow.\\nThe Ant track Stop criteria parameter can terminate an agent when the number of Illegal\\nsteps contained in the total path exceeds the defined percentage.\\nThe ant creates a small plane that is expanded along each edge. If the percentage of voxels on\\nindividual edge surfaces is not on a local maximum and exceeds the stop criteria, expansion in\\nthat direction is terminated.\\nParameter settings:'},\n",
       " {'header': 'Minimum: 0 Maximum: 50 ',\n",
       "  'content': 'Default: 5 for \"passive\" mode and 10 for \"aggressive\" mode'},\n",
       " {'header': 'Stereonet Tab ',\n",
       "  'content': 'There is one more available setting; an orientation filter. With this graphic device, you can restrict\\nwhich azimuths and dips the agents will be allowed to search. The powerful parameter control\\nallows you to generate orientation filtered volumes that can separate fault systems for ease of\\ninterpretation.\\nUse this mode to extract major and subtle fault zones in the data. The list of single parameters is\\nadjusted accordingly.\\nYou can overwrite these settings to condition the behavior of the Ants.\\nClick on the Stereonet tab to access the feature.\\nThe Orientation Filter allows you to restrict orientations that are searched. The plot itself has\\nbeen divided into sectors, which can individually be rejected (not searched by the agents).\\nThe orientation filter controls which \"sectors\" the agents are allowed to search. You can set which\\nsectors to reject or accept.\\nIf CTRL or SHIFT is pressed while clicking on a patch, it is treated as a Select Patch command.\\nIf SHIFT is pressed, all existing selections are kept. If CTRL is pressed, only the new patch is\\nselected; all previous selections are lost.\\nThe Stereonet and 3D Window are linked together. Selections in the Stereonet dialog show up in\\nthe 3D window and vice versa.\\nAreas marked as dark will be rejected during the Ant tracking calculation process. This means\\nthat no fault information will be captured within those marked dip and azimuth ranges, regardless\\nif present in the volume or not.\\nThe Stereonet tab is available when the Ant Tracking Attribute is active. Otherwise, this tab\\noption is grayed out.\\nHow to use the stereonet\\nReset orientation to default - When you press this icon, your selections will be removed\\nand the stereonet will be restored to default settings.\\nReject all sectors for patch visualization - Clicking this icon will reject all sectors in the\\nstereonet.\\nInvert the selection of rejected areas - Clicking this icon will invert the selection you have\\nmade (shaded and non-shaded areas) in the Stereonet.\\nCycle through the dip/azimuth resolution options - Will cycle through a selection of\\npredefined dip and azimuth quadrant resolution options.\\nAzimuth increment- For specifying an independent azimuth increment of\\nyour choice. Allowed value range: [2, 30].\\nDip increment- For specifying an independent dip increment. Allowed\\nvalue range: [2, 30].\\nHow to use the stereonet\\n1. When generating an ant-track attribute, click on the Stereonet tab.\\n2. Set the Dip and Azimuth sectors, by either using the Cycle through the dip/azimuth\\nresolution options icon or defining user specified values using the Azimuth\\nincrement and Dip increment .\\n3. Move the mouse pointer outside the stereonet. You can use the mouse pointer outside the\\nstereonet circle to drag and mark areas that cover dip ranges from 0 to 90 degrees.\\n4. Move the mouse inside the stereonet. You can use the mouse pointer inside the stereonet\\nto point or drag to mark single rejection areas.\\n5. When you click on a shaded (rejected) sector, the sector will turn white (accepted).\\n6. If you want to invert your selection, click the Invert the selection of rejected areas\\nicon.\\n7. Use the Reset Orientation to default icon to clear your selections.\\n8. Continuous readout A red cross with continuous readout values indicates the\\ncurrent dip and azimuth value of the position where the mouse pointer is located.\\nHow to use the stereonet - Examle\\nThe two images below show how the Stereonet filter avoids Ants entering areas marked by an\\nacquisition footprint. The image to the left is unfiltered. In the image to the right, the filter is set\\nas in the example above.\\nYou need to estimate the right angle quadrants based on your data and the orientation of\\nyour survey(s).\\nSeismic conditioning\\nPetrel offers various possibilities to condition the seismic data. This is particularly important before\\nrunning the Ant Tracking algorithm. See Enhancing Fault Appearance on Edge Detection Volumes\\nfor example.\\nHow to do the Ant Tracking Workflow\\nThe main workflow can be seen in the illustration below.\\n1. First the original seismic data can be processed or conditioned using the structural\\nsmoothing option with the fault edge preservation option.\\n2. Then a Variance cube needs to be generated that will contain all the discontinuities.\\n3. Alternatively, the Chaos attribute can be generated.\\n4. Either the Variance cube or the Chaos cube can be used as input for the Ant Tracking\\nprocess.\\n5. You can also use any other input that enhances discontinuities. (like Coherency for\\nexample). This volume needs to be loaded to Petrel first, either using the SEG-Y loader or\\nthe Open-Spirit connectivity.\\n6. Next, the Ant Tracking algorithm generates an enhanced Ant cube. This cube can be used\\nfor manual fault interpretation or, preferably, as input into the Automatic fault extraction\\nprocess.\\n7. If the Automatic fault extraction process is used, based on the set parameters, extracted\\nsurfaces will be generated and saved under a separate folder.\\n8. The new workflow is a top-down approach, where the interpreter interacts with\\nautomatically extracted fault surfaces in a 3D canvas. Several properties are connected\\nwith the surfaces, which the interpreter can use for organizing the data. For example, the\\nsurfaces can be split into groups representing fault systems. The faults that make a system\\nhave common strike, which means that the same stress field has created them in the same\\ntime period.\\nThe new workflow offers:\\n1.\\n1. Increased objectivity: Manual interpretation is highly subjective because it is difficult to\\nmap the discontinuities in the seismic data and understand their nature in 3D. In the new\\nworkflow, the surfaces are objectively extracted using automatic algorithms that work in\\ntrue 3D.\\n2. Increased level of detail: The automatic extraction maps all discontinuities that have\\nsome extent in the data. When mapping surfaces manually, the interpreter typically does\\nnot have time to interpret details.\\n3. Early understanding of fault systems: With automatically extracted surfaces, the\\ninterpreter now starts out with a structural overview of the faults in the area. From the\\nbeginning, the interpreter will start thinking in terms of fault system and tectonic history.\\n4. Faster interpretation: Order of magnitude timesavings are obtained by automating the\\nsurface mapping, which traditionally is a very time-consuming manual task. The\\ninterpreter\\'s job is moved from low-level mapping of discontinuities on seismic slices, to\\nhigh-level analysis of automatically extracted surfaces.\\nReferences and Reading\\nCarrillat, A., Randen, T., Soenneland, L., and Elvebakk, G., Seismic stratigraphic\\nmapping of carbonate mounds using 3D texture attributes, In Extended Abstracts of\\nEAGE Annual Meeting, May 2002\\nCarrillat, A., Randen, T., Sonneland, L., Elvebakk, G., Automated mapping of carbonate\\nmounds using 3D seismic texture attributes, in Extended Abstracts, Annual Meeting,\\nSociety of Exploration Geophysicists, Salt Lake City, Utah, October 6-10, 2002\\nFehmers, G.C., and Hocker, C.F.W., Fast structural interpretation with structure-\\noriented filtering, Geophysics, Vol. 68, No. 4, 2003'},\n",
       " {'header': 'Najmuddin, Ilyas, Frequency Attenuation: A Fracture Indicator, Houston Geological Society Bulletin, March 2001 ',\n",
       "  'content': 'Pedersen, S.I, Randen, T. Soenneland, L., and Steen, OE., Automatic 3D fault\\ninterpretation by artificial ants, In Extended Abstracts of EAGE Annual Meeting, May\\n2002\\nRanden, T., Pedersen, S.I., Soenneland, L. , Automatic extraction of fault surfaces\\nfrom three-dimensional seismic data, In Extended Abstracts of 71st Ann. Internat. Mtg:\\nSoc. of Expl. Geophys., pp 551-554, September 2001\\nRanden, T., Monsen, E., Signer, C., Abrahamsen, A., Hansen, J., Saeter, T., Schlaf, J., and\\nSoenneland, L., Three-dimensional texture attributes for seismic data analysis, SEG'},\n",
       " {'header': 'Expanded Abstracts, Int. 6.1, 2000 Randen, T., Soenneland, L., Carrillat, A., Valen, T.S., Skov, T., Pedersen, S.I., Rafaelsen, ',\n",
       "  'content': 'B., Elvebakk, G., Preconditioning for Optimal 3D Stratigraphical and Structural\\nInversion, EAGE abstracts, 2003\\nTaner, M.T., and Sheriff, R.E., Applications of amplitude, frequency, and other\\nattributes to Stratigraphic and hydrocarbon determination, Seismic stratigraphy-\\napplications to hydrocarbon exploration, AAPG Memoir, 26, 1977\\nTaner, M. Turhan, Attributes Revisited, 1992, revised 2000 - see:\\nhttp://www.rocksolidimages.com/pdf/attrib_revisited.htm\\nAutomatic fault extraction\\nThe Automatic fault extraction process provides a set of interactive tools to extract, display,\\nanalyze, and edit fault-patches. Fault patches can be created from an edge volume and are\\ndesigned to be used on an Ant Tracking attribute. Other edge volumes, like Variance or Chaos,\\ncan also be used in this process.\\nThe fault patches can be generated for a 3D volume, or you can pick one fault at a time using the\\nSeeded 3D fault autotracking tool. When a fault patch set has been created, it can be filtered\\nbased on properties. By default, all the extracted surfaces are displayed. This gives the\\ninterpreter an overview of the possible fault systems in the data. The interpreter will then, using\\nthe surface orientations, split the surfaces into their corresponding systems. Each of these\\nsystems can then be studied and validated separately. This represents an interaction with the\\nresult at a fault system level. If the interpreter finds that a system is due to acquisition footprints\\nfor example, or other coherent noise, the system is simply deleted. If the system is real, the\\ninterpreter will then verify, and if necessary, edit the individual surfaces within the system. This\\ncorresponds to working on the surface level.\\nBy using an interactive Stereonet plot, you can split the extracted surfaces into fault systems. By\\nmarking areas on the Stereonet, only the surfaces whose orientations correspond to these areas\\nwill be displayed. An additional filtering tool uses the histogram of a selected surface property, for\\nexample, size. The classified data in the histogram can be marked so that the surfaces that fall\\ninto these columns are hidden. For example, all small surfaces can be removed by marking the\\nhistogram columns corresponding to small surfaces.\\nBefore you start extracting faults automatically from an ant or edge volume, it is important to\\nquality control the input data. Automatic fault extraction is a very resource intensive operation,\\nthus the input volume should map the fault system as clear as possible. It is recommended to run\\nseveral tests with varied input volumes on smaller sub volumes in areas of interest before\\napplying the parameters to a larger volume.\\nInput for the Automatic fault extraction\\nprocess\\nInput can be:\\nAn Ant tracking attribute created.\\nAttributes which highlight the edge effects (variance, chaos etc.).\\nEven if this Automatic fault extraction process is designed and optimized for the Ant tracking\\nalgorithm, other attributes can be used as well, although better results are expected on an ant\\ntrack attribute.\\nFault Extraction process dialog settings\\nTo open the dialog, double-click on Automatic fault extraction on the Process pane. The\\ndialog consists of three tabs:\\nExtract fault patches: parameter settings and edge volume input selection.\\nSettings: fault patch conversion parameters and smoothing settings.\\nHints: general infomation about the Ant tracking and Fault patch extraction workflow.\\nExtract fault patches tab\\nOn the Extract fault patches tab, you can change the parameters used during the fault\\nextraction. Depending on how you specify the parameters, the process can search for a small or\\nlarge scale fault. The accuracy of the fault picking is also influenced by the parameters available in\\nthis process.\\nFig. 1 The Extract fault patches tab in Automatic fault extraction process dialog.\\nInput seismic edge volume: Seismic edge volume used for the automatic fault patch\\nextraction. When launched from the process dialog, the Input seismic edge volume field will\\nautomatically pick up the current selection from the input dialog.\\nOutput fault patches name: A patch set will be created with the same name as the input\\nseismic edge volume. If you select the Set output fault patches name check box, the text field\\nis available for you to name the resulting fault patch set.\\nUse presets ... option gives the user two pre-defined sets of parameters, Normal confidence\\nand High confidence, a pre-defined parameter to identify dominant fault patches, meaning only\\nhigh and well connected values in the input volume will be used for the fault patch extraction if\\nHigh confidence is selected. These parameters can be adjusted by you.\\nExtraction sampling distance controls how close seed points can be set to extract fault\\npatches. Starting from the lowest Inline/Crossline, the algorithm will search a cube with an edge\\nlength defined by the Extraction sampling distance. First, the top 10% of the values within this\\ncube are scanned. The first value found is the seed point. If no value is found, the next 10% are\\nscanned. If no value can be found until the Extraction sampling threshold is reached, no seed\\npoint is set.\\nExtraction sampling threshold controls the value range within the input volume which is\\nconsidered for valid seed points for the fault extraction process. The parameter is expressed in\\n10% increments of the dynamic input volume range. Example: If the input volume has data\\nvalues ranging from -1 to 1 (ant volume) and this parameter is set to \"Top 40%\", then any value\\nabove 0.2 will be considered for a seed point.\\nThe first two parameters control where and how many seed points are set, as well as the value\\nrange being used to set the seed points for the fault extraction process.'},\n",
       " {'header': 'Examples: ',\n",
       "  'content': 'If your input ant volume shows a very dense and linear distribution of high values, a low\\nExtraction sampling distance can be more suitable to set seed points for each detected linear\\nfeature in the edge volume.\\nIf your input ant volume shows a lot of noise around the detected edges which map the fault\\nsystem, a high selection (Top 10%) can help to seed only the major structures.\\nFig 2. The relationship between the ant track attribute values and the extraction sampling\\nthreshold values.\\nExtraction background threshold defines the value range for points included in the extracted\\nfault patch within the search range (Deviation from a Plane) along the initial orientation of the\\nseed points. The parameter is expressed in 10% increments of the dynamic input volume range.'},\n",
       " {'header': 'Examples: ',\n",
       "  'content': 'If the parameter is set to Top 60% (data value range -1 - 1), then any value above -0.2 will be\\nincluded in a fault patch.\\nIf you would like the background to be ignored, you should set high constraints in this parameter.\\nIf you are interested in only faults from connected high values, use a higher value % constraint in\\nthis parameter.\\nFig. 3 The relationship between the ant track attribute values and the extraction background\\nthreshold values.\\nDeviation from a plane controls the range around a seed point. Within these limits, potential\\nfault locations can be extracted. In addition, it defines the maximum fault patch dimension. Fault\\nlocations in this range, with values below the background threshold level, will not be considered a\\nvalid fault location.\\nIf you have near parallel faults and this parameter is larger than the distance between the faults,\\nthe tracked patch might jump from one event to the next.\\nConnectivity constraint is a sensitivity control for how \"connected\" the above background\\nvalues must be, before they are included into the resulting fault patch. A value of \"1\" means that\\nat least one voxel face must be touching a previously accepted position before expansion. The\\nmaximum value of \"3\" requires that each addition point in the fault surface has been connected\\non three sides.\\nThe three parameters above control how the fault patch \"grows\" starting from the seed points.'},\n",
       " {'header': 'Examples: ',\n",
       "  'content': 'If the input volume shows a clearly mapped fault system with high values, the Extraction\\nbackground threshold can be set to a high value (e.g. Top 20%).\\nIf the input volume shows large normal faults, the Deviation from a plane parameter\\nshould cover the fault separation in order to cover the whole fault, a higher value should\\ntherefore be chosen. In this case the Connectivity constraint should be set to a low\\nvalue.\\nThe Deviation from a plane parameter needs to be smaller then the fault separation in\\norder to prevent jumping from one fault to a neighboring nearly parallel fault.\\nIf the input volume shows a dense faulted system which is clearly mapped, it may be better\\nto allow only tight connections of the points within the fault patch. This will allow the\\ngeneration of bigger fault patches in combination with a small Deviation from a plane and\\nhigh Extraction background threshold.\\nIf the input value shows a poorly mapped fault system, you can allow a looser connection of\\nthe points, creating the fault patch by selecting a low value for the Connectivity\\nconstraint parameter in combination with a small Extraction sampling distance, a high\\nExtraction sampling threshold (e.g. Top 60%) and a low Extraction background\\nthreshold (e.g. Top 50%).\\nMinimum patch size (points) defines the minimum number of points the extracted fault patch\\nconsists of before added to the fault patch set. It works in combination with the Patch down\\nsampling parameter. Note that the histogram under the settings for the fault patch set can be\\nused as well, to filter by patch size.\\nPatch down sampling (voxels) controls the density of points in the extracted fault patch\\nbefore it is added to the fault patch set. It works in combination with the Minimum patch size\\nparameter.'},\n",
       " {'header': 'Example: ',\n",
       "  'content': 'If the Minimum patch size is set to 20, and the Patch down sampling parameter is set to 8,\\nthen any fault patch with less then 160 connected voxels (20x8) will be eliminated.\\nThe last two parameters should be used to limit the number of fault patches extracted. As fault\\nfeatures are generally slow varying planar objects, these parameters allow a representation of\\nsurfaces with a fewer number of points, and results in a slight smoothing of the fault patch, in\\naddition to occupying less memory.\\nExtract fault patches - when the button is clicked, the extraction of the\\nfault patches in the selected volume is started based on the set parameters.\\nAutomatic fault extraction - Settings tab\\nThe settings for the conversion of the fault patches can be adjusted in the Settings tab of the\\nAutomatic fault extraction process. You can define the number of fault sticks, the sampling,\\nthe height above and below given min/max points, and the number of fault pillars. There is also\\nan option to set the smoothing strength when you apply smoothing on selected fault patches.\\nFault stick interval: Allows you to decide the spacing of the seismic fault sticks (fault\\ninterpretation) to be created.\\nMinimum sampling: Allows you to control the minimum height of generated fault sticks (given\\nin project units, for example, milliseconds).\\nWhen fault patches are converted to a Fault model, the parameters in the fault modeling process\\nwill apply.\\nExtra height: Allows you to add extra height to modeled faults when they are created (given as\\n% above/below fault patch height).\\nFault pillar interval: Allows you to decide the spacing of the fault pillars (modeled faults) to be\\ncreated.\\nFault patch smoothing slider: Allows you to control the amount of smoothing to be applied to\\nthe fault patches using the Smooth selected patches tool in the Function bar.\\nHistogram filters\\nThe fault histogram tool is available in the Histogram tab under the settings for a fault patch\\nobject.\\nYou can filter fault patches using the properties and the histogram tool. This is a powerful method\\nto discriminate fault patches using any combination of properties.\\nAvailable properties are:\\nDip azimuth - The azimuth estimate of a best-fit plane for the patch measured in the\\ngeographic (X,Y,Z) coordinate system\\nDip - The dip estimate of a best-fit plane for the patch measured in the geographic (X,Y,Z)\\ncoordinate system\\nSurface area - The areal extend of the patch (based on sub-sampled points)\\nAzimuth in seismic - The azimuth estimate of a best-fit plane for the patch measured in\\nthe seismic (Line,CDP,Z) coordinate system\\nDip in seismic - The dip estimate of a best-fit plane for the patch measured in the seismic\\n(Line,CDP,Z) coordinate system\\nMean input - The average amplitude of the input data at the patch location\\nPatch confidence - A measure of the estimated confidence of the fault patch based on\\nextraction size and input seismic edge volume (Ant volume) intensity.\\nInline extent - The inline range of a patch\\nCrossline extent - The crossline range of a patch\\nVertical extent - The vertical range of a patch\\nReset histogram and apply for this property - will remove the filter for the current\\nproperty.\\nReset histogram and apply for all properties - will remove the filters for all the different\\nproperties in the fault patch set.\\nLog - use a log scale for the x axis of the histogram.\\nPercent - toggles between displaying percentages or numbers as the y axis of the histogram.\\nPrint a copy of the histogram.\\nCopy bitmap to clipboard - will copy the histogram view to the clipboard. It can then be\\npasted into the Input tab and displayed on Maps and Plots.\\nThe user can choose either:\\nIntervals - the data range will be split into this number of intervals.\\nIncrement - the data range will be split using the chosen increment.\\nMax / Min - by default, the range will be defined the maximum and minimum values in the\\ndata. Activating Max and Min allows you to specify the range. After setting the Max and min\\nvalues you must use the to apply the changes.\\nFig. 1 Histogram tab\\nHow to Filter fault patches using the Histogram tool\\nIf you want, for example, to filter fault patches using the Surface area property:\\n1. Activate the Histogram tab on the fault patch settings\\n2. Select the Property to filter on (for example, Surface area)\\n3. Using the left mouse-button, select the histogram bars you want to filter. The color will\\nchange from blue to pink to indicate the selection. You can also drag the mouse pointer to\\nselect a range of columns.'},\n",
       " {'header': '4. Click Apply. ',\n",
       "  'content': '5. The fault patches that fall within the selection range (pink bars )will be hidden on the\\ndisplay.\\n6. You can deselect any of the columns in the histogram at any point and hit apply to\\nredisplay hidden patches.\\n7. You can also refine the intervals (default is 20) of the histogram tool to achieve a more\\ndetailed resolution.\\n7.\\nFig. 2 A histogram with unselected and selected columns using the surface area property. Patches\\nbelonging to the selected columns (right image) will be filtered.\\nFilter settings work in additive mode.\\nStereonet filter\\nThe stereonet tool is available in the Stereonet tab under the Settings for a fault patch object.\\nHow does the Stereonet work\\nOn the Stereonet, the fault patch is plotted as a pole representing the \"normal\" incident to the\\nplane. Fault patches will be close to planar, so the normal is a good representation of its\\norientation. The azimuth [0 - 360] is read along the perimeter of the plot, and the dip [0 -90] is\\nread as the distance from the center. The Azimuth is related to the inline and crossline directions.\\nThe horizontal surface will be plotted in the center of the plot:\\nTwo surfaces having the same azimuth, but conjugate dips, will be plotted symmetrically around\\nthe center of the stereonet:\\nFrom structural geology, it is known that faults appear in systems, that is, they have the same\\nstrike (azimuth) and conjugate dips. The same stress field, indicating that faults have been\\ncreated in the same time period, has created a fault system. On the polar plot, fault systems can\\nbe identified as clusters symmetrical around the center:\\nThe most famous example of a fault system is probably the San Andreas system in California. In\\nthe image, you can see that the San Andreas faults are more or less parallel. On the polar plot,\\nthis would be plotted something like indicated in the pole plot. The black dotted line is a parallel to\\nthe faults, and the blue and yellow dots are the normals of the faults:\\nIcons for the stereonet filter\\nThe following icons are available on the Stereonet tab in the fault patch settings. Use these tools\\nto speed up the selection of quadrants.\\nReset orientation to default\\nReject all sectors for patch visualization\\nInvert the selection of rejected areas\\nCycle through the dip/azimuth resolution options\\nThe increment of the azimuth lines in the stereonet (minimum 2,\\nmaximum 30).\\nThe increment of the dip lines in the stereonet (minimum 2,\\nmaximum 30).\\nHow to Filter fault patches using the Stereonet\\nAll visible fault patches are mapped to the Stereonet as blue dots according to their respective dip\\nand azimuth. You can filter (hide) any of the posted patches by marking the areas (quadrants)\\nwith the left mouse button.\\n1. Select any sector to mark it; you can also drag the mouse pointer.\\n2. Click outside the perimeter of the Stereonet to mark all dip ranges.\\n3. Click Apply to hide the fault patches according to the last settings.\\n4. The Stereonet sectors can be adjusted to achieve a more detailed segmentation of the\\nStereonet area.\\nFigure 1. Example showing all patches displayed in the 3D Window\\nFigure 2. Example showing the filter effect of selected sectors. Only patches in the white sectors\\nare displayed.\\nShortcuts for Automatic fault extraction\\nF to activate Seeded 3D fault autotracking tool.\\nSHIFT to continue tracking the same fault patch.\\nA to select Merge selected patches (add) tool\\nSHIFT and S to activate the Smooth selected patches tool.\\nCTRL and Z to Undo the last operation.\\nDEL to Delete the selected object in the view.\\nAutomatic Fault Extraction toolbar\\nThese icons are available on the left function bar when the Automatic Fault Extraction\\nprocess is active.\\nOpen dialog for active process - opens the main dialog interface for the Automatic\\nfault extraction process.\\nOpen stereonet settings - opens and activate the Stereonet filter tool.\\nOpen histogram settings - opens and activate the Histogram filter tool.\\nSeeded 3D fault autotracking - the seeded 3D fault autotracker tool allows you to\\nextract a single patch at a time from an edge or Ant-track volume. The patch will be added\\nto the ACTIVE fault patch set. If no fault patch set is active, a new one will automatically be\\ncreated. You can also create an empty fault patch set.\\nToggle the nearest patch - toggles a hidden patch from a vertical seismic intersection\\nplane (see the workflow described below).\\nHide selected patches - hides selected patches (they are not removed from the patch\\nset, just not drawn).\\nShow hidden patches - shows patches hidden by the Hide selected patches icon (all\\npreviously hidden patches will be made visible, stereonet and histogram filtering are still\\nworking).\\nMerge selected patches - merges two or more selected patches to a single plane.\\nSmooth selected patches - smooths a selected patch.\\nConvert selected to fault interpretation - converts selected patches to fault\\nsegments.\\nConvert selected to fault in fault model - converts selected patches to Petrel fault\\npillars.\\nUndo - to undo previous operation (such as merging or smoothing, only the last step\\ncan be undone).\\nDelete - to delete selected patches (these patches are permanently removed from the\\npatch set).\\nChange the display style of fault patches\\nOn the settings for the fault patch set, go to the Style tab. You can define which method to use to\\ncolor the patches on the 3D Window. The default is the Different option which will assign a\\ndifferent color for each fault patch. It is useful, for example, to render the fault patches using the\\nDip azimuth property:\\n1. Click on the Automatic fault extraction process in the Processes pane. The\\ncorresponding tools will become available on the function to the right of the display window.\\n2. Activate the fault patch set under the Fault patch folder you want to work with in the\\nInput pane.\\n1. Select the fault patch set check box to display all the fault patches in a 3D window.\\n2. Double-click on the fault patch set or use the right mouse-button to access the settings.\\nThis will open the settings dialog for the fault patches and allow you to interact with the\\ndisplayed fault patches.\\n3. Open the Style tab.\\n4. In the Surface section, make sure the Show check box is selected.\\n5. In the Color pull-dow menu, select - As attribute.\\n6. Expand the fault patch set folder and the Attributes sub-folder.\\n7. Select Dip azimuth to color the fault patches with this attribute.\\nSeeded 3D fault autotracking tool\\nSingle fault patches can be auto tracked similar to 3D horizon autotracking. When this tool is\\nactivated, you can click on a fault displayed in the ant volume in a 3D window and start the\\ntracking of that particular fault. This tool can be used to either add more fault patches in an\\nalready existing fault patch set, or to manually auto track the faults based on the displayed ant\\nattribute.\\n1. Locate a strong fault in the ant tracking cube displayed in your 3D window.\\n2. Select the Seeded 3D fault autotracking icon from the Function bar (Short key F).\\n3. Click on the fault edge in the ant volume with the mouse. The position of the mouse pointer\\nwill define the seed for the fault tracking algorithm.\\n4. If the tracking result does not cover the whole fault, press SHIFT while picking the next\\nseed point which highlights the previous and current patch as selected. Continue with\\nfurther seed points until the whole fault is tracked. Use Undo (CTRL and Z) to remove the\\nlast patch.\\n5. You can then use the short key A to merge the selected patches.\\n6. You can then press SHIFT and S to apply smoothing.\\nThe fault autotracking will use the last five parameters set in the settings dialog for the\\nAutomatic fault extraction process.\\nMerge and Smooth fault patches\\nFault patches can be merged to compose larger fault planes. This may be necessary in the case of\\nlarge listric fault systems or when faults show a curved path in the horizontal plane. Smoothing\\ncan help when the fault patches show a noisy pattern.\\n1. Make the Select/pick mode [P] active.\\n2. Select the fault patch with the left mouse button. The selected fault patch should turn grey\\nand a highlighted red dot in the Stereonet indicates its location.\\n3. Pressing SHIFT and clicking on a second fault patch will select a new fault patch and keep\\nthe selection from the previous step.\\n4. Click on the Merge selected patches [A] icon. The two patches have been merged\\ninto one. The display is still grey showing that the new patch is still active.\\n5. Click on the Smooth icon. The patch will be smoothed.\\n6. Click on the Undo icon if you want to reset the last operation. This option only works for\\nthe last operation.\\n6.\\nNote. You can merge more than two faults at the same time by pressing SHIFT and clicking\\non more fault patches.\\nNote. You can also make the selection in the stereonet tool.\\nConvert fault patches to Fault interpretation\\nSelected fault patches can be converted to Fault Interpretation.\\n1. Make the Set Select/pick mode [P] active.\\n2. Select the fault patch with the left mouse button. The selected fault patch should turn grey and\\na highlighted red dot in the Stereonet indicates its location.\\n3. Click on the Convert selected to fault interpretation icon to convert the fault patch to\\nfault sticks. Select the converted fault from the tree under the Interpretation folder to display\\nit.\\nYou can select all of the displayed fault patches in the 3D Window using the CTRL and A key\\ncombination. Then you can convert all selected fault patches. This will potentially generate a large\\namount of fault data. The settings for the conversion of the fault patches can be adjusted on the\\nSettings tab of the Automatic fault extraction process. The number of fault sticks and the\\nsampling can be defined.\\nConvert fault patches to Fault model\\nSelected fault patches can be converted to Petrel fault pillars. With this option, it is possible to\\nclose the workflow and provide modelers with automated extracted fault segments to be\\nprocessed the conventional way.\\n1. Make the Set Select/pick mode [P] active.\\n2. Select the fault patch with the left mouse button. The selected fault patch should turn grey\\nand a highlighted red dot in the Stereonet indicates its location.\\n3. If you click the Convert selected to fault in fault model icon, the fault patch will be\\nconverted to a Fault Pillar and added to the active fault model. It is displayed automatically.\\nYou can select all the displayed fault patches in the 3D Window using the CTRL and A key\\ncombination. Then you can convert all the selected fault patches. This will potentially generate a\\nlarge amount of fault data. The settings for the conversion of the fault patches can be adjusted on\\nthe Settings tab of the Automatic fault extraction process. The height above and below given\\nmin/max points and the number of fault pillars can be defined.\\nCut and limit fault patches\\nYou can cut/limit fault patches by selecting a constant value or by assigning top and a bottom\\nsurfaces to cut against. This can be useful to limit the extracted fault patches to an existing\\nmodel.\\n1. Open the settings dialog for the patch you would like to clip and choose the Operations\\ntab.\\n2. Select the Top limit or Base limit (or both) depending on which end of the fault patches\\nyou want to clip.\\n3. Enter the required Z-value or drop a surface into the dialog box.\\n4. Click the Cut button to cut fault patches outside the defined interval.\\nYou can also limit the extent of fault patches using the Inline, Crossline or Vertical extent\\nattributes in the histogram filter.\\nHandle fault patches between fault patch sets\\nHow to create and copy new fault patch sets\\nYou can create a new empty fault patch set by using the icon under the context menu for the\\nFault patch folder. Fault patches can be copied or moved between folders. This is convenient for\\ntasks such as:\\nIsolating the desired patches for conversion to interpretation or pillars\\nSeparating a fault patch set into parts based on properties or orientation for ease of\\ninterpretation.\\nIsolating fault patches for independent fault system analysis\\nInterpreting several \"what if\" scenarios with different fault patch sets\\nMaking a safety copy of a fault patch set\\nHow to copy/cut and paste fault patches between fault patch sets:\\n1. Make the fault patch set you want to copy/cut from the active set (bold)\\n2. Right-click on the name to get the context menu.\\n3. Click on the desired option for copy/cut. You can copy all, copy only the selected patches,\\nor cut the selected patches.\\n4. Make the target fault patch set active. Then, from the context menu, select Paste fault\\npatches .\\nIf you use Cut selected fault patches , the selected fault patches will be removed from\\nthis active fault patch set.\\nHow to use a \"Hidden patch\" Workflow\\n1. Display a seismic intersection where you want to interpret faults and make it the active\\ninteraction (bold in the tree). (This does not have to be the same data from which the\\npatches were extracted.)\\n2. Click the Toggle visualization on plane icon and then turn on the fault patch set you\\nwish to use.\\n3. Click the Toggle visualization on plane icon again and re-select the desired fault\\npatch set. Click the Select all icon, followed by the Hide selected patches icon.\\n4. With the Toggle the nearest patch icon, you can click on the seismic intersection near\\nthe fault you want and pick the nearest patch. By clicking on the patch again, you will hide\\nthe patch again.\\n5. To edit this patch or to use it in modeling, change to the Select/pick mode icon, click\\non the patch to select it, then click the Convert selected to fault interpretation icon\\nor Convert selected to fault in fault model icon. The converted fault will be available\\nin the Explorer tree for editing and further interpretation tasks.\\nNote: This workflow uses the Toggle visualization on plane icon to display the\\nintersection of the patches with the seismic data. This step is not necessary; you can simply start\\nby hiding all patches, then using the Toggle the nearest patch directly from the seismic\\nsection.'},\n",
       " {'header': 'Seismic Interpretation ',\n",
       "  'content': 'In Petrel you can do standard horizon and fault interpretation on seismic data using various\\nwindows as standalones or in a combination that makes the interpretration environment more\\nconvenient.\\nSeismic Interpretation handling\\nAll interpretations in a Petrel project are stored in one or more interpretation folders. Any given\\ninterpretation folder can contain both horizon and fault interpretations. Furthermore,\\ninterpretation objects can be moved (drag and drop) from one folder to the other.\\nAn interpretation object manager is implemented in Petrel. It gives you an alternative to using the\\nPetrel Explorer tree. The following objects will appear in the interpretation manager:\\nOld (pre 2007.1) Petrel seismic interpretations\\nHorizon interpretations\\nFault interpretations\\nInterpretation manager\\nThe interpretation manager is useful both for Project administrators, seismic interpreters and all\\nother Petrel users. It includes several options to filter and sort interpretations, create new objects\\nand to turn on and off interpretation in all visible Petrel windows.\\nThe interpretation manager can be started from a given interpretation folder (showing\\nhorizon and fault interpretation residing in that folder) or from the Seismic main folder (showing\\nall interpretation in the project).\\nHorizon and fault interpretation can be exported to file(s) by right-clicking on the object (in\\nthe Input pane) and selecting Export. Alternatively, selecting more than one interpretation object\\nand selecting Export multiple will output all selected objects into separate files. Read more in\\nExport data.\\nInterpretation manager Icons\\nWhen this button is tick marked, toggling visualization will be applied in all visible\\nwindows\\nTurn on the selected interpretation in the current/all visible windows\\nTurn off the selected interpretation in the current/all visible windows\\nToggle visible of the selected interpretation in the current/all visible windows\\nShow settings dialog for selected interpretation\\nFilter content in spreadsheet on interpretation folder, type or domain\\nClear filter settings\\nInsert a new seismic horizon in the active interpretation folder\\nInsert a new fault object in the active interpretation folder\\nDelete the selected interpretation\\nSearch for horizons or faults in the interpretation manager\\nMove selected interpretation to another interpretation folder\\nSelect columns to display in the interpretation manager'},\n",
       " {'header': 'Horizon Interpretation ',\n",
       "  'content': 'Horizons can be interpreted on any type of intersection, inline, crossline, random line, composed\\nline, curved vertical intersections, etc. and in 3D or a traditional 2D interpretation window.\\nClick on the Seismic interpretation process in the Processes pane. The interpretation tools\\nwill become available on the toolbar to the right of the Display window.\\nAuto tracking can be done interactively by clicking on an intersection or by using previously\\nprepared seed points (or existing interpretation). Several different methods are available in Petrel\\nfor interpreting seismic horizons:\\nManual interpretation (drawing)\\nGuided autotracking\\nSeeded 2D autotracking\\nSeeded 3D autotracking\\nPaintbrush autotracking\\nActive box autotracking\\nIt is preferable to keep all seismic interpretation under the seismic main folder in one or more\\ninterpretation folders. Each horizon interpretation is assigned to one icon within its assigned\\nfolder. The interpretation points are in turn assigned to the survey they originated from, under\\nthe horizon interpretation icon/folder, sub-folders containing interpretation from the various\\nsyrvey exists. The interpretation is treated as grid data with every grid cell defined by its unique\\nX, Y and Z/T positions. These cells can easily be selected and edited. Pre-Petrel2007.1\\ninterpretation was treated as a cloud of points and is not fully compatible with the new format.\\nImporting pre-Petrel 2007.1 interpretation\\nThe way Petrel handles and organizes interpretation has changed compared with pre-Petrel\\n2007.1 versions. If you want to import and use already existing, pre-2007.1, interpretation in the\\nnew format, this involves a (simple) conversion step. The new seismic horizon format and its\\nstorage is described below and in Seismic main folder.\\nIn previous Petrel versions (pre-2007.1), interpretation was a collection of points. Now this\\ninterpretation is stored in the form of a grid, per seismic survey where that interpretation exists.\\nThis is why pre-2007.1 interpretation needs to be converted to the new representation. Any point\\nsets loaded or created in Petrel can also be converted to \\'real\\' seismic interpretation using this\\nprocess. During the conversion process, the existing \\'cloud\\' of interpretation points will be\\nmapped to whatever surveys those points intersect with. If the pre-2007.1 interpretation was\\nactually picked in Petrel (as opposed to being loaded via ASCII or OpenSpirit) then this process\\nwill be more robust. If picked in Petrel, the pre-2007.1 interpretation should know to which survey\\nit belongs, and thus only map to those surveys. If the interpretation has been created in Petrel\\nfrom an external source (e.g. OpenSpirit or ASCII), then it can be mapped to multiple surveys.\\nWherever a point that is being converted to interpretation lies within half the trace spacing of a\\nline, it will be stored on that line (and appear under the Seismic horizon in the relevant survey).\\nYou could end up with a single input point being turned into interpretation that exists on multiple\\nsurveys and lines. In that case, manual intervention is required to remove the unwanted points. If\\nthe seismic interpretation is imported from file, a seismic survey needs to be present, or the\\nimport will fail. If the Reference project tool is used to drag the interpretation over from another\\nproject, and no seismic survey exists, nothing can be displayed in an interpretation window.\\nFigure 1. Interpretation folder with pre-2007.1 interpretation (padlocked) and converted\\ninterpretation (with extension [Converted]).\\nSome points may NOT have been converted. These will be stored in a point set with the\\noriginal interpretation name and the suffix \\'(Not Converted)\\'. The results of the interpretation\\nconversion will be highly data dependent. The pre-2007.1 \\'padlocked\\' interpretation object will\\nremain unchanged. When it comes to unconverted points, there are a few things to consider:\\nIn many cases, it has occurred that the input point set contains multiple points (in one case\\n16!) at exactly the same map location, yet they have slightly different depths. In that case\\nonly ONE of those 16 points will be converted to the new interpretation.\\nYou may need to generate the exact trace layout and zoom in very closely on the 2D lines\\nto ascertain why the points have not been converted.\\nIt is possible to right-click on an entire Interpretation folder and convert all the horizons\\ncontained in that folder to the interpretation format at the same time. Depending on the number\\nof surveys and amount of interpretation, this could be a time consuming task.\\nHow to convert pre-Petrel2007.1 interpretation\\n1. Access the pre-Petrel 2007.1 horizon interpretation, either through the reference project\\ntool input, using Import (on selection) or open a pre-Petrel 2007.1 project in the latest\\nPetrel version.\\n2. The imported interpretation appears in the active interpretation tree with a padlock on it. It\\ncannot be edited or interpreted further.\\n3. Right-click on the locked interpretation object and select Convert to interpretation from\\nthe appearing menu.\\n4. Alternatively, use Convert to interpretation (optimized for 2D) if the interpretation to\\nbe converted is specifically 2D interpretation (this method is slightly slower than the\\n\"Convert to interpretation\" method, but works better for 2D data).\\n5. A new seismic horizon container is added, named after the input with the extension\\n[Converted]. It contains the relevant grid of interpretation stored per survey.\\nIn the current version of Petrel, seismic interpretation can only exist in a project if a seismic\\nsurvey folder exists. This folder contains the survey geometry - required for the interpretation as\\nwell as the seismic itself. The seismic bulk data is not needed. But if the Reference Project tool is\\nused to bring interpretation into a new Petrel project for modeling purposes, the relevant\\ninterpretations, plus the relevant survey folders, will need to be transferred - NOT all the seismic\\nbulk data.\\nBest practices when upgrading pre-Petrel 2007.1 projects:\\nSave the project under a different name in this version and load it again. This will free up\\nsome memory.\\nDo not display all the old interpretation into the 3D window. Convert the interpretation to\\nthe new formats. These are much more memory efficient.\\nThe old interpretation points can be attached to the seismic attribute from where it was\\ninterpreted if needed. This is done under the objects Settings dialog, style tab.\\nThe triangulation algorithm for fault interpretation was enhanced in Petrel version 2008.1\\n(and later) and as a concequence the converted fault surface may appear slightly erratic.\\nThe recommended approach is to deselect the surface intersection in the fault objects style\\nsettings.\\nHorizon Interpretation - Memory management\\nSeismic interpretation is read into RAM as needed by the BASE system (see Seismic data -\\nMemory management), but it is managed in a slightly different way than seismic bulk data. Once\\nthe BASE memory allocation has been reached (see note above - currently set to default 500MB),\\nthe interpretation can be temporarily stored in a memory format residing on a local disk. This\\ntemporary storage (or local pagefile) should be a LOCAL disk on your workstation, and should\\nideally be the fastest disk. This will ensure that the passing of data in and out of memory is\\noptimized - meaning less delay for you. In the local pagefile other information, such as the\\nundo/redo history for your interpretation, will also be stored. By default the directory that is used\\nis wherever the windows $TEMP variable points to - normally C:\\\\TEMP. This default directory can\\nbe changed from the Menu bar, Tools and System settings, under the Effects tab (see Effects\\n(System settings)).\\nThe seismic grid renderer using point style has been optimized for exploration scale horizons. The\\npoint renderer has also improved performance when displaying multiple grids at the same time\\n(see more under 3D interpretation settings).\\nThe point renderer style should now be the style of choice when using huge interpretation\\ngrids.'},\n",
       " {'header': 'Interpreting Horizons ',\n",
       "  'content': 'Click on the Seismic interpretation process in the Processes pane. The Interpretation tools\\nwill then become available in the toolbar to the right of the Display window. The Horizon\\nInterpretation icon in the tool bar must always be depressed to perform horizon interpretation\\nof any kind. The short cut key H will toggle this on automatically.\\nIn order to do any horizon interpretation, a seismic horizon must exist and be active. If not, the\\nfollowing error message appears.\\nTo correct this, either right-click on an interpretation folder and select Insert seismic horizon,\\nor left-click on an existing seismic horizon in the Input pane to activate it (name in bold text).\\nAlternatively, if interpreting inside a 3D or Interpretation window, pressing Ctrl and the up or\\ndown arrows on the keyboard will change the active seismic horizon in the input three. Also inside\\nthe display window, by right clicking on a displayed interpretation it can be hidden or made active\\nfrom the appearing menu.\\nThe autotracking settings for each of the interpreted horizons are held in the settings for that\\nhorizon. To begin a new interpretation, you must first add an interpretation folder if one is not\\nalready present in the project (Insert, New Folder, New Interpretation Folder). Next, right-\\nclick on the folder and select Insert seismic horizon. In the settings dialog for the new horizon\\nyou will find an Autotracking tab, this holds the autotracking settings for that horizon.\\nFor information on settings for the interpretation see interpreted horizon settings.'},\n",
       " {'header': 'Autotracking Settings ',\n",
       "  'content': 'The settings for the autotracking are accessed from the Settings dialog, Autotracking tab of the\\ninterpreted horizon. The autotracking tab is further subdivided into three main areas, Signal\\nfeature and the Non-zero centric selection box, Tabs and Seeds.\\nSignal feature and Non-zero centric selection area\\nSignal feature: controls the feature to be tracked;\\nNon-zero centric unselected: Peaks, Troughs, S-crossing, Z-crossing, Peaks or Troughs,\\nAny Zero Crossing and None (flat).\\nNon-zero centric selected: Local maximum, Local minimum, S-increasing, Z-decreasing,\\nlocal extremum and S/Z evolutions.\\nThe default for the tracking feature of a horizon interpretation is \"Peaks or Troughs\" (Non-zero\\ncentric unselected). When the first autotracking pick is made, the amplitude at the pick will\\ndetermine whether peaks or troughs will be tracked, and the feature setting will be changed\\naccordingly. Peaks or Troughs can also be set manually. Similarly, the feature can be set to \"Any\\nZero Crossing\", and Petrel will select \"S-crossing\" or \"Z-crossing\" automatically when the first pick\\nis made.\\nTrace features in Petrel, Z-Crossing-blue, S-Crossing-green.\\nNon-zero centric tick box: toggles between zero centric (e.g. amplitude cubes) and non-zero\\ncentric (traces not having a mean equal to zero, e.g. impedance cubes) signal feature used for\\ntracking.\\nThe illustration below indicates what non-zero centric means. Along the time axis is where a time\\nbased SEG-Y would plot. A zero crossing for this would represent a local minimum or local\\nmaximum in the non-zero centric world. A peak in the zero-centric seismic would represent an S-\\nincreasing feature while a trough would represent a Z-increasing feature.\\nTabs area\\nThere are five subtabs available, each described in the following:\\nInterpretation tab\\nValue constraints\\nSeed confidence{%}: Specifies the minimum value for the seismic amplitude as a\\npercentage of the seed point.\\nValue range: Gives the option of specifying a minimum and/or maximum amplitude value\\nseismic attribute to be tracked. Picks outside these amplitude limits will be rejected.\\nMax value delta: This parameter will control how much the amplitude is allowed to change\\nfrom one trace to the next. Picks with higher amplitude change will be ignored during\\nautotracking.'},\n",
       " {'header': 'Doublet ',\n",
       "  'content': 'Tracking rule: Specifies what part of a doublet (defined by a wavelet having 4 or more\\ninflection points and only 2 zero crossings) the tracker should follow.\\nLower: lower peak/through of the doublet.\\nUpper: upper peak/through of the doublet.\\nNone: ignores refelctors where doublets are found.\\nThe search window for the doublet feature is in samples and is linked to the dip given in the\\ngeometrical tab. By default the search has a minimum of 4 samples which it searches (even if\\nthe dip samples in the geometric tab are smaller). However if the dip samples in the\\ngeometrical tab is set to more than 4 samples, then this search window will be used.\\nOverride/locking\\nOverride: changes between overriding and locking interpreted points.\\nAdjust seed points: determines whether or not seed points can be reinterpreted (off as\\ndefault). 3D autotracking only.\\nLock/override visible points: using all visible interpreted points in the active window.\\nLock/override selected points: using only selected interpreted points (e.g. using the\\nbounding box selection) in the active window. It will be a sub-set of all visible points.\\nLock/override filter: using only the interpreted points satisfying the filter selection dropped\\nin with the blue arrow. Filter selection is taken from 3D interp inclusion filter found under\\nthe Interpretation folder.\\nGeometrical tab\\nHere the user can control how tracking will propagate in the vertical direction.'},\n",
       " {'header': 'Vertical ',\n",
       "  'content': 'Symmetrical tick boxes: This option controls if vertical position changes in the inline and\\ncrossline directions are allowed to be symmetrical (on) or assymetrical (off).\\nIncreases your bility to fine tune the autotracking.\\nNumeric value or scroll bar input between 0 and 10. Default value is 2.\\nCross-hairs assymetry in either or both directions (image representations showing three\\ntraces with selected input).\\nOptimized for dipping reflectors: This selection box will activate a guiding plane going\\nthrough the neigbors (as specified by expansion quality, i.e. 3X3 or 5X5 points) and use its\\ntrend when autotracking the event. This can increase the accuracy in areas where reflectors\\nare steeply dipping.\\nVertical range{ms}: This parameter will control the vertical interval for the autotracked\\nhorizon in project units. For example, if you specify a vertical range from -1750 to - 1790ms,\\nthe resulting autotracked horizon will be limited to this vertical interval.\\nTrend data: This is a surface or another interpretated object that Petrel will try and match\\n(in shape) when tracking. Using this option is recommended when trying to interpret a\\ndipping event. The seed expansion will only take place where the trend is defined.\\nExpansion quality: This option will control how stringently the seed points are checked\\nbefore being expanded.\\nNone: This option will merely readjust existing points.\\nBasic 3x3: Will check the 8 closest points against the seed point.\\nValidated 3x3: Will check the 8 closest points against the seed point and their\\nneighbors.\\nValidated 5x5: Will check the 24 closest points against the seed point and their\\nneighbors.\\nMax vertical delta (2D tracking only){samples}: This parameter controls how much the\\nvertical position is allowed to change from one trace to the next when autopicking along 2D\\nlines. Picks jumping to a vertical position above this vertical limit will be ignored during\\nautotracking. Default is set to 2 samples.\\nConstraints tab\\nBoundary polygon: Gives you the option to specify a closed polygon, where the\\nautotracking is not permitted to expand beyond.\\nStop at visible faults: Here faults in the fault model can be used to stop the autotracking.\\nLimit horizons\\nUpper: Horizon which the autotracking is not permitted to expand above. An offset to the\\nupper horizon can be applied.\\nLower: Horizon which the autotracking is not permitted to expand below. An offset to the\\nlower horizon can be applied.\\nWavelet tab\\nFrom this sub-tab you can access the parameters for wavelet tracking which is used when the\\nUse wavelet tracking is tick marked. It tests potential expansion points using correlation of a\\nseismic trace window.\\nCorrelation quality: Correlation threshold where tracking will fail. Identical neighboring\\ntraces give a value of 1.0. A correlation quality less than 0.5 is considered uncorrelated and,\\nconsequently, the lowest correlation quality value available is 0.75.\\nSymmetrical: This option controls if the window tracking can be different above and below\\nthe seed point pick. Ticking the box allowes it to be symmetrical (on) or assymetrical (off).\\nDistance above and below can be specified by typing the numerical value or using the\\nslide bars. Given as number of samples.\\nThe total window length is defined in the greyed out area called Length. Given as the\\nnumber of samples.\\nThe image depicts the horizon, the seismic and the picking parameters in relation to\\neach other.\\nCo-volume tab\\nThis sub-tab accesses the parameters for co-volume tracking when Use co-volume is tick\\nmarked. It uses two seismic inputs instead of one when autotracking an event.\\nUse co-volume\\nSignal feature: controls the feature to be tracked for the second volume. This volume can\\neither be zero centric or non-zero centric (tick box selection).This equals the selection for\\ntracking feature of the primary volume.\\nSeismic co-volume: specifies the second seismic volume to use.\\nUsage: defines how to use the two volumes selected as input;\\nTrack if co-volume is inside value range: finds the best pick on the primary volume\\nand uses this if the value of its location in the co-volume is inside tha value range (see\\nbelow).\\nTrack on best volume: evaluate points on both volumes and chooses the best\\nevaluation.\\nTry seismic volume then co-volume: tries to track on the primary volume first, if no\\nacceptable candidate for the pick is found it will try to track on the co-volume.\\nValue range. when selected, only values within the set range for the co-volume will be used.\\nSeeds area\\nSeeds (3D only)\\nSeismic Volume: Choose the seismic volume to be used for tracking.\\nVisible points: Use all the visible points in the current interpretation as seed points.\\nSelected points: Use the selected points in the current interpretation as seed points.\\nPoints satisfying filter: Use an interpretation filter to determine which seed points are used\\nin auto tracking.\\nOptimize for large volumes\\nProvides a performance boost to the tracker when working on large data volumes or when\\nusing a small seismic cache size.\\nInstant undo and track\\nThis tick box only becomes available after a 3D tracking has been performed. When selected,\\nany changes to the autotracking parameters will be automatically seen in the active window.\\nThis feature will instantly undo the last autotracking step and redo a 3D autotracking based\\non the new parameter settings.'},\n",
       " {'header': '3D Track ',\n",
       "  'content': 'Start autotracking using the specified parameters in the settings dialog. Only 3D tracking is\\navailabe.\\nUse the Paintbrush or Active box autotracking when investigating the parameters before you\\ndo the full volume tracking. That way you can test the parameters on a smaller area, which will\\nsave you time. When you are content with the parameter settings, you can use the new partly\\nautotracked interpretation as seeds for the complete volume.\\nStyle tab ( Interpreted horizons)'},\n",
       " {'header': '2D Interpretation ',\n",
       "  'content': 'When displaying the seismic interpretation in an Interpretation window, the interpretation can\\nbe shown as Points or Lines. The interpretation is defined by color point/line type and size/width\\n(see figure 1)'},\n",
       " {'header': '3D Interpretation ',\n",
       "  'content': 'When dispalying the seismic interpretation in a 3D window, the interpretation can be shown as\\nPoints, Triangle surface or as a Cell box. Each Style type has its own settings (see figure 1).\\nIt is possible to change the Resolution for all styles used. By selecting the Interactive check\\nbox, the Min - Max slider for the resolution can be changed interactively. From the drop-down\\nmenu, you can select; a Uniform (all displayed interpretation has the same resolution), Focused\\n(displayed interpretation in your line of sight is the last to lower its resolution) or Mixed (a\\nmixture of the two) resolution to be applied when you use the slider.\\nFigure 1. Fig. 1 Style tab for a horizon interpretation.\\nAvailable colors for 2D interpretation (points / lines) and 3D interpretation are Z-values\\n(elevation time or depth), specified (color defined in the Info tab) or standard color (a standard\\ncolor (green) for horizon interpretation optimized for display in an interpretation window).\\nHow to change the style of the interpretation in 3D for 3D Surveys\\n1. Double-click on an interpreted horizon.\\n2. Select the Style tab.\\n3. Go to Style under 3D interpretation and select Point, Triangle surface or Cell box\\n1.\\n2.\\n3.\\nfrom the drop-down menu.\\nHow to change the style of the interpretation in 3D for 2D Surveys\\n1. Double-click on one interpreted horizon which was interpreted on a 2D line\\n2. Go to the Style tab\\n3. Select to display as Points or Lines under 2D interpretation.\\n4. Set the parameters accordingly.\\n3.\\n4.\\nNote that when displaying any interpretation in an Interpretation window, points or lines can\\nbe shown for both 2D lines and 3D surveys.\\nAutotracking tab (Interpreted horizons)\\nThe Autotracking tab is very useful for keeping a backup of the tracking settings of a specific\\nhorizon, or to change the tracking settings while making the interpretation.\\nSee Autotracking settings\\nUsing Autotracking to interpret horizons\\nThe most common way of interpreting seismic data is to use autotracking. The user selects one or\\nmore seedpoints as a basis for the interpretation and Petrel searches outwards from these\\nseedpoints, tracking the seedpoints features to select adjacent points which match the tracking\\ncriteria. Seedpoints can be prepared in advance or picked interactively from a seismic\\nintersection. Parameters for controlling the autotracking are held in the horizons settings,\\nautotracking tab, for information on these criteria see Autotracking Settings.\\nThere are 5 types of autotracking available in Petrel:\\n3D autotracking - Points will be tracked outwards from the seedpoints in all directions.\\nWhen the reflectors are of good quality this method can be a very efficient way of\\ninterpreting through the seismic cube. If you hold down SHIFT before you start, the seeded\\nautotracking will display the tracking on-screen as it progresses.\\n2D autotracking - Points will be tracked in the direction of the selected line\\nintersection.\\nGuided autotracking - You select two points and the tracking will find the best route\\nfrom one to the other. This gives you a high degree of control as to how the interpretation\\nwill develop.\\nPaintbrush autotracking - Points will be tracked outwards from the seedpoints, limited\\nby the cursor box. Dragging the cursor while clicking the left mouse button will \\'paint\\'\\ninterpretation following the cursor path. Works in both 2D and 3D windows.\\nActive box autotracking - Points will be tracked outwards from the seedpoints, limited\\nby the extent of the box dragged over the area. Works only in a 2D window.\\nHow to use guided autotracking\\n1. Select Interpret grid horizons icon from the Function bar (shortcut key H).\\n2. Click on the Guided autotracking icon in the Function bar.\\n3. Start autotracking in the Display window by clicking at least two points or hold the left\\nmouse button down and move the cursor in one direction.\\nAll interpretation will go into an existing, active horizon interpretation object. If no such\\nobject exists, or is not activated, an error message will open up. To prepare for the interpretation,\\nan Interpretation folder and seismic horizon must be inserted or activated (left-click on the object\\nso the name turn into bold text).\\nTo insert a flag (that is, a break) in the interpreted data set in connection to faults, etc. turn\\noff/on the Interpret grid horizons icon, use the shortcut keys N or H or simply double-click\\nusing the left mouse button.\\nGuided autotracking uses the parameters set under the Autotracking tab in Settings dialog for\\nthe horizon.\\nFigure 1. Fig. 1 The Autotracking tab.\\nHow to change default Autotrack parameters for all new horizons\\n1. Double-click on the Seismic interpretation process on the Processes pane.\\n2. Open the Autotracking (template) tab.\\n3. Change the parameters to your liking.\\n1.\\n2.\\n3.\\n4. Click Apply or OK to update the settings.\\nFrom now on, all horizons made in your project will have the updated parameters as their default\\nsettings.\\nHow to use Seeded 3D autotracking\\n1. Make sure the Interpret grid horizons is on (shortcut key H).\\n2. Click on the Seeded 3D autotracking icon (shortcut key Shift + A) in the Function\\nbar.\\n3. Insert a new interpretation horizon in the Interpretations folder if one doesn\\'t already\\nexist.\\n4. Open the settings for the horizon and choose the Autotracking tab.\\n5. Set the tracking constraints, such as Seed confidence, parameters under the Geometry\\nand Constraints tabs and the type of seeds to use as input. Alternatively, use the default\\n6.\\n4.\\n5.\\nsettings.\\n6. Start the autotracking by clicking on an event on the seismic.\\n7. If an interpretation already exists for the seismic horizon, clicking 3D Track will expand the\\ninterpretation based on the multiple seeds.\\nThe seeded autotracking will follow the picked event until it reaches a disturbance in the data\\nquality of some sort (for example, fault, noise, etc.).\\nFigure 2. The figure shows a 3D Seeded Autotracking.\\nHow seed value confidence affects Seeded 3D autotracking\\n1. Make sure Interpret grid horizons is on (shortcut key H).\\n2. Click on the Seeded 3D autotracking icon (shortcut key Shift + A) in the Function\\nbar.\\n3. Insert new interpretation horizon in the Interpretations folder, if needed.\\n4. Open the settings for the horizon and choose the Autotracking tab.\\n5. Set the parameters fairly conservative.\\n6. Make sure Seed confidence is increased (60- 70 %), set Expansion quality to validated\\n3x3 and Seeds to Visible points.\\n5.\\n6.\\n7. Click Apply to update the settings.\\n8. Display an inline and crossline from a seismic volume.\\n9. Click on an event expected to be partly tracked with the set parameters.\\n10. When the tracking stops, click the 3D Track button on the Autotrack tab without changing\\nany parameters. In most cases, the tracking expands a bit further.\\n11. Click the 3D Track button again and it will possibly expand some more interpretation.\\n12. Eventually, the tracking will not expand the interpretation any further.\\nThe parameter controlling this behavior is the seed value confidence. If the original (first) set seed\\n12.\\npoint hit an 8-bit seismic sample with amplitude of 100 (positive peak). With a seed value\\nconfidence of 60 %, the tracking will not accept samples with amplitude values less than 60\\n(positive) as included. But the expanded interpretation now includes new potential seed points\\nwith amplitude values down to 60. Since Visible points are set as seeds, the next tracking uses\\nall the new points and can theoretically include amplitude values down to 36. The next tracking\\ndown to ~22 and so on. Remember that the other set parameters also affects the tracking steps.\\nHow to use Paintbrush or Active box autotracking in a 2D window\\n1. Make sure Interpret grid horizons is on (shortcut key H).\\n2. Activate or open a new 2D window (paintbrush and active box autotracking only works in\\n2D windows).\\n3. Display an active horizon interpretation in the 2D window (if not, make a partial\\ninterpretation in an Interpretation or 3D window).\\n4. Click on the Paintbrush autotracking icon (shortcut key R) in the Function bar.\\n5. Click once with the left mouse button, and make sure one or more active horizon\\nseedpoints are inside the cursor width.\\n6. Click and drag with left mouse button, making sure the seedpoints are captured by the first\\nselection.\\n7. Click on the Active box autotracking icon (shortcut key X) in the Function bar.\\n8. Click the left mouse button, drag and release, making sure some active horizon seedpoints\\nare inside the selected area.\\nThe size of the Paintbrush autotracking cursor can be changed by pressing the plus and\\nminus (+/-) keys on the keyboard.\\nHow to use Paintbrush autotracking in a 3D window\\n1. Make sure Interpret grid horizons is on (shortcut key H).\\n2. Activate or open a new 3D window (paintbrush autotracking works in both 2D and 3D\\nwindows, altough slightly different).\\n3. Display an active horizon interpretation in the 3D window (if not, make a partial\\ninterpretation in an Interpretation or 3D window).\\n4. Right-click on the seismic volume that is used as source to autotrack on. Select Insert\\nvirtual cropped volume from the menu.\\n5. Downsize the cropped volume around some of the interpretation.\\n6. Click on the Paintbrush autotracking icon (shortcut key R) in the Function bar.\\n7. Click and drag with the left mouse button on the (transparent) side of the cropped volume\\n(making sure seedpoints are captured by the first selection inside the cursor volume).\\nThe Paintbrush autotracker does not work for the \"peaks and throughs\" signal feature.\\nThe 3D Paintbrush autotracker will only move in two dimensions following the selected face\\nof the cropped volume/3D paintbrush cursor.\\nAutotrack parent and child relation\\nThe Autotracking technique uses a trace-to-trace method of verifying and expanding the seed\\npoint. When a point or a selection of points is accepted, it becomes a parent to other potential\\npoints (children) that are picked from neighboring traces.\\nSelect parent points (shortcut key Y) , enables you to investigate the path the autotracker\\nmade in reaching the selected point. Similarly Select child points (shortcut key Shift + Y),\\nenables you to track subsequent points originating from that pick. These options also enable you\\nto delete all points (parents/child) associated with the selected point using the delete button .\\nYou can then redo autotracking on just this area.\\nUse the Undo (shortcut key CTRL + Z) and Redo (shortcut key CTRL + Y) button to\\nretrieve the deleted Interpretation.\\nHow to use parent / child selection to fix mis-ties\\n1. Activate Select parent points (shortcut key Y) . The Select/pick mode (shortcut\\nkey P) must be selected to activate this function.\\n2. Select a point within the area where the interpretation is wrong (all the points on the\\ntracking path between the selected point and its seed will be selected).\\n3. Hold down Shift while clicking with the left mouse button to select other areas disconnected\\nfrom the first selection. Repeat until you have selected several points around the mis-tied\\narea.\\n4. Activate Select child points (shortcut key Shift + Y) and select the common point on\\nthe selected tracks (i.e. the first mis-interpreted point).\\n5. Delete the selected points.\\nThe Select/pick mode icon must be activated before either Select parent points and\\nSelect child points are accessible.\\nHow to change the tracking settings while interpreting\\n1.\\n2.\\n3.\\n1. Start your interpretation.\\n2. Open the settings for the active horizon.\\n3. Select the Autotracking tab and change the settings.\\nSeismic interpretation toolbar\\nActivate fault/horizon, use this tool to click on an interpretation to activate it.\\nSelection paintbrush, use a large cursor to select interpretation points ( +& -to\\nincrease or decrease cursor size).\\nBounding box select, draw a box to select interpretation points.\\nEraser, delete points using a lager square cursor ( +& -to increase or decrease cursor\\nsize).\\nInterpret faults.\\nJoin selected segments.\\nCut segments.\\nSelect and edit/add points.\\nInterpret grid horizons.\\nSeeded 3D autotracking.\\nSeeded 2D autotracking.\\nGuided autotracking.\\nManual Interpretation (Click to create straight line interpretations, Click and hold to\\ndraw freehand).\\nPaintbrush autotracking (2D/3D windows).\\nActive box autotracking (2D/3D window).\\nSelect parent points.\\nSelect child points.\\nScreen digitize new or existing well top point.\\nSelect line to display in current or last 3D/Interp window, use to select lines for\\ndisplay in the current window (3D windows) or to send the selection to display in the last\\nused active 3D/interpretation window (2D windows).\\nSelect inline intersection (2D/3D windows), use to select a new position for the active\\nor last active crossline.\\nSelect crossline intersection (2D/3D windows), use to select a new position for the\\nactive or last active inline.\\nCreate arbitrary polyline intersection (2D/3D windows), use to create intersections.\\nCreate seismic aligned polyline intersection (2D/3D windows), use to create\\nintersections aligned with inline and crosslines in the 3D cube.\\nSelect composite section (2D/3D windows).\\nDraw arbitrary composite sections (2D/3D windows).\\nDraw aligned composite sections (2D/3D windows).\\nCompose with intersecting line (Interpretation window).\\nCompose with inline (Interpretation window).\\nCompose with crossline (Interpretation window).\\nClip and extend composite (Interpretation window).\\nStart new line.'},\n",
       " {'header': 'Undo. Redo. Delete. ',\n",
       "  'content': 'Insert/manipulate seismic ghost.\\nRedisplay previous intersection (Interpretation window).\\nRedisplay next intersection (Interpretation window).\\nShortcuts for seismic interpretation\\nK - Select any visible line, i.e. inline, crossline, general vertical intersection or 2d line (Base\\nmap and 3D windows) or redisplay previous intersection (Interpretation window).\\nShift + K - redisplay next intersection (Interpretation window).\\nL - Select Inline Intersection (Base map and 3D windows).\\nShift + L - Select Crossline Intersection (Base map and 3D windows).\\nC - Create Arbitrary Polyline Intersection (Base map and 3D windows).\\nShift + C - Create Seismic Aligned Polyline Intersection (Base map and 3D windows).\\nB to activate the Bounding Box Select tool (All windows).\\nShift + B to activate the Selection Paintbrush tool (All windows).\\nE to Select and Edit/Add Points (All windows).\\nShift + X to activate eraser mode (All windows).\\n(+)/ (-) - increase / decrease the size of the eraser (when active).\\nPgUp/ PgDn - Move the active seismic section by a given increment (All windows).\\nShift + S - Activates fault or horizon (All windows).\\nF - Fault interpretation (All windows).\\nN - New Fault stick/interpretation (All windows).\\nH - Horizon Interpretation (All windows).\\nShift + A to set 3D seeded autotracking mode.\\nA to set 2D seeded autotracking mode.\\nG to set 2D guided autotracking mode.\\nU to set manual drawing mode.\\nR to set paintbrush autotracking mode (2D window only).\\nX to set active box autotracking mode (2D window only).\\nDel to delete selection.\\nP activates the Select/Pick Mode.\\nZ - Zoom (Interpretation window).\\nShift+Z will unmagnify (only if magnifier has been used in the Interpretation window.\\n(+)/ (-) - Zoom in/out (Interpretation window).\\nCtrl+Z will undo the last editing action.\\nCtrl+Y will redo the last editing action.\\nY selects parent points (Base map and 3D window).\\nShift + Y selects child points (Base map and 3D window).\\n(+)/ (-) - zooms in/out (Interpretation window).\\nO - select composite selection (Base map and 3D windows) or compose with intersecting\\nline Interpretation window).\\nW - draw arbitrary composite intersections (Base map and 3D windows).\\nShift + W - draw aligned composite sections (Base map and 3D windows).\\nI - compose with inline (Interpretation window).\\nShift + I - compose with crossline (Interpretation window).\\nQ - clip and extend composite (Interpretation window).'},\n",
       " {'header': 'Manual Interpretation ',\n",
       "  'content': 'In areas with poor data quality, the guided autotracking is difficult to use. In such areas, manual\\ninterpretation is the only way to interpret the seismic data. In Manual picking, the user clicks on\\nkey picks and the program interpolates between these picks. This type of manual interpretation is\\ncalled Manual picking.\\nOn the other hand, the user can click and drag along the event, thus making a freeform curve.\\nThis is called the Manual Draw.\\nManual Interpretations are flagged as \"manual\" in the 3D interp inclusion filters under the\\nInterpretation folder.\\nTo snap the interpolation to the signal feature when manually interpreting an event, press Shift\\non the keyboard and commence as normal.\\nHow to interpret manually\\n1. Select the Interpret grid horizons icon (shortcut key H) from the Function bar.\\n2. Click on Manual interpretation in (shortcut key U) the Function bar.\\n3. Start picking points on the event (Manual picking, a rubber band \\'interpretation\\' appears).\\n4. Double-click to put the proper interpretation on the seismic section.\\nMoving back over previous interpretation will update the interpretation.\\nTo insert flag (i.e. a break) in the interpreted data set in connection to faults etc, double-click or\\nuse the shortcut key N.\\nEditing the Interpretation\\nThe modification of an interpretation can be done by deleting a group of points or line-segments.\\nAlternatively, can existing interpretation be repositioned (snapped) to follow another part of the\\nsignal tracking feature (Peak, Through, Z- or S-crossing). Interpreted horizons can be edited\\nusing the Seismic interpretation process or the data can be transformed to points (horizon\\ninterpretation), or to polygons (fault interpretation). For more details see Transformation of\\nSeismic Interpretations. Performing seismic operations on the interpretation is another editing\\napproach.\\nThere are several editing tools available in the Function bar that enableyou to clean up an\\ninterpretation. The interpretation you wish to edit must be active. You can use Activate\\nfault/horizon icon (shortcut key Shift + S), then click on the interpretation you want to edit\\nand this will activate it. You can use a selected group of points or a single point for deleting.\\nHowever, you must first select the data point(s) to delete, either by using the Bounding box\\nselect icon (shortcut key B) to draw a boundary around the area you want to edit, or the\\nSelection paintbrush (shortcut key Shift + B) to draw the selection on the interpretation\\nand then use the Delete function. A more straightforward method is to use the Eraser\\n(shortcut key Shift + X) to remove any unwanted interpretations. Snapping horizon\\ninterpretation to another part of the signal is done by using the autotracker. The Undo\\n(shortcut key Ctrl + Z) and Redo (shortcut key Ctrl + Y) functions are used to move\\nbetween the last edits. The last icon on the Function bar is the Toggle seismic annotation ,\\nwhich displays the annotation on the active, displayed section.\\nHow to move interpretation from one horizon to another\\n1. Right-click on the Interpretation folder in the Input pane\\n2. Select Insert interpretation folder to create a new Interpretation (sub-) folder, click Yes to\\nmake a sub-interpretation folder.\\n3. Use Ctrl + C/X and Ctrl + V to copy and paste the horizon.\\nSimilarly, use the left mouse button to select and drag the horizon/fault from one Interpretation\\nfolder to another.'},\n",
       " {'header': 'Deleting Interpretation ',\n",
       "  'content': \"The interactive Eraser (shortcut key Shift + X) found in the Function bar deletes a point, all\\npoints or any combination of interpretation types: manual, seeded autotracking and fault\\ninterpretations. The delete function removes everything within the square map eraser, regardless\\nto the type and origin of the interpretation. Use the interpretation filters to hide data you don't\\nwant to delete (see Interpretation Filters).\\nYou can increase the rubber scale (eraser scale) by pressing plus or minus+ /- keys.\\nThe Undo (shortcut key Ctrl + Z) in the Functions bar, can be used revert to the last\\ninterpretation if you accidentally delete the interpretation. The undo function is also found under\\nEdit menu in the Petrel window.\\nHow to delete a group of point within a square area\\n1. In a 2D or a 3D window, display the data to be edited. Make sure it is active (the name is in\\nbold text).\\n2. Click on the Bounding box select (shortcut key B) in the Function bar.\\n3. Draw a rectangular box around the interpreted points to be deleted. The points will now be\\nhighlighted in yellow.\\n4. Click on the Delete button in the Function bar (normally on the right hand side).\\nAlternatively, the Selection paintbrush (shortcut key Shift + B) tool can be used to select a\\ngroup of points.\\nHow to delete several areas in one operation\\nBy using the same process as above and holding the Shift keyoard button, you can select\\nmultiple areas and delete them in one operation. When using the Select paintbrush tool,\\npressing Shift is not necessary.\"},\n",
       " {'header': 'Snapping Interpretation ',\n",
       "  'content': 'Snapping horizon interpretation to another part of the signal tracking feature is done by\\nmanipulating autotrack parameters before (re-) autotracking the horizon. With this approach, it is\\npossible to make selections of points to snap while leaving the remaining interpretation\\nunchanged.\\nHow to snap all visible interpretation\\n1. Select the appropriate signal tracking feature.\\n2. In the Geometrical sub-tab, set expansion quality to None.\\n3. Increase the Max. vertical delta to include the new tracking feature.\\n4. In the Seeds area, select Visible points as seeds.\\n5. Specify the seismic volume to use.\\n6. In the Interpretatation sub-tab, toggle on the Override checkbox.\\n7. Use Override visible points.\\n8. Click Apply to set the selected parameters.\\n9. Then click 3D Track.\\nHow to snap selected interpretation\\n1. Select the area/points in a 3D/2D/Interpretation window on which the snapping will be\\nperformed. Selection can be done with the Bounding box select icon (shortcut key B)\\n.\\n2. Select the appropriate signal tracking feature.\\n3. In the Geometrical sub-tab, set expansion quality to None.\\n4. IIncrease the Max. vertical delta to include the new tracking feature.\\n5. In the Seeds area, specify the seismic volume to use.\\n6. Use Selected points as seeds.\\n7. In the Interpretatation sub-tab, toggle on the Override checkbox.\\n8. Use Override selected points.\\n9. Click Apply to set the selected parameters.\\n10. Click on 3D Track.\\nHow to snap by means of filter\\n1. Select the appropriate signal tracking feature.\\n2. In the Geometrical sub-tab, set expansion quality to None.\\n3. Increase the Max. vertical delta to include the new tracking feature.\\n4. In the Seeds area, specify the seismic volume to use.\\n5. Select Points satisfying filter.\\n6. Select the filter to be used from the the current interpretation folder. The available filter\\ntypes are found in the 3D interp inclusion filters (i.e. 3D autotracked, 2D autotracked,\\nManual or Imported/converted).\\n7. In the Interpretatation sub-tab, toggle on the Override checkbox.\\n8. Select Override filter. Select the filter to override (should be the same as in step 6).\\n9. Click Apply to set the selected parameters.'},\n",
       " {'header': '10. Click 3D Track. ',\n",
       "  'content': 'If the snapping result is not satisfactory, you may consider snapping incrementally by going\\n10.\\nto the closest desired Z- or S-crossings. That is, snapping from a through to the peak below, first\\nsnap to the S-crossing and then to the peak. In addition, the Max vertical delta can be used to\\nadjust how far up/down snapping is allowed.\\nSeismic operations on interpretation\\nA set of operations can be performed on horizon interpretations. Apart from the commonly used\\narithmetic-, replace-, eliminate-, etc. operations, seismic operations can smooth, interpolate and\\ncreate empty attributes on the interpretation.\\nHow to create an empty interpretation attribute\\n1. Expand the seismic horizon object and right click on the survey tied interpretation (2D or\\n3D seismic interpretation).\\n2. Open settings and go to the Operations tab.\\n3. Expand the Seismic operations folder.\\n4. Select Create interpretation attribute.\\n5. If needed, go to the Templates pane and select a template to drop into the Templates field.\\nRunning the Create interpolation attribute without using a Template as input, equals\\nright-clicking on the interpretation in the Input pane and selecting Insert interpretation\\nattribute.\\nHow to smooth horizon interpretation\\n1. Expand the seismic horizon object and right click on the survey tied interpretation.\\n2. Open settings and go to the Operations tab.\\n3. Expand the Seismic operations folder.\\n4. Select Gaussian smooth or Median smooth.\\n5. Set the appropriate parameters and click on Run.\\nHow to interpolate interpretation\\n1. Expand the seismic horizon object and right click on the survey tied interpretation.\\n2. Open settings and go to the Operations tab.\\n3. Expand the Seismic operations folder.\\n4. Select Interpolate empty.\\n5. Click on Run and holes in the interpretation is filled in.'},\n",
       " {'header': 'Horizon Flattening ',\n",
       "  'content': 'Individual lines can be flattened on an interpret horizon in the interpretation and intersection\\nwindows. The Interpret horizon does not have to be consistent over the entire line, Petrel allows\\nfor gaps in the interpretation, such as breaks over faults. These gaps will be interpolated linearly.\\nThe user can interpret on the flattened sections.\\nHow to flatten on a horizon interpretation\\n1. Display an active interpreted horizon in the interpretation or intersection window.\\n2. In the Input pane, right-click on the active horizon and select Flatten horizon from the\\nappearing pull down menu.\\n3. The seismic section will be flattened on the selected horizon\\n4. To turn off the feature, right-click on the same horizon interpretation and select Flatten\\nhorizon again.\\nFlattening a horizon can be done on the horizon interpretation or different interpretation\\ngrids (survey filters accessed by expanding the horizon interpretation object). Right-click on the\\nappropriate horizon or grid to flatten the entire or part of the seismic section, respectively.'},\n",
       " {'header': 'Fault Interpretation ',\n",
       "  'content': 'There are two ways to interpret faults in Petrel:\\nClassical interpretation (drawing fault segments) in the seismic interpretation,\\nBy modeling faults directly on the seismic in 3D through the Fault modeling process. (Use\\nthe shortcut on the seismic interpretation toolbar.)\\nThe first case gives all the flexibility of traditional interpretation together with the added clarity of\\nfault planes triangulated in 3D.\\nThe advantage of using the fault modeling process is that after the interpretation, the model is\\nready for gridding as soon as the interpretation is complete. Furthermore, the interpreter is forced\\nto solve problems regarding fault hierarchy and connections during interpretation, thus avoiding\\nthe need for reinterpretation before fault modeling. This option is explained further in Fault'},\n",
       " {'header': 'Modeling. ',\n",
       "  'content': \"Interpreting fault segments in Petrel\\nFault segments (also referred to as fault sticks) are interpreted by simply digitizing directly on a\\nseismic intersection. Both 3D windows and Interpretation windows can be used. To start a new\\nfault interpretation, right-click on an existing interpretation folder (or if needed, insert a new\\ninterpretation folder first) and select Insert fault. Next, select Interpret faults or press F\\nand begin digitizing. The new fault object has appeared in the interpretation folder with a name in\\nbold, indicating that it is the active fault.\\nFaults are digitized in segments (lines), which are automatically triangulated in Petrel to give a\\nfault surface (If the fault surface is not displayed, turn it on under the fault's settings).\\nFigure 1. A triangulated fault in Petrel\\nA segment can consist of any number of points. When triangulating, points from adjacent\\nsegments will be joined to create the fault surface. When digitizing on an intersection simply\\nstepping the section forwards or backwards will automatically begin a new fault segment. To start\\na new segment press N.\\nTo start digitizing a new fault, insert a new fault under an interpretation folder in the Input pane.\\nWhen inserting new points in an already existing fault interpretation, a re-triangulation of\\nthe fault surface takes place to give a best possible rendering of the plane.\\nHow to interpret fault pillars on seismic data\\n1.\\n2.\\n1. Select the active seismic line to start the interpretation of faults.\\n2. If no faults have been interpreted in the project, double-click on the Define model\\nprocess step, and create a new fault model by entering a name and clicking OK in the\\nprocess dialog. Next, click once on Fault modeling in the Processes pane.\\n3. Select the type of key pillar (vertical, two points, three points, etc.) in the lower part of the\\nFunction bar.\\n4. Click on the Add new pillar button.\\n5. Start digitizing on the seismic section (note that a new fault will appear in the active Fault\"},\n",
       " {'header': 'Model). ',\n",
       "  'content': 'Remember to deactivate the active fault in the Fault Model whenever a new fault is going to\\nbe generated. Do so by clicking on the icon in front of the object.\\nIt is important to know that faults interpreted using the fault modeling process do not generate a\\ntriangulated plane.\\nHow to interpret faults by creating fault segments\\n1. Activate the Seismic Interpretation process (click on it).\\n2. Click on Interpret faults in the Function bar or use the shortcut key F.\\n3. Digitize the segment on the Seismic Intersection.\\n4. A rubber band display connecting the last interpreted point and the location of the cursor\\nwill be seen, aiding the interpreter to set the next fault interpretation point.\\n5. Press the N or F key to end the current segment or double-click (and begin a new fault).\\n6. When a fault is completed, insert a new fault (deactivates the older one) under an\\ninterpretation folder in the Petrel Explorer before starting the new fault.\\nIf you are interpreting in an interpretation window, you can set the Plane step increment and pan\\nthrough the data to interpret your faults. Fault interpretation from neighboring lines can also be\\nprojected onto the intersection to ease the interpretation process.\\nIn the 3D window the faults are interpreted as free-form point clouds forming a triangulation\\nplane. These points can easily be edited to give a correct picture of the plane. You can use the\\nManipulate plane tool or set increments to pan through the data.\\nEditing of Faults\\nThe method for editing and visualization of interpreted fault segments is the same as the method\\nfor interpreted horizons.\\nPetrel has a powerful and unique freeform editing in 3D space. The faults interpreted on seismic\\ncan easily be converted into a Petrel fault model. The fault polygon can be edited in z direction as\\nwell as in x and y direction.\\nThe Bounding box select (shortcut key B) and Selection paintbrush (shortcut key\\nSHIFT and B) allow you to select entire fault segments. All segments that partly falls within the\\ncursor area will be selected. Use Select and edit/add points (shortcut key E) to edit a single\\npoint or a single fault segment. The Select/pick mode (shortcut key P) is used as the\\nsegment selector if you click on the line between to points or as point selector if you click on a\\npoint.\\nThe Eraser (shortcut key SHIFT and X) is used to select single points and to instantly delete\\nit.\\nSelecting segments and points will cause their color to change from the selected to a golden\\ncolor. A selected segment will display all points and the line segment between the points in the\\ngolden select color, while a single selected point will be highlighted in golden as well as half of the\\nline segment on each side of the point.\\nMove fault segment nodes\\n1. Make sure the fault you want to edit is activated in the Input pane.\\n2. Click on Select and edit/add points (shortcut key E) .\\n3. Click on and move the selected point to reposition it. A widget is displayed to aid the\\ninteraction. The orientation of the widget is determined by the clicked point, and the\\ninterpreted point above and below. Hence, if a fault has been interpreted on an\\nintersection, clicking on the square part of the widget will limit the movement to the\\nintersection plane. To move the point out of the plane, click on the cylinder part of the\\nwidget. Alternatively, click and hold on the square (cylinder) of the widget and press CTRL\\nand the movement plane (axis) will change orientation.\\nMove whole fault segment\\n1. Make sure the fault you want to edit is activated in the Input pane.\\n2. Select all points in a fault segment by:\\nActivating the Select/pick mode (shortcut key P) and click on a fault segment.\\nThe operation will select all points in the segment.\\nAlternatively, activate Selection paintbrush or Bounding box select and\\ntouch a part of the fault segment with the mouse pointer.\\n3. Activate the Select and edit/add points button.\\n4. Click on a point in the selected segment and move the entire fault segment.\\nThe fault can be edited in a 3D window or interpretation window. The tools work in a similar\\nway, but the widget is not displayed in the interpretation window (and cannot be moved out of\\nthe section plane).\\nRemember to use Undo (shortcut key Ctrl + Z) to remove edits or to retrieve\\naccidentally deleted points.\\nHow to move all fault segments laterally\\n1. Identify the fault you want to move laterally in the Input pane.\\n2. Open the settings and go to the Operations tab.\\n3. Under the Seismic operations folder, select Move fault laterally.\\n4. Enter a Distance value and click on Run.\\n5. If you are not satisfied with the result, click Undo last operation and change the input\\nparameter.\\nThis operation will move the fault laterally, perpendicular to the strike of the approximated\\nfault plane. A negative Distance parameter will move the fault in the opposite direction.\\nAdd new nodes to the segment\\n1. Ensure the appropriate fault is active\\n2. Activate the Select and edit/add points button.\\n3. Click on a line segment between two points to create a new point.\\n4. Move the new point to the desired position.\\nRe-assign segments and points between faults\\nMore than one fault identified on a seismic intersection can be interpreted in the same fault\\nobject. Interpret the various faults, make a break between each by pressing N on the keyboard\\nor double-clicking. Continue with the same procedure through the dataset. Displayed in a 3D\\nwindow, this will look like a chaotic triangulated surface that can cross over itself. Nevertheless, if\\nyou look at the fault segments, it is easier to identify the segments belonging to the same fault\\nsystem. The process of splitting up segments into separate objects in the Input pane is described\\nbelow:\\n1. In a 3D window, make sure the fault of interest is displayed and active.\\n2. Identify all the segments that describe the same fault (based on orientation and geometry).\\n3. Use the Bounding box select (shortcut key B), Selection paintbrush (shortcut\\nkey Shift + B) or Select/pick mode (shortcut key P) to select the segments.\\n4. In the Input pane, right-click on the active fault object and select Move selection to new\\nfrom the menu.\\n5. The selected segments are now moved into a newly created fault interpretation object that\\nis the active fault.\\n6. Reactivate the first fault, do a selection of fault segments and move them into a new object\\nas described.\\nParts of a fault can be moved (or copied) from one fault to another. Activate the fault to\\nmove from, select the segments or points of interest and right-click on the fault to move (or\\ncopy) into. Select Move active selection her and the selected segments/points are pasted into and\\nadded to the already existing fault interpretation.\\nRe-assign complete segments in a 3D window\\nEntire fault segments can be selected and copied/moved into new objects without leaving the 3D\\nwindow.\\n1. Make a selection of the segments you want to move.\\n2. Right-click on one of the highlighted segments and select Move selection to new.\\n3. All the selected segments are moved to a new fault interpretation object that is now the\\nactive one.\\n4. Alternatively, right-click on any displayed fault segment (the fault does not need to be\\nactive) and select Copy fault interpretation (data only).\\n5. Right-click on another displayed fault interpretation (it does not have to be active) and\\nselect Paste fault interpretation (data only). The entire fault interpretation is copied\\nover from one fault to the other. Note that this will delete the already existing\\ninterpretation in the target fault, the undo history is taken from the source fault. This\\nmeans that the deleted interpretation is lost.\\nTransformation of seismic interpretations\\nHorizon data can be used directly in the Make horizons process; however there are tree options\\nfor transforming the interpretation:\\nTransform to points; right-click on the interpretation and select Convert to Points (these\\npoints can be converted to well tops or lines or back to an interpretation)\\nTransform to a gridded surface using the Make/edit surface process (see Make/Edit'},\n",
       " {'header': 'Surface). ',\n",
       "  'content': 'Transform seismic horizon and fault interpretation into a gridded surface and corresponding\\nfault polygons (using the Create fault polygons and map operation).\\nFault planes can be directly converted to faults in the Fault modeling process by right-clicking\\non the fault and selecting, Convert to Fault Model. However, the right-click menu also includes\\na convert to polygons option which will generate standard polygons of the interpreted segments\\nand they can be edited and exported.\\nQuality Control of your interpretation\\nThe best way to check your seismic interpretation is to play through the seismic cube using the\\nintersection player. Set the plane step increment to a specific number and start the player. It is\\npossible to play continuously or stop for each selected line.\\nInterpretation filters\\nOnce made, the interpretation can be filtered on a number of parameters. These filters are used\\nfor displaying the interpretation, but also for defining points as seeds for autotracking, locking\\npoints, or selecting them for reinterpretation. Together with Bounding box select they can\\nalso be used to delete specific parts of an interpretation.\\nInterpretation filters are included as 3D interp inclusion filters in an interpretation folder, expand\\nand click on and off the various selections.\\n3D autotracked - according to the tracking method, Seeded 3D, Paintbrush and Active box\\nautotracking\\n2D autotracked - according to the tracking method, Seeded 2D autotracking\\nManual - according to the tracking method, manual interpretation.\\nImported/converted - according to the interpretation grids imported or converted.\\nAn interpretation filter will affect all the interpretations in the interpretation folder. Sub-folders will\\nhave their own filters and be affected by these. Filter actions in different windows act\\nindependently of one another.\\nPetrel Geobody interpretation user guide\\nSystem requirements and Settings\\nThe Petrel recommended requirements are considered minimum requirements for the Geobody\\nInterpretation functionality. Selecting a high-end graphics card is essential for effective and\\nsmooth geobody interpretation. Old, slow cards with less than 256 MB memory will generally lead\\nto poor geobody interpretation performance with low resolution. In addition, graphics card\\nvendors are often updating their drivers to remove bugs and enhance new features. Be sure to\\nalways have up-to-date graphics card drivers installed on your computer. As the graphic card GPU\\nmemory is mapped on the RAM memory, having the possibility to extend the application memory\\nconsumption to the full available RAM is really a must in order to have good performance. This is\\nonly possible using a 64-bit application. Thus, when using a 32-bit Windows a message will open\\nup warning the user that the Geobody Interpretation module will not work in its full capability.\\nGraphics cards\\nProfessional NVIDIA graphics cards (for example, from the Quadro FX series) are highly\\nrecommended. Although geobody interpretation can be used on ATI graphics cards, some\\nfeatures and operations might perform poorly on these.\\nThe Geobody interpretation process uses an interactive visual approach to isolate features in\\nyour seismic data. By using state of the art blending technologies, Petrel can quickly integrate the\\nisolated body into your property model.\\nThe GPU (Graphics Processing Unit) is the name of the processor responsible for handling\\ngraphics in new computers. It is similar to the CPU (Central Processing Unit) but a highly\\nparallelized structure makes it very powerful for some special tasks like displaying and\\nsegmenting geobodies.\\nThe GPU has its own physical memory separated from the CPU memory. Data in this memory is\\nnormally visualized on the screen and/or processed very quickly, making it ideal for geobody\\ninterpretation. A drawback is that this memory is usually smaller than the CPU memory making it\\nnecessary to transport data between these two memory storages. Today, it is not possible for a\\ncomputer program to read the amount of physical memory available for the GPU. This parameter\\nmust be set by the user by opening the geobody interpretation process settings and is called\\nRender cache size. This parameter is 180MB by default which is near the maximum limit for 32-bit\\nsystems, but should be extended for 64-bit versions of Petrel. However, this number should not\\nexceed the amount of memory available on the graphics card. The actual amount of available GPU\\nmemory can usually be found in the software provided by the graphics card vendor (NVIDIA\\ngraphics cards: NVIDIA control center and ATI graphics cards: Catalyst control center). This\\nsoftware can be opened on most systems by right-clicking the windows desktop. To find the\\noptimal size of your GPU cache, subtract 100 MB and the Render cache size from the amount of\\nmemory available on your graphics card.\\nBe aware that the GPU memory is shared between the Geobody interpretation process and\\nother Petrel processes. For instance, if you have 512MB available on your graphics card and\\ndisplay a 400 MB probe or geobody, only 112MB will be available for other visual elements.\\nGraphics card memory (in the System settings window) = (Total graphics card memory) -\\n(Render cache size) - (100)\\nLevel Of Details (LOD)\\nGPU Memory limitations in the Geobody interpretation process is handled by LOD (Level Of Detail).\\nThe geobody element (probe or geobody) is rendered brick-by-brick, starting in a coarse LOD and then\\niteratively refined in finer LODs until all the GPU memory is used. If enough memory is available, the\\nwhole probe or geobody will eventually end up in the finest representation (LOD 0, no decimation). If\\nthe memory limit is reached, one or more sub-bricks of the geobody or probe will be in a coarser LOD\\nand decimation will occur. This may lead to a brick effect where areas of the geobody or probe have\\ndifferent LODs. To find the LOD for a probe in a certain area, click the probe while in Pick mode . LOD\\n0 means full resolution. LOD 1 means that the data is decimated by a factor of 2 (see figure below) in\\neach dimension and so on. If you do not reach full resolution, try increasing the GPU memory (if\\npossible), reduce the size of the probe or turn off other visible geobody interpretation objects.'},\n",
       " {'header': 'Hue ',\n",
       "  'content': 'Hue is the system used for geobody interpretation visualization and segmentation. As opposed to\\nthe Open Inventor VolumeViz that handles volume rendering of seismic cubes, Hue is rendering\\ngeobodies and probes. Since this is a separate rendering system, there are some limitations in the\\n3D world. For instance, opacity is not shared between Hue and Open Inventor objects. This\\nmeans for instance that all though your fault is only partly transparent, you will see geobodies\\nand probes 100% opaque on the other side.\\nIntroduction to Geobody Interpretation\\nPetrel Geobody interpretation (PGI) comes as a package installed on top of Petrel. It uses a\\nstate of the art technology to identify, isolate, extract and make discreet an object seen in seismic\\ndata. The extracted object is called a geobody. The geobody can then be used as input to\\nproperty modeling, surface generation, or further seismic visualization tasks.\\nWhat you see is what you pick\\nPGI utilizes GPU (Graphics Processing Unit) features. The GPU is the processing unit of a graphics\\ncard or video card, and is similar in function to the CPU (Central Processing Unit) of your\\ncomputer. The difference between a CPU and a GPU is vast with a GPU only working with the\\ncalculations required for graphics and video, and the CPU running calculations for many more\\nsystem processes than graphics alone. The GPU is the place where the majority of the calculations\\nfor graphics in video games and other applications are carried out.\\nPGI is shipped in an installer package that installs on top of Petrel. Existing customers with the\\nSeismic Volume rendering and extraction license will be able to use PGI.\\nPGI uses a volume blending approach to isolate features from seismic data. By using several\\nvisual techniques, the user is able to isolate a data feature. After the feature is isolated, it can be\\nextracted and made into a discreet object covering the isolated feature. What you see is then\\nwhat you pick. The extracted object is called a geobody.\\nWhat is a geobody\\nA geobody is a 3D object extracted from a seismic volume. A geobody can contain several sub\\nelements (Geoblobs). You can build up your 3D object representation by repeatedly extracting\\nmany sub elements. The geobody can be used as input to a property model, surfaces or as a\\nvoxel mask for further seismic visualization.\\nTypical datasets\\nPGI has been used in several different scenarios. Here are some example datasets:\\nSeismic inversion data\\nSalt domes'},\n",
       " {'header': 'Channels ', 'content': 'Core data\\nAnt tracked data'},\n",
       " {'header': 'Tools ',\n",
       "  'content': 'The Geobody interpretation process can be found under the Geophysics folder.'},\n",
       " {'header': 'Shortcuts ',\n",
       "  'content': 'Shortcut keys have been introduced for the main operations and modes in the Geobody\\ninterpretation process:\\nManipulate probe mode - Shortcut key A\\nExtract geobody - Shortcut key E\\nPaint geobody voxels - Shortcut key I\\nErase geobody voxels - Shortcut key X\\nErase geobody voxels with polygon - Shortcut key SHIFT and F\\nDraw triangle fans and lines in geobody - Shortcut Key F\\nCreate clipping polygon - Shortcut key C\\nCreate probes\\nLoad your seismic cube into Petrel. To ensure the best performance, make sure your cube is in\\nZGY format and is loaded into the system cache. Activate the Geobody Interpretation process.\\nOpen a 3D-window.\\nActivate the survey and cube, and select the desired probe. A probe will be inserted into the\\nGeobody interpretation probes folder.\\nThe probe needs a uniform geometry for all surveys in use within a single probe. To extract\\nacross surveys with different geometries, you must insert multiple probes.\\nThere are 3 types of probes:\\nBox probe\\nWell probe\\nHorizon/surface probe\\nAll probes can be inserted by right-clicking on the appropriate object and selecting the probe from\\nthe menu.\\nTo insert multiple cubes into a single box probe, select the two or three cubes, right-click and\\nselect Insert box probe .\\nTo manipulate probes (in the example below a box probe is used), click on the Manipulate\\nprobe icon and move the probe into the area of interest. The Manipulate probe works in\\nconjunction with CTRL , SHIFT and CTRL and SHIFT , and using the blue corner handles. This is\\nfurther described in the \"Handling probes\" section. Manipulate the probe to re-orient and reduce\\nthe size of it (similar to cropping a volume).\\nOpen the Settings for a probe, under the Opacity tab. This tab is where the opacity settings for\\nthe probe are controlled.\\nUse the mouse in the histogram to remove areas of the probes opacity spectrum to isolate\\ngeological objects by holding down the left mouse button, you can drag and filter out unwanted\\nfeatures from the probe. Color edges can also be moved to compress the color bar. It is also\\npossible to use log scale in the histogram for better visualization and filtering.\\nHandling probes\\nInserting a probe will use the active seismic volume to create a probe based on the type selected.\\nAny probe can be manipulated by using the Manipulate probe button. It works in conjunction\\nwith keyboard buttons.\\nBoth box sculpting and well sculpting probes can be used to remove parts of normal probes. They\\ncan be seen as anti probes and are handled the same way as their normal counterpart.\\nBox probe\\nThe box probe is a rectangular volume that can be resized and tilted.\\nNo manipulation active (left) and Manipulate probe active (right)\\nManipulate probe and Ctrl to resize (left) and Manipulate probe and Ctrl+Shift to tilt or reorient\\nthe probe (right)\\nWith the Manipulate probe active, a box probe can be moved in 3D space by clicking on a face of\\nthe box and dragging it but by pressing Ctrl while clicking on a face of the box probe this will\\nresize it in that plane. Pressing Ctrl+Shift will display rotation bar along the sides of the box, and\\nit can be reoriented or tilted in any direction.\\nWhile the box probe is active, the blue corner handles will show up from where user can click and\\ndrag to resize the probe in multi-directional manner.\\nHorizon/surface probe\\nThe horizon probe is an irregular probe that follows one or two horizon interpretations/surfaces. It\\nis also referred to as \"sculpting\" in the industry.\\nFig. 1 Using the Manipulate probe button (left image) and Manipulate probe button and CTRL\\nto resize in the vertical (right).\\nFig. 2 Using the Manipulate probe button and SHIFT to move in the vertical plane.\\nWith the Manipulate probe active, a horizon/surface probe can be moved in 3D space by\\nclicking on the outline plane of the probe. Pressing CTRL will display the resized bars along the\\noutline of the plane. Pressing CTRL and clicking on the upper or lower face of the probe will\\nadjust the thickness. Pressing SHIFT will enable shifting of the entire probe in the vertical\\ndirection.\\nIn addition to the manual controls, it is also possible to specify the thickness and vertical offset of\\nthe horizon probe from the probe settings (Horizon tab). You can specify the thickness or offset\\nand also a step. You can then play through the sequence using either the player buttons or the\\nmouse wheel when the curser is in the text field.\\nIn addition to the thickness setting, you can specify the probe datum. The options are:\\nSymmetry : Equal thickness above and below the horizon\\nLock Top : Thickness will be below the input horizon\\nLock Bottom : Thickness will be above the input horizon\\nWell probe\\nThe well probe is a cylindrical volume following a well path that can be resized and prolonged.\\nFig. 1 Manipulate probe button active (left) and Manipulate probe and CTRL shows the\\nresized ribbons (right).\\nFig. 2 Manipulate probe and CTRL between ribbons to resize diameter.\\nWith the Manipulate probe button active, a well probe can be moved along the well path in 3D\\nspace by clicking on the face of the cylinder. Pressing CTRL reveals the resized ribbons that are\\nused to change the size along the well path. Pressing CTRL and clicking in between the ribbons,\\nwill change the probe diameter.\\nLinking probes\\nLinking probes is controlled by activating the master probe and then right-click on the slave probe\\nand select Link to active probe. Once a probe is linked, the slave probe will have a chain icon.\\nOnce the probes are linked, the opacity is controlled from the master probe. All changes applied\\nto the master probe will be applied to all of the slave probes. The slave probe opacity setting will\\ndisabled.\\nTo unlink the probes, right-click on the slave probe and select Unlink probe.\\nHistogram and statistics\\nThe sampling has been improved for performance and accuracy by default 500,000 points will be\\nsampled from the probe to produce the histogram. It is also possible to control the sample\\nthreshold in the Opacity tab of the probe to change the detail of the histogram.\\nTo ensure that the histogram is always up to date with the data in the probe each time when the\\nprobe is moved, the histogram will be rescanned. To disable this option, it is possible use the\\nLock button (bottom right). This will keep the existing histogram and when the probe is moved,\\nthe rescan will not be recalculated.\\nWhen a clipping polygon or sculpting probe overlaps the probe, a shadow histogram will be\\nproduced. The shadow histogram will be in grey and display the histogram of the probe with no\\nclipping polygons or sculpting probes, while the colored histogram will show the sculpted\\nhistogram.\\nHistogram readouts\\nIf you select an amplitude on the probe using the Pick mode , the amplitude selected will be\\nhighlighted in the histogram and crossplot.\\nThis also can be used in the RGB mode to determine what amplitudes are used to produce the\\ncolor.\\nWorking with discrete seismic volumes\\nThe default rendering style for probes will interpolate between the samples, producing a smooth\\nrepresentation. However, when working with discrete seismic volumes it is advisable to turn the\\ninterpolation off. Clear the Seismic value interpolation check box to turn it off.\\nThe results of seismic interpolation on a discrete cube:\\nLeft: Interpolation is on; Right: Interpolation is off'},\n",
       " {'header': 'Crossplot ',\n",
       "  'content': 'The ability to crossplot 2 seismic volumes using the probe (box, horizon, or well) to define the\\narea of interest is now available in Petrel 2010.1.\\nThere are two key modes for crossplot selections;\\nOpacity selection\\nManual classification. This new feature brings seismic closer to the geological world.\\nHistogram to Cross-plot\\nWhen creating a probe (Box, Horizon or Well) that is rendering two volumes, you will notice that\\nan option will appear on the Opacity tab. You will have the choice between Histogram and\\nCrossplot for the Multi-volume control . This will switch the data sampling function from two\\nhistograms into a 2D Crossplot view, and vice versa.'},\n",
       " {'header': 'Fig. 1 ',\n",
       "  'content': 'The 2 seismic cubes are then sampled in order to obtain a distribution in the 2D attribute space.\\nThe X- and Y dimensions and limits are taken from the attribute cube\\'s settings. Fig. 1 above the\\nPCA (Principal Component Analysis) of the Dip of the Seismic is crossplotted against a smoothed\\nversion of the Variance*Chaos cube. The dip ranges from -90 to 90, where the Variance*Chaos\\ncubes is defined within [0;1] interval. Notice that when you move to the crossplot display, only\\none color template is rendered (the one from the 1st cube by default; this can be changed on the\\nVolumes tab settings) on the Opacity tab as well as in the 3D scene.\\nYou can then start to identify distribution patterns which can be characteristics of different rock\\nproperties or facies repartition. To enhance the separation power, you can also to switch between\\na \"points\" view or a \"density\" plot.\\nFor the points display, the distribution density is suggested by a grey to black scale, whereas for\\nthe density plot you can fine tune the color scale by editing the Crossplot density template used\\nfor the Crossplot display.\\nOpacity selection\\nWhen the Crossplot mode is selected, the notion of the opacity filtering, goes back to basic\\nprinciples. You will design some rectangle or polygons that define the 2D attribute space to be\\nrendered in the 3D canvas. The defined filter (polygon or rectangle) is binary, meaning that what\\nis inside the polygon is 100% opaque while what is outside is 100% transparent. Any intermediate\\nopacity values are not possible. Note that histogram selections are not compatible with crossplot\\nfilters; when you switch from Histogram to Crossplot , the filters will not be complementary\\nand, thus, not added to each other. Nevertheless, they will be kept in memory for a later back-\\nswitch.\\nThe selection can be adjusted or moved around, either by selecting one corner of the polygon,\\nand dragging the latter one to its desired position, or, for the entire polygon by pressing SHIFT\\nand left-clicking (polygon\\'s corners become yellow) within the polygon of interest, and dragging\\nthe entire surface to a new location, using the mouse or the keyboard arrows.\\nAny action in the Opacity selection can be undone and redone, as well as you can reset to the\\ninitial default settings.\\nClasses selection\\nIn addition to opacity selections, you can make your own manual classification, using the same\\ntools as for the opacity filtering process.\\nOnce you have switched from Opacity to Color in the Selection section, 4 default colors\\nbecomes available (red, yellow, green, and blue). You can tune this color selection or use your\\nown color code.\\nYou can now identify seismo-facies classes in the attribute space and assign classes to a given\\narea of interest with the appropriate color. Complex, class-distribution patterns can thus be\\ndesigned, with an on-the-fly update of the probe in the 3D scene, making Quality Control an\\ninherent part of the workflow.\\nCombining the automatic sampling update while moving the probe around with this classification\\ntool, feature detection will be much more effective (for example, AVO classes detection, Fluids,\\netc.). Once you have spotted a feature somewhere in the survey within the attribute domain,\\nother features can be tracked and detected in other unexplored places of the volume by displacing\\nthe probe, keeping the class defined in the Crossplot view.\\nSelection manager\\nFor the sake of a good organization and to better manage the huge amounts of classifications that\\ncan be generated, the capability of storing the selections has been developed.\\nOnce a classification has been made or a complex opacity filter has been designed, the latter ones\\ncan be stored, and new ones can then be generated, and stored as well. After several iterations, it\\nis possible to open the Crossplot Selection s manager and compare the different classifications\\ntogether, and, thus, evaluate the different possibilities in order to pick the best one. For ease of\\nuse, the names can be edited, and some information about the nature of the filters (Opacity or\\nColor) are stored as well.\\nGeobody extraction\\nA geobody is extracted based on its opacity threshold value. By default, the threshold value is set\\nto 20%. If a cell has an opacity threshold of less than 20%, it will not be included in the geobody.\\nThis value can be edited by double-clicking on the Geobody interpretation process and\\nchanging the Voxel connectivity opacity threshold value. This threshold is also visible as a dashed\\ngreen line in the opacity settings histogram.\\nHow to extract a Geobody\\nA Geobody is extracted based on its opacity threshold value. By default, the threshold value is set\\nto 20%. If a cell has an opacity threshold of less than 20%, it will not be included in the geobody.\\nThis value can be edited by double-clicking on the Geobody Interpretation process and\\nchanging the Voxel connectivity opacity threshold value. This threshold is also visible as a\\ndashed green line in the opacity settings histogram.'},\n",
       " {'header': 'Fig. 1 ',\n",
       "  'content': 'Geobody interpretation process dialog\\nIn fig. 1, you can see the process settings page of PGI. You can set up various PGI specific\\nsettings as well as monitor how you are using your memory in real time.\\n1. Click the Extract Geobody icon\\n2. Activate the filtered probe and select the body with the Extract Geobody tool . Petrel will\\nextract the body and store it in the Geobody folder .\\n3.\\n3. Repeat the previous step until the body is fully extracted. Do not worry if you extract more\\nthan you anticipated.\\nAn empty geobody can be inserted in the Geobody folder by right-clicking on it and selecting\\nInsert geobody .\\nRed boxes appear in those areas of your probe where it finds connecting cells above the\\nopacity threshold value.\\nFig. 2 Example where the Extract geobody tool extracted more than desired. In this case, the\\npart of the geobody within the red circle is not wanted\\nThere are several options to trim geobodies. For detailed removal, use the Erase geobody\\nvoxels tool and for bulk removal, use the Erase geobody voxels with polygon tool . On\\na larger scale, it is possible to remove the whole geobody. To select a geoblob, use the Select\\n/pick mode tool and then the Delete selected geoblobs tool . Geoblobs can also be\\nselected by double-clicking on the geobody in the Input pane, selecting the Statistics tab and\\nclicking on the rows of the geoblob table (multi-select by holding down CTRL while clicking).\\nFig. 2 Erase geobody voxel tool. N ote that the selected voxel on the left image is removed in\\nthe image on the right. This tool is typically used to clean edges of the geobody before sampling\\nthem into a grid.\\nFig. 3 Erase geobody voxels with polygon tool. Note the polygon on the left image. To use\\nthis tool, just draw a polygon around the area, then double-click to close the polygon and clip the\\ngeobody.\\nIn some cases, once you have clipped the edges of your geobody, you will notice that the\\ngeobody itself is not completely full. If you sample a body like this into a grid, you will get holes\\n(undefined cells) in your 3D grid. To fix this problem, you can use the tool called Draw triangle\\nfans and lines in the geobody . To use this tool, draw a polygon around the edge of the\\ngeobody. Be careful using this tool as it can distort the shape of the body. It can, for example,\\nturn a cylindrical body into a box.\\nGeobody extraction process, box probe made partly transparent\\nExtracted geobody displayed together with box probe\\nExtracted geobody\\nExtracted geobodies can be visualized on any intersection using the Toggle visualization on\\nplane button. Activate the intersection of interest (inline, crossline, time -slice, general\\nintersection, etc.), click on the Toggle visualization on plane button and select the appropriate\\ngeobody.\\nFurther information on visualization of objects on intersections are found in the General\\nintersection topic of this manual.\\nGlobal extraction\\nWhile the manual extraction is done on a blob basis, where you select the continuous body to be\\nextracted, the extraction of all independently connected blobs within the probe can be done\\nautomatically. Defining the Minimum number of voxels for a given geoblob, as well as the\\nmaximum number of Geoblobs will narrow the extraction to some specific objects in the scenes\\nbased on their size.\\nThe maximum number of geoblobs that can be extracted at once is limited to 255 blobs.'},\n",
       " {'header': 'Fig. 1 ',\n",
       "  'content': 'You also have the choice between 2 different algorithms with respect to the voxel tracking.'},\n",
       " {'header': 'Fig. 2 ',\n",
       "  'content': 'The default algorithm (to the right in fig. 2) will look at all the faces, edges, or corners of the\\nvoxel cube an check if the connectivity threshold condition is verified prior to including the new\\nvoxels to the geoblob. The other algorithm discards the edges and the corners. The latter\\nalgorithm is used when doing manual tracking; thus, in order to get similar results you need to\\nswitch from the default method to this one.\\nAs a result, the icon in the Input pane is different for the automatically extracted geobodies than\\nfor the manually generated.\\nFig. 3 The patch merging process\\nThe patch merging process will be enabled for automatically extracted blobs and are not available\\nfor manually tracked blobs. Use the Merge selected option to associate different patches under\\na single blob (even though there is no connecting voxel). This will then consolidate the property\\nassignment process.\\nFig. 4 Comparison between manually tracked geobody and Automatically extracted one\\nGeoblob management\\nA geoblob in itself does rarely represent a full geological feature. The latter one is most of the\\ntime obtained after multiple voxel extractions, and thus is constituted of several blobs of different\\ncolors. In order to facilitate the management of this list of objects (which can reach a\\nconsiderable size), some geological information has been added in order to enhance the visual\\nunderstanding, as well as the extraction to conversion workflow.\\nThe figure above illustrates how you can assign facies to a given blob once the facies template\\nhas been chosen from the templates list. It is also possible to use \"user-made\" templates if you\\nwant to name the blobs according to specific conventions. Updating the Petrel default templates\\nthat are used by the geobodies will update on-the-fly the drop-down menu and will automatically\\npick up the new facies.\\nThe geoblob management will continue during the conversion step to improve the integration of\\nthe geobody module into the modeling workflow.\\nHaving a considerable list of objects in a single geobody (especially when using the automatic blob\\nextraction process), will make QC of each blob difficult, when displaying all at once. You can then\\ndecide to visualize each blob separately, or a small group of blobs within the geobody. Dragging\\nthe mouse over several geoblobs in the Geoblobs tab, will also select them.'},\n",
       " {'header': 'Geobody Conversion ',\n",
       "  'content': 'The geobody object (constituted of so-called Geoblobs) is characterized by its geological feature\\n(for example, a channel, reef, cave, slumps, collapse features, salt dome, etc.) and has to pass its\\nadded value into the next step, which can be either interpretation or modeling.\\nBasically, there are three options for converting the geobody:\\nConvert to Seismic Horizons : Is very useful when you have picked a reef or a salt dome to be\\nincluded into the interpretation and/or the velocity model.\\nConvert to Points: Intermediate step for Neural Network training (see the Workflows section),\\nor property population.\\nConvert to Model Property : In order to include the latter one into the geological model and,\\nthus, having a true deterministic approach with the correct petrophysical properties distribution.\\nConvert Geobody to Seismic Horizon\\nThe transformation of a geobody into a seismic horizon can help the interpreter understand\\ncomplicated structures by squeezing the 3D volume and shape information into a 2,5D map. The\\nprocess can plot the extracted body thickness onto surfaces that represent the top, center or\\nbottom of the latter volume. This thickness as well as the concept of top, center, and bottom are\\ndefined relatively to the Z axis.\\nYou have control over the location where the output data is going to be stored (a new\\nInterpretation folder can be created for this purpose).\\nConvert Geobody to Points\\nThis step is very much complementary to \"Geoblob management\" where you can transfer all the\\nfacies attributes defined for each geoblob to a point set for further processing (for example,\\nNeural Network classification: see the Workflows section, property upscaling )\\nIn this case, there are options that are similar to the Geobody-to-horizon conversion process. By\\ndefault, the conversion will insert an attribute to a single point-set that can either be the Geoblob\\nID or the property; the latter one is selected by default. Of course, it will be possible to convert\\neach geoblob into a separate point-set with no attributes underneath.\\nConvert Geobody to property\\nThe two first options are strait forward; right-click on the Geobody and the result is almost\\ninstantaneous.\\nThe conversion and integration into a geological model is more time consuming. Moreover, the time\\nconsumption is not the only issue; in order to model the geological feature correctly, you have to\\nconsider some basic geometrical concepts.\\nThe voxel size is characterized by the smallest resolution volume within the seismic cube, which is:\\nIf the model\\'s cell size is smaller than the voxel in one direction or the other, you will start seeing\\ngaps regularly spaced along the latter orientation. The figure below illustrates a case where the I- and\\nJ increments in the model are one 10th smaller than in the inline and crossline directions. You can see\\nthat every 10 cell-line in the model is not populated with a property.\\nThis effect is geometrically explained by the scheme in next figure\\nThe modeling where you can convert from Voxel to Cell, offers two options:\\nMap from voxel to cell (which is the default option described above. It has the advantage of\\nbeing faster than the other option).\\nMap from cell to voxel.\\nThe latter option proceeds in almost the same way as the first one, except that it takes the center of\\nthe cell into account instead of the center of the voxel. Thus, it is checking that a cell-center is within\\na voxel or not. If the cell center is within a voxel, Petrel assignings the value given by the user into\\nthe cell (see the Assignment option in the figure below). If not, the cell stays empty.\\nNote that this option deals badly with the outer shape of the Geobody. That is especially the case if\\nthe latter one is very thin or if the 3D grid has an unconventional structure.\\nTo minimize this side effect, you can select the Check cell corners check box, which verifies, in\\naddition to the cell center, if the corners of the cells are located within a voxel. Nevertheless, if the\\nGeobody is thinner than half of the k increment of the cell, this option has limited value.\\nKeep in mind that if you use the Check cell corners option along with the Map from cell to voxel\\noption, the time consumtion of the conversion will increase drastically (multiplied by 9). Therefore,\\nyou should consider the time versus quality ratio.\\nConverting Probe to ZGY cube\\nIt is possible now to convert the probe to a ZGY cube. This process creates a cube which reflects\\nthe opacity level of the probe. The output cube has a value range between 0 (no opacity) and 1\\n(full opacity). This cube can be useful as input to the Seismic calculator or as a soft property\\ninput for the Property modeling process.\\nOpacity conversion\\nAs neither the probe nor the geobody are end products within the workflow; conversions from the\\nlatter ones into traditional Petrel objects is required. With respect to the Seismic probe (box, well,\\nor horizon), it is possible to convert it into a seismic ZGY cube (Petrel format). By default, the\\nnewly created cube will be stored in the survey of the cube the probe was attached to, but you\\ncan chose to save it in a new survey (see destination survey in the figure below). The geometry of\\nthe new ZGY cube will by default be the smallest cube, parallel to the survey, that can contain the\\nprobe regardless of the probe type. This is characterized by the Seismic extent where you can\\nchose between Wrap around probe (the default option), or Same as source seismic (the\\ngenerated cube will have the geometry of the seismic survey).\\nThe amplitude of the cube that is created from this process will be scaled based on the opacity\\nfunction defined in the Opacity tab of the converted probe. The resulting cube will have an output\\namplitude range of [0;1], where 1 represents 100% opaque and 0 represents 100% transparent.\\nThe color distribution of the latter cube is characterized by the variance template.\\nIn order to generate a normalized seismic amplitude cube, you can use the Seismic calculator\\nand combine both the post-stack seismic cube and the opacity cube by multiplying them together.\\nNote that the two cubes must have the same geometry prior to any calculator operation.\\nFig. 2 A simple example of a stair-step function (jumping from 0 to 40%) in the opacity domain,\\nwhich corresponds to the two spikes you have converted: one a 0 and one at 0.4.\\nOpacity ZGY cubes can be created from probes rendering 1, 2, (in Histogram of Crossplot\\nmode) or 3 seismic cubes, in any blending modes.\\nClass cube generation\\nThe creation of class cubes can only be made in accordance with a color selection in the\\nCrossplot mode, while rendering two seismic cubes (Cross-plot class extraction is activated).\\nSelecting the Cross-plot class extraction check box will generate a cube that contains as many\\nclasses as the number of different colors you have defined in the Crossplot mode. The color\\ncode will be respected and, thus, the conversion process will generate a new template containing\\nthe user-defined colors taken from the color selection.\\nThe latter one will be stored under Other templates in the Template pane and will have the\\nname \"Classification\" (can be edited). The newly created cube will be stored in 8-bit format, which\\nmeans that you can create up to 128 classes to be converted into the ZGY format from the\\nCrossplot tab. Once the cube is generated, it is advisable to switch the interpolation method\\n(Settings window -> Style tab of the ZGY cube) to None in order to avoid visual interpolation\\nartifacts.'},\n",
       " {'header': 'Workflows ',\n",
       "  'content': 'This section features various workflows you can utilize the PGI in. It is a work in progress and is a\\nmix of complete workflows and short tips. Some parts of the workflows section will be duplicates\\nof other parts of the document, but they are included for the purposes of creating a complete\\nworkflow.\\nHow to optimize well planning using the\\ncombination of Geobodies and Ants\\nThis example utilizes the full Petrel workflow, from Geobodies to Well Design, in order to optimize\\nwell planning and reduce the risks while drilling.\\nThe above image shows a proposed well with targets and predicted cone of error. In\\nthe background, AntTracking seismic results can be seen following the well plan.\\nHow to create a Well Probe\\n1. Create a proposed well path using the Well Design module\\n2. Activate the Geobody Interpretation module\\n3. Display well in a 3D window\\n4. Activate the AntTracking volume (bold)\\n5. Activate the new proposed well (bold)\\n6. Click Insert well probe\\nA new well probe appears under the Geobody interpretation probes folder:\\n\"Geobody interpretation probes\" folder where all the well probes are stored.\\nWell probe with the time slice of the Ant tracking result.\\nHow to edit the diameter and length of the Well Probe\\n1. Actvate the select/pick mode icon (white arrow) and click on the grey conic handles at the\\nend of the probe to increase the length of the probe until it reaches the full well design.\\n2. Activate the select/pick mode icon (white arrow) and click on the grey frame situated in\\nbetween the grey conic handles. The grey frame turns into a yellow 3D cube.\\n2.\\nGrey conic handles should extend the length of the probe along the well path and\\nyellow cube, which allows the reducing or increasing of the diameter of the probe.\\nTwo different displays of the Well Probe after increasing length and changing the\\ndiameter.\\nHow to filter data to extract geobodies\\nThe first step is to use the volume rendering capacity and isolate the features you want to extract\\ngeobodies from.\\nHow to volume render a Well Probe\\n1. Go under settings of the Well Probe\\n2. Select Opacity and set up a threshold which will keep only the maximum of the Ants\\nOpacity Settings where the threshold is defined to isolate the maximum of the Ants.\\nVolume probe filtered using Opacity Settings and showing faults isolated\\nHow to extract Geobodies from the filtered Well Probe\\n1. Select Geobody Extraction module\\n2. Click on the icon \"Extract Geobody\"\\n3. Click on the Well Probe and the connected geobodies are extracted automatically\\n4. The geobodies are stored under a specific folder called \"Geobody Folder\". Each geobody\\ncreated belongs to one specific object, and by default is called \"Geobody 1\"\\n4.\\nGeobodies extracted from the Well Probe.\\nIf the data is not connected, several geobodies are generated (as shown in the figure above)\\nwhere four different geobodies are created.\\nThe well probe option\\nCreating a well probe along a proposed well path can be useful for several purposes. The well\\nprobe below is using as an Ant Tracking volume to see if there are any fault or fracture areas in\\nthe proposed well path.\\n1. Create a digitized proposed well path, display well in a 3D-window.\\n2. Highlight (activate) the AntTracking volume, and click on the new proposed well.\\n3. Click Insert well probe . A seismic probe will be attached to the well path.\\n4. Activate the Manipulate probe icon and position the cursor over the well probe. Press\\nCtrl on the keyboard, left mouse click and drag out the disc to make the well probe thicker\\nor thinner.\\nA well probe\\nDouble click on the well probe file and toggle on the Melding tab. By holding down MB1, you can\\ndrag and filter out unwanted sampling values from the probe. Color edges can also be moved to\\ncompress the color bar.\\nRendering of the Ant-tracking probe\\nToggle on \"Extract Geobody\" and move the cursor into the 3D-window. By clicking on the\\nexpected fault pan, a geobody from each fault \"plane\" is added to the existing Geobody. In the\\nend, you will have several geobodies which describe faults and fractures in the proposed well\\npath.\\nExtracted well probe after rendering\\nExtracted geobody which enhances fault planes in the well path, from the Ant-tracking\\nprobe\\nThe horizon probe option\\nOne way of cutting a seismic cube is to create a horizon based probe. The probe can be between\\nhorizons or can be from a single horizon from the top or bottom of the seismic cube.\\nHighlight (activate) the volume of interest (e.g. the Ant-tracking cube), then click on the horizon\\nto use. Click on \"Insert Horizon probe\". A seismic probe will be created based on the selected\\nhorizon. Double click on horizon probe file and click on the Horizons tab. Now you can edit the\\nhorizons input (i.e. go from a single to two horizons), and then click OK.\\nSetting for Horizon probe file, Horizons tab is active. A single horizon is selected, with\\noption Clip above, render below.\\nOutput of a horizon probe, single horizon and option clip above and render below. The\\nprobe can be moved up or down which gives you the option to cut and slice seismic at\\na horizon.\\nGeobody Interpretation and Neural Network\\nThis is an iterative method for Salt Delineation.'},\n",
       " {'header': '1. Attribute Generation ',\n",
       "  'content': 'Select a set of attributes that you think are relevant for salt delineation (for example: Chaos,\\nEnvelop, RMS-amplitude, Variance, PCA-Azimuth, Dominant frequency...). Visually QC that they\\ndo separate the salt from the continuous seismic reflectors (sediments).\\nFig. 1 In this case, 3D curvature (Vertical radius = 14; Inline/xline radius = 1; Method = Strike\\ncurvature), Local structural dip (principle component), and an edge defining cube (here Chaos x\\nVariance) were used in order to train the network that were used.\\n2. Geobody extraction phase\\nThe edge detecting cube was used as a first pass to extract a geobody that will characterize the\\nspecific class you want to identify. Depending on the number of classes you want to isolate,\\nseveral blobs can be extracted and then converted to points. Note that if you have several\\nisolated and independent bodies, you will only need to pick one as the classification process\\nshould (if the non-linear relationship derived from the neural network is robust enough) be able to\\nidentify the similarities and, thus, assign to the same class the other bodies that correspond to\\nthe same geological feature. This can also be a good QC for evaluating the robustness of the'},\n",
       " {'header': 'Neural Network. ',\n",
       "  'content': 'Assigning the geoblob ID as the attribute for the generated point-set will create a class per\\ngeoblob. Nevertheless, if several blobs are corresponding to the same class, you should assign a\\npredefined property to the blobs corresponding to the same seismic facies and, thus, exporting\\nthe \"facies property\" as the point-set attribute and use the latter one as training point.\\n3. Neural Network training\\nOnce this is done, if you need to define a \"background\" training point set, this can be done by\\nsome manual picking of points. This can be done by either picking polygons or faults that are\\ngoing to be converted to points later on.\\nYou need to assign a class identification to this selection. Note that the class needs to be\\nindependent to the already existing Geobody picked classes.\\nOnce all the classes you want to identify and isolate are defined, you need to merge all the point-\\nsets together. This can be done in the Operation tab of one of the point sets (Common\\noperations -> Append point with attributes ). This process must be run so that all the\\nclasses are gathered into one single file (some time optimization can be done by automating this\\nprocess using the Workflow manager in case the volume of point-sets is important).\\nThe result will be a merged point-set, that can be QC\\'ed visually in the 3D window as well as in a\\nspreadsheet.'},\n",
       " {'header': '4. Classification ',\n",
       "  'content': 'Once the attributes used for the training are defined and computed, as well as the training point-\\nset is ready, it is possible to start the classification process.\\nDo not forget to select the Supervised button as the classification method to use, and select the\\nright \"attribute template\" to use for the training process. Max number of iterations , Error\\nlimit , Cross validation , and Probability threshold are input variable that can be used in\\norder to refine the output result. It is advised to tune these settings to create the best possible\\nrelationship. A trial-and-error process is very appropriate in this case.\\n5. Geobody extraction phase 2\\nThe cube resulting from previous step can then be fed into the Geobody interpretation process\\nfor a new extraction run. At this point, if the Neural Network classification was successful, you can\\nexpect an extraction of all of the interesting features on the same probe using a single cube as a\\nsupport for the segmentation process.\\nThe workflow that was described here dealt with the specific Salt body extraction case, but can\\nalso be applied to any seismic feature that can be isolated by a non-linear combination of some\\nwell chosen structural and/or stratigraphic attributes; for example, extracting some cavities (for\\nexample, Karsts) or some carbonate depositional features (for example, reef patches). Moreover,\\nthe extracted geobody is not an end result, but needs to be part of a more advanced workflow\\nwhere it can be used for several purposes (for example, velocity modeling, facies modeling,\\nvolume estimation).\\nGeobody Interpretation and Genetic Inversion\\nThis workflow will show how a combination of the Genetic Inversion and Geobody\\nInterpretation modules can help to link geophysics with modeling.\\nThe combination of this two modules of Petrel are providing results that are going beyond simple\\ngeophysical use. In addition, interactivity and quality control done on-the-fly in this fast process\\nwill add a remarkable value to the modeling workflow.\\n1. Compute Acoustic Impedance cube\\nWhen we use the Genetic inversion in order to populate a model with a given property, we\\nautomatically make the assumption that the latter property is the only parameter responsible for\\nthe variation of the seismic signal in amplitude and shape, and thus, that all of the other reservoir\\nparameters do not have any influence, or do not \"parasitize\" the seismic signal. This\\napproximation is quite important and even doubtable when you are looking at a full reservoir\\nscale where facies changes, compaction, cementation processes occurs and do have a dramatic\\nimpact on the seismic signal. Thus, in order to reduce this uncertainty you can subdivide the\\nreservoir in layers where the facies is constant, the fluid saturation is constant and uniform, and\\nso on. Another reason why we compute the inversion within specific zones is linked to the fact\\nthat the frequency content of the Acoustic Impedance logs has a larger band-width compared to\\nthe seismic amplitude cube, especially in the lower part of the spectrum. Indeed, the lower\\nfrequency limit for marine seismic is around 5-6Hz, whereas the logs contains much lower\\nfrequencies (for example, trends). This means that this part of the spectrum cannot be modeled\\nwithin the seismic.\\nA way to overcome this issue is to sub-divide the inversion into layers where the lower frequency\\ncontent is the same as the seismic. For example, in a time window of 200ms, you cannot find\\nfrequencies lower than 5Hz.\\n2. Generate a Seismo-Facies cube\\nBased on the inverted Acoustic Impedance cube, and some relevant attributes (in this case, the\\ndominant frequency), you can isolate different classes, following some regional facies charts or\\nsimply by visual interpretation, using the Crossplotting tool in the Geobody Interpretation\\nmodule.\\nOnce quality controlled and converted into ZGY format, the next step is to upscale it into a\\npreviously created Structural Grid (based on the Seismic Interpretation). Each interpreted class\\nneeds to get assigned a given facies. The upscaling has to be done for the Acoustic Impedance\\ncube as well.\\nNow, you have set the fundaments for modeling the properties that are correlated with the\\nAcoustic Impedance dependent to the environment of deposition (for example, facies).\\nIn this case, the density was a good candidate as the correlation with AI was 85%. Density of\\ncourse varies with respect to the rock type and, thus, it might be a good idea to model it\\nseparately for each facies\\nFrequently asked questions'},\n",
       " {'header': 'Troubleshooting ',\n",
       "  'content': 'Q: The probe is gone!\\nA: Try to right click on the probe and reset the orientation. If this does not work you might need\\nto restart Petrel. Remember to save the project.\\nQ: I cannot see the geobody interpretation process!\\nA: The first version of Petrel Geobody interpretation needs to be installed with a separate\\ninstaller. Contact SIS to obtain the latest installer.\\nQ: My probe seems distorted, but after a while the display improves. What is going on?\\nA: Petrel applies something called \"Super sampling\" to improve the display quality. When you stop\\nmanipulating the scene the super sampling is applied.\\nQ: My geobody does not display completely!\\nA: This can be due to the fact that you have run out of memory. Turn all geobody objects off and\\nfree memory. Turn the geobody on again. It should display correctly.\\nQ:Petrel freezes when I insert a box probe. Eventually I get a probe with holes in it.\\nA: If you are using a SEG-Y cube this will impact performance. There are many disadvantages\\nwith SEG-Y files. Loading time is one of them, as the file is trace-based and does not support\\ndifferent resolutions (LODs).\\nIt works, but takes a very long time to load the data. Therefore, you will see holes in the middle\\nwhere data are not loaded anymore. As you are accessing the data over the network, loading will\\nbe even slower than on a local disk.\\nRealize the file as a zgy file and try again. Only use SEG-Y files when you have enough memory\\navailable.'},\n",
       " {'header': 'Licensing ',\n",
       "  'content': 'Q: The geobody interpretation process is grayed out!\\nA: This indicates that you do not have a valid license for the functionality. Contact SIS and ask for\\na license for \"Seismic volume rendering and extraction\"'},\n",
       " {'header': 'Seismic Modeling ',\n",
       "  'content': \"This section describes the functionality (beyond interpretation) of relating the seismic data to a\\ngeological grid model.\\nA seismic attribute can be sampled into the 3D grid. It is then treated as any other\\npetrophysical property.\\nSeismic atributes can contain correlated geological information, either the attribute seen\\nalone, in combination with other seismic attributes or correlated to other (geological) data\\ntypes.\\nGeobodies defined in the Petrel Geobody interpretation process is, per definition, linking\\nseismic data directly to the modeling processes.\\nTrain estimation model process can use seismic volumes or surface attribute maps as input.\\nThe Ant tracking workflow is linking seismic edge volumes to fault modeling and\\nsubsequentially to fracture modeling.\\nA seismic volume can be attached to a 3D grid. The seismic can then be viewed inside the\\ngrid.\\nGenetic inversion is linking property log data (porostity) to post-stack seismic amplitude\\ndatasets.\\nNot all of these processes are described here as they are covered in other parts of the manual\\n(please follow the links on this page).\\nCreating a Seismic Property\\nAny seismic attribute can be sampled into a 3D grid. The seismic volume must be in the same\\ndomain as the 3D grid when this is performed.\\nThe process can be initiated either from the Geometrical modeling process or from the\\nPetrophysical modeling process. The results will be the same regardless of which process step\\nwas used to create the property.\\nWhen an attribute of a seismic volume is sampled into the grid, each sample along the trace that\\nis within the bounds of the grid cell will contribute to the resulting value of that grid cell. Each\\nsample has the same weight.\\nAfter choosing the seismic volume, there are four different Quality options:\\nClosest: each property cell will be contributed to only by the closest (or most central)\\nseismic cell. This method is very fast, but unsuitable for geological grids that have a lower\\nresolution than the seismic volume. It is well suited for resampling discrete value (e.g.\\nfacies) volumes.\\nInterpolate: each property will be a weighted interpolation of the four seismic cells closest\\nto the center of the grid cell. This method is very fast, and suitable for slightly lower\\nresolution grids. The interpolation makes this method unsuitable for resampling discrete\\nvalue volumes.\\nIntersecting: all seismic cells intersecting the property cell will contribute to the average\\ncalculations. The contribution is NOT corrected for the intersection volume. Use 'most of' or\\n'median' averaging for discrete value volumes.\\nExact: gives you the same as Intersecting, but volume correction is performed. This\\nmethod will take a long time, but will produce the most accurate results in all cases.\\nUse 'most of' or 'median' averaging for discrete value volumes.\\nThe available averaging methods are the standard methods used in upscaling, for details of each\\nsee Averaging methods.\\nHow to make a seismic property for the whole model\\nFrom the Geometrical modeling process step:\\n1. Double-click on the Geometrical modeling process step to open the process dialog.\\n2. Select Create new property; define the property template and name of the property.\\n3. Select Seismic resampling under Settings.\\n4. Click on a seismic volume and drop it by clicking on the blue arrow in the process dialog.\\n5. Select the required Quality and choose the Averaging Method if appropriate.\\n6. Check filter if preferred. Filters affecting this procedure are the Segment filter and the Zone\\nfilter. Because seismic sampling is time consuming, the filter can be used to verify the\\nresult in a shorter time.\\nIf you want to sample a virtual volume that involves heavy calculations, like a depth\\nconverted or an attribute volume, it is recommended that the volume be realized before sampling.\\nThis will make the sampling process quicker.\\nHow to make a seismic property for individual zones\\nSeismic sampling can be time consuming, so you may want to restrict the sampling to a specific\\nzone.\\n1.\\nFrom the Petrophysical modeling process step:\\n1. Double-click on the Petrophysical modeling process step to open the process dialog.\\n2. In the Modeling settings tab, define the property template and name of the property.\\n3. In the common settings sub-tab, check the filter if desired.\\n4. In the Zones settings, unlock the zone and select Assign values as method. Then use\\nSeismic from the list of assigning options.\\n5. Click on a seismic attribute volume in the Input pane of Petrel and drop it by clicking on the\\nblue arrow in the process dialog.\\n6. Define average method.\\nNote that you are working zone by zone. For details on the process dialog and its options,\\nsee General settings for Petrophysical modeling.\\nNote that properties can be copied from one grid to another (if they are of the same size).\\nFirst, click on the property to be copied, the Copy item icon and then on the property folder of\\nthe other grid before clicking on the Paste item icon.\\nSeismic attributes\\nSeismic attributes, either in the form of attribute volumes or surface attributes, can contain\\ncorrelated geological information that can be used to support modeling. There are several ways to\\ngo from seismic attributes to properties in a geological model. however, there are only to ways to\\nsample seismic data into the model or Geobody interpretation.\\nThe generation of various attributes is further described in the Attribute generation section of this\\nmanual.\"},\n",
       " {'header': 'Domain Conversion ',\n",
       "  'content': 'Domain conversion allows you to take data from one domain, typically seismic data in time, and\\nconvert it to another, typically depth, to correlate it with well data and perform volume\\ncalculations. This action can be performed at any time in the workflow (before or during model\\nbuilding) and exactly when it is done will depend on the particular issues in the project.\\nThe uncertainties connected to interpolating velocities far from well control makes domain\\nconversion a critical step in the modeling process that should be investigated thoroughly.\\nThe workflow of converting data between domains within Petrel is split into two processes:\\nMake velocity model: Defines how the velocity varies in space.\\nDepth conversion: Uses the velocity model to move data between domains.\\nDomain conversion can be used to move data from time to depth or reverse, but also to move\\ndata between two versions of the same domain. Examples would be to stretch and squeeze\\noverlapping seismic cubes so that they match (4D seismic) or to match a depth migrated attribute\\ncube to an updated model with more well control.\\nAll the domain conversion in Petrel follows a layer cake model, for example data is shifted in\\nthe vertical direction only.'},\n",
       " {'header': 'Domain Conversion - Background ',\n",
       "  'content': 'Depth conversion is calculated vertically, starting from datum, progressing downwards and taking\\none zone at a time. Each node \"looks upwards\" to find the time and depth in the layer above and\\nfrom that, using the velocity model for the specified zone, the base of the zone is converted. Any\\nrequired corrections are done at this point before going on to the next zone.\\nWhen using a 3D grid with reverse faults, the shadow zone cannot be depth converted until the\\nzone beneath (which is spatially above near the fault) has been converted.\\nThe figure shows the basic principle of depth conversion.\\nVelocity methods and basic formulas\\nFor an interval the conversion from time to depth can be of the following types:\\nConstant velocity: V=V\\nint\\nThis is the same when the Linvel formula V=V +kZ is used with k=0.\\n0\\nAfter calculation: Z=Z +V (t-t )'},\n",
       " {'header': 'T 0 T ',\n",
       "  'content': \"Linvel: V = V +kZ\\n0\\nAt each point in an interval, the velocity at that point is V +kZ.\\n0\\nAfter calculation:\\nTop time is T , base time is T and top depth is Z .\\n0 0\\nThe following figure illustrates a cross section of a 3D grid:\\nThe figure shows different situations in the 3D grid that are handled by the program. As\\nmentioned previously, all nodes are depth converted.\\nMake velocity model process\\nWithin this process, you define the zones in space where the velocity can be described in a\\ncommon manner, and then describe the velocity model to use in each zone. For example, a set of\\nsurfaces with constant velocities between each pair. You can also do corrections to match well\\ndata or surfaces at this stage and incorporate it into the velocity model.\\nThe velocity model requires 4 sets of input:\\nA zone description. For example, a set of surfaces in two-way time.\\nA definition of the velocity model for each zone. For example, V=V .\\nint\\nInput parameters for the velocity model. For example, a surface of V .\\nint\\nCorrection data, if required. For example, well tops for the specified zones.\\nThe process also gives you options for writing out intermediate data for QC purposes, such as a\\nwell report or well information representing the model's velocities, and settings for extrapolating\\ndata.\\nDefining zones (Make velocity model)\\nVelocity zones can be defined using:\\nConstant values: Quick to define for a first test.\\nSurfaces: Easy to build, even in the early stages of a project, and covers most\\nrequirements. Useful for defining layers above the 3D grid such as the seabed.\\nHorizons (3D grid): Requires a 3D grid, but can describe complex geometries, such as\\nreverse faulting and Y-truncations.\\nA mixture of these can be used in the same model.\\nAvailable velocity models\\nEach zone in the velocity model must have a definition of the velocities within that zone. Velocity\\nmodels available in Petrel include:\\nV=V : At each XY location the velocity is constant through the zone.\\nint\\nV=V +kZ: At each XY location, the velocity changes in the vertical direction by a factor of\\no\\nk. V represents the velocity at datum, and Z the distance (in length units, not time) of the\\no\\npoint from datum. NB V is the velocity at Z=0, not the top of the zone and will therefore be\\no\\nmuch lower than the velocities seen in the layer, possibly even negative in extreme cases.\\nAs time and depth decrease downwards, a negative value of k results in velocities which\\nincrease with depth. Typical values for k are between 0 and -0.2. This velocity model is also\\nreferred to as Linvel .\\nV=V +k(Z-Zo): As above, however, here the values are measured relative to the top of\\no\\nthe zone. For example, V represents the velocity at the top of the zone and (Z-Zo)\\no\\nrepresents the distance between the point and the top of the zone. Again, a negative value\\nof k will result in velocities which increase downwards. Typical values for k are between 0\\nand -0.2. This velocity model is also referred to as Adlinvel .\\nV=V +kT: This is the same as V=V0+K*Z except that it is for conversion to the time\\no\\ndomain.\\nAvg. cubes: These should have an attribute representing the average velocity between the\\npoint in the cube and the datum. Cubes of instantaneous velocity, or time/depth, can be\\nconverted to average velocity in the attribute generation process.\\nAvg. property: If the 3D grid is used to define the zone, and includes a property\\nrepresenting average velocity (down to the center of the grid cell), then this can be used to\\ndepth convert the interval. Such grids can be created by sampling data into the grid or\\nusing Data analysis and Petrophysical modeling to extrapolate from well data. This\\nmethod is useful for complex structures, such as reverse faults.\\nSame as above: This option can be used for thin zones where extrapolating data from\\nwithin the zone alone might cause problems. It is particularly useful when interpolating V\\n0\\nor k from the wells time depth relationship.\\nDefining velocity input\\nThe methods available for defining the velocity input are dependant upon the velocity model that\\nhas been used. For seismic velocity cubes and 3D grid properties, there is only one option\\navailable and the object to be used should be entered using the blue drop in arrow. When using\\nV=V , V=V +kZ or V=V +k(Z-Zo), V or V and k can be entered using a variety of methods:\\nint o o int o\\nConstant: a constant value.\\nSurface: a surface defining the value at each XY location. The surface must cover the\\nwhole area of the velocity zone.\\nWell TDR constant: The value will be estimated using the time depth relationship (TDR)\\nthrough the zone for each well and a single constant value used. Petrel employs a\\nminimum depth error method to estimate this value. See Velocity modeling algorithms\\nfor a detailed description of the algorithm. The well TDR is defined on the Time tab of the\\nwell settings dialog, see Time tab (Well) .\\nWell TDR surface: The value will be estimated using the time depth relationship (TDR)\\nthrough the zone for each well and interpolated to give a surface describing the variation of\\nthe value across the model. Controls for the creation of this surface are found on the\\nAdvanced tab. Petrel employs a minimum depth error method to estimate this value.\\nSee Velocity modeling algorithms for a detailed description of the algorithm.\\nCorrection constant: Data in the correction column will be used to define the value. Petrel\\nwill find the value at the location of each of the correction points so that the resulting\\nconversion will match the correction point. A single value is then estimated that gives the\\nbest fit for all the points. Petrel employs a minimum depth error method to estimate this\\nvalue. See Velocity modeling algorithms for a detailed description of the algorithm.\\nCorrection surface: Data in the correction column will be used to define the value. Petrel\\nwill find the value at the location of each of the correction points so that the resulting\\nconversion will match the correction point. The values will be interpolated to give a surface\\ndescribing the variation of the value across the model. Controls for the creation of this\\nsurface are found on the Advanced tab.\\nCorrection data (Make velocity model)\\nThe corrections made to match the zones of the velocity model will be made as an adjustment to\\nthe velocities within the model itself. This ensures that the information from the correction will be\\ncarried forward and can be used when converting objects with no well correction.\\nThe residual will be calculated at each point in the correction data (i.e. correct value - modeled\\nvalue) and the appropriate change in V made so that the two are the same.\\n0\\nCorrection options are:\"},\n",
       " {'header': 'None ', 'content': 'Well tops'},\n",
       " {'header': 'Constant Surface Horizon ',\n",
       "  'content': 'The most common type of corrections is on well tops. In certain types of domain conversion,\\nparticularly time-time or depth-depth conversions, it can be useful to correct to surfaces or\\nhorizons. Before sampling a depth migrated seismic attribute cube into a 3D grid (in depth), it can\\nbe useful to depth-depth convert the seismic cube so the interpreted horizon exactly matches the\\n3D horizon.\\nWhen making corrections to well tops, ensure the well tops are toggled on for depth\\nconversion in the well top spreadsheet (default).\\nNote that specifying constant velocity model parameters precludes a precise well correction.\\nTo tie wells correctly, one of the velocity models inputs should be a surface.\\nMake velocity model settings\\nThe Make velocity model process is found under Geophysics in the process tree. Open it by\\ndouble-clicking on the process.\\nBy default, the dialog will be set up to overwrite the last edited velocity model and the settings in\\nthe dialog will display those used for that model. Switch to Create new velocity model to make\\na new model and press the reset button to remove the current settings.\\nThe Convert from and to drop down boxes are used to check the input data for the model and to\\nalso define the forward and backward directions.\\nOnce the velocity model is defined it will appear in the velocity modeling folder in the\\nModels pane. The Velocity model will contain velocity surfaces and any output data requested, as\\nwell as depth converted versions of the input data. If using the TDR - Constant , TDR - Surface\\nor Correction - Constant , the K-RMSError functions generated by the minimum depth error\\nprocess will be output to the velocity model. These may be viewed in a function window.\\nVelocity model (Make velocity model settings)\\nYou can define the the zones and velocities to use in the depth conversion in the Make velocity\\nmodel process, under the Settings tab.'},\n",
       " {'header': 'Datum ',\n",
       "  'content': 'By default, SRD (Seismic Reference Datum) is used as Time datum (the datum of the project\\ncoordinate system), in many cases this equals MSL.\\nHowever, you can use other data. When using other data, the datum must be specified in both\\ndomains (i.e. specified in accordance with the To and From selection in the Convert from ... to\\n... ), and can be specified as a constant, surface, or as a horizon.'},\n",
       " {'header': 'Intervals ',\n",
       "  'content': \"Intervals are added to the model by adding rows to the dialog using the standard buttons\\nAppend item in the table\\nInsert item above the selected row in the table\\nInsert item below the selected row in the table\\nDelete selected row(s) in the table\\nEnable/disable multiple drop in the table\\nActivate uncertainty page. When toggled on, an extra column will be inserted where you can\\nspecify the value or surface representing one standard deviation of the interval's velocity field.\\nUsed in connection with the Uncertainty tab, see Uncertainty sub-tab (Make velocity model) .\\nApply the calculation only to the wells conforming to the selected saved searches. This\\nactivates the drop-down menu where any saved searches can be accessed. The saved searches\\nare defined in the folder with the same name found in the Wells folder.\\nShow or hide settings. A set of sub-tabs is shown or hidden in the lower part of the Make\\nvelocity model dialog.\\nEach interval is defined by its lower surface and stretches up to the base of the interval above, or\\nin the case of the first interval, the datum. Each interval requires a definition of its lower surface,\\ncorrection (if any), a velocity model type and the data for the velocity model. To drop objects\\nfrom the Petrel Explorer, highlight the object and click the blue arrow beside the appropriate\\nbox.\\nUse the multiple drop button to add a series of data into the dialog in one go.\\nFor detailed descriptions of the different options for each of the input data see:\\nDefining zones (Make velocity model) - Bottom\\nCorrection data (Make velocity model) - Correction\\nAvailable velocity models - Model Type\\nDefining velocity input - Input Data\\nUsing Append item in the table to add intervals will have the same settings as the\\nprevious row. If you are defining many rows with the same settings, set one row up first and then\\nadd the subsequent rows.\\nMake velocity model settings sub-tabs\\nWhen you create a velocity model for the first time, clicking on the Show or hide settings\\nicon will (un-)display tree sub-tabs that are used to control the generation of the velocity model.\\nEach sub-tab is described in the following sections:\\nCorrection and output subtab (Make velocity model settings)\\nWell TDR estimation sub-tab (Make velocity model settings)\\nUncertainty sub-tab (Make velocity model)\\nCorrection and output subtab (Make velocity\\nmodel settings)\\nThis sub-tab controls how corrections (e.g. using well tops) to the velocity model is handled as\\nwell as what output is created.\\nThe various outputs that can be created during the velocity modeling process is selected by tick\\nmarking the required objects in this tab. These can be reported in terms of the original velocity\\nmodel, the final velocity model (after correction) or as the difference between these two, i.e. the\\ncorrection that has been made. When requesting data for the original model and the correction,\\nthe conversion may be required to run twice and will therefore take longer.\"},\n",
       " {'header': 'Thickness ',\n",
       "  'content': 'The minimum tolerance for depth and time domains is specified here. If the difference between\\ntop and base of the interval is less than the tolerance, the interval will be ignored.'},\n",
       " {'header': 'Surfaces ',\n",
       "  'content': 'The X,Y increment and interpolation method used for gridding of surfaces (e.g V0 surface) as\\noutput is set here.'},\n",
       " {'header': 'Correction ',\n",
       "  'content': 'Defines how any correction (e.g. well tops) should be applied to the velocity model. If Use\\ninfluence radius is selected, output surfaces will be gridded by the influence radius method. If\\nnot the Interpolation method as specified under Surfaces will be used.\\nZone logs can be used to avoid a situation where well paths wrongly cross a horizon in a 3D\\nmodel after domain conversion. A minimum distance between the horizon and the well path after\\nthe correction can be specified (Tolerance ). The user should specify whether to use the zone\\nlogs or not, the well path increment in MD, a radius and a threshold distance. The threshold\\ndistance is the maximum distance between the well and the horizon at which the horizon is still\\ncorrected. This means there will be a correction of the horizon if the distance between the horizon\\nand the well path is less than this maximum distance. A radius around the residual points should\\nalso be specified to define how far to extrapolate the correction.'},\n",
       " {'header': 'Output ',\n",
       "  'content': 'Specifies what output is created when running the make velocity model. The available output is:\\nWell points: Well data points (TDR and Residuals) that are put in the QC data folder of the\\nvelocity model.\\nTime logs: Well logs representing the time derived from the velocity model along the\\nwell paths. These can be displayed in the well correlation window for QC purposes and used\\nto display the well in time (see time tab on well settings). They will appear under global well\\nlogs and under the individual wells found inside the velocity model. The MD increment can\\nbe set for the logs.\\nVelocity logs: Well logs representing the velocity derived from the velocity model\\nalong the well paths. These can be displayed in the well correlation window for QC purposes\\nand used to display the well in time (see time tab on well settings). They will appear under\\nglobal well logs and under the individual wells found inside the velocity model. The MD\\nincrement can be set for the logs.\\nTime-depth: Function of time vs. depth from the velocity model that are put in the QC\\ndata folder of the model. Number of samples can be specified.\\nDepth-velocity: Function of depth vs. velocity from the velocity model that are put in the\\nQC data folder of the model. Number of samples can be specified.\\nAdd residual on well tops: The difference between the Z value at the well top and the\\ncorresponding surface after the depth conversion.\\nReplace dip and azimuth on well tops: With this option selected, the dip and azimuth\\nattributes for the well tops used for correction will be updated with the dip and azimuth of\\nthe velocity model surface.\\nMake well report: The depth of the corresponding surfaces at the XY of the well top. This\\nis written to the output sheet, which can be reset when running the velocity modeling.\\nWell TDR estimation sub-tab (Make velocity\\nmodel settings)\\nThis sub-tab controls what estimation method is used and the outputs that are created when\\nmaking the velocity model based on well time-depth relationships (TDR). The Well TDR\\nestimation sub-tab is only available if the TDR is used to model the velocity in at least one of the\\ndefined intervals. This sub-tab is again split into two tabs that are available if Interval velocity\\nor Linear velocity are the chosen functions. The parameter settings are similar for interval and\\nlinear velocity, except for one entry:'},\n",
       " {'header': 'Methods ',\n",
       "  'content': 'The chosen function can minimize the error on either depth or velocity residuals. Min number\\nof TDR samples defines the minimum number of points that must be present in each well and\\neach zone, or it will be ignored as input.\\nLinear velocity function specific: Minimum % of zone sampled by TDR defines the\\npercentage of the zone that must be filled with input data for it to be included in the estimate.\\nOptimize for estimation of K will calculate V0 and K coefficients that minimizes error in depth\\nor velocity, but still honors the rate of increase of velocity. If unselected the estimate does not\\nnecessarily follow the input data trend as seen in the figure below.\\nIf using the Well TDR as input for extracting velocity functions without correcting for well\\ntops, it is advicable to use the Optimize for estimation of K . This ensures that the velocity\\ntrend is honoured and reflects the input data in a better way.\\nEstimation will be aborted if K exceeds the absolute value of 5.\\nRobust estimation\\nIn least squares fitting, the assumption is made that errors are normal distributed with a constant\\nvariance. If this assumption is not met, the least squares estimate can be unduly affected, see\\nfigure below. The robust fitting methods attempts to generate good fits to a range of error\\ndistributions, by down-weighting large residuals. A least squares fit is performed, then the\\nresiduals are wieghted by a formula before a weighted fit is applied. New residuals are calculated\\nand weighted by the same formula, then repeating this procedure until the convergence criteria is\\nmet. The Max number of iterations defines the maximum number of loops before terminating.\\nThe Tolerance is then the convergence criterion where the estimation will terminate before the\\nMax number of iterations are done.\\nUse well weights: only used when estimating a constant V0 for all wells. Wells with large\\nresiduals are down-weighted. The Minimum number of wells is the minimum\\nUse data weights: Data with large residuals is down-weighted.'},\n",
       " {'header': 'Base ',\n",
       "  'content': 'The pull down menu defines the object to use to find the Base well intersection for each zone:\\nCorrection uses the corresponding object in the Correction column for the intersection\\n(e.g. Well tops)\\nTDR intersection is based on the time-depth relation and find the base wher it intersects\\nwith the well path.\\nCorrection or TDR intersection uses the correction object if existing, if not it uses the\\nTDR intersection.\\nEstimate and adjust to base uses the TDR and selected minimum method (depth or velocity)\\nto estimate the base of the zone in each well. It then tries to use this base in estimating the\\nunknown coefficients (V0 and K).\\nif no correction is used for the velocity functions (typically well tops)it is advicable to use the\\nEstimate and adjust to base\\noption.'},\n",
       " {'header': 'Output ',\n",
       "  'content': 'Specifies what output is created zone by zone when running the make velocity model. The\\navailable output is:\\nThese settings are used when using the well time depth relationship (TDR) to calculate V and k\\n0\\nfor the depth conversion or for the well adjustment of the depth converted horizons.\\nTime logs: 1D time log for each zone under each well.\\nVelocity logs: 1D velocity log for each zone under each well.\\nMd inc: the sampling interval for the time and velocity logs.\\nTime-depth: Function of time vs. depth from the velocity model that are put in the QC\\ndata folder of the model.\\nDept-velocity: Function of depth vs. velocity from the velocity model that are put in the\\nQC data folder of the model.\\nError: Function of error in the the velocity model that are put in the QC data folder of the\\nmodel.\\nNumber of samples: specifies the number of samples that are created for the time-\\ndepth , depth-velocity and error functions.\\nData points: TDR data points that are created and put in the QC data folder under the\\nvelocity model.\\nThe output defined here must not be confused with the output as defined in the Correction\\nand output sub-tab. The correction output is derived from the final model, while the Well TDR\\nestimation output is derived from the estimation for each interval.\\nUncertainty sub-tab (Make velocity model)\\nAs for the Make horizons and Make zones processes, it is possible to define stochastic uncertainties\\ndirectly in the Make velocity model process. The principle for including uncertainty in the velocities is\\nto identify the possible error representing one standard deviation and to multiply that error with a\\nstochastic surface with values around zero, which again will be added to the base case velocity\\nsurface. In other words: Final_Velocity = V0 + U1s * Usgs.\\nVelocity uncertainty handling and access to the Uncertainty tab is achieved by selecting the Activate\\nuncertainty page icon.\\nYou can find information on how to use the Uncertainty tab settings to produce the Usgs surface, as\\nwell as information about the terminology in this section.\\nTo perform uncertainty calculations, you must first specify the value/surface representing one\\nstandard deviation error on the zone interval to investigate. This is done on the Settings tab where a\\nStd Dev. column will appeare when you click the Activate uncertainty page button.\\nThe settings for the error surface generation are specified on the Uncertainty sub-tab. The error\\nsurface is defined by a normal distribution with a mean of zero and a standard deviation of one. You\\ncan adjust the variogram settings and specify the degree of smoothing. The error surface can also be\\nextracted by selecting the Iconize uncertainty error surface check box and will, in that case, be\\nstored on the Input pane.\\nThe process of applying an uncertainty to the velocities can also be done in the Workflow editor or in\\nthe Uncertainty and optimization process.\\nNote that the uncertainty only applies to the V0 surface, hence, the k value is not affected when\\nusing the Linvel algorithm.\\nNote that the uncertainty option is not available when using a velocity cube or a velocity property\\nas input.\\nHow to define the value/surface representing one standard deviation error on\\nthe velocity\\n1. Open the Make velocity model process and specify the intervals of interest.\\n2. Click on the Activate uncertainty page icon\\n3. Specify the value or the surface representing one standard deviation on the intervals of interest.\\n4. The final step is to set the variogram parameters on the Uncertainty tab.\\nThe value representing one standard deviation should be specified in units of the velocities being\\nused.\\nTips for Making velocity models\\nVelocity modeling heavily depends on the environment in question and the available data. This\\nmodule in Petrel has a number of features to make velocity modeling straightforward in many\\ncircumstances. In addition to these set methods, you have full access to the data so you can take\\ncontrol of the velocity model and take advantage of the other tools in Petrel.\\nWhat method you use will depend on the available data, but a few of the options are described\\nbelow.\\nIdentifying and removing poor quality well\\ntops\\nWell tops can be inaccurate due to poor deviation surveys or complex stratigraphy. They can be\\nremoved from the velocity modeling process without being deleted simply by toggling them off for\\ndepth conversion.\\nIn the well tops spreadsheet, there are two options; Used by Depth Conversion and Used by\\nGeo Modeling . Turning them off will remove the well top from the Make Velocity Model\\nprocess and Make Surface , Make Horizons , Make Zones, etc.\\nThere are also a few easy ways to identify poor well tops. First, run the velocity model using the\\nwell tops as correction and in the Correction and output sub-tab, toggle on Well points and\\nAdd residual on well tops for the final velocity model. The velocities used and residuals at the\\nwell tops will be written as well top attributes and can then be browsed to find inconcistencies.\\nHow to identify and remove poor well tops in velocity modeling\\n1. Create the velocity model using well correction and output the residuals and well data onto\\nthe well tops.\\n2. Display the relevant well tops in a 3D window and choose Any as the depth scale.\\n3. Open the well tops spreadsheet.\\n4. Check on the desired attribute to test (residual or velocity) to display the values.\\n5. Right-click on the attribute and choose use as Z position. Unusually high or low values will\\nnow be obvious (change the vertical scale to accentuate differences). The velocity surface\\nfrom the velocity model can also be displayed to see the effect of extreme values.\\n6. Select the Make/edit well tops process and select the extreme well tops in the 3D window,\\nthe same well top will be selected in the well top table.\\n7. Uncheck the Used by Depth Conversion option for the extreme well tops.\\n8. Re run the Make velocity model again.\\n7.\\n8.\\nOutliers in the residuals can also be identified by using a function window. Open the Well\\ntops spreadsheet and a funcion window. Expand the Well tops attributes folder and cross plot\\ndepth (Z) or time (TWT auto) against the Z or Residual derived from the velocity model. Use the\\nSelect and edit/add points icon and click on the a point deviating from the trend. The\\ncorresponding row will be marked in the Well tops spreadsheet.\\nPreparing well velocity data\\nIt is easy to open the make Velocity modeling process and quickly create a velocity model. However,\\nthe estimation of realistic velocity model parameters involves a delicate balance of well and surface\\ndata (see Velocity modeling algorithms for a detailed description of the algorithm). Small errors and\\ninconsistencies in the input data will often lead to dramatic errors in the result. This makes QC of the\\ninput data a very important step in the velocity modeling process.\\nA few examples of well velocity QC are:\\nInterval velocity is the closest equivalent in the raw data of the instantaneous velocity used by\\nPetrel in the velocity modeling process. It is useful to create and view this data before building\\nthe velocity model.\\nPetrel will calculate bad V0 and K parameters if there are anomalous velocities in the input data.\\nThese should be removed before proceeding with the velocity modeling.\\nCross-plotting the velocity data is necessary to confirm that the Linvel law is applicable. You\\nshould remove outliers, and look for zones in which a linear trend can be distinguished. These\\nplots can also show whether constant values can be used, or whether a surface is required.\\nQC of the tie of time structure well tops is important as a poor well tie in time will lead to\\nconflicts in the estimation algorithm. A mismatch can be tolerated, but only within reasonable\\nlimits, and consistently throughout the dataset.\\nHow to derive and view interval velocities from checkshots\\nPetrel will automatically derive Average velocity and Interval velocity logs for checkshot objects.\\nThis provides you with the advantage of plotting those values directly on a Function window and\\nvisually look for problems within the data. The Function window provides a link to the spreadsheet\\nview of the data, so that you can select any point (or points) in the plot and highlight the\\ncorresponding row in the spreadsheet. Next, you can decide whether to edit or delete the data point.\\n1. Right-click on the checkshots object and select Spreadsheet.\\n2. Open a function window, and plot Interval velocity against TWT picked values.\\n3. Identify any outliers, use the Select and edit/add points icon and click on any outlier.\\n4. The corresponding row in the spreadsheet is highlighted and can be edited or deleted.\\n2.\\n3.\\n4.\\n5. Both Average and Interval velocities from well TDR can be displayed in a Well section window,\\nboth have pre-defined templates for display.\\nHow to create an Interval velocity point attribute for the checkshots\\nAllthough the Interval velocity attribute exists for the checkshots object, a point attribute for the\\ninterval velocity is convenient to have for QC of the checkshots data.\\n1. Right-click on the attributes folder of the checkshots and select Insert new attribute .\\n2. Select type Continuous , and select the interval velocity property template in the settings\\ndialogue which appears. Also give itt an appropriate name.\\n3. Open the spreadsheet for the checkshots.\\n4. Copy and paste the values of the existing interval velocity (Interval Velocity) attribute into the\\nblank attribute column.\\n4.\\nHow to find and edit bad velocity values\\n1. Create an interval velocity point attribute on the checkshots as described in How to create an\\nInterval velocity point attribute for the checkshots\\n2. Display the wells in a well section window.\\n3. Display the interval velocity attribute (easiest to see on the newly created point data). Use\\nSSTVD as the depth setting. In the left-hand track within the figure below, spurious values stand\\nout clearly as outliers from the dominant trend.\\n4. Open the spreadsheet for the checkshots and delete rows with bad values. If you do this on a\\ncopy of the checkshots, remember that you have to select the edited file in the Time tab of Wells'},\n",
       " {'header': 'Settings. ',\n",
       "  'content': 'How to look for relationships in the velocity data\\n1. Open a function window and cross-plot the check shots interval velocity and Z attributes.\\n2. Use the Select and edit/add points icon (click on a single point) or Select using\\nfreehand draw icon (draw to include multiple points) to identify outliers in the check shots\\nspreadsheet. Verify or delete the points in question.\\n3.\\n2.\\n3. Look for changes in the velocity trend to identify natural boundaries for different velocity\\nintervals.\\nInterval velocity vs Z for checkshots colored by zone; raw data (left) and edited (right)\\nHow to add a zone attribute to the checkshots\\n1. Right-click on the attributes folder of the checkshots and select insert new attribute\\n2. Select type Discrete , and select Zones as template in the settings dialogue that appears\\n3. Use the Attribute operations tab to sample the Zone log onto each point.\\nIf the Zone log linked to \"Well tops\" log does not exist, right-click on the \"Well tops\" folder\\nand select Insert/update zone log in the appearing menu.\\nHow to QC the well ties in the time domain\\n1. Display the wells in a well section window\\n2. Display the checkshots, well tops and structural surfaces from the Input pane.\\n3. Select TWT from the domains menu and look for inconsistencies\\nConstructing and QC\\'ing the velocity model\\nfrom well velocities\\nThe Vo as Surface and K as Constant option is the recommended option in most cases. There\\nis rarely sufficient data to accurately determine k for each well, and combinations of extrapolated\\nk and V values away from the wells may not be sensible. To help reduce this problem, Petrel\\n0\\ngives you an option to set the minimum number of TDR samples in a zone before excluding wells.\\nVelocity modeling often involves several iterations of reviewing and updating of the models. A\\nhigh quality velocity model is seldom produced in the first run.\\nA few workflow suggestions are described below.\\nBegin without using well correction. With the well correction turned on, any large errors in\\nthe model will be disguised by the correction and problems can become difficult to see.\\nWhen the velocity model result converges on the well tops and you are satisfied, then turn\\non the correction and run the model once more with the optimized parameter setting in the\\nprocess.\\nIn the first iteration, use the Well TDR - Surface option for both k and V . In the Well TDR\\n0\\nestimation sub-tab use Optimize for estimation of K and Estimate and adjust to\\nbase. Look at the resulting surfaces for V and k, these will highlight problems in the data.\\n0\\nFor the final conversion where correction to well tops is done it is recommended to use\\nconstant k and a V as Correction - Surface. There is rarely enough data in each well to\\n0\\ncalculate a robust value of k for each well and since V is derived as a surface that is\\n0\\ncorrected to the well tops a consistent velocity model is generated.\\nProblem wells can be fixed by removing poor data points in the time depth relationship. Use\\nthe depth tolerances to remove data from very thin zones which may be inaccurate (see\\nCorrection and output sub-tab (Make velocity model settings) for details). Also use the\\nRobust estimation methods (using well or data weights) to reduce the effects of outliers\\nin the input data. If the problems persist, extreme data points needs to be removed.\\nThe velocity modeling process provides numerous types of output data which can be used to QC\\nthe results. See Correction and output sub-tab (Make velocity model settings) for details on which\\nare available.\\nA few examples of velocity model QCs:\\nCheck the output V and k well data points. All values should be reasonable, and adjacent\\n0\\nwells should have similar values. Variations across the model should be systematic, not\\nmerely noisy. This may indicate wells with poor input data.\\nCheck the output V and k surfaces against well data points by setting the point\\'s V or k as\\n0 0\\nthe Z attribute (in other words, right-click on the attribute you want and select Use as\\nvisual vertical position), the points should plot on the surface. Are trends extrapolated\\ntoo far, or should the surfaces be truncated? If the wells are close together, then small\\ndiscrepancies in the values may create a trend that is extrapolated to extreme levels;\\nremove one of the wells from the model if the cause of the spike cannot be edited.\\nThe Velocity log output can be plotted in the well section panel and compared with the\\nInterval velocity attribute for the check shots. The 2 logs should overlie when plotted using\\nthe same scale.\\nCheck the well correction report for anomalous large residuals. If the corrections are large\\nin particular wells, review the inputs. The time depth relationship may be incorrect or the\\nseismic picks may be bad (run synthetics), or the well pick may be poor (re-pick or turn off\\ncorrection on the well top spreadsheet).\\n1.\\nHow to QC the modeled velocity logs against the raw data\\n1. Under Correction and output sub-tab (Make velocity model settings) select time and\\nvelocity logs\\n2. Display wells in a well section window\\n3. Display the check-shots interval velocity attribute\\n4. Display the velocity log from velocity modeling. This log will be inserted under the Global\\nwell logs folder.\\n5. Set both logs to display with the same scale. In the right hand track of the figure below,\\nyou can see an excellent match between the check-shot velocities and the velocity log from\\nvelocity modeling\\nDealing with poor quality well tops\\nWell data and seismic interpretation are often the main inputs for depth conversion, and there is\\nno guarantee that these two pieces of data will match, particularly with deviated wells. If the\\nzones are thin, there may be a significant discrepancy between their thickness in time and their\\nthickness in depth at each well. This requires unrealistic velocities if the well tops are going to\\nmatch.\\nIn this instance, it is not possible to honor all the data, so you have three options:\\n1. Honor all the well tops, interpretation is inaccurate - In this case, the well tops can\\nbe used directly for correction, a velocity model chosen, e.g. V=V =V where V :'},\n",
       " {'header': '0 Int 0 ',\n",
       "  'content': 'Correction - Surface is used. The velocities on the V map will be unrealistic, but can be\\n0\\nconsidered to be pseudo velocities used to correct the interpretation.\\n2. Honor the interpretation, well deviations (and therefore well tops) are inaccurate\\n- Use the tops for correction with a velocity model but use V : Correction - Constant.\\n0\\nPetrel will find the constant velocity for the layer that gives the minimum error at the well\\ntops.\\n3. Honor most of the well tops, some are inaccurate - Often, many of the well tops will\\nbe correct, but certain ones may result in unrealistic velocities which will damage the\\nvelocity maps. Use the tops for correction as in the first example, however, on the\\nCorrection and output sub-tab increase the tolerance for depth and time. You can also\\nuse the Saved searches to only include wells that are specified in the selected saved\\nsearches.\\nManually controlling velocity interpolation\\nUsing well ties and interpretation directly is often a good way of getting an initial velocity model.\\nHowever, there may be specific reasons why you need more control over the interpolation.\\nFirst, run the velocity model with the appropriate settings and well control, ensuring that Well\\npoints and Add residual on well tops are selected for the final velocity model in the\\nCorrection and output sub-tab. These points can then be used as input to the make surface\\nprocess where you have full control over the interpolation. The result can then be used as input to\\nthe velocity modeling process directly.\\nWithin the make surface process, you can choose different algorithms for interpolation, use a\\ntrend surface to steer the interpolation, add fault lines as a break in the interpolation, etc. See\\nMake/Edit Surface for more details.\\nIf the resulting map does not match the well data and well correction is turned on, then the\\nmap will be adjusted to match the wells. If this is not required, turn off the well correction.\\nManually editing velocity surfaces\\nUsing well ties and interpretation directly is often a good way to get an initial velocity model.\\nHowever, there may be specific reasons why you need more control over the interpolation.\\nFirst, run the velocity model with the appropriate settings and well control. The velocity model will\\nappear on the Models tab and will include the velocity surfaces created from the velocity model\\nand well correction (use V0 (Corrected)). Right-click on this surface and select Convert to\\nseparate surface, the surface will appear on the Input pane. This surface can now be edited\\nusing the Edit surface option and used as input to the velocity modeling process.\\nIf the resulting map does not match, turn on the well data and well correction and the map\\nwill be adjusted to match the wells.\\nExtracting interval velocity point-sets from\\nWell TDR\\nAn option to extract Interval velocities as scatter point-sets for a defined layer from Well TDR\\ndata exists. This opens up possibilities to first QC layer-consistent velocities and then to grid &\\ncontour interval velocity surfaces using more elaborated gridding and contouring methods,\\nincluding kriging, co-krgging, or adding extra points to control the extrapolation of velocities in\\nareas with no well control. This method is less automatic, but it has the advantage to provide a\\nvery good control on the data being used to build a velocity model.\\nThe options are available from the Settings for a ceckshot object, under the Operations tab. It is\\npossible to define intervals between two constant levels, or between a constant level and a\\nsurface, a top surface and a bottom surface and between a surface and a bottom constant level.\\nSelect the type of operation to be performed.\\nSelect the \"Average velocity\" attribute from the checkshot object in the tree using the blue\\narrow button.\\nSelect corresponding values or surfaces for the \"Top elevation\" and the \"Base elevation\",\\ndepending on the selected type of operation.\\nClicking on Run , a new point set object is created with the computed interval velocities for the\\nlayer in the Input tree. The default name will be composed by Petrel to reflect the top and bottom\\ninputs.\\nVisualize the values using any available window in Petrel, like a Function window or 3D window.\\nThe interval velocity value points will be positioned at the mid-point of the corresponding layer.\\nThis combined view allows you to easily spot any anomaly Interval velocity value and decide how\\nto correct it. You can use the filter options in Petrel to select any region in the Function window\\nand see where the Interval velocity values correspond in the geographical space. Using the\\nSelect using freehand draw icon to draw an area in the Function window around the points\\nyou want to filter. This creates a filter set in the Petrel Input tree that filters on the points in 3D\\nview when activated. The active free hand draw polygon can be moved around in the function\\nwindow and the 3D window will update on the points inside and outside the filter selection.\\nYou can also highlight single values and open the spreadsheet corresponding to the Interval\\nVelocity point-set to edit a value if required. Applying the change in the spreadsheet will commit\\nthe change in the point-set and update the display in the Function window accordingly.\\nFinally, using the Make/edit surface process in Petrel, you can grid and contour the Interval\\nvelocities. It is here where you can opt to use a more elaborated approach, like co-kriging as one\\nexample. Please refer to the documentation and help for the Make/edit surface process for further\\ndetails on this topic.\\nRepeating this process for all layers needed will supply the input for making a velocity model\\nbased on Interval velocity surfaces.\\nCreating a 3D grid for velocity modeling\\nThere are a number of reasons why the user may wish to create a grid for velocity modeling:\\n1. To interpolate velocity data in 3D using the full range of property modeling tools (data\\nanalysis, petrophysical modeling).\\n2. To create complex velocity functions.\\n3. To deal with varying velocity functions under reverse faults.\\nIf the interpolation is only required for the reservoir interval (i.e. the zones above the reservoir\\nhave a velocity model defined using maps), then the standard 3D grid can be used. However, if\\nthe entire velocity model is to be defined, then the grid must extend to the surface and a separate\\ngrid should be created. This may also be preferable if the reservoir grid has a large number of\\ngrid cells and is slow to use.\\nIf faults are insignificant, then it may be worth using the Make simple grid process. Drop the\\nprinciple horizons into the process to create the zones for modeling, and divide the model in the\\nvertical direction using the Layering process. Remember that the grid resolution should match the\\ndensity and scale of the data. There is no need to create a high resolution grid to model stacking\\nvelocities which have high uncertainty and are averaged over a relatively large volume.\\nYou are now ready to use the standard property modeling workflows to create a velocity property\\nin the 3D grid. Once created, the property model can either be used directly or V maps\\n0\\nextracted.\\nOnce the velocity model has been created, it can be used to convert any data. The velocity\\nmodel can be defined using a coarse 3D model but used to depth convert a fine scale geological\\nmodel.\\nUsing stacking velocities\\nStacking velocities can be loaded into Petrel as Petrel points with attributes (ASCII) (*.*),\\nprovided the files contain X, Y coordinate information. Additionally, a few common formats have\\nbeen added to the loader to support ASCII-Stacking Velocity files where there is only information\\nrelated to 2D and 3D surveys and the X, Y coordinates are not defined. The corresponding 2D or\\n3D surveys must be defined in Petrel before attempting to load these types of files. Petrel will try\\nto match the name of the survey and/or the names of the 2D lines. Formats supported are\\nESSOV2, STATOILH2 and DISKOS.\\nStacking velocities must first be converted using the Dix formula. Initially, import the velocities\\nusing the appropriate format, then create average velocities using the Dix conversion found\\nunder Points operations in the Operations tab. As a result, new attributes are created for the\\npoint data set. Interval and average velocitiy attributes positioned at the mid point between\\nexisting values are some of them. These can now be used for various purposes in Petrel.\\nIn the Operations Tab, it is possible to extract surface-consistent interval velocity points between\\na top and a bottom layer. These scatter values can then be edited, visualized and mapped to\\nderive Interval velocity maps. The Interval velocity maps can be assigned in the Make velocity\\nmodel process to create a velocity model.\\nAlternatively, these points can be sampled into a 3D grid (see Creating a grid for velocity\\nmodeling) and further the velocity interpolated using data analysis and petrophysical modeling\\nprocesses.\\nOnce velocities have been created in the 3D grid, they can be used directly as input to the velocity\\nmodeling process or average maps created from the velocity properties settings and used as\\ninput.\\nZ vs t or Z vs V plots can be made directly from the stacking velocities in a function window.\\nA function can then be created to pass through these points and describe the relationship. If a\\nstraight line is used, then V and k will be reported on the function\\'s settings dialog on the\\n0\\nFunction tab.\\nHow to extract interval velocity points from stacking velocities for depth\\nconversion\\n1. Import the stacking velocities as points with attributes or any of the predefined formats.\\n2. Use the Dix conversion under seismic operations on the Operations tab of the points\\nsettings dialog to create a set of average velocity points.\\n3. Open the settings for the point data set and go to the Operations tab.\\n4. Expand the Velocity conversion folder and select Interval velocity calculation\\n(surface,surface).\\n5. Make sure the average velocity attribute is used and enter the bordering surfaces as top\\nand base elevation. Run the operation.\\n6. The new datapoint set can be used to grid a surface using the Make/edit surface process.\\nMake sure to use the Interval velocity attribute for gridding.\\n7. The resulting surface can be used in the Make velocity model process.\\nHow to use stacking velocities as a 3D grid property in depth conversion\\n1. Import the stacking velocities as points with attributes or any of the predefined formats.\\n2. Use the Dix conversion under seismic operations on the Operations tab of the points\\nsettings dialog to create a set of average velocity points.\\n3. Create a coarse grid with the major horizons using the Make simple grid process and insert\\n4.\\n2.\\n3.\\nappropriate layering.\\n4. Sample the points into the grid using the Scale up well logs process. Use Point attributes\\nas input in the process and select the Average velocity attribute for upscaling.\\n5. Interpolate the average velocity values using petrophysical modeling (and data analysis if\\nrequired).\\n6. Use the resulting average velocity property as input to velocity modeling.\\nCreating complex velocity functions\\nComplex velocity functions cannot be used directly in the Make velocity model dialog, but they\\ncan be used to create a velocity property within a 3D grid. This property can then be used in the\\ndepth conversion.\\nThere are a number of ways to create the property, the most obvious is sampling velocity data\\ninto the 3D grid and interpolate it using Petrophysical modeling. Here, the Data Analysis\\nmodule can be used to investigate trends (e.g. vertical increases in velocity) and ensure they are\\nhonored.\\nAlternatively, you can plot the velocity data in a function window, fit a function to the data and\\nthen use that in the calculator to create a smooth velocity property (see Functions and Using\\nFunctions and Surfaces in the Calculator).\\nHow to create complex velocity functions in make\\nvelocity model\\n1. Create a coarse time grid with the major time horizons using the Make simple grid process\\nand insert appropriate layering.\\n2. Plot any available data as time (x) versus velocity (y) in a function window.\\n3. Create a function using the button and fit it to the data (any number of additional\\npoints can be added).\\n4. Rename the function TimeVsVel .\\n5. In the property calculator write Velocity=TimeVsVel(Z) to create a velocity property and\\nmake sure that the property has the correct template.\\n6. Use the property as input to Make Velocity Model.\\nDepth converting thin layers\\nWhen the velocity model contains thin layers, the available velocity information for the layer may\\nbe sparse. In this case there are two options:\\n1. Ignore the layer - Choose one of the horizons (top or bottom) and use this as a zone\\nboundary. The layer will be converted as though it was part of the zone above or the zone\\nbelow. However, it will only be possible to perform well correction at the horizon in the\\nvelocity model.\\n2. Convert the layer together with the layer above or below - By using the Same as\\nabove option in the velocity model, either for the thin layer or the layer below it, the\\nvelocity for the thin layer and the well correction will be calculated together with the layer\\nabove or below it. This allows both the top and base of the thin layer to use well correction\\nwhile grouping the two layers together in terms of input data.\\nUsing a velocity cube with well correction\\nIf an extensive depth conversion study has been done outside Petrel, then it may be desirable to\\nuse a velocity or time/depth cube as input to the velocity model. If additional well data has\\nbecome available since the original study was done, then it can be useful to use well correction at\\nthe same time as this cube.\\nWell correction can only be used if there is an associated time surface in the velocity model.\\nHow to do well correction when creating a velocity model from a velocity\\ncube\\n1. Convert the seismic cube into an average velocity cube using the attribute generation\\nprocess if required.\\n2. Create the zones of the velocity model using the relevant time horizons for the well tops\\nwhere the correction should be performed.\\n3. Drop in the well tops at the correct depth.\\n4. Choose velocity cube as the velocity input and drop the average velocity cube into each\\nzone in the model.\\nUsing velocity models for stretching or\\nsqueezing seismic\\nEven if the seismic is in the same domain as the 3D grid or other seismic volumes, they may not\\nmatch exactly due to well corrections or resampling around the faults. If the seismic is to be\\nsampled into the grid, or two volumes compared, then they need to match exactly. This can be\\ndone by using a domain conversion in the velocity modeling process.\\nCreate a surface based on notable horizons in the seismic and create the same surface from the\\n3D grid or from the second seismic cube. Use these surfaces (from the seismic cube to be shifted)\\nto define the velocity model and choose Surface as the correction in the dialog. For the velocity\\ndata choose Correction - Surface. Ensure that the domains at the top of the dialog match the\\ndomains for the seismic (e.g. Convert from TWT to TWT).\\nThe velocity model can now be used to shift and squeeze the seismic.\\nUsing velocity models for well correction\\nBy using depth - depth conversions, the velocity modeling process can be used for well correction.\\nThe difference between this and the standard depth conversions in Make Horizons, Make Zones\\nor Make Surface is that while these deal with the correction on individual surfaces, the velocity\\nmodel carries the corrections downwards.\\nHow to use depth conversion to do well correction\\n1. Use the 3D model or set of surfaces to be corrected as input for the velocity model.\\n2. Ensure that the domains are correct in the Make Velocity Model dialog (e.g. Convert from\\nZ to Z).\\n3. Add the well tops as the correction.\\n4. Choose Correction - Surface as the velocity input.\\n5. Create the velocity model.\\n6. Depth convert the 3D grid or surfaces using the velocity model.'},\n",
       " {'header': 'Depth Conversion Process ',\n",
       "  'content': 'Once a velocity model has been created, it can be used to depth convert objects. Objects which\\ncan be depth converted include:'},\n",
       " {'header': 'Surfaces Horizon Interpretation Fault Interpretation Points ',\n",
       "  'content': \"Wells & logs\\nWell tops\\nSeismic data (attribute of the original which can be realized)\\n3D grids (copy of the original or overwrite the original)\\nSurfaces, interpretations and points are depth converted by adding an additional attribute to the\\nobject. This means they can be automatically switched between time and depth using the\\nwindow's domain. When displaying depth converted objects, Petrel will ensure that only objects\\nthat are converted by using the same velocity model can be displayed together (this can be\\noverridden by switching to Any domain on the active window).\\nThe depth conversion of 3D grids has its own process as adjustments to the types of pillars used\\nmay be required.\\nWell data is time converted based on checkshots, log data (time, velocity or sonic) or the\\nfull synthetics workflow - see Synthetic seismograms or Time tab (Well). To use the velocity\\nmodel to time convert wells, create time and velocity logs in the Make velocity model process.\\nInteractive domain switching\\nWhen you depth convert surfaces, horizon/fault interpretations, and points, the objects will get an\\nadditional attribute representing the final domain of the depth conversion. The new attribute will\\nautomatically inherit the name of the velocity model that you used to create it.\\nWhen the window is switched between domains, the attribute used as the Z coordinate will\\nchange automatically. As a preference, each object will be displayed in its native domain (the\\ndomain of the main object). If that does not match the window's domain, the object will be\\ndisplayed using the attribute created by the active velocity model. If the object has not been\\nconverted using the active velocity model, it will not be displayed but will be given a grey tickmark\\nin the Petrel Explorer. In some instances, the velocity model will have been updated since the\\nobject was last displayed. In this case, the object will automatically be converted again.\\nBy switching to the user defined domain on the active window, right-clicking on an attribute and\\nselecting Use as visual vertical position, you can choose to display objects which have been\\nconverted using different velocity models, or display time and depth at the same time.\\nGeneral depth conversion\\nSurfaces, horizon and fault interpretations, and points can be converted using the General depth\\nconversion process under Geophysics.\\nThe objects to be depth converted are dropped into the dialog and the process automatically\\ndetects their native domain. Simultaneously, it determines the direction of the conversion based\\non the selected velocity model. Clicking Apply or OK will calculate the new attribute for each of\\nthe chosen objects.\\nIf the velocity model is changed, each object will be depth converted again using the updated\\nvelocity model the next time it is displayed.\\nThese objects can also be depth converted individually by right-clicking on the object and\\nselecting Domain convert by active velocity model.\\nHow to depth convert surfaces, interpretations, seismic, and points in\\nbatch\\n1. Create a velocity model if one is not present (see the Make velocity model process).\\n2. Open the General depth conversion process (under Geophysics).\\n3. Select the appropriate velocity model.\\n4. Select the objects to depth convert and drop them into the dialog using the button.\\n5. Click OK.\\n6. Switch the active window to the appropriate domain. The object will be correctly displayed.\\nHow to depth convert surfaces, interpretations, seismic, and points\\nindividually\\n1. Create a velocity model if one is not present.\\n2.\\n3.\\n1.\\n2. Right-click on the object you want to convert and select Domain convert by active\\nvelocity model.\\n3. Switch the active window to the appropriate domain and the object will be correctly\\ndisplayed.\\nThere is an issue regarding the depth conversion of seismic data and back again to the\\noriginal domain. Even if the same velocity model is used to depth convert and then backward time\\nconvert the seismic (for example, a 3D volume), both the sample rate and the time range can\\ndiffer from the original seismic to the roundtripped version of the same data. When converting\\nfrom time to depth, the constant datums representing the top and bottom of the cube becomes\\nsurfaces that varies with XY in the resulting cube. The depth cube gets its constant top/bottom\\ndatums as the extrema of the depth converted time datums. The area between the real depth\\nconverted datum and the constant used as extreme is padded with zeros (null values). When\\nconverting back to time, the padded samples are converted too, and the resulting time cube will,\\nafter the roundtrip have a wider timerange than the time cube used as starting point for the\\nroundtrip. An additional side effect is that since depth conversion in Petrel keeps the number of\\nsamples from the inpt cube, the sample rate increases.\\n3D Grid depth conversion\\n3D grids are depth converted by using the 3D grid depth conversion process under Structural\\nmodeling.\\nBefore you open the process, you should ensure the correct grid is active, as it is that grid which\\nwill be depth converted. By default, the conversion will create a new grid in depth. However, if\\nrequired, it can be used to overwrite another grid (horizon and property information will be\\nretained, if possible, so that these can be recreated) or overwrite the time grid.\\nThe velocity model to be used must be chosen and the direction of the conversion will be\\nestimated from that. If the grid is being converted back to time so that it can be rebuilt using\\nMake horizons etc., then you can choose to only convert the model pillars to save time. All the\\ndata in the grid will be lost, but the settings used to create it will be retained.\\nPillar geometry tab (Depth Conversion)\\nThe menu is identical to the Pillar geometry tab in Pillar gridding. The menu specifies how the\\nshape of the new depth converted pillars will be and how this should be done. A straight line in\\ntime does not necessarily become a straight line in depth, and the Pillar geometry sub-tab\\nprovides the tools to reconstruct the correct pillar shapes in depth.\\nFaulted and non-faulted pillars are treated separately. This gives the user more flexibility, but can,\\nin worst case, also cause some unwanted twisting and distortion of the 3D grid. For example,\\nkeeping the non-faulted pillars bound, but allowing all possibilities for the faulted pillars might\\ncause problems.\\nThe menus for non-faulted pillars and faulted pillars are identical and are used in the same way:\\nUse existing geometry: The program reconstructs the pillars to the same type of shape\\nthey had in the time grid. A straight pillar in time becomes a straight pillar in depth; a listric\\npillar becomes a listric pillar, etc.\\nCreate pillar geometry type: The program is given more flexibility when creating pillars\\nin depth. Pillars in the depth converted grid will be of the type the defines. The simplest\\npossible type will be used while ensuring that the pillar remains within the requested\\ntolerance.\\nTolerance distance - sets the threshold for the program to choose one type or another. If\\nthe new pillar is further away from the original pillar than the stated threshold distance,\\nthen a new node is added to the pillar (increasing the curvature).\\nHow to depth convert a 3D grid\\n1. Create a velocity model if one is not present.\\n2. Ensure the grid to be converted is active.\\n3. Open the Depth convert 3D grid menu and select the appropriate velocity model.\\n4. Select a destination grid for the depth conversion or leave this option blank to create a new\\ngrid.\\n5. Choose the pillar types for non-faulted and faulted pillars.\\n6. Click OK. The converted grid will appear on the Models tab.\\nDomain convert Seismic data\\nSeismic domain conversion\\nSeismic data can be converted using the General depth conversion process under\"},\n",
       " {'header': 'Geophysics. ',\n",
       "  'content': 'The objects to be depth converted are dropped into the dialog and the process automatically\\ndetects their native domain. At the same time, it determines the direction of the conversion based\\non the selected velocity model. Clicking Apply or Ok will calculate a new virtual seismic attribute\\nfor each of the chosen objects.\\nDomain convert by active velocity model:\\nSeismic data (3D cube or 2D line) can be domain converted individually by right-clicking on the\\nobject and selecting Domain convert by active velocity model while the velocity model is\\nactive.'},\n",
       " {'header': 'Structural Framework Introduction ',\n",
       "  'content': 'The Petrel structural framework allows interpretation data to be combined together to construct a\\nstructural model. The structural framework functionality solves many of the problems posed by\\ncomplex fault relationships. The model then feeds construction of geocellular models, including\\nstair-step faults to handle complex geometries. Consequently, these tools improve both the time\\nto model and the quality of geocellular grids.\\nThe creation of the models can be tightly linked to seismic interpretation, allowing models to be\\nbuilt on the fly in a \"Modeling While Interpreting\" workflow. The objective here is to facilitate the\\ncreation of structurally correct interpretation.\\nFig 1. To the left, input data like fault interpretations and horizon interpretations. To the right, the\\nstructural framework with faults and horizons.\\nThe principal steps in creating a structural model are contained in three new processes:\\nGeometry definition , sets up the area of interest.\\nFault framework modeling , grids up the faults and creates relationships between\\nconnected faults.\\nHorizon modeling , grids up the horizon data then applies geological rules.\\nFig 2. Structural framework with zones.\\nCorner point gridding is enabled by two new processes:\\nFault model from structural framework which creates a set of pillar grid faults\\nautomatically connected together and limited to the zone of interest\\nStair-step faulting allows the addition of complex faults as IJK stair-step faults.\\nFig. 3 The Processes pane with the new Structural framework and Corner point gridding processes\\nin red frames.\\nGeometry definition\\nThis process is used to define the geometry of the new structural framework by specifying its\\ncoverage, defining the X- Y resolution and optionally the interval in Z (time or depth). The default\\nX and Y coverage and resolution is automatically adopted from a seismic survey , e.g., the same\\ncoverage and orientation as the seismic cube, if this is available in the project. If multiple cubes\\nare in the project, any cube lattice can be dropped in as a model grid geometry setting. Other\\nobjects that have geometry can also be used, such as horizon and fault interpretation, point sets\\nand surfaces. The results will vary depending on whether or not the object is defined on a lattice.\\nIf it is not, then the geometry will be set to cover the object with a default rotation and resolution.\\nA Coarsening factor can be used to create a geometry that honors the input grid extents but\\nwith multiples of the grid increments. In this way seismic trace locations can be honored on the\\ncoarse grid. The input geometry can be set to automatically coarsen, which will target the\\ncreation of geometries with less than 60,000 nodes. Petrel can effectively handle much larger\\ngrids but modeling speed can decrease with large grids.\\nThe geometry parameters can be used to edit the coverage by specifying the origin, width, height\\nand rotation of the lattice. The origin remains stationary when changing the width, height, and\\nrotation. The other two endpoints cannot be edited and are only shown for reference.\\nA polygon can be used to create a non-rectangular boundary for the model.\\nThe Z extent of the geometry is normally not user-defined since it adapts to cover surfaces being\\nmodeled with some marginal extension. If desired, this can be overridden with explicit Shallowest\\nand Deepest Z values.\\nFig. 1 The Define geometry process dialog\\nList of Parameters\\nParameters and their definitions are listed below.'},\n",
       " {'header': 'Parameter Function ',\n",
       "  'content': 'Create A new structural framework with the given name will be created.\\nnew\\nEdit The currently active structural framework will be edited. The framework\\nexisting geometry will change, but any models contained in the framework must be\\nupdated by running the relevant processes.\\nDomain Determines if the structural framework will be in depth or time. It must have\\nthe same domain as the interpretation that is going to be used.\\nGet Drop objects here and the dialog will attempt to extract a structural\\ngeometry framework geometry from it.\\nfrom\\nselected\\nOrigin The origin in world coordinates.\\nI axis The I axis end point in world coordinates. This value is read-only.\\nJ axis The J axis end point in world coordinates. This value is read-only.\\nWidth Length of the I axis.\\nHeight Length of the J axis.\\nRotation Angle of the I axis measured in degrees counter-clockwise from east. The J\\naxis angle is always 90 degrees counter-clockwise from the I axis.\\nInline The inline annotation coordinate values of the origin, I axis, and J axis. These\\nare only available if the geometry is derived from a seismic cube.\\nCrossline The crossline annotation coordinate values of the origin, I axis, and J axis.\\nThese are only available if the geometry is derived from a seismic cube.\\nShallowest Shallowest Z value. Default is adaptive to cover all modeled surfaces. To\\nenter an explicit value, check the Define Z extent option then enter a value\\nfor both Shallowest and Deepest .\\nDeepest Deepest Z value. Default is adaptive to cover all modeled surfaces. To enter\\nan explicit value, check the Define Z extent option then enter a value for\\nboth Shallowest and Deepest .\\nPolygon Specifies a closed polygon to use as boundary for the model. This boundary\\nboundary should be within the VOI. The boundary is not applied until the horizon rules\\nhave been applied i.e. the volume model in the Horizon modeling process.\\nI Model resolution in I.\\nincrement\\nJ Model resolution in J.\\nincrement\\nTutorials: Geometry definitions\\nHow to define the volume of interest from 3D seismic (or other supported\\nobject)\\n1. In the Processes Pane open the Structural Framework > Define geometry process.\\n2. Select the 3D seismic to use to define the geometry.\\n3. Drop it on the blue arrow next to get geometry from selected.\\nHow to define the vertical extent of the volume of interest\\n1. In the Processes Pane open the Structural Framework > Define geometry process.\\n2. Check Z extents.\\n3. Enter Shallowest and Deepest values.\\nHow to define the geometry using origin and angle values\\n1. In the Processes Pane open the Structural Framework > Define geometry process.'},\n",
       " {'header': '2. Enter ',\n",
       "  'content': \"a. Origin\\nb. Width and Height\\nc. Rotation\\nd. I increment and J increment\\nThe values you enter will be automatically updated to ensure orthogonality. The origin is a\\nstationary point. The I axis endpoint is shifted in the I axis direction so that the extent is evenly\\ndivisible by the I increment. Similarly, the J axis endpoint is shifted, first in the J axis direction so\\nthe extent is evenly divisible by the J increment. Then a rotational shift about the origin is made\\nso that all three points are exactly orthogonal.\\nHow to coarsen the volume of interest (VOI)\\nWhen modeling horizons where no salt is present\\n1. In the Processes Pane open the Structural Framework > Define geometry process.\\n2. Update the I increment and I increment.\\nWhen modeling salt, the model grid geometry must be identical to the grid geometry of input\\ninterpretation data.\\n1. Create a Petrel Surface from your interpretation using the Make/edit surface process.\\nYou have full control over the interpolation options. Define your coarse lattice and\\ninterpolate your data. Be sure to select Trend in the Algorithm tab which is the preferred\\nway to extrapolate salt data (how null interpretations are filled in).\\n2. In the Processes Pane open the Structural Framework > Define geometry process.\\n3. Define your geometry using the same exact lattice as the one used in the Make/edit\\nsurface process.\\n4. Switch to the Structural Framework > Horizon modeling process.\\n5. Use this new Petrel Surface as your data set to model your horizon.\\n4.\\n5.\\nFault framework modeling\\nFaults are modeled from their inputs into individual smoothed surfaces. Each is bound by a tip loop\\nwhich represents the edge of the fault. This tip loop edge is computed from the input fault\\ninterpretation with an optional amount of (user defined) extrapolation which allows each fault to be\\nmodeled at or beyond its initial interpretation.\\nWhen modeling faults, the Compute faults tab of the process dialog is used, which allows individual\\nsettings for each fault to be modified. Note that the settings can be changed globally for all faults in the\\nSettings tab.\\nFig. 1 Fault framework dialog, the Compute faults tab.\\nFaults are added to the dialog using the multi-drop insert tool, which is designed to automatically add\\nthe required number of rows for the relevant input data. Each fault is modeled as a grid which is\\nrotated based on the general orientation of its interpretation data in a best-fitplane. If the assigned\\nbest-fit plane does not accurately honor the input data for a particular fault,you can use the Gridding\\nplane drop-down list to choose a new 'best-fit' plane for each fault individually. This is occasionally\\nrequired where an individual fault interpretation changes significantly in strike direction, or has a\\nshallow dip angle.\"},\n",
       " {'header': 'Icon Controls ',\n",
       "  'content': 'The following icons in the dialog provide control for populating the fault spreadsheet. In order these\\nicons let you:\\nTable Columns: Compute faults tab'},\n",
       " {'header': 'Parameter Function Index Identifier Fault ',\n",
       "  'content': 'Name of the fault as it will appear in the Faults folder of the corresponding structural framework.'},\n",
       " {'header': 'Color ', 'content': 'Color used to display the fault'},\n",
       " {'header': 'Size ',\n",
       "  'content': 'Number of points in all Data Set s defining the fault.'},\n",
       " {'header': 'Calculate ',\n",
       "  'content': 'Select the faults to be calculated. By default, all faults are selected.'},\n",
       " {'header': 'Status ',\n",
       "  'content': 'The status will be New if not currently built into the model, otherwise, it will be Done .\\nGrid interval\\nSpecifies the resolution of the grid used to create the fault. It should be as high as possible, while still\\nrespecting the data, as this will both speed up the processes and generally results in a cleaner model.'},\n",
       " {'header': 'Smoothing ',\n",
       "  'content': \"Number of smoothing iterations applied. This will generally be used after the Grid interval to fine tune\\nthe result. It's better to have a large Grid interval and low Smoothing.\\nTip loop style\\nTip loops are the boundaries of the faults. There are two alternatives: Convex hull and Sculpted.\\nConvex hull wraps the data with no indents whereas sculpted follows the data more closely.\\nTip loop sculpting diameter\\nControls the smoothness of a tip loop with sculpted tip loop style. A larger diameter will give a\\nsmoother result.\\nExtrapolation distance\\nControls how far beyond the data the fault plane is extrapolated. Not available for sculpted tip loops.\\nGridding plane\\nFaults are gridded in a best fit plane through the data. Normally the automatic selection of the principal\\nplane gives a good result, but in some cases where the fault has a large curvature, you may have to\\noverride the default and manually try some different options.\\nFault top\\nFault tops are used to correct the fault plane. The default influence radius is large so a single top will\\nshift the fault plane perpendicular to the gridding plane of the fault. If no other data is present, the\\nFault tops will be treated as input data.\"},\n",
       " {'header': 'Input #1 ',\n",
       "  'content': 'Fault interpretation data used as input data while building the fault. Multiple input columns can be\\nadded.\\nWhen faults are created, the modeling engine will detect fault relationships and attempt to set a\\ntruncation rule automatically. All rules are displayed in the Edit relationships tab where they can be\\nedited. Major (truncating) and minor (truncated) faults can be swapped and the type of the truncation\\ncan be changed. To reverse the truncation of a minor fault, change Above to Below or vice versa.\\nAbove or below is in relation to the major fault and it is difficult to know which side is above and which\\nis below without first applying a rule and observing the results. Use this binary setting as a way to flip\\nthe truncation from what it was previously.\\nFig. 2 The Fault framework dialog, the Edit relationship tab\\nTable columns: Edit relationships tab'},\n",
       " {'header': 'Parameter Function ',\n",
       "  'content': 'Fault pair\\nThe table lists fault pairs where the major fault is considering truncating the minor fault'},\n",
       " {'header': 'Visible ',\n",
       "  'content': 'Option to visualize or hide the selected fault pair'},\n",
       " {'header': 'Input ',\n",
       "  'content': 'Option to visualize or hide the input (fault sticks) for the selected fault pair\\nMajor fault\\nThe truncating fault\\nMinor fault\\nThe truncated fault'},\n",
       " {'header': 'Truncation ',\n",
       "  'content': 'Above/below: determine which side of the major fault the minor fault is truncated\\nNone: set to no truncation\\nSwap: change around the fault pair, i.e. swap major and minor faults\\nAuto calculate: reapply the Petrel fault relationship logic to the chosen fault pair.'},\n",
       " {'header': 'Verified ',\n",
       "  'content': 'Reminds the user that the relationship has been verified. Verifying has no effect on the model\\nRecalculate all\\nreapply the Petrel fault relationship logic to all fault pair\\nEditing of fault truncation relationships can also be carried out in the 3D window using the right mouse\\nbutton context-sensitive menu. This allows users to:\\nDisplay input data of the fault framework.\\nShow connected faults.\\nAlter fault extrapolation distance.\\nSwap major/minor fault truncation relationships.\\nSwap minor fault above/below truncation.\\nRemove minor fault truncation.\\nRemove all truncations on a fault.\\nAuto calculate fault truncation.\\nAltering the Major/Minor Fault truncation relationships in the 3D window is achieved by initially\\nselecting a major fault and then altering the way a connected minor fault interacts with it. The image\\nbelow outlines this process where a major fault is highlighted (wireframe mode) and then each fault\\ntruncation can be altered, removed or recalculated by right clicking on each minor fault respectively.\\nFig. 3 Fault contex menu in 3D window\\nFault grids are typically small in size and do not consume much memory or require much computation\\nwhen compared with horizon modeling. It is however good practice to have as large a grid interval as\\ncan be supported while still honoring the input data.\\nGetting the fault relationships correct in a structural model is a critical first step. Accurate geologically\\nsound fault models will save time later in the workflow. It is very common that problems arising during\\nhorizon modeling are due to faults not being correctly modeled and intersected.\\nSome tips to consider are:\\nDoes the fault interpretation make good geological sense? Is this structurally feasible?\\nDoes each minor fault have a solid intersection with its major fault? Does this fault-fault\\nintersection continue deeper into the earth model where it should? If this intersection breaks\\ndown with depth, horizons modeled at those levels will show the two faults disconnected (not\\nbifurcated). This may be okay if it reflects reality.\\nAre faults modeled to their true X,Y and Z extent within the model VOI? Sometimes faults are not\\nfully interpreted, leading to faults not modeled deep or shallow enough. Incomplete fault models\\ncan lead to degraded horizon models.\\nDo faults extend beyond where they truly exist? Make sure any extrapolation is reasonable.\\nStarting out it is prudent to consider excluding some of your faults. For the ones you do model, make\\nsure they honor the input data and make geological sense. Often, it adds to overall modeling efficiency\\nto start out with the more important faults (the ones with large vertical throw) and subsequently add\\nsubordinate faults (usually ones with smaller throw). Quite often, this method will expose many issues\\nthat will adversely affect horizon modeling results. This can also give you a better understanding of how\\nthe workflow reacts to updating your model with additional faults.\\nFig. 4 Fault framework dialog, the Settings tab'},\n",
       " {'header': 'Parameters Function ',\n",
       "  'content': 'Grid interval\\nThis controls the faults grid interval. It should normally be gridded with a coarser interval then the\\nhorizons.'},\n",
       " {'header': 'Smoothing ',\n",
       "  'content': 'This controls the overall smoothness of fit to fault data expressed as the number of smoothing passes.\\nSet 0 for no smoothing and higher numbers of passes for increased smoothing.\\nTip loop style\\nThis controls the general shape of the tip loop.\\nConvex hull'},\n",
       " {'header': 'Sculpted ',\n",
       "  'content': 'Tip loop sculpting diameter\\nThis controls the degree to which the tip loop is a sculpted or shrink wrapped fit to the data. Only\\napplied when the tip loop style is set to Sculpted. A small diameter results in more sculpting, while a\\nlarge diameter results in less sculpting. An extremely large diameter produces a convex hull fit to the\\ndata. The effect is like a ball rolling around the edge of the data where a small diameter enables the\\nball to roll between data points with at least this distance of separation.\\nExtrapolation distance\\nThis horizontal distance controls the distance the tip loop is extrapolated beyond the data.\\nFault top influence radius\\nControls how far a well top correction is spread out from the top. The correction is applied in the best\\nfit plane of the fault. A large correction distance (default) will essentially move the fault perpendicular\\nto the best fit plane.\\nApply to all faults\\nThis applies the selected settings to all faults.\\nTutorial: Fault modeling\\nHow to model faults\\n1. In the Processes pane, open the Structural Framework > Fault framework modeling\\nprocess.\\n2. Select the model you want to build/edit as the Active model.\\n3. Select the Faults tab.\\n4. Inspect your faults and update the relevant information.\\n5. Build your Structural Framework by clicking either OK or Apply.\\nHow to model one fault with multiple data sets\\n1. In the Processes pane open the Structural Framework > Fault framework modeling\\nprocess.\\n2. Select the model you want to build/edit as the Active model.\\n3. Select the Faults tab.\\n4. Click the Append a column in the table button . A new Data Set column is added at the\\nend of the table.\\n5. Select your data in the Petrel Input tree and drop them in the new Data Set column for\\nthe appropriate fault.\\n6. Build your Structural Framework by clicking either OK or Apply.\\nHow to drop data for multiple faults\\n1. In the Processes Pane open the Structural Framework > Fault framework modeling\\nprocess.\\n2. Select the model you want to build/edit as the Active model.\\n3. Select the Faults tab.\\n4. Click the Enable/disable multiple drop in the table button .\\n5. Add the appropriate number of rows in the table, one for each fault. Click the Set number\\nof items in the table button , enter the number of faults and click OK.\\n6. In the Petrel Input pane, select the first fault interpretation to be dropped.\\n7. In the Faults tab, select where this first fault should be dropped. That fault and other\\nsubsequent ones will be populated with their respective interpretation data.\\nFault framework while interpreting\\nPetrel Structural framework delivers new functionality which allows rapid real-time creation of the\\nstructural framework during fault and horizon interpretation and update of the framework by\\nediting geophysical interpretation. Fault model from structural framework places geophysical\\ninterpretation at the core of good model building by fully integrating with the seismic\\ninterpretation tool set. This allows users to\\nGet it right the first time - Asset teams fix modeling problems in the context of seismic\\ndata.\\nDirect link between geophysical interpretation and geocellular modeling.\\n\\'On the fly\\' approach to fault relationships, horizons and model construction.\\nImproved QC speed and functionality.\\nQuick validation of varied seismic interpretation within the \\'Petrel Unified Environment\\'.\\nOften geophysical interpretations are incompatible with geocellular modeling constraints and\\nsubsequently, due to modeling limitations, interpretation needs to be edited to build a coherent\\ngeocellular model. This often happens without any reference to the original seismic. Fault\\nframework while interpreting fully-integrates geophysical interpretation as part of the core\\nstructural framework construction process. Faults are automatically added to the fault framework\\nas interpretation progresses and critical fault-fault relationships can be interactively constructed\\nat the time of interpretation. This verifies the fault-fault relationships by the geophysicist and\\nremoves the need for later editing by geologists/modelers. During fault interpretation, the faults\\nare gridded and intersected \"on the fly\" as new data is added or changed. Horizons are gridded or\\nre-gridded on demand as the interpretation is modified.\\nFig 1. The \"right mouse button\" -menu on a fault interpretation folder.\\nHow to use Fault framework while interpreting\\nDisplay preferred interpretation environment (3D/2D Interpretation window).'},\n",
       " {'header': 'Display Seismic Data (2D/3D). Insert New Interpretation Folder. ',\n",
       "  'content': 'Insert a new fault in interpretation folder (use RMB context menu or interpretation\\nmanager).\\nRight click on the new interpretation folder and choose \\'Fault framework while\\ninterpreting .\\nUse the Fault interpretation tool from Seismic Interpretation and start interpreting the fault\\nin the 3D or 2D Interpretation window.\\nFig 2. Fault framework while interpreting in a 3D window while displaying a time-slize and a\\ncross-line.\\n\\'On-the-fly\\' computation of Fault-Fault Intersections\\nHorizon modeling\\nOnce the fault framework is completed, adding horizons is the next key workflow. Given horizon\\ndata, geologic relationships and modeling parameters, the Horizon modeling process will first\\ncreate horizons individually honoring the fault surfaces, and then apply horizon truncation rules.\\nResults are stored in the Petrel Models tab as collections of Horizons and Zones under the\\nnamed Structural frameworks .\\nAlong with interpretation data other kinds of input data can be used to model horizons.\\nWell tops are used to tie horizons to interpreted well points. Influence radius around well\\ntops along with other horizon adjustment settings are defined in Settings tab. Well tops, or\\nany sparse data, can also be used without any other inputs using the conformal modeling\\noption.\\nHard data is usually used to guide horizons along the fault surfaces or in thin fault blocks.\\nIt is really no different from any other input data except that it is not filtered close to the\\nfaults.\\nIsochore is a zone thickness map. It can be used for a better pinch-out handling and\\ncontrol over the zone volumes. Isochores stack up or down from the reference horizon\\nwhen conformal modeling is chosen. If the isochores have a zero thickness area, then this\\nshould be extrapolated to be negative to ensure clean horizon intersection lines.\\nInput field is a general input field for seismic interpretation, points or surfaces. Extra input\\ncolumns can be added to accommodate multiple inputs, this is often necessary for multi-Z\\ninputs such as reverse faults. The data provided in the input field will be filtered out around\\nthe faults.\\nFig. 1 Horizon modeling dialog, the Compute horizons tab.\\nHorizons must be entered in their correct stratigraphic order. A typical layer-cake stratigraphy is\\nthe default option (Conformable), unconformities, disconformities and salt interfaces must be\\ndesignated so that horizon intersections are correctly modeled.\\nIf surfaces intersect they are truncated according to their type (Horizon type option). Available\\ntypes are listed in the table columns below: The different Horizon type settings are applied by\\nselecting the option \"Apply geological rules and create zone model \" in the dialog window.\\nFig. 2 Horizons are trimmed according to their type\\nWhen rules are applied to surfaces they are applied in correct stratigraphic surface order, e.g.,\\nstarting with the oldest surface and finishing with the youngest surface.\\nSurfaces with only sparse data may be guided by another surface, this is conformal modeling. Use\\nthe Conforms To column to select another surface. The horizon will be shaped by that surface.\\nThis is done by first computing an isochore, then stacking that isochore onto the reference\\n(conformal) horizon to produce the final horizon model. When modeling all horizons, any horizon\\ndeclared as a conformal reference to another horizon is modeled first and then the conformal\\nhorizon is modeled.\\nTable Columns: Compute horizons -tab'},\n",
       " {'header': 'Parameter Function Index ',\n",
       "  'content': 'Index for horizons used for \"Conform to\" settings'},\n",
       " {'header': 'Horizon ',\n",
       "  'content': 'Horizon name, automatically picked up from the Input #1 column. Names can be edited in the\\nHorizon column. Horizon names will appear in the Horizons folder of the corresponding structural\\nframework.'},\n",
       " {'header': 'Color ',\n",
       "  'content': 'Color used to display the horizon in Petrel windows.'},\n",
       " {'header': 'Calculate ',\n",
       "  'content': 'Select the horizons to be calculated. By default, all horizons are selected.'},\n",
       " {'header': 'Status ',\n",
       "  'content': \"The status will be New if not currently built into the model, otherwise, it will be Done .\\nHorizon type\\nDepositional - a sedimentary horizon usually 'moulded' by adjacent depositional horizons.\\nWhere two depositional horizons meet, the younger is truncated to onlap the older.\\nErosional - unconformity which truncates older horizons. Parts of an older horizon above\\nthe erosional surface are truncated. Younger horizons are ignored.\\nBase - unconformity which truncates younger horizons. Parts of a younger horizon below\\nthe base surface are truncated. Older horizons are ignored.\\nDiscontinuity - unconformity which truncates younger and older horizons (a combination of\\nerosion and base types). Younger horizons crossing a discontinuity are truncated below the\\ndiscontinuity; older horizons crossing a discontinuity are truncated above the discontinuity.\\nTruncations apply regardless of surface type. Where two discontinuities meet, the younger\\nis truncated to the older.\\nSalt Top - a salt surface representing one or more local tops of salt.\\nSalt Base - a salt surface representing one or more local bases of salt.\\nSalt Cap - a salt surface representing one or more tops of salt where edges are modeled\\nvertically down from the cap. The salt base is either the VOI base or another Salt Base\\nsurface if that surface is the next oldest in the table.\\nSalt Body - a triangulated mesh surface representing one or more salt bodies. A Salt Body\\nsurface has already been modeled, whereas all other surface types are internally modeled\\nby the Structural framework dialog.\\nConforms to\\nSelect a horizon this horizon conforms to:\"},\n",
       " {'header': 'None ', 'content': 'Another horizon'},\n",
       " {'header': 'Smoothing ',\n",
       "  'content': 'Number of smoothing iterations applied.\\nWell tops\\nWell tops are used to correct the horizon as a post processing step.\\nHard data\\nNo different to other data except it is not subject for filtering around the wells'},\n",
       " {'header': 'Isochore ',\n",
       "  'content': 'Isochore maps can be used to correct the horizon when using the correct domain. Accepts only\\nThickness depth, True vertical thickness (TVT) or True stratigraphic thickness (TST). Specify a\\n\"Conforms to\" horizon before selecting an isochore map.'},\n",
       " {'header': 'Input #1 ',\n",
       "  'content': 'Interpreted data points such as horizon interpretation, point set, surface or polylines used as\\ninput data while building the horizon. Multiple inputs can be combined by adding input columns.'},\n",
       " {'header': 'Icon Controls ',\n",
       "  'content': 'The following icons in the dialog provide control for populating the horizon spreadsheet:\\nFig. 4 Horizon modeling dialog, the Common settings tab.\\nList of parameters: Common settings tab'},\n",
       " {'header': 'Parameter Function ',\n",
       "  'content': 'Well adjustment\\nInfluence radius\\nIf the influence radius is not specified, the radius is set to infinity. Petrel will calculate a residual\\nsurface (difference between the horizon before and after correction).\\nCorrect at all cells penetrated by well accurate\\nWell report\\nIconize the residual surface\\nIconize the residual points'},\n",
       " {'header': 'Iconize ',\n",
       "  'content': 'Unfaulted smooth surface\\nAll points used (points outside the fault influence)\\nFault center lines\\nFault trace mid points\\nOther settings\\nCoarsening factor for the unfaulted horizon\\nThe unfaulted grid is used to calculate the fault midline. The increment (grid cell size) of the initial\\nunfaulted grid will be the (coarsening factor * increment) greater than the increment defined in\\nthe Geometry definition process. Recommended values are 1 to 5, where 1 is the same as the\\nincrement defined in the Geometry definition process.\\nZ offset of the unfaulted horizon\\nThe horizon modeling process must first detect faults by intersecting a smooth surface with the\\nfaults for creating a initial centerline. The surface and resulting center lines can be viewed by\\nusing the iconize option.\\nCompute horizons in rectangular area defined by polygon\\nPolygon for temporarily reducing the area for horizon calculating.\\nSalt modeling technique\\nClamshell salt modeling technique : Cause a zone to be created by fully extrapolating the salt\\nsurfaces to the extent of the model and then truncating the extrapolated surfaces against each\\nother. All parts of the extrapolated Salt base which are above the Salt top will be deactivated,\\nsimilarly, all parts of the extrapolated Salt top which are below Salt base will be deactivated. For\\na simple pair of top and base, this can be resemble to halves of a clam when closed, hence the\\nname. Multiple top and base pairs can be used to model complex salt overhangs. All salt zub\\nregions are merged into one single salt zone. Complex clamshell salt modeling technique :\\nThis option does no extrapolation. It requires the input surfaces or interpretations to be modeled\\non the same grid as in the Geometry definition. Sparse interpretations are not recommended as\\nthe can result in very strange models containing empty columns. Each top and base pairs are\\nfiltered to ensure they are corresponding samples in both top and base. The surfaces are then\\ntruncated each other where they are defined by the same rule: deactivate base above top and\\ndeactivate top below base.\\nWith horizons identified as Salt Top and Salt Base, there are two Salt modeling technique options\\nin the Horizon modeling Common settings tab: Clamshell and Complex Clamshell. These\\ntechniques merge all salt sub-regions into a single salt zone.\\nThe Clamshell option will cause a salt zone to be created by fully extrapolating the salt surfaces\\nto the extent of the model and then truncating the extrapolated surfaces against each other. All\\nparts of the extrapolated Salt base which are above the Salt top will be deactivated; similarly, all\\nparts of the extrapolated Salt top which are below the Salt base will be deactivated. For a simple\\npair of top and base, this can resemble two halves of a clam when closed, hence the name.\\nMultiple top & base pairs can be used to model complex salt overhangs. All salt sub-regions are\\nmerged into a single salt zone.\\nThe Complex Clamshell option does no extrapolation. It requires the input surfaces or\\ninterpretations to be modeled on the same grid as the Define geometry grid. Sparse\\ninterpretations are not recommended as they can result in very strange models containing empty\\ncolumns. Each top and base pair is filtered to ensure there are corresponding samples in both the\\ntop and base. The surfaces are then truncated against each other where they are defined with the\\nsame rule: deactivate base above top and deactivate top below base. This approach helps remove\\nbubbles. The precise filtering rules are as follows:\\nIf a top pick is located above its corresponding base pick, then this salt interval will be\\nconsidered valid and will be kept as it is.\\nIf a top pick is located below its corresponding base pick, then this salt interval will be\\nconsidered invalid and will be ignored. Basically, the top pick is snapped onto its\\ncorresponding base.\\nIf there are Interleaved top/base configuration and both salt intervals are considered valid,\\nthen the lowest top is dropped onto the highest top and the highest base is dropped onto\\nthe lowest base.\\nIf a top pick is determined to be a single top interpretation (no corresponding base), then a\\ncorresponding base will be created at the base altitude of the volume of interest and from\\nthat point will be processed as any other top/base pair.\\nFig. 5 Horizon modeling dialog, the Fault settings tab.\\nList of parameters: Fault settings tab'},\n",
       " {'header': 'Parameter Function ',\n",
       "  'content': 'Use default\\nPetrel will use default settings when this position is selected. Must be deactivated for using other\\nsettings.\\nActive fault\\nIf not active the faults will have no displacement for the horizons\\nDistance to fault\\nInput data that are closer than this distance (measured horizontally) to the fault are treated as\\nuncertain and are not used in the interpolation algorithm. Petrel will then back-extrapolate into\\nthe fault plane.\\nPer side\\nThe extrapolation distances can be specified differently for the front and back sides of the fault.\\nBy using this selection, the different sides will be marked in the 3D window.'},\n",
       " {'header': 'Displacement Min/Max ',\n",
       "  'content': 'The fault displacement will be modeled from the input data as normal, but where the offset is less\\nthan the minimum or greater than the maximum, it will be changed. For constant offset on the\\nentire fault, simply set the minimum equal to the maximum. The displacement is measured\\nvertically.\\nAllow hinge\\nAllows faults to swap between reverse and normal displacement along its length. With this option\\nselected, Petrel will create the offset according to the input data and then decide which side of the\\nfault is downthrown.'},\n",
       " {'header': 'Smoothing ',\n",
       "  'content': 'Smooth the fault displacement. Select this option to access the Number of iterations and/or\\nTolerance settings. Displacement smoothing is recommended, and should be used if min or max\\ndisplacement is specified.\\nNumber of iterations\\nSet number of smoothing iterations. Recommended values are 3-10.'},\n",
       " {'header': 'Tolerance ',\n",
       "  'content': 'Make a smooth displacement with a maximum change (tolerance) pr. 100 horizontal units along\\nthe fault.\\nHorizon modeling tips\\nIt is often more efficient to model horizon by horizon using the Calculate option to turn\\non/off individual horizon calculation.\\nIt is good practice to first build horizons without applying horizon rules. It saves time but\\nalso allows control of horizon-horizon intersections before they are clipped.\\nIf a conformably modeled horizon is unacceptable, then choose the settings option Iconize\\nall points used , this will produce a point set which represents the input created by the\\nsystem. Now use this directly in the Horizon modeling table to enable editing of the input\\ndata.\\nUse the fault center lines. Iconize the fault center lines when running the horizon modeling.\\nEach fault will be split with a different color at intersections. It is usually a good idea to\\nstudy the center lines in the 2D window to find problem areas. Once a problem is identified,\\nobserving the center lines in 3D, together with the faults and their intersections, will help\\nfind a solution to the issue.\\nControl the filtered data. Iconize filtered data to identify wrong sided data.\\nAdjust fault filtering. Filter distance can be adjusted on a fault by fault, horizon by horizon\\nbasis in the faults tab of horizon modeling. However it is good practice to keep a small\\nblanking distance and erase wrong sided data instead.\\nFor faults that are not active, use the faults tab to disable them for a given horizon.\\nFig 8. The Fault settings tab in the Horizon modeling process. The fault F3 is deactivated by\\ndeselcting the Active fault option.\\nUse local area calculations. To improve speed of interactive horizon work, set a temporary\\nboundary in the area of interest.\\nFig 9. The option Compute horizons in rectangular local area defined by polygon for\\nperforming local area calculations. This option is located in the Common settings tab in the\\nHorizon modeling process.\\nApply Geological rules and create Zone Model\\nHorizon modeling can be split into two stages, initial horizon generation for QC and the final\\nmodeling stage, where correct geological rules are applied to each model horizon. Applying\\ncorrect geological rules ensures all model horizons are ordered and cut correctly and knits each\\nhorizon to fault surfaces. This process creates a model with zones.\\nThis option is toggled in the Horizon Modeling process and can be independently run from the\\nhorizons. Once all horizons have been generated and have undergone QC, the Calculate\\ncheckboxes for each horizon row can be deselected. Toggle on the Apply Geological Rules &\\nCreate Zone Model to finalize the rules on each model horizon.\\nYou may choose to turn this option on as default, however once applied there is no option to see\\nthe intermediate horizon modeling results and QC processes may prove difficult.\\nFig 10. Initial Horizon modeling step prior to application of geological rules\\nFig 11. Geological rules applied - all horizons now correctly eroded by top surface\\nFig 12. Generated Zone model\\nVisualize a Structural Framework\\nAll components of a Structural Framework (Horizons, Faults or Zones) are represented as triangle\\nmeshes. Their level of detail can be adjusted to render only a fraction of the model.\\nHorizon modeling can create discontinuous meshes constituted of patches. You can visualize those\\npatches independently using random coloring. Some patches, referred to as unreal patches, were\\ndiscarded during the modeling process, however, they can be visualized for trouble shooting.\\nFree framework model memory\\nLarge structural frameworks can occupy a lot of memory. The Free framework model memory\\nfrees all significant memory of a structural framework, and is recommended if users want to work\\nwith more than one structural framework. This prevent keeping multiple large models in memory.\\nFig 13. The Free framework model memory \"option available from the Tools menu.\\nInitial vs Final Visualization\\nOnce the application of geological rules has been carried out, you are able to toggle between the\\ninitial and final model stages.\\n1. Open the Models pane, find the Structural framework you want to render.\\n2. Right click on the Structural framework name, and bring up the Settings dialog.\\n3. Open the Style tab.\\n4. Change the dropdown menu \\'Geometry Version\\' style\\n3.\\n4.\\nFig 14. Initial Structural framework Style .\\nFig 15. Final Structural framework Style .\\nTutorial: Horizon modeling'},\n",
       " {'header': 'Conformal Modeling ',\n",
       "  'content': 'Non-salt surfaces may be modeled where one is shaped by another. This applies to Depositional\\ntype surfaces by may be any non-salt surface and is the conformal modeling option. Use the\\nConforms To column to select another surface. The horizon will be shaped by that surface. This\\nis done by first computing an isochore then stacking that isochore onto the reference (conformal)\\nhorizon to produce the final horizon model. When modeling all horizons, any horizon declared as a\\nconformal reference to another horizon is modeled first, then the conformal horizon is modeled.\\nHow to model horizons\\nIn the Processes window open the Structural Framework > Horizon modeling process.\\nSelect the model you want to build/edit as the Active model.\\nSelect the Horizons tab.\\nInspect your horizons and update the relevant information, especially the surface type and\\nage order. Depositional surfaces that are geometrically shallower than a deeper surface\\nmust be ordered correctly, otherwise the shallower surface will not appear in the model.\\nBuild your Structural Framework by clicking either OK or Apply.\\nHow to remove a horizon from the model\\n1. In the Processes window open the Structural Framework > Horizon modeling process.\\n2. Select the model you want to build/edit as the Active model.\\n3. Select the Horizons tab.\\n4. Deactivate by unselecting the corresponding item in the Active column, or select the\\nhorizon and remove the corresponding line in the table.\\n5. Build your Structural Framework by clicking either OK or Apply.\\nHow to model one horizon with additional data sets\\n1. In the Processes window open the Structural Framework > Horizon modeling process.\\n2. Select the model you want to build/edit as the Active model.\\n3. Select the Horizons tab.\\n4. Click the Append a column in the table button . A new Data Set column is added at the\\nend of the table.\\n5. Select your data in the Input tree and drop them in the new Data Set column for the\\nappropriate horizon.\\n6. Build your Structural Framework by clicking either OK or Apply.\\nHow to drop data for multiple horizons\\n1. In the Processes window open the Structural Framework > Horizon modeling process.\\n2. Select the model you want to build/edit as the Active model.\\n3. Select the Horizons tab.\\n4. Click the Enable/disable multiple drop in the table button.\\n5. Add the appropriate number of rows in the table, one for each horizon.\\n6. Click the Set number of items in the table button, enter the number of horizons to\\nmodel and click OK.\\n7.\\n8.\\n5.\\n6.\\n7. In the Petrel Input tree select the first horizon interpretation to be dropped.\\n8. In the Horizons tab, select where this first horizon should be dropped. That horizon and\\nother subsequent ones will be populated with their respective interpretation data.\\nHow to visualize a Structural Framework and its components\\n1. Optionally, open the Tools > Free memory in the Petrel menu bar.\\n2. Open the Models pane, and find the Structural framework you want to display and expand\\nit.\\n3. Expand the Horizons, Faults or Zones folder.\\nFig 1. Models tab view of a Structural framework.\\n4. Open a new Petrel 3D window.\\n5. Select the Structural framework element to display.\\n6. Optionally, when your visualization session is over, free Petrel memory again as large\\nvisualization data were cached.\\nHow to change the Fraction of model to render\\n1. Open the Models pane, find the Structural framework you want to render.\\n2. Right click on the Structural framework name, and bring up the Settings dialog.\\n3. Open the Style tab.\\n2.\\n3.\\nFig 2. The Style sub tab for the a Structural framework.\\n4. Update the Fraction of model to render, a value between 0.001 and 0.999.\\n5. Update your Structural framework display by clicking either Apply or OK.\\n6. If your Structural framework was displayed, it will be automatically updated.\\nHow to display Patches and/or Unreal patches of a fault or horizon\\n1. Open the Models pane, find the Structural framework you want to render.\\n2. Expand the Horizons and/or Faults folder.\\n3. Right click on the horizon or fault name you want to display, and bring up the Settings\\ndialog.\\n4.\\n2.\\n3.\\n4. Open the Style tab.\\nFig 3. Style Settings of a Horizon or Fault\\n5. Select/unselect Show patches and/or Show unreal patches.\\n6. Update your Structural framework display by clicking either Apply or OK.\\n7. If your Structural framework was displayed, it will be automatically updated.\\nCorner point gridding\\nThis is the classical process for making a structural model in Petrel. Before Petrel 2010, it was\\nknown as Structural Modeling\\nCorner point gridding in Petrel is subdivided into three processes:\\n1. Fault Modeling - defining the faults in the geological model which will form the basis for\\ngenerating the 3D grid. These faults will define breaks in the grid, lines along which the\\nhorizons inserted later may be offset. The offset which occurs is entirely dependant upon\\nthe input data, so modeling reverse faults is just as easy as modeling normal faults.\\n2. Pillar Gridding - generating the grid from the fault model. Limits on the geometry or the\\ngrid can be defined during the process so it is easy to generate two grids from the same\\nfault model - one designed for geological modeling and another optimized for simulation.\\n3. Make Horizons - building the vertical layering in the model, it is here that the offset on\\nthe faults is defined. Make Horizons generates independent geological horizons from XYZ\\ninput data, to generate additional horizons using relative distance to existing horizons (e.g.\\nisochores) use Make Zones. These two processes are used to create the geological zones\\nwithin the model. It is expected that each zone will have similar petrophysical properties\\nand can therefore be modeled using a single set of input data. Layering inserts the fine\\nscale grid cells which will describe vertical variation within each geological zone.\\nThese three processes should always be considered together and the user will normally go back\\nand forth between them. Problems with the fault model will often not be obvious before you begin\\nPillar Gridding, and problems with the pillar grid may not be obvious before you build your\\nhorizons in Make Horizons. Similarly, many problems identified when using Make Horizons will\\nrequire an edit of the pillar gridding options or even the fault model.\\nIt is recommended that you build the model simply at first and go right through these three\\nprocesses before progressively adding more complexity to the fault model. This will help you\\nidentify which features cause problems and how best to solve them.\\nWhat happens to the pillars during the corner\\npoint gridding'},\n",
       " {'header': 'Fault Modeling ',\n",
       "  'content': 'The process of Fault Modeling defines the faults in the geological model which will form the basis\\nfor generating the 3D grid. These faults will define breaks in the grid; lines along which the\\nhorizons inserted can be offset later. The offset which occurs is entirely dependant upon the input\\ndata, so modeling reverse faults is just as easy as modeling normal faults. All pillars in the 3D grid\\nwill be extended to meet the top and base of the horizons defining your grid (in Make Horizon and\\nMake Zones processes), so make sure all of your fault models are modeled above the top and\\nbase horizon. A modeled fault must never cross another fault without being connected.\\nFigure c (left) and d. In figure c the horizons has been inserted into the 3D grid. Note that the\\npillars in the grid have been cut by the top and base horizon in the grid (compare the\\nintersections with figure b above). Figure d shows the result after zones have been inserted into\\nthe model. The 3D grid is displayed with horizons and edges.'},\n",
       " {'header': 'Pillar Gridding ',\n",
       "  'content': 'The process of Pillar Gridding will generate a corner point 3D grid from the fault model. Pillar\\nGridding is the process of making the Skeleton Framework. The skeleton is a grid consisting of a\\nTop, a Mid and a Base skeleton grid (See figure a below), each attached to the Top, the Mid and\\nthe Base points of the Key Pillars (the fault model).\\nIn addition to the three skeleton grids, there are pillars connecting every corner point of every\\ngrid cell to their corresponding corners on the adjacent skeleton grid(s).\\nWhen creating your skeleton grid you will work with the Mid Skeleton grid. The Mid Skeleton grid\\nis the grid attached to the mid-lines that connect the Key Pillars. The purpose is to create a grid\\nthat looks OK at the midpoint level, with respect to the grid cell size, orientation and appearance\\nof the cells. The next step is to extrapolate this Mid Skeleton grid upwards and downward in order\\nto create the Top and Base skeletons. The result of the Pillar gridding has to be checked for\\ncrossing pillars, and the intersections (shown in the figure b below) are the most efficient tool for\\nQC. Once the skeleton is , the input surfaces can be inserted into it, honoring the faults that have\\nbeen created.\\nVertical layering\\nVertical layering, or the creation of Stratigraphic horizons and subdivisions, is the final step in\\nStructural modeling. Make Horizons generates independent geological horizons from XYZ input\\ndata, and it is here that the offset on the faults is defined. To generate additional horizons using\\nrelative distance to existing horizons, (e.g. isochores) use Make Zones. When horizons are\\ninserted into the 3D grid, the skeleton grid is modified if the Top and/or Base of the input data\\nextend above or below the Top and/or Base- Shape point. The Pillars in the 3D grid are cut by the\\nlimiting horizons (the top and base horizons) during Make Horizon process if the pillars exceed\\nthroughout the limiting horizons; this is illustrated by figure c below. If additional zones are added\\nabove or below the limits of the 3D grid (Make Zones), the pillars will be extended in order to\\nmeet the top and base of the new zones.\\nGuide to fault modeling and gridding in Petrel\\nStructural modeling is the first step in building a geological model in Petrel. Unlike Seismic\\nInterpretation, Well Correlation, Property Modeling, etc., the way the Structural Modeling is\\nperformed is unique in Petrel. In this chapter we will provide you with some information on how to\\ncreate a fault model and generate 3D grids. However, we will mainly focus on the background\\ninformation of the Structural Modeling process in Petrel. Ultimately, this should help you avoid and\\nsolve any problems which may occur during the process. Specifically, we will cover:\\n1. How Pillar Gridding works\\n2. What you can do to make Pillar Gridding quicker and more successful, allowing you to build\\nmore complex models\\n3. What situations will cause problems when Pillar Gridding.\\nFault modeling, Pillar Gridding and Building Horizons in the grid should be considered as one stage\\nin the model building process. Pillar Gridding is heavily dependant upon a high quality fault model\\nand many of the problems that can occur in the pillar gridding stage are not apparent until\\nhorizons are built within the grid.'},\n",
       " {'header': 'Structural Modeling - Basic Theory ',\n",
       "  'content': \"This section introduces the basic theory of structural modeling in Petrel. The method for building a\\n3D grid in Petrel is quite unique, and having a good knowledge of what actually happens will help\\nyou to recognize problems and understand why they occur.\\n2D and 3D grids\\nA grid is simply a way of storing XYZ locations which describe a surface.\\nIn a 2D regular grid you can do this by giving the elevation of the surface at regular intervals in X\\nand Y. If you imagine two surfaces stored in the same grid, the XY location of each node will be\\nidentical and only the Z coordinate will be different. Petrel's surface objects are examples of 2D\\ngrids.\\nIn Petrel, the fault model is used to define where these curved pillars should be and what shape\\nthey should have. Accordingly, reverse faults can easily be modeled and grid cells will match the\\nedge of the faults.\\nDefining the grid vertically\\nAs described above, the pillars of a 3D grid can be curved in the vertical direction. It is therefore\\nimportant to specify the top and bottom of each pillar. In a 2D grid, all of the pillars are parallel\\nand will never cross at any point. However, in a 3D grid, if we extend all the pillars vertically\\nfollowing the same curve, at some point they will begin to cross. The grid is therefore only useful\\nwithin a certain depth interval. If this coincides with where your model is there are no problems, if\\nnot, you will get negative cells.\\nThe best way to prevent this is to ensure that your fault model covers the whole vertical distance\\nfrom your lowest modeled horizon to your highest. That way you can QC your grid before you\\nbuild your horizons. If you have horizons above or below your fault model, add them to the model\\nin the Make Horizons process, the existing pillars will be extended until they meet these new\\nhorizons. Thus, an initially perfect grid may become twisted after Make Horizons .\\nThis is one of the reasons why it is important to also QC the pillar grid after the Make Horizons\\nand Make Zones processes.\\nHow faults are incorporated into the grid?\\nIn general, it is the shape points in a fault that are honored when you build the model grid and\\nnot the pillars. For example, although a pillar is curved, grid pillars at the same location in the grid\\nwill not necessarily have the same shape.\\nCurved pillars in the center of a fault are ignored in the 3D grid, although all the shape points are\\nhonored.\\nHowever, there are certain instances where the pillar is honored as well as the shape points:\\n1. At the end of a fault.\\n2. At the connection between two faults.\\n3. If there is a trend attached to the fault pillar.\\n2.\\n3.\\nCurved pillars at the end of a fault result in curved pillars in the 3D grid.\\nHow can I QC the grid?\\nThere are a number of tools for QCing the grid.\\n1. Examine the top, middle and bottom skeleton grids\\n2. Examine the pillars using I and J intersections\\n3. Build horizons in your model and display gridlines on the horizons\\n4. Insert horizons and layers (at a relatively fine scale) in your model, and use geometrical\\nmodeling to create a bulk volume property model, then check the statistics and filter on\\nnegative volumes to identify problem areas.\\nWhat should I look for?\\nPoints describing the geological horizons in your model can only be located along the pillars in the\\nmodel grid. It is desirable to have an even distribution of pillars, with enough pillars in all areas of\\nthe model to adequately describe the horizons in the model. If one area of the model has very\\nfew pillars, then the resolution of the horizon in this area will be limited.\\nGrid pillars, together with the model horizons and layers, form the cells for the property modeling\\nand volume calculation. It is important that the pillars do not cross as this will result in cells with\\nnegative volumes. Look for crossing grid lines in the skeleton grids and on horizons and crossing\\npillars in the grid intersections. This usually occurs at the end of steeply dipping faults, or faults\\nwith trends that contrast with the local grid direction.\\nHere a fault in the grid (which must be aligned with a grid line) cuts a grid intersection, indicating\\nnegative cells in the model.\\nWhat causes poor grids?\\nWhen you run pillar gridding, Petrel will first place pillars in the model to honor the faults and\\ntrends in the fault model. Once this is done, pillars will be placed between these defining pillars\\nthroughout the model. When placing these pillars, the aim is to have as smooth a transition as\\npossible, both in the pillar orientation and in pillar shape.\\nWhen building the fault model, try to imagine where Petrel is going to put the pillars and what\\nthey will look like. Try to avoid situations where the angle of pillars varies dramatically over a\\nshort distance, or where the pillars will be forced to diverge or converge. In both of these\\nsituations there is a much higher risk of pillars crossing (and therefore having negative cells) and\\nalso of having areas with few pillars and therefore poor resolution on the horizon.\\nIn some situations, complex geometries will be unavoidable. When these cases arise, pay\\nparticular attention when you QC the result. If the pillar gridding fails, it is highly probable that\\nthe problem is a result of complex geometries. If the model is too complex, try to increase the\\ndistance between the two key pillars that are creating the problems.\"},\n",
       " {'header': 'Simplicity ',\n",
       "  'content': 'In all cases, the grid geometry should be kept as simple as possible. Use as few pillars and shape\\npoints as possible to model the shape of the fault as this will make pillar gridding and fault editing\\neasier. Using five point fault pillars instead of three point pillars may match the input data slightly\\nbetter, but your model is more likely to have crossing pillars and negative grid cells. Choose the\\ntop and bottom of your reservoir model carefully and make sure the top of the faults are smooth.\\nBy minimizing vertical thickness you can often remove the need for truncating faults and will also\\nhave a much more manageable model when you come to property modeling.'},\n",
       " {'header': 'Truncations (Background) ',\n",
       "  'content': 'Truncations in the model grid increase the complexity and is best avoided. Nevertheless, in reality\\nmany, possibly even the majority, of faults are vertically truncated at some point. This problem can\\nbe overcome by reducing the thickness of the model to only the reservoir volume. Truncations above\\nor below this zone can then be ignored and fault modeling and pillar gridding will be much simpler.\\nIf you still need to use truncated faults in your model, the following section will help you.'},\n",
       " {'header': 'Truncations Basics ',\n",
       "  'content': \"There are a few basic things to remember when using truncating faults:\\n1. All of the pillars on the truncated area of the fault must have a corresponding pillar on the\\ntruncating fault, and vice versa.\\n2. The truncated fault must have a trend, although that trend could change from I to J if the\\ntruncation bends.\\nWhat happens in the grid?\\nWhen faults are truncated in the fault model, the pillars in the 3D grid will also be truncated. Inside\\nand adjacent to the truncation, the pillars will follow the plane of the truncating fault and truncate\\nagainst it. On the opposite side of the truncating fault, the pillars will be parallel to the truncating\\nfault.\\nFig. 1 A grid intersection through a truncated fault\\nPetrel's 3D grid is made up of rows and columns and, thus, truncated pillars cannot simply disappear.\\nInstead, they follow the line of the truncating fault until the end of the truncation, where they will fan\\nout into the grid again. These converging grid cells are a natural consequence of having a truncated\\nfault in the grid and need not be a problem. However, these are areas of sharp changes in the pillar\\nangles, and in more complex situations (that is, with steeply dipping faults or other truncations\\nnearby) problems might occur - look out for it when you QC the grid.\"},\n",
       " {'header': 'Fig. 2 ',\n",
       "  'content': \"Multiple Truncations - what's possible\\nIf you look at figure 2, it is obvious that several parallel truncations could be inserted without having\\na great impact on the grid. See figure 3.\\nFig. 3 A grid intersection through a double truncation\\nIt is also possible to have truncations on both sides of a fault, see figure 4.\"},\n",
       " {'header': 'Fig. 4 ',\n",
       "  'content': 'Faults which are truncated both at the top and the base, see figure 5.'},\n",
       " {'header': 'Fig. 5 ',\n",
       "  'content': 'Fig. 6 A fault whose top is truncated by a fault whose base is truncated.\\nBy considering how Petrel deals with truncations (by aligning pillars parallel to the truncated fault),\\nyou can see that certain combinations of truncations are impossible. A rule of thumb is that\\ntruncations cannot be truncated against a fault with a similar truncation (top truncation against top\\ntruncation, etc.).'},\n",
       " {'header': 'Fig. 7 ',\n",
       "  'content': 'Key points when gridding truncations\\nPillars on the truncated fault should be kept as parallel as possible to each other and as perpendicular\\nas possible to the truncating fault. Changes in angle along the fault should be as smooth as possible\\nto make gridding as easy as possible. Simple models will often work without this, but when the faults\\nare steep, the structure complex, and trends are involved, this is essential.\\nWith double truncations, it is important to keep the pillars for both truncations and the truncated\\npillar aligned. The easiest way to do this is to edit the fault shape points in 3D while looking at the\\nsame faults in a 2D view. When the yellow arrows marking the two truncations are aligned, the pillars\\nare aligned.\\nIt is often useful to have trends on the truncated pillar and you might also need to specify the\\nnumber of cells on the trend to ensure that there are sufficient cells inside the truncation. As a\\ngeneral rule, the height of the shape points should be smooth. This is important for the mid shape\\npoint, since it is used to create the mid point skeleton grid which forms the basis for the 3D grid.\\nTruncations to make gridding easier\\nAs a general rule, it is best to avoid truncating faults; however, in some situations it can make the\\ngridding process easier. The transition across the end of a truncation is often a problem area as the\\nangle of the grid pillars changes rapidly in a short distance. If a fault has truncations at intervals\\nalong its length then it may be preferable to have at least one truncation along its whole length to\\nreduce the occurrence of these problematic areas.\\nFig. 8 A gap in the truncation means that pillars revert to passing straight through the grid. By\\ntruncating the adjacent fault, the pillars will have the same aspect along the truncating fault and the\\ngrid becomes much smoother.'},\n",
       " {'header': 'Ending Truncations ',\n",
       "  'content': \"Leaving a truncation open at the end is probably the easiest way of ending it, but many truncations\\nwill probably be closed. This caould be because the truncation has joined the truncating fault or has\\nintersected a crossing fault.\\nIn the case below, the truncation is joined to the fault it was truncated by. This is done by first joining\\nthe two faults, then truncating the pillar where the joining occurs. As both the truncation and the\\ntruncating fault have a trend, a small section of the truncation must be given an arbitrary direction\\n(joining faults cannot have the same trend).\\nWith a more abrupt closure, or in cases where it is not possible to give a section of the truncating\\nfault an arbitrary direction, a second pillar can be added to the end of the truncation. The procedure\\nis identical to that described above; however, the truncation is joined to the same truncating pillar as\\nthe last truncation, rather than the adjacent pillar. In the pillar gridding process, the last section of\\nthe truncated fault is now given an opposite trend to those of the rest of the truncated fault, and all\\nof the columns in the model remain on the same side of the truncating fault.\\nIn cases where the truncation joins a second truncation with the truncating fault, the joining against\\nthe second truncation must be done this way.\\nIf the truncation ends against a crossing fault, the truncation is performed in much the same way.\\nFirst, connect the truncation to the crossing fault, and then truncate the pillar where the joining\\noccurs to the truncating fault.\\nIt might be necessary to move the adjacent pillar on the crossing fault closer to the truncating fault\\nto ensure the fault shape is honored correctly. Nevertheless, this is not essential. In certain\\nsituations, particularly if the truncating fault is steeply dipping, you may wish to truncate additional\\npillars on the crossing fault (see the figure below).\\nThe truncation is handled in much the same way as when the crossing fault also cuts the truncated\\nfault. First, connect the truncation and the truncating fault to the crossing fault, then truncate the\\nconnected pillars against each other.\\nTruncations, what's possible\\nSingle, base truncated\\nSingle, top truncated\\nMulti, base truncated\\nMulti, top truncated\\nTop and base truncated\\nMulti, top and base truncated\\nTruncated base, truncating top\\nTruncations, what's not possible\\nAs a general rule, a fault cannot be truncated by a fault which is itself truncated in a similar way (i.e.\\nboth by the base).\\nTruncated base, truncating base\\nTruncated top, truncating top\\nTruncated base, truncating base\\nBefore truncating\\nEach truncation will make the gridding process more complex and should not be done unless the user is\\nsure that it is the correct solution in each case. Before deciding to truncate two faults, check that the\\nlowest/highest horizon in the grid will be below/above the truncated points. If not, a truncation might\\nnot be the appropriate way to go.\\nAs with connecting faults, it is important to prepare truncations properly. Use the editing functions in\\nPetrel to move the truncating pairs of Key Pillars as closely into position as possible - that way you\\navoid surprises in the truncating process.\\nExample : In this figure there are a few problems, the largest being that the number of truncating Key\\nPillars does not match between the first and the last one!\\nNot very well prepared for truncating.\\nThe other problem is that several of the Key Pillars pairs are not close enough for the user to be sure\\nwhat will happen when the Key Pillars are truncated.\\nThis other figure shows how well the Key Pillar pairs that are to be truncated should be matched up\\nbefore the actual truncation!\\nReady for truncation!\\nNote how little space there is for any surprise movements of the Key Pillars when they are truncated.\\nConclusion : Use the input data available to model how the truncation should be before actually\\nexecuting the truncation. In this way, you will avoid surprises and can spend minimal time on editing\\nthe truncating Key Pillar pairs afterwards.\\nMore information on dealing with truncated faults can be found under Truncations (Background) .\"},\n",
       " {'header': 'Truncating Faults ',\n",
       "  'content': '1. Make the truncating fault active (bold) (click on it in the Petrel Explorer). In the figure in the\\nmain window, this corresponds to the blue colored Key Pillar.\\n2. Select the two Key Pillars that you want to truncate against each other and click on the\\nTruncate Top Pillars or Truncate Base Pillars icon. The Key Pillar from the non-active\\nfault will now be truncated against the Key Pillar in the active fault\\n3. Select the next two Key Pillars to truncate and repeat the process. Continue until satisfied. Use\\nthe Remove truncation icon if needed.\\n4.\\n3.\\n4. At least two Key Pillar pairs must be truncated in Petrel for the truncation to be handled\\ncorrectly. A truncation must by definition have a beginning and an end, hence two pairs of\\ntruncating Key Pillars.\\nCreate the faults first and position them in the correct relation to one another before starting with\\nthe truncation process.\\nThe truncating Key Pillars will now have an extra Shape Point, see the figure in the main window. The\\nnew Shape Point may be edited in the same way as any other Shape Point, the only difference being\\nthat it cannot be moved away from the truncating Key Pillar.\\nThere are two reasons for only being able to truncate one Key Pillar at the time:\\nVery often you will have two faults that are only partly truncated towards each other\\nTruncation is an interpretative geological feature and should not be automatic.\\nWhen doing the Pillar Gridding (see Pillar Gridding ) later on, you will need to make the faults that you\\nhave truncated another fault towards as one main direction. This is to assist the gridding algorithms in\\nthe best possible way. See Trends for more details.\\nMore information on truncated faults can be found under Truncations (Background) this includes\\nan explanation on how to deal with ending truncated faults.\\nHow to truncate rotated faults\\nPetrel will not only allow single truncation but also multiple truncations. For instance, if you are working\\nwith a field of a series of rotated faults you may have one fault truncating two adjacent faults.\\nThe procedure for truncation is the same as described previously in this section.\\nHow to make several truncations on the same side of a Key Pillar\\nIn a case where you have two parallel faults being cut by a common fault, just build the faults in the\\nnormal procedure and position them as you would want them to be. Then truncate them one by one as\\ndescribed previously in this section. The figure below shows how these types of faults will look.\\nHow to truncate a fault offset by another fault\\nTo create this kind of multiple truncation, build the faults as you would normally first, and position them\\ncorrectly relative to each other. Then truncate them one by one as described previously in this chapter.\\nThe figure below shows how these types of faults will look.\\nSolving problems with crossing pillars\\nCrossing pillars normally occur when the fault model requires that two pillars close together have\\nconsiderably different orientations. As explained above, fault pillars within a fault are not normally\\nused directly in the grid themselves, only their shape points. However, when fault end pillars,\\npillars with trends attached or pillars at fault connections are used directly, two such pillars\\ntogether can create a twist in the grid.\\nSteeply dipping faults with opposing angles may cause severe twists in the 3D grid\\nIn the example above, two steeply dipping faults with opposing angles are located close together.\\nIn this situation the mid skeleton grid looks good, but the top and bottom skeleton grids are\\nstretched in different directions, leading to crossing pillars. This can be seen by the fact that the\\ngrid lines of the same orientation cross each other.\\nTop mid and base grids for the above situation\\nThis can often be solved by adding a trend from the end of each side of the two faults and\\nperpendicular to the fault directions.\\nA 2D window showing the opposing faults with perpendicular trends\\nThe 3D grid before and after the trends have been added, with the trends in place the grid is no\\nlonger twisted\\nIf the fault model is complex, then it may not be possible to insert such trends or the trends may\\ncause problems in other areas of the grid. In this case the problem could be solved by simplifying\\nthe situation by either:\\n1. Increasing the distance between the two faults, or\\n2. By slightly straightening the last pillar of each fault.'},\n",
       " {'header': 'Trends (Background) ',\n",
       "  'content': \"Trends control the direction of gridlines in the midpoint skeleton grid and allow the user to control\\nhow the grid is built.\\nIt is a good idea to start without any trend lines at all and see how Petrel manages with the\\ngridding. Inserting too many trends will make the gridding too inflexible and may cause problems,\\nso if you need to put trends in, don't be afraid to also try taking them out.\"},\n",
       " {'header': 'Trends Basics ',\n",
       "  'content': \"There are a few basic rules regarding trends:\\n1. Trends of a similar type (I or J) should be roughly parallel to each other.\\n2. Trends of the opposite type should be roughly perpendicular to each other.\\n3. Trends cannot cross each other or cross a fault without connecting to one of the fault's\\npillars.\\n4. Connected faults cannot have trends of the same type (at the connection point).\"},\n",
       " {'header': 'Twisted Trends ',\n",
       "  'content': 'Inserting trends throughout the entire model is often a good idea. This effectively splits the model\\nup into sections and prevents problems in one area becoming magnified and passed on to\\nanother. However, when you do this, be sure to check the orientation of any pillars you attach the\\ntrend to. Although the trend is inserted in a 2D window, it will honor the 3D shape of the pillars it\\nis attached to and although the trend may appear straight in 2D, in 3D it may be creating a twist\\nin the grid.\\nThe same trend between two fault pillars shown in 2D and 3D.\\nThis is an extreme example, but in some cases, one of the pillars in the trend is in the center of a\\nfault. The orientation of that particular fault pillar can then be changed, making the grid straighter\\nand more uniform without compromising the shape of the fault. Cleaning up this type of problem\\nwill make pillar gridding quicker and produce a much better grid.'},\n",
       " {'header': 'Boundary Trends ',\n",
       "  'content': 'Gridding will go much quicker if the edge of the model is defined by trends and faults with trends.\\nEnsure that all of these bounding faults and trends link up to fully close the model and that each\\nsegment is set as part of the model boundary. Then in the pillar gridding dialog box set the\\noption:\\nWhen using this method it is a good idea to ensure that faults near the edge of the boundary\\ncross the boundary rather than ending just inside it.\\nWhen and Where? (trends)\\nExactly when and where to use trends in a model is highly dependant on the fault structure you\\n1.\\nhave, but there are a few hints:\\n1. Trends running right through the model make the model more stable.\\n2. Trends running perpendicular between two roughly parallel faults help keep the grid\\nstraight. This is especially useful for truncated faults.\\n3. Trends on the end of a fault often help straighten out the grid in a difficult area (especially\\nif the fault is steeply inclined).\\n4. Trends running parallel to faults can help in difficult areas such as around truncations.\\nFault model from Structural Framework\\nThis process converts an existing fault framework from the structural framework to a key pillar\\nbased fault model in a corner point based grid. This process allows the selection / de-selection of\\neach fault within the structural framework model to be converted to a pillar fault model.\\nConnections between faults defined in the structural framework are used for guiding the\\nconnections in \"Fault model from structural framework\".\\nFig. 1 The dialog window for the fault model from the structural framework-process.\\nRules for doing connections between faults: If the angle between two faults is within 70 degrees\\nof vertical then it will be treated as a vertical connection, otherwise it will be considered\\ntruncated. Truncated faults will be modelled as fully truncated if they are a similar length to the\\ntruncating fault, otherwise they will be partially truncated.\\nList of parameters: Fault model from structural framework:\\nCreate new: Specify to create a new fault model.\\nEdit existing: Specify to edit/update an existing fault model\\nStructural framework: Select the structural model holding the fault model\\nHorizons: Select the Top and Base horizons that the process will trim the resulting fault\\nmodel against.\\nList of parameters: Fault model from structural model-process.'},\n",
       " {'header': 'Parameter Function ',\n",
       "  'content': 'Faults: Select to include/exclude all faults from structural framework.'},\n",
       " {'header': 'All/None ',\n",
       "  'content': \"Pink tick Display and undisplay the selected faults in 3D window.\\nbutton\\nName Display the fault's name from structural framework.\\nInclude Specify faults from structural framework being converted to pillar based\\nfaults.\\nShape Specify the amount of shape points (2,3 or 5) for resulting key pillars.\\npoints\\nResult Identify the quality of extracted pillar fault (good, medium and poor) and the\\nquality worst created pillar.\\nResult Identify the type of fault connection (vertical, part truncation and full\\nstatus truncation)\\nSet all Specify the same amount of shape points for key pillars for all faults selected\\nshape\\npoints\\nPillar Specify distance between resulting key pillars\\nspacing\"},\n",
       " {'header': 'Tips: ',\n",
       "  'content': 'The worst quality of pillar in a fault can be selected by single clicking the result quality cell\\nto which belong to that fault.\\nThe fault which cannot be extracted properly can be selected by single clicking the result\\nstatus cell with displayed status.\\nDetails of quality and status report can be seen from tooltip by leaving the mouse into\\nresult quality or status cell in which you are interested.\\nTutorials: Fault model from Structural'},\n",
       " {'header': 'Framework ',\n",
       "  'content': 'Converting a Structural framework into a pillar fault model\\n1. In the Processes Pane open the Corner point gridding > Fault model from the\\nstructural framework process.\\n2. Select to either Create a new structural model or to Edit existing model.\\n3. Choose the name of the new corner point model\\n4. Specify the Structural framework holding the faults used in the process.\\n5. Ensure the correct horizon window is selected - top and base structural horizons are\\nautomatically added\\n6. Select the structural framework faults to be converted to pillars. Use the visualize option\\nto see the faults chosen in the table.\\n7. Select the pillar style (2, 3 or 5 node pillars) and then click Apply.\\n8. By clicking Apply , rather than OK , the dialog will report its analysis of the results.\\nFig 1. The dialog window for the Fault model from structural framework process\\nFig 2. Traditional pillar-fault model constructed based on the Structural framework'},\n",
       " {'header': 'Fault Modeling ',\n",
       "  'content': 'Linear, vertical, listric, S-shaped, reverse, vertically truncated, branched and connected faults can\\nbe created in Petrel. The program allows you to create structurally and geometrically correct fault\\nrepresentations.\\nFaults are built using Key Pillars. A Key Pillar is a vertical, linear, listric or curved line described by\\ntwo, three or five so called Shape Points; two for vertical and linear, three for listric and five for\\ncurved. Several Key Pillars joined together by these Shape Points define the fault plane.\\nWhen building a structural model in Petrel, fault modeling is the first step. The user must create\\nKey Pillars along all the faults to incorporate them into the reservoir model.\\nKeep in mind when building the model, that the Fault Modeling process, in conjunction with the\\nPillar Gridding process, is very much an iterative procedure. Going back to the Fault Modeling\\nprocess may (in some cases) be the solution to some Pillar Gridding problems. This will be\\ndiscussed further in Pillar Gridding.\\nThe theory behind fault modeling and generating the 3D grid is outlined in Structural Modeling,\\nincluding some hints and tips for solving problems with the grid.\\nDefining the Model\\nPetrel lets you work with several different models in one session. It is important to define the\\ndifferent models by giving them appropriate names.\\n1. Double-click on Define Model in the Process diagram.\\n2. Type the name of your model in the opened process dialog and click OK. A model icon\\ntogether with a fault model icon will appear under the Models pane in the Petrel Explorer.\\n3. Type the name of your model in the process dialog.\\nFault Modeling process dialog\\nBefore starting to create faults, it is a good idea to check the settings in the fault modeling dialog.\\nTo open the process dialog, double click on the Fault Modeling text in the Process diagram.\\nThe settings for the display of the faults in the fault model are described in Style (Faults).See\\nStyle tab (Fault Model) for settings regarding the display of the faults themselves.\\nSettings tab (Fault Modeling)\\nUnder the Settings tab, you can change the default increment and height the program gives the\\nKey Pillars when they are created automatically (from fault polygons).\\nHow much the Key Pillars will be extended above and below the selected vertical extension can\\nalso be changed here. The point of being able to extend the Key Pillars vertically is to make sure\\nthat the Key Pillars will extend far enough to cut all input surfaces, isochores, etc. This is\\nimportant since Petrel will extrapolate the faults to the top and base horizon in the Make Horizon\\nprocess, if you have not. This may lead to pillars crossing each other without being properly\\ntruncated/connected. Pillars crossing each other in the 3D model without being truncated will\\ncreate cells with negative volume, which we want to avoid!\\nThe Settings tab in the Fault Modeling process dialog.\\nOperations tab (Fault Modeling)\\nThere are two options available on the Operations tab:\\nCut/Extend Pillars - The tops and bases of the fault pillars in the fault model should be as\\nsmooth as possible before beginning the pillar gridding process. To help with this, Petrel\\nallows the user to extend or clip the top or bottom of the fault pillars to a surface or a\\nconstant z level.\\nAutomatic fault connection - This option will step through the model and automatically\\nconnect faults that are on course to cross within a certain radius of their end points.\\nThe Settings tab in the Fault Modeling process dialog\\nHow to clip the top and base of the fault model to a surface\\n1. Open the fault modeling process dialog and choose the Operations tab.\\n2. Check Top limit or Base limit (or both) depending on which end of the pillars you want to\\nclip.\\n3. Input the required Z-value or drop a surface into the dialog box.\\n4. Choose which pillars the process should be applied to and whether both cutting and\\nextending are active.\\n5. Choose the minimum height for the pillars after the process.'},\n",
       " {'header': '6. Press Execute. ',\n",
       "  'content': '5.\\n6.\\nIt may be useful to clip the faults to the top and bottom geological surfaces in your project.\\nGenerate surfaces from the interpretation data for the top and bottom geological horizons. Use\\nthe calculator to move the top horizon 100 m higher and the bottom horizon 100 m lower. Use\\nthese new surfaces as input for clipping the model.\\nMake sure that the surfaces used for the cut/extend operations are not faulted.'},\n",
       " {'header': 'Creating Faults ',\n",
       "  'content': 'Before you start building the faults, it is important to look through the input data to get an\\nunderstanding of the structural settings of the area you are working on.\\nKey Pillars can be generated in several different ways, based on different types of input data.\\nThey can be generated from seismic sections, surfaces, fault polygons, line data, point data, fault\\nsticks or fault planes and serve as a basis for creating the fault model.\\nAs a Key Pillar for new fault is added, there will be an icon for the new fault in the faults folder of\\nyour model (models pane).\\nNew Key Pillars will be added to the currently active fault (bold in Petrel Explorer). If no fault is\\nactive or if there are no faults in the model yet, a new fault will be created when a new Key Pillar\\nis created. To deactivate a fault, click on it. Remember to deactivate a completed fault in order to\\nbe able to start with a new one.\\nFaults in the fault folder, Main Fault NS being the active one.\\nAny kind of data describing the fault planes can be used as input data to create Key Pillars in\\nPetrel, such as:'},\n",
       " {'header': 'Fault Point Data Fault Polygons/Lines ',\n",
       "  'content': 'Seismic lines\\nGridded surfaces'},\n",
       " {'header': 'Fault Sticks Fault Planes/Surfaces ',\n",
       "  'content': 'Seismic intersections (inlines, crosslines)\\nHow many Key pillars do I need?\\nKey pillars are just used to describe the fault. If the fault geometry is fine and matches the input\\ndata, then you do not need any more pillars. Using as few pillars as possible will ensure the\\nsmoothest possible fault and therefore make the gridding process as straightforward as possible.\\nIt will also mean less work when editing the fault.'},\n",
       " {'header': 'Creating Curved Faults ',\n",
       "  'content': 'Listric and curved Key Pillars should be used to describe faults that are listric or S-shaped such as\\nfaults in flower structures or slump faults.\\nWhen using the tool Create Fault by Two Points , listric and curved Key Pillars will follow a\\nnon-linear surface as accurately as possible. There is one limitation however; the Z-values must\\nbe consecutive, meaning that the Key Pillars cannot follow a structure in which an end Shape\\nPoint (Top- or Base-) has a Z-value that is in between two other Shape Points.\\nLimitation on a curved Key Pillar.\\nKey Pillars from Fault Polygons\\nFault polygons with structurally defined Z-coordinates can be used in the generation of Key Pillars.\\nThe fault polygons are normally generated in the seismic interpretation station or in a mapping\\napplication, and are commonly defined by the hanging wall line and the footwall line for a given\\nsurface.\\nA selected set of fault polygons in 3D.\\nPreparation of fault polygons\\nPolygons may require editing prior to generating faults in the fault model. See Make/Edit Polygons\\nand Operations on points lines and surfaces for a full description of the available operations.\\nPolygons that have no elevation information can be given the Z-values of an input surface -\\nsee Examples of use of operations for an explanation.\\nHow to disconnect fault polygons\\nClick on Disconnect Polygon and click with the left mouse button on the point where you\\nwould like to separate (cut) one fault polygon from another. The longest part of the polygon will\\nbe selected as the active one. This is an important editing process for fault polygon data with no\\nflags or where the polygons need to be disconnected. For more information on fault polygon\\noperations, see Operations.\\nHow to make Key Pillars from fault polygons\\n1. Display the fault polygons.\\n2. In the Process diagram, click on Fault Modeling . A Function bar with icons related to\\nthis process will appear.\\n3. Select Vertical , Linear , Listric or Curved Pillars (located in the Function\\nbar, note that Linear is the default) depending on the type of fault you are describing.\\n4. Select the polygons, representing a specific fault, with the left mouse button.\\n5. To select more than one polyline, press the Shift key as you select.\\n6. Click on Create Fault From Fault Polygons to generate Key Pillars along the selected\\npolygons.\\nProblems associated with making Key Pillars from fault\\npolygons\\nIf the polygons are converging, the end Key Pillars may be converging too, or even become\\ntwisted. If this happens, delete relevant Key Pillars. To select a Key Pillar, click on the Key Pillar in\\nthe Display window. To lengthen the cropped fault, select the current end Key Pillar and click on\\nAdd Pillar to End . See Editing Key Pillars in 3D for further editing operations.\\nThe Key Pillars will automatically be extrapolated above and below the polygons. This is to make\\nsure that the Key Pillars will cover the vertical extension of the fault plane.\\nFor short fault polygons you may need to change the Key Pillar increment defined under the\\nSettings tab in the process dialog for Fault Modeling. The default increment (300 length units)\\nmay be so large that no Key Pillars can be generated with the Create Faults from Fault\\nPolygon tool. The problem is overcome by making the increment smaller.\\nKey Pillars from Structural Surfaces\\nThe throw of the fault is usually quite obvious when looking at a gridded surface. If you can define\\nthe up thrown and the down thrown sides of a fault on a surface, then you can also create Key\\nPillars by digitizing them in 3D. Start by digitizing the up thrown side of the top surface and finish\\noff the Key Pillar by digitizing (actually snapping) the bottom part of the Key Pillar to the down\\nthrown side of the base surface. The Key Pillars will extend beyond the top and base limits of the\\nsurfaces based on a user-defined distance. It should be noted that the Shape Points are not tied\\nto the vertical layering of the 3D grid.\\nOne Key Pillar Following the fault plane with a range between top of Surface 1 and base of'},\n",
       " {'header': 'Surface 2. ',\n",
       "  'content': \"When you are working with large input surfaces, the computer's graphic card can limit the speed\\nand accuracy with which you can move around the surface. To improve these attributes, place the\\ncursor in the Display window and open the display Settings menu by clicking with the right mouse\\nbutton. Select draw style and, for example, move low res. Only the depth contours will now be\\ndrawn when the image is rotated in the Display window, which improves the speed.\\nHow to digitize Key Pillars from surfaces\\n1. From the Input window in Petrel Explorer, display the top surface.\\n2. Select Vertical , Linear , Listric or Curved Pillar.\\n3. Click on Add New Pillar by One Point and make sure that the Set Top Shape Point\\nActive icon is active.\\n4. Start digitizing the upper ridge of the fault. This will be seen as straight Pillars in the\\ngraphics window. A new fault icon (Fault 1) will appear in the Models window in the Petrel\"},\n",
       " {'header': 'Explorer. ',\n",
       "  'content': '5. Continue digitizing until you reach the end of the fault.\\n5.\\nTop of fault digitized.\\n6. Switch off the top surface and display the lower surface.\\n7. Click on Snap Selected Shape Point .\\n8. Select the Base Shape Point you want to move (i.e. position on the base surface) by\\nclicking on it.\\n9. Click on the surface where you want the Base Shape Point to be positioned. Click several\\ntimes if necessary to fine tune. The selected Shape Point will keep being selected until\\nanother Shape Point is clicked on.\\n10. To move another Shape Point, click on that one - the newly selected Shape Point will be the\\none affected when clicking again on the surface.\\nAlways deselect the last fault by clicking once on it before making a new fault.\\nNote that there is a possibility to work with the Snap the Shape Point by Picking tool\\ninstead of the Snap Selected Shape Point . In that case, the procedure is slightly different.\\nDigitized lower surface.\\nHow to use the Snap the Shape Point by Picking tool for digitizing the Base'},\n",
       " {'header': 'Shape Points ',\n",
       "  'content': '1. Click on the Snap the Shape Point by Picking icon.\\n2. Make sure that Set Base Shape Point Active is active.\\n3. Digitize the lower range of the fault by clicking along the base of the fault on the surface to\\nsnap the Base Shape Points to the surface.\\n4. If needed, modify the position of the \"Snapped\" Base Shape Point by clicking again on the\\nsurface.\\n5. Always deselect the last fault by clicking once on it before making a new fault.\\nIn this process, the program will select the mathematically closest Base Shape Point to move. As\\nthe window is in 3D, it may not be the Shape Point that you intended.\\nKey Pillars from Fault Surfaces\\nIf you have fault surfaces available from the seismic interpretation, they can be used directly in\\nPetrel for defining the Key Pillars.\\nKey Pillars from fault surfaces.\\nHow to digitize Key Pillars from fault surfaces\\n1. Display the fault surface.\\n2. Click on Add New Pillar .\\n3. Select Vertical, Linear , Listric or Curved Pillar.\\n4. Digitize one Key Pillar at a time, starting with the top point of the Key Pillar on the fault\\nsurface. It is not necessary to digitize them in a sequential order; the Key Pillar will be\\nplaced on the fault plane where you put them, next to the last one or between two of them.\\n5. Always deselect the last fault by clicking once on it before making a new fault.\\nIf the Add New Pillar by Two Points tool is used instead and the top and bottom point is\\ndigitized only, listric and curved Key Pillars will try and follow the fault surface as accurately as\\npossible.\\nAn alternative way of creating Key Pillars from fault surfaces can be to convert the surfaces to\\nlines. After this has been done, the polygons or lines can be used as input for creating the Key\\nPillars. This can sometimes be a quicker method.\\nHow to convert fault surfaces to polygons\\n1. Click with the right mouse button on the fault surface icon in the Input pane.\\n2. Select Convert to polygons. The lines will have the same name as the fault, but with a\\ndifferent icon. These lines can now be used as fault polygons or fault sticks.\\nThe result of the Convert to polygons operation depends on the gridding of the original data.\\nKey Pillars from Interpreted Seismic\\nInterpreted seismic lines can be used, in the same way as structural surfaces, to define the Key\\nPillars. The geophysicists normally leave a gap in the interpretation where there is a fault. These\\ngaps could be defining the hanging wall line and the footwall line for the fault.\\nGenerating Key Pillars from seismic interpretation.\\nHow to create faults from 3D seismic interpretation lines\\n1. Display the seismic top surface (faulted).\\n2. Click on the Map View Position icon and then on the Orthogonal On/Off icon to\\n\"remove\" the 3D perspective (this is only a visual effect).\\n3. Note that the Magnify icon becomes active. Click on this and use it to select an area in\\nwhich the fault is located. Do not rotate the image!\\n4. Open the Settings window for the seismic surface and tick the Show: points option. Resize\\nthe box shape if necessary.\\n5. Select the Add New Pillar by One Point tool.\\n6. Select Vertical, Linear , Listric or Curved Pillar.\\n7. Digitize the top of your Key Pillars by clicking on the end points of the seismic lines. Note\\nthat the Key Pillars are only there to define the shape of the fault, i.e. do not digitize them\\ntoo densely.\\n8. If needed, move the seismic surface by using Shift+left mouse button (pan).\\n9. When satisfied with the top of that fault, turn off the seismic top surface and display the\\nseismic base surface instead.\\n10. Digitize the base of the Key Pillars using the Snap Selected Shape Point . Always\\ndeselect the last fault by clicking once on it before making a new fault.\\nKey Pillars from an Intersection\\nTo easily include faults that are only slightly offset, Petrel has the option to digitize faults on an\\nintersection plane.\\nTo create an intersection plane, right-click on the folder with, for example, input surfaces (you\\ncan also use folders for other data types such as seismic lines, fault polygons, etc.) and select\\nInsert General Intersection from the menu. For more details about the General Intersection,\\nsee General Intersection. Use the tools for the General Intersection that appear in the Function\\nbar below the Display window. Note that the intersection plane is transparent by default. Click on\\nthe Toggle Visualization on Plane (shortcut key Ctrl+B) icon situated at the left side of\\nthe Function bar. When this icon is active, most input data files (those getting a blue filling in their\\ncheck box in front of the name) can be displayed on the intersection. To display such an object\\noutside the intersection, toggle the Toggle Visualization on Plane icon off.\\nIt is important to remember that we are now talking about different display modes, not changes\\nin the actual data. Only use this \"blue-box\" functionality for intersection view display.\\nTo view both of the lines on the intersection and the item, turn on the item before you click on the\\nToggle Visualization on Plane icon and then turn it on again when the Toggle Visualization\\non Plane is active. Use the Clip in front icon to hide data in front of the plane.\\nTo clip the fault model as well, use the Toggle Clipping by Plane together with the clip\\nin front/behind tools.\\nAn example showing Key Pillars digitized on an intersection.\\nHow to make Key Pillars from an Intersection\\n1. Create a General Intersection plane as described above and click on the Toggle\\nVisualization on Plane.\\n2. Display area of interest based on input data, e.g. top and base reservoir data (surface,\\nseismic lines, etc.).\\n3. Click on the Map View Position icon to get an overview.\\n4. Make the intersection plane vertical; click on the Align Vertically icon in the Function\\nbar below the Display window.\\n5. Activate the intersection plane by clicking on the Manipulate Plane icon.\\n6. Move the plane to the beginning of the fault you want to digitize. Drag it forwards and\\nbackwards with the cursor (in Select/Pick Mode ) or use the right and left arrow keys.\\nTo rotate the plane around its own axis, press the Shift key while moving the cursor.\\n7.\\n8.\\n6.\\n7. Select Vertical, Linear , Listric or Curved Pillar.\\n8. Digitize the Key Pillars by using the Add new pillar icon. First, click on the icon, and\\nthen digitize points, Key Pillar by Key Pillar, by clicking on the plane. The number of points\\nto digitize per Key Pillar depends on the type selected in step 7.\\n9. Select the Manipulate Plane icon again and move the Intersection Plane away from\\nyou to where you want the next Key Pillar to be. Continue until the fault is completed. The\\nGeneral Intersection can also be moved using the Page Up and Page Down keys on the\\nKeyboard. To rotate the plane, use the left arrow and right arrow keys.\\nBuilding your fault model directly on a seismic intersection is an excellent way of interpreting\\nfaults. The interpreter will then spot connecting faults early on and can decide on the type of\\nconnection required, avoiding the need for a \\'reinterpretation\\' fault sticks or polygons later on.\\nKey Pillars from fault sticks\\nFault sticks can be used like fault polygons to create Key Pillars. Fault sticks are sets of line data\\nthat represent the fault plane. The file with fault sticks can represent one fault or a set of faults.\\nFault sticks seen in a 3D window.\\nKey Pillars are auto-generated from the fault sticks, either from all the fault sticks in one file, or\\nfrom selected fault sticks.\\nHow to make Key Pillars from fault sticks\\n1. Display the fault sticks in Petrel Explorer.\\n2. Select Vertical, Linear , Listric or Curved Pillar. All the Key Pillars of the\\nfault will be of the same type when created, but that can be changed after generation.\\n3. In a file with several faults, select the fault sticks in the fault that you want to create the\\nKey Pillars from and then click on the Add to or create fault from selected fault sticks\\nicon.\\n4. In a folder with only one fault, click on the Create fault from fault sticks, surface or\\ninterpretation icon without selecting any fault sticks first.\\n5. A dialog, Convert to Pillar Faults, will pop up.\\n6. In the dialog, set the number of fault sticks to skip. A Key Pillar will be generated for every\\nnth fault stick.\\n7. Set the default height and the extra height. The extra height will be added above and below\\nthe fault sticks to ensure that the fault is defined throughout the model.\\n8. Click OK, and a fault is created on the basis of the fault sticks.\\n8.\\nEditing Key Pillars in 3D\\nAfter you have created a fault you may want to do some fine-tuning on a specific Key Pillar or on\\nthe whole fault. Petrel has the option to either edit single Shape Points or pillars, as well as a\\nselection of Shape Points or pillars. To select more than one, press the Shift key as you make\\nyour selection.\\nRemember that an active fault is always drawn with white lines between the Key Pillars. Some\\nediting features (such as digitizing new Key Pillars or truncating) will affect the active fault.\\nHow to edit a single Shape Point\\n1. Make sure the Select Shape Point tool is active.\\n2. Select the Shape Point you want to edit. A 3D editing widget will appear.\\n3. Click on the editing widget and move the Shape Point in a chosen direction, X, Y or Z.\\n4. To flip the widget before moving it, position the cursor on the square area and press X, Y or'},\n",
       " {'header': 'Z . ',\n",
       "  'content': '5. To undo the movement, click on the Undo tool.\\nNote that the current movement setting ( , or ) will define how free the editing movement\\nis. The Move along line tangent only option is default.\\nTo flip the widget, press the Ctrl key while positioning the cursor on it.\\nDifference in widget direction. Free movement to the left, along tangent to the right.\\nLateral movement of a Shape Point in 3D.\\nThe size of the editing widget can be changed by changing the size of the Shape Point or Horizon\\nNode that it represents. The easiest way is to use the Increase size of shape points icon.\\nThe relative size of the widget can also be changed, see Project Settings . The size of the Shape\\nPoints are set under the Style tab in the Settings window for the Fault Model (see Style Tab\\n(Fault Model) ) or under the Edit Draw Style tab in the Settings window for fault planes (see'},\n",
       " {'header': 'Faults Settings ). ',\n",
       "  'content': 'The Undo tool allows you to undo all the editing movements in the Fault Modeling Process.\\nExcept if you have saved the project or activated another process step in between.\\nTools for editing\\nUndo - Will undo the last editing action. Will work for several steps backwards, unless a\\nconnection/disconnection of faults have been made, the project has been saved or another\\nprocess step has been activated in between. Undo does not work for connecting/disconnecting\\nfaults.\\nToggle fill between pillars - Fills solid color between the pillars. Can be useful as you will get a\\ndifferent view of the fault planes.\\nIncrease size of shape points\\nDecrease size of shape points\\nDrag parallel to intersection - Move Key Pillars parallel to an intersection. Can only be activated\\nwhen an intersection is displayed.\\nAdd/Remove horizon nodes on the active horizon. Only active when select horizon nodes\\ntool is active.\\nAdd New Pillar - Digitize a new Key Pillar to an active fault. Select type of Key Pillar. Digitize\\neach Shape Point of each Key Pillar.\\nAdd New Pillar by One Point - Digitize a new Key Pillar by one point to an active fault. Select\\nalso type of Key Pillar. The Key Pillar will initially be vertical regardless of the type selected.\\nAdd New Pillar by two Points - Digitize a new Key Pillar to an active fault. Select type of Key\\nPillar. Digitize the top and the base shape point of each Key Pillar.\\nSnap the Shape Point by Picking - Snaps the nearest Shape Point to where you click on an\\nobject. Remember that you are in 3D.\\nSnap the Selected Shape Point - Snaps a selected Shape Point to where you click on an object.\\nA safer version of the tool described above.\\nDisconnect polygon - Select this tool and then click on a polygon in the Display window to cut a\\npolygon.\\nFree movement - A selected Shape Point or Key Pillar can be moved in all directions with no\\nrestrictions.\\nMove in Pillar Plane - A selected Shape Point or Key Pillar can be moved within its plane only.\\nMove along Tangent - A selected Shape Point or Key Pillar can be moved along its Key Pillar\\ntangent only.\\nSelect Shape Point - To edit on Shape Points.\\nSelect Pillar - To edit on Key Pillars.\\nAdd Pillar to End - Select an end Key Pillar and click on this tool to add a new one next to it.\\nAdd Pillar Between - Select two Key Pillars next to each other and click on this tool to add one\\nbetween them.\\nConnect Two Faults - Merge or connect faults that meet or intersect.\\nDisconnect Faults - To disconnect previously connected faults.\\nNew branched fault - To start building a branched fault from a specific Key Pillar.\\nNew crossing fault - To start building a crossing fault from a specific Key Pillar.\\nTruncate Top Pillars - Will truncate two selected Key Pillars at the top.\\nTruncate Base Pillars - Will truncate two selected Key Pillars at the base.\\nRemove truncation - Will remove a previously done truncation.\\nSmooth Shape Points - Will smooth selected Shape Points.\\nSmooth Shape Points (Z-level only) - Will smooth the Z-level of selected Shape Points.\\nEqual Space Pillars - Will smooth the distance between selected Key Pillars.\\nMove Pillar Into Plane - Will move selected Key Pillars into a plane along the normal of a fault.\\nLock/Unlock to well top - allows the user to lock/unlock a Key Pillar to a well top. Any type of\\nwell top can be locked to a Key Pillar. Select the Key Pillar and the well point that should be tied\\ntogether and then click on this icon.\\nSelect Horizon nodes - Toggle on/off a tool bar for editing fault-horizon intersection lines\\nexclusively.\\nAuto-select Horizon nodes - Only available when Add/Remove horizon nodes on the active\\nhorizon is active\\nCreate Horizon lines from selected polygon - Will generate a new horizon line from the\\nhighlighted polygon.\\nAdd/move horizon node at the front of the fault.\\nAdd/move horizon node at the back of the fault.\\nCollapse Horizon Nodes - Will collapse pairs of nodes that are highlighted.\\nExpand Horizon Nodes - Will expand pairs of nodes that are highlighted.\\nHow to move Key Pillars between models\\nKey Pillars can be copied from one fault model to another. This enables the user to, for example,\\nmerge two models.\\nHow to copy a selection of Key Pillars from one model to\\nanother:\\n1. Display those Key Pillars to be copied in the 3D window.\\n2. Go to the right mouse button pull down menu (of the Fault Model from which to copy) and\\nselect Copy visible faults . A warning message appears urging you to select all connected\\nfalls if the connections should be copied over.\\n3. Right-click on the Fault Model to which the faults are being copied, and select Paste visible\\nfaults .\\nChanging Key Pillar type\\nThe type of Key Pillar can always be changed at any time during the Fault Modeling process.\\nSelect a Key Pillar and click on a new Key Pillar type: Vertical , Linear , Listric or\\nCurved . When changing to a more complex Key Pillar type, the Key Pillar will keep its original\\nshape. If changing to a less complex Key Pillar type, however, the Key Pillar will be drawn\\naccording to its new criteria.\\nHow to lock a Key Pillars to a well tops\\nA Key Pillar can be locked to a well top to ensure that this part of a fault is located exactly where\\nindicated by a fault top in a well.\\n1. Select the Key Pillar and the well top in the Display window. Press Shift in order to select\\nmore than one object.\\n2. Click on the Lock/Unlock To Well Top icon. Note the disc shaped point that appears\\non the Key Pillar. This indicates that the Key Pillar is properly locked to the well top.\\nTo unlock, select the Key Pillar and click on the Lock/Unlock To Well Top icon again.\\nThe size of the disc is relative to the size of the Shape points.'},\n",
       " {'header': 'Connecting Faults ',\n",
       "  'content': 'All faults intersecting each other in a Petrel model must be properly connected. This is important\\nbecause the gridding process in Petrel will use the faults for guiding the gridding lines and faults\\nthat are unconnected are treated differently from faults that are connected. Furthermore, faults\\nwhich are close together but unconnected are likely to lead to problems in Pillar Gridding and'},\n",
       " {'header': 'Make Horizons. ',\n",
       "  'content': 'Petrel has an automatic fault connection option which will connect all the simple branching and\\ncrossing faults in a single operation. Use this option carefully and always QC the grid afterwards.\\nConnecting faults requires some editing of the fault position and you will normally have to edit the\\nconnection manually afterwards. Truncated faults will not be handled by automatic connections.\\nAutomatic fault connections\\nAutomatic fault connection naturally requires that Petrel edits the faults in the fault model and\\nthis option should be used with great care. It is recommended that you use this option as a first\\nattempt at connecting faults and QC the results carefully afterwards. You should always make a\\ncopy of your fault model before you use the Automatic fault connection option.\\nAutomatic fault connection will not handle the following faults correctly:\\nTruncated faults\\nFaults of different elevations\\nFaults at different heights\\nFaults with complex geometries\\nTurn these faults off before using the Auto Connect option.\\nThe settings for automatic fault connections can be found in the Fault Modeling process dialog.\\nDouble-click the Fault modeling icon in the Process window and select the Operations tab.\\nThere are four settings for Automatic fault connection\\nOnly use visible faults - connects only the visible faults. Use this option to prevent Petrel\\nfrom trying to connect truncated or complex faults in the model.\\nExtend distance - this defines the maximum radius at which to connect faults. Crossing\\nfaults or faults on course to cross another fault within this radius will be connected.\\nRemove Distance - this defines the distance from the connecting pillar within which other\\npillars will be deleted. If a fault crosses another fault by less than this distance, then the\\nconnection will be made as a branch (T-junction) rather than a crossing fault.\\nAuto Connect - use this button to automatically connect the faults in the fault model.\\nPrepare a connection\\nIt is recommended to prepare the connection before executing it. Make sure the vertical extension\\nof the two connecting Key Pillars is fairly similar. If not, adjust the least extended fault smoothly\\ntowards the connecting Key Pillar.\\nA rough (left) and a smooth (right) connection.\\nFor faults that connect at an angle in the vertical direction, it is also important to try to adjust the\\nangel/inclination on the Key Pillars before connecting. We do this to get a smooth transition\\nbetween the pillars since a sharp shift in the pillar directions will give a more complicated grid.\\nExample of how to move Key Pillars for a smooth connection.\\nThe importance of having smooth transitions between connecting faults in Petrel is to lay the\\nground for a pillar grid as orthogonal as possible. The better the pillar grid quality, the better the\\nprecision of the final model and its volumes.\\nHow to connect two faults\\n1. Zoom in on the area where two faults are to be connected.\\n2. Select the two Key Pillars you want to connect. To select more than one Key Pillar, press\\nthe Shift key while selecting.\\n3. Click on Connect Two Faults and define how you want to connect them by answering\\nthe Input data dialog that appears.\\n4. If you change your mind, use Disconnect Fault\\nAlways try to keep the connection between two faults as smooth as possible.\\nConnecting two faults.\\nInput data dialog\\nWhen connecting two faults, a Data dialog will pop-up and will show the different possibilities for\\nthe connection. All possibilities may not be available for every connection. The dialog will sense\\nwhich faults are involved and state their name and display their color. There are four different\\noptions for how to connect the two selected faults:\\nExtend one of the faults.\\nExtend the other one.\\nCreate a new fault in between the two.\\nMerge the two faults into one.\\nIf the option Fit the connected pillars to both fault planes is checked, the connecting Key\\nPillars will be directed so that they become parallel.\\nHow to make branched or crossing faults\\nPetrel has a couple of alternative tools for making branched and crossing faults. For general\\ndetails of how to connect faults in Petrel, see How to connect faults.\\nSelect the Key Pillar where you want the crossing or branching fault to initiate from.\\nClick on New branched fault or New crossing faults to generate the new fault.\\nYou can then continue building the new branched or crossing fault by adding new pillars.\\nRemember that the fault you are working with must be active (highlighted).'},\n",
       " {'header': 'Vertically Truncated Faults ',\n",
       "  'content': 'Vertically truncated faults are common in nature but difficult to implement properly in a structural\\nmodel. Petrel solves this situation by connecting and truncating the Key Pillars along the faults\\nbefore the full 3D grid is made. For a more detailed explanation of how truncations are dealt with\\nin the 3D grid, the problems associated with truncations and how to solve them, see Truncations'},\n",
       " {'header': '(Background). ',\n",
       "  'content': 'There are some specific icons for truncation:\\nTruncate Top Pillars will truncate the Top Shape Point towards the selected Key Pillar.\\nTruncate Bottom Pillars will truncate the Base Shape Point towards the selected Key'},\n",
       " {'header': 'Pillar. ',\n",
       "  'content': \"Remove truncation . Use this when you revise the interpretation of how two faults are\\ntruncated toward each other.\\nTruncations, what is possible\\nSingle, base truncated\\nMulti, base truncated\\nTop and base truncated\\nTruncated base, truncating top\\nTruncations, what is not possible\\nAs a general rule, a fault cannot be truncated by a fault which is itself truncated in a similar way\\n(i.e. both by the base).\\nTruncated base, truncating base\\nTruncated top, truncating top\\nBefore truncating\\nEach truncation will make the gridding process more complex and should not be done unless you\\nare sure it is the correct solution in each case. Before deciding to truncate two faults, check that\\nthe lowest/highest horizon in the grid will be below/above the truncated points. If not, a\\ntruncation may not be the appropriate way to go. As for connecting faults, it is important to\\nprepare the truncations properly. Use the editing functions in Petrel to move the truncating pairs\\nof Key Pillars as closely into position as possible  that way you avoid surprises in the truncating\\nprocess.\\nTruncating faults\\n1. Make the truncating fault active (bold) by clicking on it in the Models pane.\\n2. Select the two Key Pillars you want to truncate against each other and click on the Truncate\\nTop Pillars or Truncate Base Pillars icon. The Key Pillar from the non-active fault will now be\\ntruncated against the Key Pillar in the active fault\\n3. Select the next two Key Pillars to truncate and repeat the process. Continue until satisfied.\\nUse the Remove truncation icon if needed.\\n4. At least two Key Pillar pairs must be truncated in Petrel for the truncation to be handled\\ncorrectly. A truncation must, by definition, have a beginning and an end, hence two pairs of\\ntruncating Key Pillars.\\nCreate the faults first and position them in the correct relation to one another before starting with\\nthe truncation process. The truncating Key Pillars will now have an extra Shape Point, see the\\nfigure in the main window. The new Shape Point may be edited in the same way as any other\\nShape Point, the only difference is that it cannot be moved away from the truncating Key Pillar.\\nThere are two reasons for why you can only truncate one Key Pillar at the time:\\nVery often you will have two faults that are only partly truncated towards each other\\nTruncation is an interpretative geological feature and should not be automatic.\\nLater on, when you do the Pillar Gridding (see Pillar Gridding) , you will need to make the faults\\nthat you have truncated another fault towards as one main direction. This is to assist the gridding\\nalgorithms in the best possible way. See Trends for more details.\\nMore information on truncated faults can be found under Truncations (Background). In addition,\\nthere is an explanation on how to deal with ending truncated faults.\\nHow to truncate rotated faults\\nPetrel will not only allow single truncation but also multiple truncations. For instance, if you are\\nworking with a field of a series of rotated faults you may have one fault truncating two adjacent\\nfaults. The procedure for truncation is the same as described previously in this section.\\nHow to make several truncations on the same\\nside of a Key Pillar\\nIn the instance, where you have two parallel faults being cut by a common fault, build the faults\\nin the normal procedure and position them as you would want them to be. Then, truncate them\\none by one as previously described.\\nHow to truncate a fault offset by another fault\\nTo create this kind of multiple truncation, build the faults as you normally would, and position\\nthem correctly relative to each other. Next, truncate them one by one as prevously described.\\nHow to generate Fault-Horizon intersections\\nfor the 3D Grid\\nThe fault modeling process is also used to create/edit fault-horizon intersections for use in the 3D\\ngridding processes. The geometrical relationships are stored on the fault model as Horizon\\nLines. These Horizon Lines can be used as input for the Make Horizons and Scale Up\\nStructure processes to ensure structural consistency between different 3D grids belonging to\\na common fault model. There are several ways to generate Horizon Lines on the Fault Model.\\nFrom input polygons describing the intersection between the horizon and each side of the\\nfault.\\nBy digitizing them directly on to Fault key pillars in a 3D window\\nBy re-sampling from a previously defined 3D grid\\nFolder structure containing Horizon Lines.\\nThe different sides of the fault are distinguished by dotted lines (back) or solid lines (front)\\nHow to generate new horizon lines from polygons\\n1. Activate the Select Horizon Nodes icon from the function bar\\n2. Display the desired polygon in the 3D window\\n3. Select Create Horizon lines from selected polygon\\n4. A horizon line is generated on the Fault Model.\\n3.\\n4.\\nIf you want to add to existing horizon lines, you can activate the object (make it bold)\\nHow to generate new horizon lines without input data\\n1. Activate the Select Horizon Nodes icon from the function bar\\n2. Select Add/move horizon nodes on the active horizon\\n3. Select either to Add/move horizon node at the front of the fault or back of the\\nfault\\n4. Select a key pillar in the appropriate position to add the point and continue to the next key\\npillar\\n5. Repeat the process until you have completed the fault-horizon intersections for all faults.\\n6. Edit the horizon nodes accordingly to refine the horizon-fault relationship\\nSelect Auto-select Horizon nodes to add nodes between the picked and selected\\nhorizon node.\\nWhy use Horizon Lines in modeling\\nHorizon lines are extremely useful as they represent the desired relationship between a fault and\\na horizon. Because they are stored on the Fault Model they can be used to generate multiple 3D\\ngrids with consistent structural relationships. Typically, you would use the horizon lines stored on\\nthe Fault model during Scale Up Structure or to refine the geological grid to ensure that the\\nstructural relationship remains constant between the fine and coarse grids.\\nHow to generate Horizon Lines from 3D grid\\nA common situation is to go through the Fault modeling, Pillar Gridding and Make Horizon\\nprocesses using the available input data, and then to use the quality control tools available in\\nPetrel (see General Intersection.) to check the quality of the resulting 3D grid. In most situations,\\nthe workflow runs fine and no editing is required. However, in certain situations, for example\\nwhere there is a complex fault-horizon relationship, it may be necessary to fine-tune the model\\nbefore property modeling and Up-Scaling:\\n1. Run through Fault Modeling, Pillar Gridding and Make Horizons processes.\\n2. Quality check the model. There can be areas where the fault-horizon relationship is not as\\ndesired .\\n3. Open the settings for horizons or the chosen horizon and choose the Operation tab.\\n4. Choose the appropriate settings and sample the lines to any fault model, or resample them\\nfrom a fault model.\\n5. Click on the Resample icon, icon and use the pick tool to edit the desired points\\n6. After editing, select the option to Resample from fault model on the horizon object to\\nupdate the changes\\n7. Quality control the result and continue with the further modeling steps\\n8. During Scale Up Structure select to resample the horizon-Fault intersections from the\\nFine Grid (default)\\nNote that the re-sampling from the fault model uses one grid cell interpolation. You can re-\\nrun Make Horizons to use a greater fault stepping distance.\\nYou can also choose to use the horizon lines stored on the fault model when you upscale the\\nfine geological grid to a coarser simulation grid in the Scale Up Structure process.\\nAlternatively, you can use the horizon-fault intersections directly.\\nHorizon from fine grid.\\nHorizon from fine grid (red) and up-scaled horizon (pink) with no re-sampling - note the\\ndifference in horizon intersection with the fault.\\nHorizon from fine grid (red) and up-scaled horizon (pink) using re-sampling technique\\nHow to generate Horizon Lines using polygons\\nIn situations were it is necessary to avoid the extrapolation that will take place during Make\\nHorizons, it is possible to use polygons as input for horizon lines. Use the following workflow:\\n1. Display polygons representing offset horizons in 3D.\\n2. Display the corresponding faults from the Fault Model folder. Make the fault that the\\nhorizon line is to be attached to active (bold).\\n3. Activate Fault Modeling and click on the Select Horizon Nodes icon from the\\nfunction bar (red circle).\\n4. Select the polygon to be used to generate the horizon line (green circle).\\n5. Click on the Create horizon lines from a selected polygon on the active fault icon\\n(yellow circle). If you do not already have an active horizon line, a dialog will open up,\\nasking if you want to generate a new one. The Horizon line is displayed on the fault and\\nalso placed in the Horizon Lines folder in the fault model.\\n6. To make a horizon line for a different horizon, de-activate the horizon line before you\\nrepeat the steps above.\\n7. In order to be used in the Make Horizons process, the horizon lines must be renamed to be\\nthe same as the output horizon.\\nHorizon lines are organized according to the horizon's placement relative to the orientation\\nof the fault. Horizon lines located on the 'front' of the fault are solid and horizon lines located on\\nthe 'back' of fault are dotted.\\nFault from fault model and fault polygon displayed in 3D window. The two circled icons are used in\\nthe process to generate the horizon lines.\\nQuality control of the fault model\\nThe end result must be a fault model which accurately represents the input data provided along\\nwith your own interpretation of the structure. In addition, the generated fault model must comply\\nwith a few rules in order for the 3D grid to be created by the gridding algorithm without too many\\nproblems.\\nAlways connect crossing faults\\nTruncated faults must be properly truncated to each other, Key Pillar by Key Pillar. End\\ntruncations must be connected.\\nIn general, keep the top and base Shape Points of the faults as even as possible.\\nKeep the pillar geometry as simple as possible. There is no point in creating a listric fault if\\nit is not needed.\\nKeep the shape of the faults as simple as possible. Minimize the number of Key Pillars in\\neach fault - they shall only define the shape of the fault, not sample the data at close\\nintervals.\\nAn Allen diagram is also a way of analyzing the fault models. For details on this, check Allen\"},\n",
       " {'header': 'Diagram (Juxtaposition Diagram). Pillar Gridding ',\n",
       "  'content': \"The generation of structural models is done in a process called Pillar Gridding. Pillar Gridding is a\\nunique concept in Petrel where the faults in the fault model are used as a basis for generating the\\n3D grid. Several options are available to customize the 3D grid for either geo-modeling or flow-\\nsimulation purposes.\\nSince the Key Pillars are closely involved in the gridding process, there is a close relationship\\nbetween the Fault Modeling process and the Pillar Gridding process. You may need to go back and\\nwork on the Fault Modeling process in order to solve problems appearing in the gridding process.\\nThese problems could have been created during the fault modeling but not visible before you start\\nwith the gridding process. The relationship between the Fault Modeling process and the Pillar\\nGridding process is an iterative one and you should spend time on it in order to attain a grid of\\ngood quality and high cell orthogonality.\\nThe result from Pillar Gridding is a set of pillars, both along the faults but also in between faults.\\nThe grid has no layers, only a set of pillars with user given X and Y increments between them (like\\na pincushion). The layering is introduced when making horizons and zones, see Make Zones and\\nLayering and Make Horizons.\\nThe main focus in developing Petrel's pillar gridding process has been aimed at the gridding\\nalgorithms, to make them flexible as well as fast, accurate and reliable. During the Pillar Gridding,\\nyou can guide and control the result of the grid interactively by adding or removing trend lines, by\\nchanging increments and other settings, and by choosing different pillar geometries. This is an\\niterative process, almost like a dialog between the user and the application.\\nThe theory behind Pillar Gridding and Fault Modeling is outlined in Structural Modeling,\\nincluding some hints and tips for solving problems with the grid.\"},\n",
       " {'header': 'Gridding Process ',\n",
       "  'content': 'Gridding begins with the generation of a \\'skeleton\\' or \\'2D\\' grid between the mid points of the Key\\nPillars. Top and bottom grids are then generated from the top and bottom points of the Key\\nPillars, (see figure below). The Z coordinates of top, middle and bottom grids have nothing to do\\nwith the positions of any future horizons. We usually refer to this stage as being \"dimensionless\".\\nMid skeleton grid (left) and Top-, Mid-, and Base skeleton grid (right) defined between Shape'},\n",
       " {'header': 'Points. ',\n",
       "  'content': 'The reason for having a so-called \"dimensionless\" grid is to simplify future updating of your\\nstructural model. By not introducing Z-values (vertical layering) at this stage, the actual\\nframework can be kept intact when adding new or changed data to the model. Using input data\\nsuch as interpreted seismic lines, scattered points (well tops) or surface grids imported from an\\nexternal mapping package, will create horizons in Petrel, and will be discussed further in Make'},\n",
       " {'header': 'Horizons. ',\n",
       "  'content': 'Geological vs. simulation grid\\nPreserving small features from well logs and seismic data is significant for a geological grid. These\\ngrids are designed to preserve the heterogeneity of the reservoir by typically subdividing it on a\\nfine scale vertically, as well as keeping the XY-representation of the grid cells as small as possible.\\nA geological grid often has millions of cells. Volume calculations are important in this type of grid\\nand that is also why we try to honor the faults during the 3D gridding process by choosing the\\nmost appropriate fault geometries.\\nThe simulation grid must have grid cell geometries which conform to the requirements of the\\nspecific flow simulator used. Using zigzag type faults is one option to keep the grid cells as\\northogonal as possible. The size of the simulation grid is commonly around 50,000 cells,\\ndepending on the flow simulator and the hardware used for the simulation. Going from a\\ngeological grid to a simulation grid requires a more or less radical homogenization of property\\nvalues, which also needs to be taken into account. Fault geometries may also require\\nsimplification.\\nBefore starting with the Pillar Gridding\\nThere are some things that we recommended you check before you start with the Pillar Gridding\\nprocess:\\nAre there any crossing faults that are not properly connected\" Check (in the 3D window) for\\nfaults that have a crossing path and for faults that meet - do they have a shared (gray\\ncolored) Key Pillar? If not - use the Connect Two Faults tool in the Fault Modeling\\nprocess to connect them. (see figure below.)\\nTwo faults not properly connected (left) vs. correctly connected pillars (right), note the grey\\nconnecting pillar.\\nDoes any Key Pillar extend beneath another in Z? See the figure below for an example.\\nCheck in a 3D window - it may not be obvious in 2D as only the Mid Shape Points are\\ndisplayed here. If there is a problem, go back to Fault Modeling and edit the Key Pillars\\ninvolved until there is no overlap anywhere. A truncation may be the correct solution to the\\nproblem in some cases, see Vertically Truncated Faults for details.\\nKey Pillar extending beneath another in Z (viewed from above).\\nDo all of the Key Pillars extend above and below the top and base of the final top and base\\nof the model. If they do not, they will be automatically extended by Petrel during the Make\\nhorizon or Make zones processes. If the original pillars converge, then this extension can\\nresult in pillars that cross each other as described above. Remember that the Key Pillars are\\nthere to define the slope and shape of the faults only, not their vertical extension, so don\\'t\\nworry about extending dying out faults above their true extension. The one exception to this\\nrule is truncated faults.\\nAre all transitions between neighboring Key Pillars smooth? If not, go back to Fault Modeling\\nand correct this. Radical differences in vertical extension of neighboring Key Pillars will\\nimpede the gridding algorithms.\\nIs the Z-extension reasonably similar to all Key Pillars - relative to the top and base\\nreference? If not, go back to Fault Modeling and correct it. The smoother the total\\nimpression of the fault model is, the greater the probability of the grid becoming smooth\\nand of high quality.\\nTruncated faults have a number of additional requirements, see Gridding of Truncations.\\nGeneral workflow in Pillar Gridding\\nIt is important to keep the future 3D model in mind when working on the grid layout. Try to keep\\nthe skeleton grid cells as orthogonal as possible. A good rule is to start simple and then add\\ndetails to generate a more complex grid, one step at a time\\nThe complete workflow in the Pillar Gridding process comprises a series of important steps:\\n1. Double-click on Pillar Gridding in the Process diagram. The Pillar Gridding process\\ndialog will open up. A 2D window will automatically open and display your fault model in a\\nmap view.\\n2. Rename the 3D grid in the Settings tab. Move the process dialog aside (or close it) for\\nbetter view of the 2D window.\\n3. Build your boundary around the area of interest (for instance, display an input surface to\\ncheck the area of interest).\\n4. Open the process dialog and check the various settings under the different tabs (optional)\\nbefore going to the Execute tab and clicking Apply to generate the 2D grid.\\n5. If required, two perpendicular fault directions (I and J) can be defined within the grid.\\nAssign I- and J-directions to faults, and parts of faults, that follow these directions\\nrespectively. Run the gridding process again to find out where the grid needs more work.\\n6. Add trends to further improve the grid. Run the grid to check how well the trends work. Edit\\nif needed and run again.\\n7. When you are satisfied with the 2D grid, click OK to generate the 3D grid. If there are\\nproblems that cannot be solved with directions and trends go back and edit on the Key\\nPillars in the Fault Modeling process step.\\nIt is a good idea to go through the 2D gridding several times with different selections of directions\\nand trends before generating the 3D grid. The program will allow you to quickly rebuild the XY\\ngrid as many times as you wish.\\nPillar Gridding process dialog, the Settings tab.\\nSometimes a pop-up dialog will appear with the message Can not incorporate ... Continue\\nanyway\" - This message is telling you that there is something in the settings that the program\\ncannot solve mathematically.\\nIf you answer Yes to the question, the gridding will continue and color the affected points on the\\ngrid when finished. A No answer will stop the gridding process and color the affected points.\\nSome of the common reasons for this message appearing are:\\nA trend crossing a fault - this is not allowed.\\nA trend set in conflict with a fault defined as I- or J-direction\\nTriple points: Are there more than two faults and/or trends originating from one point\"\\nTwo faults at exactly 45degrees angles - solve this with trends.'},\n",
       " {'header': 'Make Simple Grid Process ',\n",
       "  'content': 'The Make simple grid process is located under Utilities, and provides a simple alternative to\\nthe pillar gridding process for creating 3D grids with no faults. Creating a simple 3D grid in this\\nmanner gives you access to the more rigorous volume calculations of the Volume Calculation\\nprocess without the need to go through the Pillar gridding and Make horizons processes.\\nAt the top of the Make Simple Grid process dialog, the name of the new 3D grid, or the name of\\nthe grid to overwrite, must be given. There is also an option to supply a boundary.\\nInput data tab (Make Simple Grid)\\nThe top and base of the 3D grid can be defined using constant values or surfaces.\\nHorizons can be defined in the 3D grid at this stage. Horizons are defined using surfaces as input.\\nThe surfaces must be organized in stratigraphic order before pressing Apply to generate the grid.\\nTo reorder the surfaces, use and . The horizon type can be set by changing the surface type\\nin the Info tab of the settings dialog of the surface used as input.'},\n",
       " {'header': 'Erosional ', 'content': 'The horizons below will be truncated.'},\n",
       " {'header': 'Base ', 'content': 'The horizons above will be on-lapping.'},\n",
       " {'header': 'Discont ', 'content': 'Combination of erosion and base types.'},\n",
       " {'header': 'Conformable ',\n",
       "  'content': 'Will be truncated by erosional, base and discontinuous horizon.\\nGeometry tab (Make Simple Grid)\\nThe boundary of the grid can be chosen as the boundary specified above or set automatically\\nfrom the input data.\\nThe settings here are identical to those in Make Surface see Geometry tab (Make Surface) for\\ndetails.\\nTartan grid tab (Make Simple Grid)\\nThe Make tartan grid option allows you to create grids with non-uniform refinement. The grid\\nsize and position are taken from Geometry tab in the normal manner.\\nThe region for gridding is divided into sub-regions (one per row of the table) in the order supplied\\nin the table. A rule defines the size of a sub region, number of cells and type of refinement\\n(uniform or logarithmic).\\nRules in I and J logical directions are specified and applied independently. If rotation is not used I\\nand J directions will coincide with X and Y directions.'},\n",
       " {'header': 'Density Uniform ', 'content': 'cells have equal size'},\n",
       " {'header': 'Logarithmic, Central ',\n",
       "  'content': 'cell sizes grow logarithmically from the center of the sub region'},\n",
       " {'header': 'Logarithmic, Custom ',\n",
       "  'content': 'cell sizes grow logarithmically from the specified well position in the sub region'},\n",
       " {'header': 'Logarithmic, I-,J- ',\n",
       "  'content': 'cell sizes are growing logarithmically in the direction with decreasing I or J.'},\n",
       " {'header': 'Logarithmic, I+,J+ ',\n",
       "  'content': 'cell sizes are growing logarithmically in the direction with increasing I or J.\\n#cells\\nnumber of cells in the sub region. This must be an odd number if logarithmic density is\\nchosen.\\nAver. cell. size\\nfor uniform refinement it is the actual dimension of the cell, for other refinements the size of\\nthe sub Aver. cell. size * number of cells represents the dimension of the sub region. The\\nlogarithmic refinement options then fits the desired number of cells into this size of region.\\nInner cell\\nthe size of the first cell in a logarithmic refinement.\\nWell position\\nis defined by X or Y coordinate of the first point in a well trajectory, a point set or a polygon\\ndropped into a rule for I or J direction. The well position must lie within the grid boundary. If\\nGridding to a set of wells is not chosen it also must lie within the sub region\\'s boundary.\\nIf Normalize to fit the grid size option is chosen all sub region sizes are uniformly scaled to fit\\nthe boundary (given on Geometry tab). Otherwise sub region sizes are determined as average\\ncell size multiplied by the number of cells. The resultant overall grid size as a sum of sub region\\'s\\nsizes may not fit the boundary.\\nIt is recommended to use Gridding to a set of wells option if more than one well is specified\\nusing the Logarithmic, Custom density rule. Rules will be automatically reordered and cell sizes\\nwill be computed to fit the given configuration of wells. Only Logarithmic, Custom density is\\nallowed with this option.\\nIt is recommended that the Preset rules are used to understand the sometimes complex\\ninteraction between the options within each region.\\nTools for Pillar Gridding\\nThere are a number of tools available in the Function bar during the Pillar Gridding process steps.\\nThese tools will be used throughout this chapter and some of them will be described in greater\\ndetail.\\nMagnify - Tool for controlled zooming. Click on the icon and then click and drag to define\\nwhich area to display.\\nSelect and Edit Points- Move selected boundary or trend point. Select the point you want to\\nmove, and then drag it along with the cursor. If you click on a boundary or trend where there is\\nno previous point, a new point will be added.\\nCreate Boundary - Build a boundary around your data set. Use this tool when there are no\\nfaults that extend to the limit of the area of interest. Note that a boundary cannot cross over a\\nfault. An external boundary can be imported to or digitized in Petrel, see Digitizing polygons for\\ndetails.\\nCreate Boundary Segment- Create a boundary segment between two faults. Use this tool\\nwhen there are faults within the model that extend to the limit of the area of interest.\\nShow Points - Toggle to show all points (representing Key Pillars) or to show end points only\\nfor better viewing. The size of the points can be changed as can the color of selected faults - go to\\nthe Legend tab in the Pillar Gridding process dialog.\\nSet I-Direction- Define a fault or a selected part of a fault as being in I-direction. Select fault\\nor part of a fault first - then click on the icon.\\nSet J-Direction- Define a fault or a selected part of a fault as being in J-direction. Select fault\\nor part of a fault first - then click on the icon.\\nNew I-Trend- Add an I-trend in or outside your data set. Click on the icon first - then digitize\\nthe points. A trend should not be digitized across a fault. When starting or terminating a trend on\\na fault, it needs to be connected to a Key Pillar on the fault. You can start/stop a trend in the\\nmiddle of the grid, or snap it to an existing Key Pillar by digitizing on the Key Pillar. To stop the\\ntrend in the middle of the grid - double click.\\nNew J-Trend - Add a J-trend in or outside your data set. Click on the icon first - then digitize\\nthe points. A trend should not be digitized across a fault. When starting or terminating a trend on\\na fault it needs to be connected to a Key Pillar on the fault. You can start/stop a trend in the\\nmiddle of the grid, or snap it to an existing Key Pillar by digitizing on the Key Pillar. To stop the\\ntrend in the middle of the grid - double click.\\nSet Arbitrary Direction - Define a fault or a part of a fault as being in A-direction. This is the\\ndefault selection in Petrel. The only time this tool is needed is when you want a fault previously\\nselected as I- or J-direction, to be changed back to being an arbitrary fault.\\nAutomatic direction Assignment - Let Petrel define I or J trend(s) to all visualized faults in\\nthe active 2D window\\nAdd Pillar Between - Select two Key Pillars next to each other and click on this tool to add\\none between them.\\nSet Part of Grid Boundary - Build part of a boundary along a fault or trend line. Select\\nstarting and end points along that part of a fault you want to be part of the boundary - then click\\non this icon. This tool can be combined with the Boundary Segment tool.\\nSet Part of Segment Boundary - Use this tool to define a fault or trend line as part of a\\nsegment boundary, by selecting it and clicking on this icon. A fault/trend line that is set to be a\\nsegment boundary will have a white or light red/green color.\\nSet No Boundary - Removes grid and segment boundary from the selected part of a fault or\\ntrend line. A fault/trend line that is set to no boundary, will have a gray or dark red/green color.\\nSet No Fault - Use this tool to define a modeled fault as no fault. The Fault will then be\\ntreated as a 3D trend in the gridding process and not incorporated as a fault in the generated 3D\\ngrid. A fault that is set to no fault will be drawn with a stippled line.\\nSet Number of Cells on Connection - Define how many cells should be between the end\\npoints of a trend or a part of a fault.\\nLock/Unlock Virtual Translation - If activated, you are allowed to move (virtually) nodes\\non faults. Used to fix difficult gridding situations. This is an expert function and should be used\\nwith care. See Virtual Translation.\\nUndo Virtual Translation - Will undo a previous virtual translation. Click on the shape point\\nto move back before clicking on the tool.\\nMouse button functions in 2D\\nNote that when working in 2D windows, the mouse button functions are slightly different from\\nwhen working in 3D windows. In viewing mode, just move the mouse towards or away from you\\nto zoom in or out. To pan, press the left mouse button and the Ctrl key. To rotate, press the left\\nmouse button and the Ctrl+Shift keys.\\nProcess steps\\nThe most important process steps in the Pillar Gridding process are:\\nCreating a boundary - To define the horizontal extension of the 3D model.\\nDefining main directions - Define the most important faults of the model and force the\\ngrid cells to follow them.\\nAssisting with trends - Putting trends between faults and around the model to assist the\\ngridding algorithms and \"clean up\" messy areas.\\nNote that the size of the points representing the faults, boundary and trends can be\\nchanged as can the color of selected points - go to the Legend tab in the Pillar Gridding process\\ndialog to do this.\\nFaults in pillar gridding\\nThe faults modeled in the Fault Modeling process are the base for the generation of the 3D grid\\n(Pillar grid).\\nThe mid points of the faults (Key Pillars) are displayed in the 2D window as points with lines in\\nbetween. Individual faults can be turned on/off in the Petrel Explorer, and only the displayed\\nfaults will be incorporated in the 3D model.\\nA fault or a part of a fault can be defined as \"no fault\" by the use of the Set no fault tool. It\\nwill then be treated as a 3D trend or a segment boundary without being modeled as a fault in the\\ngenerated 3D grid.\\nFaults that are defined as faults (default) will be displayed with a solid line. Faults that have\\nbeen set to \"no fault\" will conversely by displayed with a dotted line.'},\n",
       " {'header': 'Grid Boundary ',\n",
       "  'content': 'The boundary will define the area of interest in your model. You can make as many points along\\nthe boundary as you wish and edit them afterwards if necessary. It is a good idea to display some\\nof your input data while making the boundary to ensure that you include all of the relevant data.\\nThe boundaries can be defined in three different ways depending on how the faults terminate in\\nyour model.\\nWhen a fault continues beyond the limits of the model, Create Boundary Segment\\nshould be used, making the faulted 3D grid terminate correctly at the boundary.\\nWhen defining a fault or a trend line as part of the boundary, Set Part of Boundary\\nshould be used.\\nIf all the faults terminate laterally within the model, then Create Boundary should be\\nused.\\nBoundary (blue) around area of interest.\\nHow to use the Boundary Segment tool\\nWhen some faults extend beyond the area of interest (the area limit of the data set used), use\\nthe Create Boundary Segment tool. In this way, it is possible to isolate fault segments. This\\nis important for separating your model into fault compartments (segments).\\nThis is probably the most commonly used boundary tool. Note that it is not possible to combine\\nthis tool with a general Boundary tool.\\n1. Select the Boundary Segment tool.\\n2. To make a straight boundary segment between two faults, digitize the segment by clicking\\non the two pillar points that should define that segment. A boundary segment is now\\ncreated between the two pillars.\\n3. To make a boundary segment between two faults with some additional points in between,\\ndigitize the segment by first clicking on one of the pillar points, then digitize points\\nwherever you want the boundary to go. End the segment by clicking on another pillar point.\\n4. The last segment must close the boundary by connecting to the same pillar point as the\\nfirst segment started on.\\nHow to use the Set part of Boundary tool\\nThe Set Part of Boundary tool allows you to use a fault or a part of a fault as boundary. A\\ntrend can also be a part of a boundary. This tool cannot be combined with the general Boundary\\ntool. Use it together with the Boundary Segment tool.\\n1. Select the fault (or trend) that should be a part of the boundary (click on the line along the\\nfault). Alternatively, select a section of a fault that should be a part of the boundary. To\\nselect a fault section, click on the fault point where the section should begin. Then, while\\npressing down the Shift key, click on the fault point where the segment should end.\\n2. Click on the Set Part of Boundary tool.\\n3. Continue building the boundary by using the Boundary Segment tool as described\\nabove.\\n4. To remove a \"part of grid boundary\", select it and click on the Set No Boundary tool.\\nIf you need to delete the project boundary, the faults that act as Part of Boundary needs to be\\nupdated manually. To do this, select the fault and click on the Set Part of Boundary icon.\\nHow to make a boundary (Create Boundary)\\nThe Create Boundary tool is used to surround a whole data set without dividing up the area in\\nsegments. It applies to data sets where faults terminate laterally within the model. This type of\\nboundary cannot be combined with any of the other types of boundaries (Create Boundary\\nSegment, Set Part of Boundary).\\n1. Click on Create Boundary .\\n2. Digitize in the 2D window where you want your boundary polygon. The boundary will follow\\nthe cursor from one point to the next.\\n3. Complete the boundary by double clicking the last point close to the one you started\\nwith. This will close the boundary.\\nWhen using this boundary tool, we recommended you make trends that extend through the\\nboundary from the end of faults, see figure below.\\nHow to use an external boundary\\nA boundary can also be imported from an external application or digitized in the Make/Edit\\nPolygon process step and converted to a boundary.\\n1. Open the Settings window of the polygon and change the category in the Info tab to'},\n",
       " {'header': 'Boundary Polygon. ',\n",
       "  'content': '2. Open the right mouse button pull down menu of the Boundary Polygon and select the\\noption Convert to 3D grid boundary.\\n3. The boundary will now be copied into the active 3D grid under the Model tab in Petrel'},\n",
       " {'header': 'Explorer. Directions ',\n",
       "  'content': 'The grid will be aligned along faults having defined directions in order to preserve regularity of the\\ngrid cells. Defining the relative directions of the faults in your data set will improve the gridding\\nprocess. The purpose is to define two main directions; I- and J- direction and one sub-direction;\\nA-direction (arbitrary) in order to assist the generation of the grid. Arbitrary direction is the\\ndefault and set for all faults which are NOT set as being in I- or J-direction. The I- and J-direction\\nshould be kept as close to perpendicular to each other as possible.\\nNote that the I- and J-directions do not necessarily follow the X- and Y-directions.\\nGeneral procedure for defining fault directions\\n1. From the structural setting of your data set, define the pre-dominating fault directions as\\nbeing of either I- or J- type.\\n2. Mark all faults and parts of faults following this main direction with the same type as\\ndefined above.\\n3. Mark all the faults and parts of faults perpendicular, or near perpendicular to this direction\\nas being the other main direction. Leave the remainder as arbitrary (this is the default\\nsetting).\\n4. When working with vertically truncated faults, make sure the truncated fault is marked as\\nbeing in either I- or J-direction. This is necessary for the algorithm to be able to incorporate\\nthe truncation in the 3D grid.\\nHow to define fault directions\\nTo mark a fault as an I-direction:\\n1. Click anywhere on the fault line - the fault will be highlighted.\\n2. Click on Set I-direction .\\nTo mark part of a fault as a J-direction:\\n1. Click on the points along the fault that you want to select (to select multiple faults, press\\nShift as you make your selection). You can also select the first and last point from a fault\\nsegment.\\n2. Click on Set J-direction .\\nTo facilitate the fault line selection, click on the Show Points icon to turn off all except the\\nend points\\nDirections (red and green lines) defined along faults.'},\n",
       " {'header': 'Trends ',\n",
       "  'content': 'Sometimes, it can be desirable to improve the quality of the grid between faults. This can be\\nachieved by using trends.\\nThe option of defining trends in areas with no faults can be very useful. The trends can be defined\\nin I- and J-directions. Trends can be defined connecting one fault to another, along faults or in\\nbetween faults. They cannot cross faults. When a trend starts or terminates on a fault, the start\\nor end point must be a Key Pillar on the fault.\\nIf you define a trend from one fault to another, there is an option to define the number of grid\\ncells between two faults by selecting Set Number of Cells on Connection in the Function\\nbar.\\nTrends can be used inside the model to separate areas into different segments. See Segments for\\ninformation about how to use this option.\\nYou can also use trends around the entire data set, both inside and outside the boundary. This\\ncan be helpful in data sets with specific trends, like flow or depositional directions, etc.\\nTrends (Background) gives a description of what happens when trends are inserted into the\\ngrid and explains how trends can be used to straighten out twisted cells.\\nHow to make trends\\n1. Click on the icon defining the trend I- or J-trend .\\n2. Digitize the points of the new trend. Click once to define a point, and double-click where\\nyou want to end the trend.\\n3. If the trend starts or ends on a fault, it needs to be connected to a Key Pillar on the fault,\\nand you only have to click once to start or end the trend.\\nRemember that a trend cannot cross a fault. Such a trend will not be incorporated in the grid.\\nIf you need to redefine all trends, use the option on the right mouse button menu: delete\\ncontent on the Trends folder.\\nDefined trends (stippled red and green lines)'},\n",
       " {'header': 'Segments ',\n",
       "  'content': 'A segment in Petrel is an area that is closed by faults, grid boundary, segment boundaries or any\\ncombination of these.\\nSegments are used in several processes in Petrel. For example, different settings and filtering\\noptions can be applied to segments and volumes, and the results will be reported per segment\\nwhen running the Volume Calculation process.\\nThe basis for the generation of segments is made in the Fault Modeling process, by connecting\\nfaults or creating pseudo faults in between real faults. The grid boundary and segment boundaries\\n(trends) can then be used to further control the generation of segments in the Pillar gridding\\nprocess.\\nObjects that control segments\\nFaults and segments\\nAreas that are closed by connected faults will automatically be treated as separate segments.\\nFaults are defined as being part of the segment boundary by default, but the use of the Set No\\nBoundary tool can change this.\\nThe figure below shows segments separated by faults. In the picture to the right, the highlighted\\nfault (in the middle) is defined as no boundary and will not separate the area into different\\nsegments. While in the left figure, the same fault is treated as part of boundary segment\\n(default), thus separating the same segment into two segments (the yellow and the blue colored\\nsegments).\\nFaults that are defined as part of boundary segment (default) will be displayed with a\\nwhite or light green/red color. Faults that have been set to no boundary will conversely be\\ndisplayed with a gray or dark green/red color\\nFaults as segment boundary'},\n",
       " {'header': 'Grid Boundary ',\n",
       "  'content': 'Segments will be defined when creating a grid boundary between faults. If the boundary is going\\nto be used for defining segments, it is recommended to use the Set part of grid boundary\\nfunction in combination with the Create Boundary Segment tool to digitizing the boundary\\nbetween the faults.\\nGrid Boundary used to generate segments\\nGridding of Truncations\\nTruncations in a model require some extra care when going through the Pillar Gridding process.\\nTruncated faults will be drawn with yellow lines between the truncating Key Pillar pairs as seen in\\nthe figure below.\\nTruncated Key Pillar pairs as seen in 2D.\\nNotice that the two end Key Pillar pairs are drawn in a lighter shade of yellow. This indicates that\\nthese Key Pillars are the end pillars in the truncation. We recommend adding a trend between the\\npillars at the end of the truncation.\\nThere are three required settings for vertically truncated faults in the Pillar Gridding Process in'},\n",
       " {'header': 'Petrel: ',\n",
       "  'content': 'The fault or part of a fault that is vertically truncated (i.e. the one that stops against the\\ntruncating) must be given an orientation (defined as being an I- or J-direction). The\\ntruncated fault can be identified in a 2D window as being the fault with yellow arrows\\npointing away from it.\\nThe fault or part of a fault that is vertically truncating (the one towards which the arrows\\nare pointing i.e. the one that cuts the other) does not need to be given an orientation but it\\nis recommended to do this it if it fits the model.\\nThe two extreme Key Pillar pairs in vertically truncating faults must be given trends that\\nare of perpendicular direction to the direction set for the truncated fault.\\nYou can set additional trends between truncating pairs in parts of the truncation other than the\\nends. This is especially recommended if the truncation is turning in an arc.\\nAdditional information regarding gridding truncations is given under Truncations'},\n",
       " {'header': '(Background). ',\n",
       "  'content': 'Correct settings of directions and trends for vertically truncated faults.\\nDouble truncations\\nIn a case where there is a double-truncated fault, the same basic rules apply as for single\\ntruncations. An important point to remember is that trends set at the extreme Key Pillar pairs of\\nthe truncations, must be separate for separate truncations.\\nDouble truncations as seen in 2D\\nA double truncation is displayed in this figure as it is drawn in a 2D window in Petrel. The trends\\nare drawn from A to B and from B to C separately, never from A to C. Trends should always be\\nkept separate when they are crossing a fault.\\nIn this case, an extra directional definition has been set for the fault to the right (C to C)'},\n",
       " {'header': 'Virtual Translation ',\n",
       "  'content': 'This is an additional advanced function that can help the gridding process when working with\\nmultiple truncations. This procedure is also applicable when there are pronounced salt domes or\\nfault structures with closely spaced and extremely shallow dipping faults (dipping in opposite\\ndirections). Virtual Translation is a method to adjust the mid point of the pillars in the 2D window\\nwithout actually changing the shape of the fault. This is an expert function and the user should\\nhave a good understanding of the gridding functionality in Petrel before working with these kinds\\nof projects.'},\n",
       " {'header': 'Case Study ',\n",
       "  'content': 'Consider the following fault structure: Two parallel vertical faults with two dipping faults truncated\\nat top and base in between. In 3D and 2D it would look like this in Petrel:\\nThe left part of the figure shows the fault structure in 3D, the figure to the right shows the same\\nstructure in 2D.\\nFaults displayed in the 2D window are represented by lines connecting their mid shape points. In\\nthis case, the result is that the lines connecting the mid shape points of fault 2 and 3 coincide and\\nwill cause the gridding process to fail. To solve this problem, the points representing faults 2 and\\n3 must be moved apart.\\nIn this case, the hierarchy in the gridding process is such that the points of fault 2 must be moved\\ntowards fault 1 and the points of fault 3 must be moved towards fault 4. When viewed in a 2D\\nwindow, the result will be four separate lines representing the four faults. Had faults 2 and 3 been\\ndipping the other way, like the example below:\\nThe order in which they are gridded would be different and the numbering of faults 2 and 3 would\\nbe reversed. The points in Fault 2 should be moved towards fault 1 and fault 3 should be moved\\ntowards fault 4.\\nIt is difficult at times to figure out which way to move which points. It is therefore necessary to\\nperform a thorough quality control. After the grid is made, insert the horizons (Make Horizon) and\\nthen display an intersection (I- or J-) perpendicular to the faults. Open the Settings window of the\\nintersection and check the option Show Pillars. Step through the model and make sure that the\\npillars between the (in this case) vertical faults are parallel, see figure below:\\nIn the figure to the left, the points were moved the wrong way and the pillars are crossing each\\nother. In the figure to the right, the points were moved correctly and the pillars are parallel, as\\nthey should be.\\nHow to perform a Virtual Translation\\nUse this figure for reference:\\nThe left part of the figure shows the fault structure in 3D, the right figure shows the same\\nstructure in 2D.\\n1. Switch off fault 3 (faults 1, 2 and 4 should be displayed).\\n2. Click on the Edit Points tool.\\n3. Click on the Lock/Unlock Virtual Translation icon.\\n4. Click and drag the points of fault 2 (one by one) slightly towards fault 1.\\n5. Display fault 3 instead and switch off fault 2.\\n6. Click and drag the points of fault 3 (one by one) slightly towards fault 4.\\n7. Display all four faults. It should now look like the figure shown below.\\n6.\\n7.\\nThe movement of the points representing the mid shape points of the faults in the 2D window,\\ndoes not affect the actual Key Pillars. It is only a virtual movement and the purpose of the\\nmovement is to \"trick\" the gridding algorithm into working.\\nPillar Gridding Process dialog settings\\nOptions for different settings and geometries pertaining to Pillar Gridding are set in the process\\ndialog. There are a number of different options and settings to choose from in the process dialog\\nto help define an appropriate X and Y representation of the 3D grid. Below the tabs of the Setting\\nwindow are three buttons: Apply, OK and Cancel.\\nApply: By pressing Apply, a 3D skeleton grid is created between the Mid-Shape Points of the Key\\nPillars and the boundary.\\nOK: If the 3D skeleton grid is consistent and accurate, we continue to build the 3D model by\\nclicking OK. This step creates another two skeleton grids for the Top- and Base- Shape Points\\nrespectively.\\nCancel: Click here to close the window.\\nInfo tab (Pillar gridding)\\nWorkflow information describing the different stages of Pillar Gridding:\\nA boundary is digitized around an area of interest, which will also be the limit of the 3D\\nmodel.\\nKey Pillars are assigned directions according to reservoir geometry indicated by major fault\\ntrends.\\nIn some areas it may be necessary to help the gridding process by digitizing trends. This is\\nan iterative process where the user successively works towards an optimal result, having\\nthe geo- and flow- grid in mind.\\nShow Faults: By checking this option (default), the Key Pillars will be shown in the 2D\\ndisplay.\\nSettings tab (Pillar gridding)\\nOptions for increments and grid layout:\\nResult 3D grid\\nCreate new, named: Several grids can be created in a single project, making it necessary\\nto give a unique name to each 3D grid.\\nOverwrite the active 3D grid: Will overwrite the active (bold) grid in the Petrel Explorer\\n(all settings will be remembered). Make Horizon and Make Zones will have to be run again,\\nbut the settings will be preserved (just open and press OK).'},\n",
       " {'header': 'Increments: ',\n",
       "  'content': 'Pillar Gridding uses the given increment as an average. The distance between grid nodes will NOT\\nbe constant.\\nWhen you start making your grid, begin with a rather large grid increment, perhaps 200 or even\\nlarger. Then, as your grid increases in quality, make the grid increment smaller.\\nBecause the 2D grid generated in Petrel has grid cells proportionally spaced between faults, the\\ngiven increment must be an average and not a constant. For example, cells are not truncated\\nagainst faults with a given relative direction.'},\n",
       " {'header': 'Horizons: ',\n",
       "  'content': 'If this option is selected, the Horizon Lines stored on the fault model will be used to generate\\nhorizon objects in the resulting 3D grid. The physical calculation of the horizon will be done in the\\nMake Horizons process. The setting is only available if Create new is selected. If there are no\\nHorizon Lines stored in the fault model, no Horizon objects will be made.\\nLayout of arbitrary directed faults:\\nFor obtaining regular shaped grid cells along faults, the option Make Zig-Zag type faults should\\nbe checked. This option creates a best-fit split of the rectangular shaped grid cells along the faults\\ndefined as arbitrary.\\nZig-zag type faults are commonly used when creating a simulation grid.\\nThe zig-zagging is not applied in the Z direction.\\nMove node at end of zigzag faults. This option is available when Make Zig-Zag type faults\\nis checked. When selected, the node at the end of an arbitrary fault will be forced to the position\\nof the last Key Pillar in that fault. When not selected, the last node will be positioned close by but\\nnot exactly at the position of the last Key Pillar of that fault. Deselect this option to increase\\northogonality of the resulting grid.\\nAn example of grid cells equally spaced along an arbitrary fault.\\nAn example of grid cells moved perpendicular to the arbitrary fault - spacing of grid cells along\\nthe fault vary.'},\n",
       " {'header': 'Edge Limit ',\n",
       "  'content': 'The edge of the grid is limited by trends and directed faults. In this case, a boundary is not\\nneeded if there are trends and faults (directed) continuing around the project.\\nMinimum Curvature Settings - opens the global settings for Minimum Curvature used.\\nMore tab (Pillar gridding)\\nThere are 2 methods for assigning trends to gridlines:\\nLocal Iterative Method: This will assign trends to groups of connected faults one at a\\ntime. It is a good general algorithm.\\nVector field Method: Trends will be assigned using a vector field over the whole field at\\nonce. This algorithm is smoother in situations where there are many unconnected faults and\\ntrends.\\nAssignment of arbitrary faults: In this section, the user has the option to modify the grid\\nlocally around the faults. We do not recommend using this option when there are specified trends\\nand directed faults in the grid. See tool tip for more details.\\nAutomatic assignment of faults: The trends along the faults can be auto assigned. The\\nAssignment angle is the maximum angle in degrees in which faults are automatically assigned\\nan I or J trend. Whether the trend is I or J, is initially determined by the fault layout, unless the\\nrotation angle is set to User Specified in the Expert Tab. You can control the number of auto\\nassigned segments (trends between two key pillars) by setting a minimum value in the Minimum\\nnumber of auto assigned segments box.\\nHow to assign trends automatically\\n1. Specify the Assignment angle in the More tab\\n2. Add the minimum number of segments to auto assign a trend.'},\n",
       " {'header': '3. Press Apply ',\n",
       "  'content': '4. On the Function bar select Automatic direction Assignment to update the action.\\nTo reset the trends to Arbitrary, press Ctrl+A and then select Set Arbitrary Direction\\nPillar Geometry tab (Pillar gridding)\\nDefines the geometry of the pillars in the fault plane as well as the geometry of pillars between\\nfaults. You can define the geometry you want for non- faulted and faulted pillars respectively. If\\nonly one geometry type is selected, that geometry will be applied to all pillars in the 3D grid.\\nOtherwise, the geometry is auto-generated, see the description below.\\nAuto-generation of pillar geometry: Auto generates geometry based on the XY-distance\\nbetween the Shape Points. To build the grid as quickly as possible, the algorithm seeks the\\nsimplest geometry of Key Pillars. For example, it is easier for Petrel to incorporate a linear pillar in\\na grid than a listric pillar. You can define a tolerance distance (10 meters by default) which is used\\nto revert the specific pillar geometry to a lower geometry. Example: If dx is less than 10 (default),\\nthe specific fault geometry reverts to a lower geometry. A tolerance distance of around 10% of\\nthe grid cell size is recommended.\\nUse the closest pillar in the faults: This will change the geometry for a faulted pillar equal to\\nthe geometry of the closest key pillar.\\nResample the shape points: By default off. Use this option if the mid-skeleton grid is messy\\nand refuses to be disentangled. When the option is off, the distance between the Shape Points\\nalong the pillars differs according to the fault shapes modeled by the user (for listric and curved\\nKey Pillars). This will conserve the shape of the faults during the gridding process.\\nWhen this option is checked the distance between the shape points will be adjusted so that it is\\nequal between all Shape Points along a Key Pillar. This can alter the shape of some fault planes\\nslightly, but could help disentangle the skeleton grid.\\nA figure showing how the pillar geometry changes based on the XY-distance.\\nThe Pillar Geometry tab in the Settings window for Pillar Gridding.\\nIf possible, keep faulted and non-faulted pillars linear when generating truncated faults.\\nExpert settings(Pillar gridding)\\nRotation angle\\nAutomatic: The faults and trends will guide the rotation angle of the resulting grid.\\nUser specified: Rotation angle specified by the user - this option should be used restrictively and\\nnormally when you have arbitrary type faults only.\\nDifferent edge settings have an impact on the algorithm used.\\nEdge settings\\nEdge locked width: Defines how many cells that are locked along the edge of the total grid.\\nEdge growth: The closest distance between the edge of the total grid (in number of cells) and\\nthe defined boundary around a project.\\nUse boundary: This is the default setting. By not checking this option, the grid will extend to the\\ndefined edge of the total grid.\\nGrid line layout\\nThe grid line layout affects the lines between the grid nodes.\\nSmooth the lines between the Key Pillars (recommended): Will smooth the lines between\\nthe Key Pillars to make the grid look cleaner (only visual effect).\\nLinear grid lines: Simple equal space algorithm. Best suited for very orthogonal fault patterns\\nor for simulation grid.\\nSmooth grid lines: Advanced equal space algorithm. Best suited for geo modeling, or not very\\northogonal fault pattern.\\nInterpolation across faults\\nContinuous equal spaced cells: Smoothing of grid cell size is done across faults.\\nBarrier when equal spaced cells: Cells are gridded on one side of a fault without affecting\\nthe other side of the fault.\\nSmooth grid lines across fault: Smoothing of grid lines across faults.\\nLinear grid lines across faults: Grid cell shapes are kept within each segment separately and\\ndoes not affect the shape of the grid cell on the other side of a fault.\\nThe Expert settings tab.'},\n",
       " {'header': 'Fault Tab (Pillar Gridding) ',\n",
       "  'content': 'As a default, all the visible faults and trends displayed in the 2D window will be used to generate\\nthe grid. However, by checking Selected Faults/Trends and un-checking the All Faults or All\\nTrends options, the faults and trends to be used can also be selected manually. This can also be\\ndone by making only the appropriate faults and trends visible and pressing the Update List\\nFrom Visible button.\\nThis enables the selection (and de-selection) of specific faults and trends for gridding when using\\nthe Workflow editor.\\nFaults tab in the pillar gridding dialog'},\n",
       " {'header': 'Legend (Pillar Gridding) ',\n",
       "  'content': 'The size of the points that represent the faults, the boundary and the trends can be changed as\\ncan the color of selected points:\\nMarker size: Type a number specifying the size of the points, click on the icon to\\nexecute.\\nSelected color: Click on the small arrow next to the color sample and pick the color to mark\\nselected points. Click on the icon to execute.\\nShowing the different data types used in the 2D window.\\nExamples of Pillar Gridding\\nThe best practice is to start by using the Arbitrary default setting for all faults, and then work\\nthrough the gridding process by adding more and more directions to the faults.\\nExample of grid directions\\nThe figure examples below show parts of the 2D grid during a Pillar Gridding run. Boundaries have\\nalready been made.\\nAs a first step, a grid can be made without using any directional information for the faults. All\\nfaults (Key Pillars) are displayed and gridded using the default settings (all faults are defined as\\narbitrary). The grid will be offset along the faults, but cells will adjust toward the faults and\\nbecome non-irregular in shape.\\nFaults running in a predominating direction will be given a relative direction. Iin this case, J-\\ndirection. Notice how grid cells adjacent to the directional faults are aligned along the same axis.\\nThe green faults indicate that I-directions are set for these faults. Grid cells will be aligned along\\nthe faults, but the problem in this case is that the lower green fault ends in the middle of the grid-\\nsystem.\\nTrend lines are added to straighten the grid-system.\\nA user defined number of cells running along the green directions of the grid-system have been\\nadded.\\nHow different grid guidance work in the Pillar\\nGridding process\\nThese figures show parts of the 2D grid during a Pillar Gridding run. Boundaries have already\\nbeen made.\\nAs a first step, a grid can be made without using any directional information for the faults.\\nAll faults (Key Pillars) are displayed and gridded using the default settings; i.e. all faults are\\ndefined as arbitrary. The grid will be offset along the faults, but cells will adjust towards the\\nfaults and become non-regular in shape.\\nFaults running in a predominating direction will be given a relative direction, in this case, J-\\ndirection. Note how grid cells adjacent to the directional faults are aligned along the same.\\nConverging grid cells in the SE part of the grid are taken care of by ending the J-direction of that\\nfault before the end of the fault itself.\\nLook at the eastern fault. A trend for J-direction is added where the I-direction of that fault ends,\\nand runs parallel to the next fault to the west. This straightens up the grid cells a little bit more\\nfor that particular segment.\\nThe green fault indicates that I-directions are set for these faults. Grid cells will be aligned\\nalong the faults, but the problem in this case is that the lower green fault ends in the middle\\nof the grid-system.\\nA new point is added to the red line across from the extension of the green fault. This point\\n(yellow in figure) is needed as an attachment to a trend that we want to add from the end of the\\ngreen fault.\\nThe trend is added to the green fault and attached to the new point. We have also defined 20 grid\\ncells in the N-S direction. A system can be detected where segments are made into compartments\\nbetween directed faults and trends. The dialog indicates an arbitrary fault that could not be\\nincorporated in the model. This fault is indicated with yellow nodes.\\nThe problem in the previous slide is solved by defining number of cells in the N-S direction along\\nan already existing fault, instead of using an extra trend for this purpose. Notice how the number\\nof cells needs to be given for each line segment of the fault (in this case 12 and 5).\\nFurther refinement of the grid by defining 12 cells in I-direction.\\nInfluence of Trends outside the grid\\nTrends can be used outside the project boundary to define large-scale trends. They can also be\\nused if you want the grid to follow a trend other than the predominant fault direction.\\nThree faults, a boundary and a set of trends are used in the gridding process. The grid is aligned\\nwith the trend lines.\\nIn this case, the trends are used as a grid boundary.\\nThe grid will only be defined inside the boundary.\\nScaled up well logs quality control and 3D\\nvisualization\\nBefore Property modeling is performed, the upscaled well logs should be quality controlled.\\nThere are several ways of checking that the scaled up well log data set is as you intended.\\nHow to quality check the Scaled up well logs\\nMany options of quality control for upscaled logs are available, some of them are:\\n1. Display the new property in a 3D window\\n2. Turn on the grid lines for the property by clicking the Show/hide grid lines button in\\nthe Function bar.\\n3. Turn on the color legend using the Show/hide auto legend button in the Menu bar.'},\n",
       " {'header': 'Or ',\n",
       "  'content': '1. Click Show results in well section or set up a Well Section and display the upscaled cells\\nand raw logs with a fill.\\n2. View the logs and upscaled cells of interest; check for inconsistencies.'},\n",
       " {'header': 'Or ',\n",
       "  'content': '1. Check the Statistics and the Histogram under the Settings for the upscaled properties.\\n2. Compare the proportion of the raw logs to the upscaled cells.\\n3. Redo the Scale up well logs process, if necessary.\\nScaled up well logs quality check using a Well Section\\nThe best way to check the upscaling is to display the property in the well section together with the\\noriginal well log. The upscaled property can be edited directly in the well section view and any\\nupdates transmitted automatically to the property model, see Properties in the well panel for\\ndetails.\\nThe property cannot be edited interactively when it is displayed in a track panel. Make a\\ncopy of the property outside the track panel to edit it while displaying the track panel.\\nIn the image below, the property is displayed in a well section window together with a track panel\\nof the property and the original log.\\nCheck the statistics of the upscaled well logs\\nAfter the upscaling, compare the input data from the well logs to the upscaled result. Range and\\nstatistics of the data can be found in the Statistics tab of the property. A more useful way to\\nview statistics is in a Histogram .\\n1. Open the Settings dialog for the property by double-clicking on the icon. Select the\\nStatistics tab\\n2. Look at the various statistical parameters. Note that statistics are given for the raw log, the\\nupscaled cells, and the full 3D model of the property (which is equal to the upscaled log if\\nProperty modeling has not yet been performed).\\n3. Select the Histogram tab to generate the histogram of the raw log, the scaled up well\\nlogs, and the distribution in the property model. Again, the values within the property\\nmodel will be equal to those in the upscaled wells until the Property modeling is\\nperformed.\\nStatistical parameters of scaled up well logs (see Use of Statistics and Histogram for QC ).\\nExample of a histogram of scaled up well logs (green), displayed with the original well log (red)\\nand the modeled petrophysical property (blue).\\nAdjust the color table to the data range\\n1. Select the property in the Models pane.\\n2. Click the Adjust color table on selected icon in the Menu bar.'},\n",
       " {'header': 'Or ',\n",
       "  'content': '1. Open the Settings dialog for the property and select the Colors tab.\\n2. Click the Min and Max buttons to ensure that all the colors are used.\\nDisplay grid lines on the Scaled up well logs\\n1. Display the property and make sure you have activated one of the processes under the\\nProperty modeling process.\\n2. Click the Show/hide grid lines button in the Function bar.\\n1.\\n1.\\n2.'},\n",
       " {'header': 'Or ',\n",
       "  'content': '1. Open the Settings dialog for the Properties folder.\\n2. Select the Style tab and choose Show grid .\\nTwo well traces inside a single grid cell\\nIn a case where two well traces penetrate the same grid cell, Petrel will upscale in the following\\nway:\\n1. For continuous data, an algebraic average of all samples located in the same grid cell will be\\nperformed. Hence, multiple wells penetrating the same cell will be averaged.\\n2. For discrete data (for example, facies), the process assigns the most frequently occurring\\nvalue per cell, regardless of how many wells penetrate the same cell.\\nProblems when pillar gridding?\\nGenerating a grid from a complex fault model is time consuming and can be tricky. This section is\\ndesigned to help you determine why the gridding doesn\\'t give you the answer you expect and\\nhow to adjust the setup to make the process as easy as possible.\\nGuide to fault modeling and gridding in Petrel gives a description of how Petrel builds a 3D grid\\nfrom the fault model and gives a number of tips explaining how to make the gridding go more\\nsmoothly.\\nWhat went wrong? - Pillar Gridding\\nHave you checked that all the faults that should be connected are properly connected? Fault\\npillars can sometimes be very close to each other without being connected, connected\\npillars are grey.\\nDoes your grid have trends that contradict each other? Faults and trends assigned to the\\nsame direction (either I or J) should be roughly parallel to each other and roughly\\nperpendicular to opposite trends.\\nAre the chosen pillar geometries appropriate? Allowing curved faulted pillars but only\\nstraight non-faulted pillars could result in negative cells close to the fault, especially if the\\nfaults are strongly listric.\\nIs the tolerance distance appropriate? (see the pillar geometry tab in pillar gridding) This is\\nthe distance Petrel uses to decide which type of pillar is appropriate. A good rule of thumb is\\nto use a distance that is 10% of the initial grid spacing.\\nIs Shape Point Resampling turned on? (Pillar gridding dialog, pillar geometry tab). This\\nwill help Petrel make the smoothest possible grid.\\nIf you are modeling truncated faults, have the faults been given a trend? Are the\\ntruncation\\'s pillars roughly 90 degrees to the truncating fault in 2D\"\\nHow to optimize the fault model for Pillar Gridding\\nGenerally speaking, Petrel assumes that faults go in a straight line. While curving faults\\npose no problem to the gridding process, it can sometimes be wise to replace a single fault\\nwith a 90degrees bend, with two faults connected at the bend.\\nIf areas of the grid have large cells it can be because there are diverging or converging\\nfaults with fixed trends. Remember, it is possible to remove trends from sections of faults.\\nIf the problem persists, use arbitrary trends across the section (choose the same direction\\nas that made without the trend) and specify the number of grid cells.\\nIf there are a number of trends in the grid with a specified number of grid cells, or the\\ntrends cause large changes in the size of the grid cells, it may be necessary to increase the\\nnumber of cells in the model. Do this by increasing the edge growth setting under the Pillar\\ngridding dialog, Expert Tab.'},\n",
       " {'header': 'Make Horizons ',\n",
       "  'content': 'The Make Horizons process step is the first step in defining the vertical layering of the 3D grid in\\nPetrel. The vertical layering of the 3D grid is defined in three process steps:\\nWork flow of Vertical layering generation in Petrel.\\nNormally, the seismic interpretation is used to define the main vertical architecture of the\\nreservoir model. When introducing the horizons to the set of pillars generated in the Pillar\\nGridding process, all intersections between the pillars and the horizons become nodes in the 3D\\ngrid.\\nGeneral overview of Make Horizons\\nThe 3D grid will have as many main layers as number of horizons inserted into the set of pillars.\\nIn the Petrel Explorer this is shown as Horizons in the Models window.\\nThis is a true 3D approach in the generation of 2D surfaces; all are gridded in the same process,\\ntaking the relationships between the surfaces into account (erosion, on-lap, etc), honoring the\\nfault model to ensure proper fault definitions in the surfaces and keeping the well control (well\\ntops).\\nFor the faulted areas, the horizons are blanked (deleted) in a user given area around the faults\\nand an extrapolation is performed to \"stretch\" the surface back onto the fault plane. This will\\nensure that rollovers or pull-ups near faults are eliminated and a high quality layering of the 3D\\ngrid is preserved.\\nIt should be noted that the skeleton grids are modified if the top and/or base of the input data\\nextend above or below the Top and/or Base Shape Points respectively. The Key Pillars should\\nextend above top horizon and below base horizon. If you have horizons above or below your fault\\nmodel and add them to the model in Make Horizons, the existing pillars will be extended until\\nthey meet these new horizons, and in some cases it can cause the pillars to cross. Thus, an\\ninitially perfect grid may become twisted after Make Horizons.\\nInput for the Make Horizons process\\nInput can be any combination of:\\nInterpreted seismic lines. For example from Charisma, IESX, Seisworks, GMA, Seismic Micro\\nTechnology, etc...\\nSurfaces (2D maps). For example from Zmap+, CPS-3, IRAP, EarthVision, etc...\\nWell tops.\\nPoint or line data (for example, contoured maps).\\nThe horizons become cell layers of the 3D grid, but can also be exported as standard regular\\nsurfaces (see Gridded surfaces).\\nReverse faulting\\nReverse faults cannot be treated in standard mapping applications and are always somewhat\\ndifficult to implement in applications that can handle them.\\nPetrel makes no distinction between normal and reverse faults and one is just as simple to model\\nas the other. The fault modeling and pillar gridding processes combine to generate splits in the\\ngrid corresponding to the position of the interpreted faults. The elevation of the horizon on each\\nside of the fault, and therefore the aspect of the fault, is controlled by the data input used in the\\nMake Horizon process. Therefore, a single fault can just as easily have normal and reverse\\nsections along its length.\\nMake Horizons Process dialog settings\\nThe Make Horizons process is a fully automatic procedure once the input data and some settings\\nhave been specified. The user sets up a spreadsheet with the various seismic horizons as rows,\\nand process settings as columns. A description of the settings is given in the sub-chapters after\\nthe general procedure on how to make horizons.\\nHorizon tab (Make Horizon)\\nThe Horizon tab is the main tab in the Make Horizon dialog. It consists of a spreadsheet with\\nhorizon names as rows and horizon settings as columns.\\nMultiple drop - Allows the user to drop several files, such as surfaces, simultaneously.\\nThe following columns exist:\\nIndex - Numerical index of horizon\\nHorizon - Name of the horizon\\nColor - Change color of horizon. The icon in the process dialog can also be used for\\nchanging the horizon colors.\\nCalculate - Useful when regenerating only a few selected horizons. For example, one of the\\nseismic horizons has been reinterpreted and the 3D structural model must be changed.\\nInsert the new interpretation and calculate only this horizon. This column may be hidden if\\nthe dialog is small - drag the bottom right corner of the dialog to increase its size.\\nHorizon Type - Each horizon can be given a particular type that defines the relationship to\\nother horizons. This is done in the type setting. This represents the geological environment\\nof the reservoir. It is important to make the 3D grid similar to the geological setting and\\ndepositional environment to represent the reservoir in the best possible way. The following\\ntypes are available:\\nErosion - The horizons below will be truncated.\\nBase - The horizons above will be on-lapping.\\nDiscontinuity - Combination of erosion and base types.\\nConformable - Will be truncated by erosional, base and discontinuous horizon.\\nConform to Another Horizon - Useful to use in situations where the input data is sparse.\\nIf Yes is selected, Petrel assumes the thickness between the active horizon and the selected\\none is smooth across the model. Select Growth Fault checkbox in the Faults tab if the\\nthickness across faults is to varied. Selecting If No Data ensures the active horizon is\\nconformed to the chosen horizon based on the average of the thickness of the closest\\nhorizon nodes in the surrounding segments. See the Tool Tip for further details.\\nStatus - New or Done, depending on whether the process has been performed or not.\\nUse Fault Lines - If selected, the fault lines stored on the fault model will be sampled and\\nused as input. See How to generate Fault-Horizon intersections for the 3D Grid\\nSmooth - Smoothing of the horizons. Can smooth several times before insertion.\\nWell tops - To be able to tie the horizons to the well tops. Insert the well top data objects\\nfrom the Input window in the Petrel Explorer.\\nInput #1 - By default the only Input field.\\nInput #2, Input #3 - Several additional input fields can be defined to enable the usage of\\nseveral different versions or data types for individual segments. This is particularly useful in\\ncomplex fields with large low angle reverse faults. See also How to build complex models\\nusing the segment settings.\\nHow to make Horizons\\n1. Double-click on Make Horizons in the Process diagram. The process dialog for Make\\nHorizons will open up. Note that the Petrel Explorer will display the Input window for easier\\naccess to the input data.\\n2. Click on the Add Horizon icon in the process dialog to add rows to the spreadsheet. Use\\nthe Set number of items in table and specify how many horizons you want to insert.\\n3. In the Petrel Explorer, Input window, activate the data object (surface, line or point data)\\nto be used for defining the first horizon.\\n4. Click the blue arrow next to the input field called Input #1 in the Make Horizons process\\ndialog and check that the name of the active data object is inserted into the input field.\\nRemember to have the correct data object active. Note also that the name of the horizon is\\nset equal to the name of the inserted data object. The user is free to change this name.\\n5. Continue inserting the data objects into the spreadsheet until you have all Input#1 fields\\ndefined. See the following sub-chapters for a description of the various available settings.\\n6. By clicking OK, the Horizons will be generated. See that the Horizons folder in the Petrel\\nExplorer, Models window, now has the new horizons inserted.\\nMultiple drop\\nThis allows the user to drop several files, such as surfaces, simultaneously. Add the number of\\nhorizons needed first by clicking the Add horizons icon. Then click on the first surface to use\\nin the surface folder in Petrel Explorer. Click on the blue arrow next to the top horizon. The\\nselected surface will be inserted, followed by the rest of the surfaces within the surface folder.\\nUncertainty icon\\nToggling on the icon will insert an extra column where the user can specify the value or\\nsurface representing one standard deviation on that particular horizon. Used in connection with\\nthe Uncertainty tab, see Uncertainty tab .\\nSettings tab (Make Horizons)\\nThe Settings options include a selection of algorithms and techniques when generating horizons.\\nThe tab consists of three main parts with options for separate elements of the Make horizons\\nprocess.\\nThe inserted horizon becomes part of a cell layer in the 3D grid. The gridding has a true 3D\\napproach since all horizons are gridded at the same time, taking relationships between the\\nhorizons (On-lap, truncations, etc.) into account and at the same time honoring the fault model.\\nThis ensures a consistent set of horizons with a perfect fault implementation.'},\n",
       " {'header': 'Convergent Gridder Method ',\n",
       "  'content': 'This method is always used when conforming to another horizon. It is a fast and general-purpose\\nalgorithm with good extrapolation. It adapts to sparse and dense data distributions through\\nconverging iterations at successively finer grid resolutions. This means that general trends are\\nretained in areas with little data while detail is honored in areas where the data exists. For further\\ndetails see Make Horizon Algorithms.'},\n",
       " {'header': 'Minimum Curvature Method ',\n",
       "  'content': 'If this option is selected, Petrel will create the horizon in two stages. First the points will be\\nsampled to the surrounding pillars, and then this data will be extrapolated to fill in any gaps in the\\ngrid that did not receive any data using the global extrapolation.\\nFor both gridding methods, when surfaces are used as input, the data can be converted to points\\nprior to processing\\nTemporary pre-smoothing: this will smooth the local data prior to extrapolation and thereby\\navoiding small local irregularities affecting the extrapolation. After the global extrapolation the\\noriginal values are put back.\\nIf points around the same node are more variable than the Max difference in Z values then the\\nnode will be estimated by the global method rather than the local one.\\nStep 1. Local interpolation - Points and Lines only (expert settings)\\nUnder local interpolation the user can set the local influence radius of the point data, and the local\\ninterpolation algorithms to be used. The user can control how the input data is sampled on to the\\nadjacent pillars. With few data points, it is possible to let the interpolator work with a higher Local\\nInterpolation radius. This may enable the interpolator to find input data.\\nThe available options for local influence radius are:\\n1/2 cell: This option is best for low density of points.\\n1 cell: This option is best for high density of points.\\nThe available options for local interpolation method are:\\nMoving average: This algorithm calculates the average of the points near the grid node,\\nand works best for low density of points or point data with bad quality.\\nPlane: This algorithm makes a linear plane, which represents data points near the grid\\nnode.\\nParabolic: This algorithm makes a 3D parabolic surface to represent the points near the\\ngrid nodes, and works best for high density of points and points with good quality.\\nStep 2. Global extrapolation (expert settings)\\nThere are a number of options for global extrapolation:\\nExtrapolation Method: choose the algorithm to use. Minimum Curvature, for trend\\nfollowing results, or Full Tension for a more linear (flat) result. For further details see Make\\nHorizon Algorithms. Click on Minimum Curvature settings to open the global setting of'},\n",
       " {'header': 'Minimum Curvature. ',\n",
       "  'content': 'Extrapolation to faults: There are a number of options for different types of faults, see\\nthe tool tip for details.'},\n",
       " {'header': 'Other Settings ',\n",
       "  'content': 'Locked horizon nodes: Useful when regenerating horizons. If some nodes are not to be\\nchanged, they can be locked (in the Edit 3D Grid process) and when the horizon is\\nregenerated the locked nodes are unchanged. You can iconize the locked nodes by right\\nclicking on the horizon and selecting Convert locked horizon nodes to points.\\nForce horizons to be calculated: this will ensure that a horizon is created even if there is\\nno input data (NB the horizon may be eroded). If the option Influence radius is not checked,\\nlocked nodes will be overwritten in the Make Horizon process.\\nCollapse the zones to zero thickness: Use this option to collapse cells less than the\\nminimum thickness specified in project units. Cells are collapsed towards the eroded\\nhorizon. If no horizon is set to erosional the cells are collapsed at the mid-point. See Tool\\nTip for more details.\\nIconize all points used: Select this option to generate a point set describing the data\\npoints used in the Make Horizons Process. Useful for establishing what data is outside of the\\nfault influence radius and thus used as input for gridding.\\nCross section through model: Collapse the zones to zero thickness set to 1m tolerance.\\nNote that locked nodes will be overridden by well adjustment if well tops are used in the\\nprocess. Locked nodes inside or at the well influence radius will not be calculated in the local\\ninterpolation, only in the global interpolation. Locked nodes will be kept locked during smoothing.\\nFault Re-sampling from the Fault Model\\nThese settings are only relevant when Use Horizon Lines is checked on in the Horizons tab.\\nThere are 2 ways to sample the fault-horizon intersection from the fault model:\\nBy Name: Petrel searches for a match between the name of the horizon lines stored on\\nthe fault model and the name of the horizon and faults in the 3D grid.\\nBy ID Number (recommended): If the name of the fault(s) has been changed, or you\\nare unsure of the history of the project, the ID Number should be used to match the faults.\\nThe ID Number is hidden from the user but is used internally in the Fault Model and the 3D\\ngrid.\\nLock all Re-sampled Horizon Nodes: Select this option if you do not want the nodes on\\nthe horizon lines to be changed during the Make Horizons processing (smoothing etc).\\nSee How to generate Fault-Horizon intersections for the 3D Grid and for further details.\\nFaults tab (Make Horizons)\\nThe Faults tab allows the user to control how the fault affects the interpolation of the horizon.\\nUncheck Active Fault to effectively remove the fault from the chosen horizon. In addition to\\ndefining whether or not the fault is modeled, the user can control the fault distance and various\\naspects of the fault displacement.\\nEach of the modeled horizons is shown as a folder containing all of the faults in the model. In\\naddition, there is a folder for individual fault defaults and a single item for the overall default\\nsettings. The fault settings are changed by selecting the fault and then editing the settings in the\\ndialog. Checking or un-checking the Use Default checkbox will toggle between using the current\\nsettings and the default settings for that fault.\\nMultiple faults can be selected using the Shift or Ctrl keys. Changes to the settings will then\\napply to all the selected faults.'},\n",
       " {'header': 'Growth Fault ',\n",
       "  'content': 'This setting is only used for horizons conforming to another. When this option is selected, the\\nthickness of the zone between the 2 conformable horizons may vary across fault(s). Use this\\noption when you want to preserve thickness variations due to syn-tectonic sedimentation or other\\ngeological processes.\\nGrowth Fault checked on.'},\n",
       " {'header': 'Fault Distance ',\n",
       "  'content': \"Data close to the fault is often likely to be erroneous due to smearing of the seismic close to the\\nfault. Therefore, it is often advantageous to ignore this data and instead use data located further\\naway from the fault to back interpolate into the fault plane.\\nThe effect of different fault distances during interpolating the horizon to the fault.\\nThe fault distance is specified in project units and can be specified independently for each side of\\nthe fault. Use the button to determine which side of the fault is 'yellow' and which is 'blue' then\\nassign the values accordingly.\\nDifference between distance set to zero (left) and 100m (right).\"},\n",
       " {'header': 'Fault Displacement ',\n",
       "  'content': 'There are a number of settings controlling the displacement along the fault:\\nAllow hinge - this option will permit faults to switch between being normal or reverse\\nalong their length.\\nMin/Max - specifies the minimum or maximum displacement across a fault. A minimum\\ndisplacement cannot be specified unless the Allow Hinge option is turned off.\\nSmooth - will smooth the displacement along the fault length such that sharp changes in\\nfault displacement do not occur.\\nTolerance - this will smooth the displacement by specifying a maximum tolerance for the\\nfault displacement in displacement per 100 project units.\\nTools on the Faults tab\\nThere are a number of tools on the Faults tab to help the user enter the correct settings and\\nmake the process more transparent.\\nColors the sides of the fault such that the fault distance can be set separately on each side.\\nResets the settings for the chosen fault.\\nCopies the settings for the chosen fault\\nPastes the copied settings to the chosen fault.\\nDisplays the selected faults and hides other faults.\\nSegments tab (Make Horizons)\\nThe segment window in the Process diagram contains a list of all segments (fault compartments)\\ndefined by the faults. The list of segments starts with the largest segment and continues with\\nsegments of decreasing size. For each segment the user can specify which input data to use.\\nDefault number of input data for each horizon is one (Input #1). By clicking the Add column\\nicon in the Horizons window, new input fields for Input #2 and Input #3 are generated.\\nAdditional segments can only be added if the model is re-gridded.\\nHow to build complex models using the segment settings\\nIn the majority of cases Petrel will deal with building horizons within complex structures without\\nany problems. However in certain circumstances, when working with very low angle faults or\\ntruncated low angle faults and poorly defined input data, it can be useful to specify which areas of\\nthe input data apply to which fault segment. This is generally only required when input data from\\none side of a low angle fault, crosses through to the other side of the fault, i.e. data for the same\\nhorizon at two different levels exists on one side of a fault.\\n1. Copy the input data and edit it so that there is one input object (points, lines or surface) for\\neach horizon in each segment. It is important to ensure that all the data for a specific\\nsegment only has data for the horizon within that segment.\\n2. On the Horizon tab use to add one input column for each segment. (see Horizon Tab'},\n",
       " {'header': '(Make Horizon)) ',\n",
       "  'content': '3. In the Segments tab specify which input to use in each segment.\\nWells tab (Make Horizons)\\nTo make sure that the well tops tie the generated horizons, a correction must usually be done.\\nThe Wells tab options enable the user to select an algorithm for creating the error between well\\ntop and generated horizon. Several reporting options are also available.\\nWell adjustment\\nThe error horizon is applied to the gridded horizon to create a horizon matching the wells. Select\\nwhether the adjustment should interpolate across segments or be restricted to segment\\nboundaries. If cells penetrated by the wells only is selected only those cells penetrated by the\\nwells will be adjusted. This is a useful option to visualize the local error.\\nIt is possible to choose an influence radius defining how far from a well the well adjustment will\\ninfluence the horizons. If an influence radius is not chosen, an algorithm for the well adjustment\\ncan be selected. Well adjustment is done along the pillars.\\nCorrect all cells penetrated by a well accurate: Use this option to re-calculate the\\nnodes in cells that penetrate wells so that the residual is zero. This option should not be\\nused where more that one well penetrates a single cell.\\nAdjust for missing well tops and zone log: Select this option to use the zonation of the\\nwell tops in the active Well Tops folder to correct the horizons. If there is no Zone Log\\npresent, a temporary one will be made during processing. Use this option if Well Tops are\\nmissing from some of the wells tops. If well tops are absent from some of the wells, Petrel\\nassumes they do not exist. If well tops are absent because they are not interpreted then\\nyou should not use this option.\\nUse Zone logs: Select this option to prevent the horizons crossing the well path between\\nwell tops. This option uses the zone log created from the well tops used to correct the\\nhorizons. The zone log will not be created on the fly, but the correction will honor user-edits\\nto the auto-generated zone log. If well tops are absent from some of the wells, Petrel\\nassumes they do not exist. If well tops are absent because they are not interpreted, then\\nyou should not use this option.\\nWhen using well tops in Make Horizon or Make Zones then the correct attribute (time or\\ndepth) will be used depending on whether the horizon is in time or depth.\\nCross-section through a 3D grid with 4 horizons A, B, C & D. The well to the right of the picture\\nhas no Well Top C interpreted. With Adjust for missing well tops unchecked, Petrel assumes\\nthe well top is present but not interpreted and attempts to fit the Horizon C in this well ignoring\\nthe zone log.\\nWith Adjust for missing well tops checked, Petrel will use the zone log during processing.\\nBecause Well Top C is missing, it is assumed that Zone C (in green) is missing in the well on the\\nright of the picture.\\nZone logs can be used to avoid a situation where well paths wrongly cross a horizon in a 3D\\nmodel. A minimum distance between the horizon and the well path after the correction can be\\nspecified (tolerance). The user should specify whether or not to use the zone logs, the well path\\nincrement in MD, a radius and a threshold distance. The threshold distance is the maximum\\ndistance between the well and the horizon at which the horizon is still corrected. This means there\\nwill be a correction of the horizon if the distance between the horizon and the well path is less\\nthan this maximum distance. A radius around the residual points should also be specified to define\\nhow far to extrapolate the correction. The next two figures show the result of the Make Horizon\\nprocess by using the zone logs or not.\\nYou can synchronize the names/colors of the zone log and the 3D model by right clicking on\\nthe 3D grid and selecting Sync names/colors by attached well tops.\\nWell report\\nIf the Make Well report option is checked, a miss-tie table will be created. When a miss-tie table\\nis written the well report will be copied to the Output Sheet and shown in the Display window, see\\nReporting. If the Reset sheet option is checked, a previously made report will be updated,\\notherwise the new report will be added below earlier results.\\nIn the well report sheet from Make Horizons, each horizon will be listed with information about\\nwells that pass through that horizon. The point of intersection will be listed with X, Y and Z\\ncoordinates together with:\\nWhere (in Z) the horizon was before correlation with the well top.\\nHow much the horizon has been corrected towards the well top.\\nWhere (in Z) the horizon is after correction.\\nThe depth difference between the horizon and the well top after correction.\\nThe Output sheet can be saved or the data copied and pasted into another windows program\\nhowever the sheet will not be saved with the project when it is closed.\\nIf Iconize the residual points and/or Iconize the residual surfaces is checked, a folder with\\nthe correction information will be put under the Input tab in Petrel Explorer. The Overwrite if\\nexisting option allows the user to update an already existing folder or create a new folder with\\ndelta points.\\nUncertainty tab (Make horizons)\\nThe principle for including structural uncertainty in Petrel is to identify the possible error\\nrepresenting one standard deviation and to multiply that error with a stochastic surface with\\nvalues around zero, which again will be added to the base case surface. In other words:'},\n",
       " {'header': 'S = S + U * U ',\n",
       "  'content': 'r bc 1s sgs\\nWhere Sr is the surface realization, Sbc is the base case surface, U is the surface or constant\\n1s\\nrepresenting one standard deviation error and U is the stochastic error surface.\\nsgs\\nWhen varying the seed value and running several runs, you will get several different realizations\\nwhich again can be investigated. With respect to the effect on volumetrics, they can be extracted\\nand plotted for visual inspection and they can be used to produce models representing for\\ninstance P10 and P90.\\nSee Structural Uncertainty for more information.\\nThe user has the option to identify the uncertainty value directly from the Make horizons\\nprocess. This is done by entering in the value representing one standard deviation as well as\\ndefining the settings for the error surface. The settings for the error surface,U is defined under\\nsgs,\\nthe Uncertainty tab. The error surface is defined as a normal distribution with a mean of zero and\\nstandard deviation of 1. The user must specify the variogram type and ranges/azimuth that are\\nused to populate the error surface. Some smoothing can also be added.\\nNote that for the base case horizon, the U is zero, hence Sr=Sbc.\\n1s\\nHow to specify the value or surface representing one standard deviation,'},\n",
       " {'header': 'U ',\n",
       "  'content': '1 s\\n1. Open the Horizons tab on the Make horizons process\\n2. Toggle on the Uncertainty icon\\n3. In the Std Dev. Column, specify the value representing one standard deviation, either as a\\nconstant or as a surface. It should be specified in the same unit as the horizon.\\n3.\\nSettings for specific cases\\nThere are some input data sets that need some particular settings in the Make Horizon process\\nstep to be able to get the best possible result.\\nHere we have listed examples where the best result requires experienced use of Petrel.\\nHow to keep a hole in the internal Petrel horizons in case of e.g. a salt\\ndome\\nWhen modeling salt domes in Petrel, we recommended using different settings in the Make\\nHorizon process for the tops of the salt domes and the areas around them.\\n1. Create a fault around the hole - make sure that data from the input surfaces does not\\nprotrude through this fault. The Key Pillars of this fault should extend above and below the\\ntop and the base surface forming the hole. To be able to close the circular fault, it is\\nnecessary to create two faults and then connect them. Do not merge them!\\n2. Go through the setup for the Make Horizon process step, as you normally would do.\\n3. Under the Stratigraphy tab, deselect the option Force the horizons to be calculated for\\nsmall segments.\\n4. If the hole is not created then - Check which segment represents the hole on the horizons\\nby turning off the segments in the segment folder one by one. It is probably the last one\\nsince they are sorted by size.\\n5. Go back to the Make Horizon process dialog and under the Segments tab, turn off the input\\nfor that specific segment - to do this click on the tick mark.\\n6. Run Make Horizon again.\\nHow to use Line data in complex fault systems\\nWhen using line data, like seismic interpretation, as input for creating horizons in the 3D grid,\\nthere is an option to make sure that they are accurately defined towards the faults.\\nThe option is cut by faults and can be found on the right mouse button menu for line data. This\\noperation will cut the line data towards the modeled faults. This option is particularly useful in\\ncomplex fault systems, where it helps the Petrel algorithm to better define the created horizons\\ntowards the faults.\\nWhen using this option, remember that the distance to faults in the Fault tab in the process dialog\\nhas to be zero. The option also requires the line data to extend beyond the fault limit (through the\\nfault).\\n1. Model the faults based on your input data and create a grid.\\n2. On the line data set that is input for the Make Horizon process step, click with the right\\nmouse button and select cut by faults.\\n3. In the Make Horizon process dialog in the Horizon tab, select the line data set as input and\\nin the Faults tab set zero distance to all faults.'},\n",
       " {'header': '4. Run Make Horizon. ',\n",
       "  'content': 'How to use line data as input in Make Horizons\\nDepth contours and line data sets can have large increments between the data points. Petrel will\\nonly consider the data points themselves as input. To be able to grid these data as accurately as\\npossible, there are two different approaches in Petrel.\\n1. Use the lines or contours as input in the Make Surface process step, but in the\\nSettings tab in this process dialog, check Use in If input is contours or 2D lines.\\n2.\\n3.\\n1.\\n2. In the Make Horizon process dialog, select the contours or 2D lines as input in the\\nHorizons tab.\\n3. In the Settings tab, check the Use option in If input is contours or 2D lines, and select\\nmax and min search radius.\\n4. Run Make Horizon with the above surface as input.\\n5. Use the Refine options in the Polygon operations folder under the Operations tab in\\nthe lines data settings to add new points to the line.\\n6. Use the Make Surface utility with a small increment to create a 2D gridded surface and\\nuse this as input for the Make Horizon process. This way data points from the input data\\nare sampled in two steps and will generally give a very accurate vertical layering of the 3D\\ngrid.\\n7. Run the Make Surface Process; see Make/Edit Surface for the input data with a very\\nsmall increment, e.g. 50x50 and ensuring that the pre-processing, Refine polygons\\noptions are set.\\n8. In the Make Horizon process use the produced surface as input.'},\n",
       " {'header': '9. Run Make Horizon. ',\n",
       "  'content': 'Note that you will have to test several settings for the Make Horizon process dialog in order to\\nfind the best settings for your data set.\\nQuality Control of Make Horizons process\\nAfter the Make Horizon process, the Horizon folder of the 3D grid contains the inserted horizons,\\nand the Zones and Zone Filter folders contain the zones between the horizons. The Horizons can\\nbe displayed one by one, all together or by using the Segment Filter. By using the Segment\\nFilter, selected parts of the horizon can be displayed. A good visual control of the input and the\\ngenerated horizon is achieved by displaying input surface(s) or lines together with the\\ncorresponding horizon in the 3D grid. If the input used is a surface, subtracting the horizon from\\nthe input can create a difference map. See below for further details.\\nRemember that the Make Horizon process step is a fast algorithm and a number of different\\nsettings should be tested out to find the optimal result for your data set.\\nVisual quality control\\nThe best way to check the quality of the 3D grid that has been created in Petrel is by viewing the\\ngrid with different visual settings. View the horizons in the grid and check that they look as\\nexpected. Particularly towards the faults, it is important to visually check the horizons in case the\\nfault settings in the Make Horizon process step need to be changed.\\nHow to generate a traditional 3D grid display\\n1. Open the Models window of the Petrel Explorer.\\n2. Display the top horizon with grid lines. See the Style tab of the Settings window for the'},\n",
       " {'header': 'Horizons. ',\n",
       "  'content': '3. Display the zones. Use Edges to switch on/off display.\\n4. Zoom in on a fault to get a good view of the quality of the faulting in the 3D grid.\\nHow to use the Segment Filter when visualizing the grid\\n1. This requires that fault segments have been defined in the Fault Modeling and Pillar\\nGridding process steps.\\n2. Display a horizon and open the Segment Filter folder.\\n3. Switch Off all Segments and switch On one by one.\\n4. Observe the change in the Display window.\\nHow to use the Zone Filter when visualizing the grid\\n1. This requires that more than one zone have been defined in the Make Horizons process and\\nlater in the Make Zones process steps.\\n2. Display the top horizons and the Edges.\\n3. Open the Zone Filter and switch Off zone by zone.\\n4. Observe the change in the Display window.\\nHow to use the General Intersection on the grid\\n1. Open the Models window of the Petrel Explorer and open the Intersections folder.\\n2. Use the option Insert General Intersection on the menu on the right mouse button on\\nthe Intersections icon. Observe that a new General Intersection icon has been added\\nto the Intersections folder.\\n3. Display and move the Intersection in the Display window.\\n4. Double click on the General Intersection icon to access further display settings.\\nFor further information on how to use the General Intersection, see General Intersection.\\n4.\\nA General Intersection as seen in Petrel.\\nHow to generate a difference grid between input and generated data\\n1. Convert a horizon from the 3D grid to a regular surface.\\n2. Double click on the horizon to open the Settings window.\\n3. Select the Output tab and define area of interest and XY resolution.\\n4. Press the Make surface button.\\n5. Note that the converted surface is placed in the Input window of the Petrel Explorer, and is\\ngiven the name of the horizon.\\n6. Subtract the input surface to get the difference between the input and the horizon in the 3D\\ngrid.\\n7. Use the Operations tab in the Settings window for the converted surface.\\n8. Select the surface in the Petrel Explorer and drop it in the area for A= by clicking on the\\nblue arrow .\\n9. Press the button.'},\n",
       " {'header': 'Flatten Model ',\n",
       "  'content': 'After building a faulted 3D model, it can be difficult to understand how the sediments were\\ndeposited as the structural changes have altered the original model. In Petrel, a very useful\\nprocess has been implemented which gives the possibility to select a horizon and flatten it by\\nremoval of fault throws on the horizon. All other horizons in the 3D grid will be changed according\\nto the flattened horizon.\\nThe flattened model will set the model back to the situation when the layers were deposited. This\\ngives a very good quality control of the model with respect to the depositional environment. This\\nview of the 3D model gives very good quality control of the thickness of the different zones in the\\n3D grid.\\nFlatten Model is NOT a reversible process. It is NOT possible to go back to the 3D grid.\\nRemember to always make a copy of the active 3D grid before running this process.\\nHow to Flatten the Model on a specific horizon\\n1. Make a copy the active 3D grid by selecting the grid, click on the Copy item icon in the\\nTool bar menu and then on the Paste item icon. The copied 3D grid will be added to the\\nbottom of the Models tab in Petrel Explorer.\\n2. Go to the copied 3D grid and select the horizon that you want to flatten.\\n3. Click with the right mouse button on the selected horizon and select Flatten model.\\n4. In the pop-up dialog, click on Yes. The Horizons in the 3D grid have now been altered.\\nVolume quality control\\nOne very dangerous error in building 3D models, particularly in simulation grids, is the presence\\nof negative volumes. Negative volumes can be present in Petrel when the grid has been build on a\\npoor fault model or with poorly defined directions and trends in the gridding process. The most\\ncommon cause of negative volumes in Petrel is faults that cross each other without being\\nconnected or truncated.\\nAfter the Make Horizon process it is important to check for negative volumes before doing more\\nwork on the model. If negative volumes are present, we highly recommend that the user go back\\nto quality control the 3D grid and the fault model.\\nNote that the grid cells at this stage are normally large. Negative volumes can be generated\\nafter further vertical layering when the cells are divided into smaller parts even if no negative\\nvolumes were present after the Make Horizon process.\\nHow to check the model for negative volumes\\n1. Go to the Geometrical Modeling process step in the Process diagram and open the\\nprocess dialog by double clicking.\\n2. In the process dialog, under Settings, select Geometrical and click OK. The property Bulk\\nVolume, which is default, will be calculated for the grid. For more information about this\\n3.\\n2.\\nprocess step, see Geometrical Modeling .\\n3. In Petrel Explorer go to the Property folder in the active grid. The property Bulk Volume will\\nbe listed in this folder. Open the Settings window for the property Bulk Volume by double\\nclicking on the property.\\n4. In the Settings window go to the Statistics tab. The max and min values for the\\nproperty are listed in the upper part of the window. If the minimum value is above zero, no\\ncells with negative volume are present in the 3D grid.\\n5. If the minimum value is below zero, there are cells with negative volume in the grid. To\\nlocate these cells, open the Settings window for the Property folder and go to the Filter\\ntab\\n6. Select Use value filter from the Filter settings list, and select the Bulk Volume from the\\nValue filter list. Select the Use filter check box. The max and min values for the Bulk\\nVolume will be shown. Change the max value to zero and click OK. For more information\\nabout the filter option, see Filtering of Property Models.\\n7. In the Display window visualize the Bulk Volume property. Only cells with negative volume\\nwill be visualized. To better understand where the cells with negative volume are, visualize\\nthe faults at the same time.\\nMake Zones and Layering\\nThe Make zones and Layering processes are the two last steps in defining the vertical resolution\\nof the 3D grid. The Make zones process is used when a geological zonation (isochores) is\\navailable. This process step may be skipped when no zonation is given. The Layering process\\nenables the user to define the final vertical resolution of the grid by setting the cell thickness or\\nthe number of desired cell layers.\\nStatus difference between zones and layering\\nWhen creating zones in Petrel each zone will be defined by two horizons. These intermediate\\nhorizons inserted into a Petrel project (disregarding of the input for generation of the zone) will\\nhave the same status as horizons in the continuing work in Petrel (also when exporting the 3D\\ngrid). These horizons can also be edited in the Edit 3D grid process step.\\nLayering however, will not be defined by enclosing horizons. Layering is defined as the internal\\nlayering reflecting the geological deposition of a specific zone. They are only sub-dividing the grid\\nbetween the zone-related horizons.\\nThe layers are not affected by editing in the Edit 3D grid process step. The Layering process\\nmust be run again after editing has been performed on the grid. Open the Layering process\\ndiagram and click OK without changing anything to correct the layering towards the edited grid.'},\n",
       " {'header': 'Make Zones Process ',\n",
       "  'content': 'This dialog has three tabs. In principle it works in the same way as the Make Horizon dialog - a\\nspreadsheet with the geological zones and horizons as rows and the specific user settings as\\ncolumns. Additional options are found in the Settings and Wells tabs.\\nThe Make zones process is calculated one stratigraphical interval at a time. Each horizon delimits\\na stratigraphic interval. The program will also allow for a stratigraphical interval above and below\\nthe top- and base- horizon respectively.\\nExample: If there are three horizons, called Top, Mid and Base horizon, in a model, there will be\\nfour stratigraphical intervals that the Make zones process can be applied to:'},\n",
       " {'header': 'Above Top Top - Mid Mid - Base Below Base ',\n",
       "  'content': 'Eroded horizons\\nIf you are working with eroded horizons and they are not being properly eroded in the Make\\nHorizon and/or the Depth Conversion process, this should be corrected before running Make\\nZones. Remember that this is an expert operation and is seldom needed.\\nTo do this, first go to the Output2 tab of the Zone filter Settings window. Generate output\\nisochores and choose the most appropriate erosion tolerance for your data set.\\nThen go to the Settings window of the 3D grid . In the Operations tab - enter the erosion\\ntolerance and click on the Make consistent button.\\nThe horizons should now be correctly eroded and the grid ready for the Make Zones process.\\nThe Petrel Explorer after inserting zones to the model\\nHow to make Zones\\n1. Double-click on Make Zones in the Process diagram. A process dialog will open up.\\n2. Select the Stratigraphical Interval for the definition of the zones, from the pull-down\\nmenu in the upper left part of the dialog. These main intervals are the intervals defined in\\nthe Make Horizons process. Note that only one interval can be calculated at a time.\\n3. Click the Add Zone button to add rows to the spreadsheet. Note that one click inserts\\nthree rows with two zone icons and one horizon icon (if the chosen stratigraphic interval are\\neither Top - Mid or Mid - Base). The zone icons represent the isochores used for calculating\\nthe new intermediate horizon.\\n4. Click on the Set number of items in table button and specify how many zones you\\nwant in the current stratigraphic interval.\\n5. Define input type. If a data object (isochore or well points) is used for defining the zones,\\nselect it in the Input window in the Petrel Explorer.\\n6. Click on the blue arrow next to the input field called Input and make sure that the name of\\nthe active data object is inserted. Several data objects can be inserted simultaneously but\\nremember to check the Multiple drop in table first.\\n7. Continue inserting the data objects into the spreadsheet until you have filled all Input\\n8.\\n7.'},\n",
       " {'header': 'Fields. ',\n",
       "  'content': '8. Select Build from Top or Build from Bottom. This is important when working with\\nerosional surfaces or with on-lapping geological sequences.\\n9. Select whether to use a Volume Correction or not. When adding isochores to a base or a\\ntop surface, the sum very seldom matches the top or base surface, respectively. The error\\nnormally is distributed proportionally or equally among the various sub intervals. By\\nselecting No correction all of the volume error will be added to the last zone that is built.\\n10. The thickness calculation can be preformed as True Stratigraphic Thickness (TST), True\\nVertical Thickness or Along pillars. When the pillars in a data set are vertical, it is\\nadvised to perform the thickness calculation along pillars, as this is a much faster operation\\nin comparison with the calculation of TST and TVT.\\n11. When clicking OK the intermediate Horizons and Zones will be generated. The new Horizons\\nand Zones are now available from the Horizons and Zone Filter folders in the Petrel'},\n",
       " {'header': 'Explorer. ',\n",
       "  'content': 'If you want to make zones for several intervals simultaneously (i.e. without closing the\\nMake Zones process dialog), make sure that you click on the Apply button before moving on to\\nthe next interval.\\nMake Zones settings\\nThere are three tabs with various settings in the process dialog for Make Zones:\\nZones - This is where the input data such isochores or well tops for the Make Zones\\nprocess is entered. In cases with no input, a numerical setting can be entered.\\nSettings - Some settings with regards to well correction, erosion and cell thickness.\\nWell Adjustment - well adjustments and reporting.\\nUncertainty - Is activated once the uncertainty icon has been toggled on. The settings for\\nthe stochastic uncertainty surface may be changed here.\\nZones tab (Make Zones)'},\n",
       " {'header': 'Stratagraphic Interval (Make Zones) ',\n",
       "  'content': 'The Stratagraphic Interval defines on which interval the spreadsheet of isochores is to be applied.\\nEach interval is defined from the main zones generated in the Make Horizons process.\\nExample: If two horizons (Top Reservoir, Base Reservoir) were generated in the Make Horizons\\nprocess, the following stratagraphic intervals can be used in the Make Zones process:'},\n",
       " {'header': 'Above Top Reservoir ',\n",
       "  'content': 'Between Top Reservoir and Base Reservoir'},\n",
       " {'header': 'Below Base Reservoir ',\n",
       "  'content': 'Separate zone matrices are set up and defined for each interval.\\nZone definition (Make Zones)\\nName - Name of the zone/horizon.\\nColor - Color of zone for visualization. Click on the Color legend icon to apply a rainbow color\\nscale to your zones. Click again on the icon to reverse the color scale.\\nInput type - Different Input types are available for the Zones:\\nConstant - A user defined constant value for the thickness of the zone. The thickness value\\nis entered in the input column.\\nIsochore - An isochore surface grid defining a variable thickness of the zone.\\nConformable - The values are gridded in Petrel to generate a horizon based on well tops\\nonly.\\nPercentage - A percentage value for the thickness of the zone, 100% being the total\\nthickness. The thickness value is entered in the input column.\\nRest - The residual thickness. No thickness specified. Petrel calculates the residual based on\\nthe other zones making up the total thickness. When one of the zones (independent on\\nwhich one) is defined as being Rest, the other zones are built towards that zone and\\nwhatever is being left over will become the \"rest\" zone. This zone will disappear if there is\\nno rest.\\nInput - Set automatically when the input type is defined as an isochore, well top or rest.\\nOtherwise define percentage or constant thickness here.\\nVolume Correct - Toggle on to perform the volume correction. When working with volume\\ncorrection this option allows the user to toggle off the tick for special zones that should not be\\nvolume corrected. Note that this column is not accessible when \"None\" is selected for volume\\ncorrection.\\nStatus - New or Done, depending on whether the process has been performed or not.\\nMultiple drop in table - Allows the user to drop several files, like isochores, simultaneously. Add\\nthe number of zones needed first by clicking to add several zones with the same settings in a\\nsingle operation. Alternatively, use to add single zones. Then click on the first isochore to use\\nin the isochore folder in Petrel Explorer. Click on the blue arrow next to the top zone. The\\nselected isochore will be inserted, followed by the rest of the isochores within the isochore folder.\\nSelect to set in a number of zones with the same settings.\\nUncertainty icon\\nClicking the Uncertainty icon will insert an extra column where the user can specify the value or\\nsurface representing one standard deviation on that particular horizon. Used in connection with\\nthe Uncertainty tab, see Uncertainty tab (Make Zones).'},\n",
       " {'header': 'Build From (Make Zones) ',\n",
       "  'content': 'When Building from Top the isochores are added from the top of the stratigraphic interval.\\nDepending on the Input type used, this option can be used to let the calculated horizons be\\nparallel or conform to the top. The same applies when Building from Bottom. Build From Both Top\\nand Base is only relevant when there is a zone defined as Rest. For example, if you select a rest\\nzone to be somewhere in the middle of the zone table, all zones above and below will be built\\ntowards it respectively.\\nVolume correction (Make Zones)\\nWhen adding e.g. isochores to a base or a top surface, the sum will normally not match the\\ntop/base. Therefore, a correction of the zone volumes can be applied differently.\\nProportional correction will split the error proportionally into the zones according to its\\nrelative thickness. This option is useful when the zones have a broad range in the thickness\\nvariation.\\nEqual correction will split the error into equal proportions for each zone. This option is useful\\nwhen the zones have little thickness variation.\\nNone correction will not make volume corrections for all zones. All of the volume error will\\nbe added to the last zone that is built, irregardless of its input type (even if that last zone\\nhas been defined as constant). If the zones are built from the top, the bottom zone will\\nincorporate all of the thickness rest and vice versa. It is a good idea to use this option\\ntogether with defining the last zone as Rest, see input types described in Zone definition'},\n",
       " {'header': '(Make Zones). Thickness (Make Zones) ',\n",
       "  'content': 'The calculation of zone thickness can be done as True Stratigraphic Thickness (TST), True Vertical\\nThickness (TVT) or Along Pillars:\\nTST  Thickness of a zone, measured perpendicular to the upper and the lower horizon of\\nthe zone.\\nTVT  Thickness of a zone, the vertical distance between the upper and the lower horizon\\nof the zone.\\nAlong Pillars  Vertical thickness of a zone along the pillars. This procedure should be used\\nwhen the pillars are vertical or close to vertical, because this calculation is much faster\\ncompared with the calculation of TST and TVT.\\nWhen TVT or Along Pillars have been selected, it is possible to select an option called Horizon\\nwith steep slopes. The algorithm used in this option can handle very steep horizons, such as\\nthose found around a salt dome.\\nSettings tab (Make Zones)\\nThe Settings window in the process dialog for the Make zones process step gives the opportunity\\nto select the different options and algorithms to be used for making the zones.'},\n",
       " {'header': 'Well Correction ',\n",
       "  'content': 'Well tops can be used for correction of new horizons in three different ways.\\nAfter each zone is generated, so the next zone is built from a well corrected\\nprevious horizon - Select this option to correct each zone to the Well Tops before building\\nthe next zone.\\nAfter all zones are built and the volume correction has been done if any - Well\\ncorrection is done after all zones have been built and after volume correction has been\\napplied.\\nBoth after each zone are generated and then also after all zones has been build\\nand the volume correction has been done -This option will correct the zones to the well\\ntops in 2 stages. To activate this method tick the checkbox in front of both the \"After each\\nzone\" and \"After all zones\".\\nWell correction will only be used if Volume Correction is set to Proportional or Equal in the\\nZones tab and the Well Adjustment is not set to \"None\" in the Well Adjustment tab.\\nKeep in mind that well correction and volume correction are conflicting operations and one will\\noverwrite the other. This results in whichever operation was performed last being the one that will\\ndominate the results.\\nThere is an option to honor the Well Adjustment settings used in the Make Horizons process (if\\napplicable). If this is selected the Well Adjustment tab will be deactivated.\\nWell Correction and Conformable Gridding\\nThe well tops and zone log can be used to control the way zones are built during the Make Zones\\nprocess. This is a particularly useful in settings where Well Tops are missing in one or more of the\\nwells due to faulting or stratagraphic pinch-out. When using this setting it is important to consider\\nthat Petrel assumes any missing Well Top is indeed \"missing\" and not \"uninterpreted\". If no zone\\nlog exists, a temporary log will be created during processing.\\nCross-section through model. No adjustment for Well Tops and zone Log. In well 227 Well Top A\\nand D are missing, in Well 696 Well Top A & B are missing. Note how the zone logs (displayed\\nalong the well traces as thick colored pipes) are ignored.\\nIn this example adjustment for Well Tops and zone Log has been made. Note how the zone logs\\n(displayed along the well traces as thick colored pipes) are matching the zones in the model.\\nAbsent Well Tops are considered to be genuinely missing.\\nConformable gridding: Only of interest when conformable has been chosen as Input type in the\\nZones tab. Select Across segments or Inside segments only. The different algorithms for creating\\nthickness maps are Convergent Gridder, Minimum Curvature, Moving average and Cos expansion.\\nHints in the dialog will explain the difference between these three methods. More details can be\\nfound in the Appendix.\\nUnconformity Handling: when the Make Zones process step handles erosion, the inserted\\nzones will be eroded towards the eroded horizon. This means that the erosion surface will be\\nrestored temporarily during processing if this option is selected. The erosion tolerance can be set\\n(in absolute Z-value). If the thickness between the eroded horizon and a horizon below is less\\nthan the tolerance, it is regarded as eroded. A higher value can help correct for erosion in areas\\nthat are not properly truncated. There is an option to iconize the restored isochore.\\nThe difference in results when the erosion option is not checked vs. is checked.\\nUse minimum cell thickness: It is possible to collapse layers below a specified threshold. This\\nsetting is especially useful in erosional or onlap settings where thin cells accumulate at the\\nunconformities. All cells below the threshold thickness are collapsed and set to Undefined. If\\nProportional or Fractions laying methods are selected the direction must be specified.\\nOther Settings: Select the number of smoothing iterations desired. Use zero if the input data is\\nof high quality. By checking the option Iconize the temporary calculated objects, some important\\nintermediate calculation steps can be saved and put in Petrel Explorer under the Input tab.\\nUnfaulted node position surface (Structural Grid)\\nUnfaulted node normals (Polygons)\\nUnfaulted difference surface (Regular Grid)\\nUnfaulted difference surface, adjusted for normals, (Regular Grid)  how the surface would\\nhave looked if not faulted.\\nIsochore, adjusted for normals, (Regular Grid)\\nThis is an expert setting and is normally not needed\\nWell Adjustment tab (Make Zones)\\nThe well adjustments are only available when well tops have been specified as input data and the\\nwell adjustment box under the Settings tab has not been checked.\\nWell adjustment can be selected as:\\nNone - The input data will not adjust to the well points.\\nAcross segments - The well point adjustments are done across fault segments.\\nInside segment only - Adjust only the segment that the well penetrates and not influence\\nthe input data across faults.\\nUse influence radius can be selected if well adjustment has been selected. It annotates how far\\nfrom a well the well adjustment will influence the creation of zones. However, the well adjustment\\nwill override the influence radius.\\nExample: If the radius defined is larger than a segment extension in one direction and Inside\\nsegment only has been selected as well as adjustment condition, then the segment boundary\\nwill limit the lateral extent of the well adjustment.\\nIf Use Influence Radius is not selected with any of the well adjustment options, an algorithm\\nfor the well adjustment can be selected. See Appendix 2 for explanations of the different available\\nalgorithms.\\nUse Zone logs: Select this option to prevent the horizons crossing the well path between well\\ntops. This option uses the zonelog created from the well tops used to correct the horizons. The\\nzone log will not be created on the fly, but the correction will honor user-edits to the auto-\\ngenerated zonelog. If well tops are absent from some of the wells, Petrel assumes they do not\\nexist. If well tops are absent because they are not interpreted then you should not use this\\noption.\\nUse the option Make Well Report for quality control of before and after well correction. Residual\\nsurfaces and point sets can be output for visual quality control. Replace Dip and Azimuth on\\nWell Tops will update the appropriate attributes stored on the Well Tops.\\nWhen using well tops in Make Zones the correct attribute (time or depth) will be used\\ndepending on whether the horizon is in time or depth.\\nUncertainty tab (Make Zones)\\nSee Uncertainty tab(Make Horizons) for information about how to use the Uncertainty tab settings\\nas well as information about the terminology used in this section.\\nTo get access to the Uncertainty tab, you must first specify the value/surface representing one\\nstandard deviation error on the zone interval to investigate. This is done on the Zones tab.\\nThe settings for the error surface are specified under the Uncertainty tab. The error surface is\\ndefined by a normal distribution with mean of zero and standard deviation of one. The user can\\nadjust the variogram settings and specify degree of smoothing. The error surface may also be\\nextracted and will then be stored on the Input tab.\\nHow to define the value/surface representing one standard deviation error\\non the zone interval\\n1. Open the Zones tab in the Make Zones process\\n2. Toggle on the icon\\n3. Specify the value or the surface representing one standard deviation on the intervals of\\ninterest.\\n3.\\nNote: uncertainty is always added to the resultant horizon generated between two known\\nhorizons (or above or below a known horizon). The generated zones must be adjusted to fit in\\nbetween the fixed interval defined by the top and base horizon. If there is uncertainty added to\\none of these zones, the other zone will have to be adjusted accordingly.'},\n",
       " {'header': 'Layering Process ',\n",
       "  'content': 'By double-clicking on Layering in the Process diagram, the Layering process dialog opens.\\nThis dialog has only one tab. In principle, it works the same way as the Make Horizon and Make\\nzones dialogs - a spreadsheet with the zones as rows and the specific zone settings as columns.\\nHow to build layers\\n1. Double-click Layering in the Process diagram. The process dialog for Layering will\\npop up.\\n2. The dialog lists the zones generated in the Make Horizons and Make Zones processes.\\nFor each zone select the desired resolution and layering layout.\\n3. Make sure you have one or both of the I and J intersections displayed in the graphics.\\nZoom in to see the full vertical interval.\\n4. Create the internal layering of the zones by clicking OK , and observe the results.\\nThe Horizons, Zones and Layering can be removed by clicking with the right mouse button on\\nthe 3D grid icon and selecting one of the Remove options.\\nA cross section with layering displayed.\\nLayering settings\\nThere are some options available for the process of defining the layers.'},\n",
       " {'header': 'Common Settings (Layering) ',\n",
       "  'content': 'Build Along: Select how the thickness is to be calculated. Choose from TST, TVT or Along Pillar.\\nSee tool tip for further details. The Horizons with steep slopes option is only available if TST or\\nTVT build selection is chosen.\\nUse minimum cell thickness: It is possible to collapse layers below a specified threshold. This\\nsetting is especially useful in erosional or onlap settings where thin cells accumulate at the\\nunconformities. All cells below the threshold thickness are collapsed and set to Undefined. If\\nProportional or Fractions laying methods are selected the direction must be specified.\\nName - Name of the zone.\\nColor - Color of zone for visualization.\\nCalculate - Useful when regenerating only a few selected zones.\\nZone division - Options on how to subdivide the zone into cell layers (For further details, See\\nZone Division ). The zone division is always done along pillars in the 3D grid.\\nProportional - Constant number of cell layers at every pillar of the grid. The cell layering\\nwill be somewhat conformed to both the top and base of the zone.\\nFollow top - Cell layering parallel to the top of the zone.\\nFollow base - Cell layering parallel to the bottom of the zone.\\nFollow surface - Defines layers in the 3D grid paralell to a specific surface. It preserves\\nthe correct layering in eroded zones and enables a more accurate property distribution.\\nFraction - Layering, with user controlled proportional thickness of each cell layer.\\nLabel - Number of cells, cell thickness or how cells are divided within a zone. This is dependent\\non what is selected in the Zone division option.\\nInput - Resolution either in cell thickness, number of layers or division coding. Depends on the\\nprevious selections.\\nReference Surface - Input a surface to control the orientation of the layers. This surface\\nrepresents the orientation at the time of deposition and layers generated will therefore not have\\nthe same inclination as the input surface.\\nRestore Eroded/Base - Option to correct for erosion.'},\n",
       " {'header': 'Zone Division ',\n",
       "  'content': 'Building layering proportionally\\nDivides the zone into a given number of layers of the same thickness. Figure below shows 5 cell\\nlayers.\\nBuilding layering from top and downward (Follow top)\\nDivides the zone into cell layers with a constant user controlled thickness. The cell layers are\\nparallel to the top of the zone. Figure below shows 5 cell layers.\\nBuilding layering from base and upward (Follow base)\\nDivides the zone into cell layers with a constant user controlled thickness. The cell layers are\\nparallel to the base of the zone. Figure below shows 5 cell layers.\\nBuilding layering by using Fractions\\nBy using fractions you may divide each layer proportionally into smaller units. The figure below\\nshows 5 layers with a division coding of 31122 (SUM of 3+1+1+2+2=9). This means that the first\\nlayer is divided in 3/9 of the zone thickness, the second and third in 1/9, the forth and fifth into\\n2/9.'},\n",
       " {'header': 'Allen Diagram (Juxtaposition Diagram) ',\n",
       "  'content': 'As a first step in fault seal analysis, an Allen Diagram is a quick way to check the juxtaposition\\nbetween individual stratigraphic zones across faults of interest. The areas of juxtaposition will be\\ncalculated and can be viewed in the 3D window.\\nHow to generate an Allen Diagram\\n1. Display the faults in a 3D model and make sure that the model is active (bold).\\n2. Open the Settings window for the Fault folder in a 3D model in Petrel Explorer.\\n3. Tick the option As separation diagram in the lower area of the Style tab and click OK.\\nOnly those parts of the faults that share the same stratigraphic interval on both sides will now be\\nseen in the Display window. Click on a field to get its calculated area. It will be displayed below\\nthe Display window. The area is calculated in units, that is, in square meters for metric data and\\nsquare feet for imperial data.\\nQuality Control of Make Zones and Layering\\nAfter the Make Zones and Layering processes, the Horizons and Zone Filter folders of the 3D grid\\nwill contain new horizons and zones. Several visualization tools can be used to quality control the\\nresult:\\nSegment, Zone and Fault Filter.\\nI- and J- Intersections.'},\n",
       " {'header': 'General Intersection. ',\n",
       "  'content': 'The zones will be stored together with the horizons in the Horizons folder in Petrel Explorer,\\nhowever, the layers will not be found as objects in Petrel Explorer, but will simply be a finer\\ndivision of the zones.\\nThe Sub-horizon lines can be switched on/off in the Settings dialog for the Edges icon. Switching\\nthem off may improve the speed of the graphics display.\\nStructural modeling in Petrel is very strong and delivers 3D grids with a high quality. These grids\\ncan be exported on file formats like ECLIPSE and VIP for transfer to other applications. The\\nindividual main layers (Horizons) can also be exported as 2D surfaces on a range of different\\nmapping system formats (See Export Data).\\nWhen visualizing only the Edges, the display is showing the \"walls\" along the Area of Interest and\\nthe fault planes. The display along the faults shows hanging wall and foot wall lines for both sides\\nof the fault and can be messy to look at. Improve the view by displaying a horizon in addition.\\nSee How to use the General Intersection for information on using the general intersection.\\nHow to use the Segment Filter\\n1. Display selected zones and one or two horizons.\\n2. Switch off all segments and switch on the ones you are particularly interested in taking a\\ncloser look at. Note that the speed of the graphics improve when displaying fewer\\nsegments.\\nWhen viewing and zooming inside a zone or segment use the Target Zoom button for\\nimproved control on the zooming.\\nHow to use the Zone Filter\\n1. Display selected zones or Intersections.\\n2. There are two levels of icons in the Zone Filter folder. Level one consists of the main zones\\ngenerated in the Make Horizons process. Level two consists of the zones generated in the\\nMake Zones process. When opening a zone folder for one of the main zones the zones are\\nautomatically displayed. Each zone can also manually be switched On/Off.\\nHow to use the I and J Intersections\\n1. I- and J- intersections are intersections along the grid lines. Visualize one of the\\nintersections in the Display window. Note that if you have your zone folders in the Zone\\nFilter open, all zones are displayed in the intersection.\\n2. If one of the intersections is active (bold font), utilize the \"play\" tools at the base of the\\nPetrel window. These tools are very useful when stepping through the various intersections\\nin the 3D grid.\\nFor further information on how to use the I- and J-Intersections, seeI- and J- grid intersections.\\nA display with intersections.\\nVolume quality control (Make Zones)\\nThe 3D model should be checked for negative volumes after both the Make Zones and the Make\\nLayering processes. The earlier negative volumes are detected, the less work will have to be\\nrepeated. Since the Make layering process divides the cells into smaller parts, negative volumes\\ncan be present in the 3D grid after the Make Layering process, even if no negative volumes have\\nbeen detected after the Make zones or the Make Horizon processes.\\nNegative volumes can be present in Petrel when the grid has been built on a poor fault model or\\nwith poorly defined directions and trends in the gridding process. The most common cause of\\nnegative volumes in Petrel is faults that cross each other without being connected or truncated.\\nFor a description on how to check for negative volumes, see Volume quality control.'},\n",
       " {'header': 'Flatten Model ',\n",
       "  'content': \"After building a faulted 3D model it usually is difficult to see how the formations were deposited as\\nthe structural changes have altered the original model. In Petrel, a very useful process has been\\nimplemented which enables the user to select a horizon and flatten it by removing fault throws on\\nthe horizon. All other horizons in the 3D grid will be changed according to the flattened horizon.\\nThe flattened model will enable you to see the model as it was when the layers were originally\\ndeposited. This gives a very good quality control of the model with respect to the depositional\\nenvironment. This view of the 3D model gives very good quality control of the thickness of the\\ndifferent zones in the 3D grid.\\nTo flatten a model on a particular horizon, right-click on the horizon and choose flatten model.\\nFlatten Model is NOT a reversible process. It is NOT possible to go back to the 3D grid.\\nAlways make a copy of the active 3D grid before running this process.\\nZone remapping\\nAfter importing 3D model data from another 3D modeling software, or import of 3D simulation\\nresults, all layers are listed as horizons because the file does not hold any information about\\nwhich layers are horizons. As a result, the horizons and zones need to be re-arranged to match\\nthe original zonation and layering. In Petrel, the Zone remapping process has been implemented\\nwhich enables the user to remap the zones and layers.\\nIf you need to transfer a model from an external 3D modeling software into Petrel, it is\\ncompulsory that you know the layering and zonation for that model.\\nTo remap the zones and layers of a 3D grid, right-click on the 3D grid and choose Zone\\nremapping from the context menu. In the dialog window that appears the user can create new\\nzones and horizons by disabling or enabling horizons from the original horizon layout.\\nOn the left hand side all original horizons are listed with the intermediate horizons (layers).\\nTo stack layers into zones simply select all intermediate horizons for the zone and click the\\nDisable/Enable button . Only enabled horizons (in black) will be in the\\nHorizons tree of the 3D grid.\\nOn the right hand side is the resulting zone/horizon mapping. Here you can also click on a\\nzone/horizon to rename it. Type in the new name in the field above the list.\\nAfter importing data you may end up with a very large list of horizons in your model, and no\\nintermediate horizons. To quickly organize the layers and zones in Zone remapping, start by\\nselecting all the horizons on the left hand side (don't forget to scroll down) and click the\\nDisable/Enable button. This will create 1 zone with a top and bottom horizon on the right hand\\nside. Now, you can make up all the intermediate zones by selecting the pair of horizons on the left\\nhand side that makes up the top/bottom of those zones and again pressing the Disable/Enable\\nbutton.\\nThe Zone remapping process is also useful if you wish to remove a few layers from within a\\nzone (and not the entire zone) to clean up the 3D model, or before using the Output for the grid\\n(Copy 3D grid) functionality.\\nThis process can be repeated at a later stage should you wish to enable a horizon again.\\nIf you have nested zones, and do something with the zone mapping here, you will lose the\\nsub zonation.\\nStair-step faulting\\nThis process creates stair stepping faults based on fault geometries defined in the structural\\nframework. This facilitates modeling of complex fault relationships while avoiding crossing pillars\\nand inside-out cells.\\nThe Stair-step faulting process will adjust an existing 3D grid to incorporate additional faults by\\nstair-stepping. As this does not require alignment of the grid to the faults, difficult fault\\ngeometries can be more easily modeled in this way.\\nThe process is intelligent and automatically understands which faults from the structural model\\nhave been converted into a pillar fault model. These faults are automatically deactivated within\\nthis process.\\nFig 1. The dialog window for the Faults tab.\\nList of parameters: The Faults tab\"},\n",
       " {'header': 'Parameter Function ',\n",
       "  'content': 'Target grid The grid to which to add stair-step faults (this grid should already have\\n(active) horizons and layering)\\nStructural The structural model from which to sample the stair-step faults and\\nframework horizons\\nNone/All Buttons for selecting all or no faults for stair stepping\\nFault Column listing the fault names, referring to the faults folder in the\\nstructural framework\\nStair-step Select individual faults for stair stepping\\nSample Specifies whether to sample horizon lines from the structural model to\\nhorizon lines guide layer adjustment; disable this for a particular fault if the stair-\\nstepping initially results in \"smeared\" horizons across the fault.\\nList fault Also list faults from the structural model which have already been included\\nalready via key pillars.\\nincorporated\\nas pillar faults\\nFig 2. The dialog window for the Expert tab.\\nList of parameters: The Expert tab'},\n",
       " {'header': 'Parameter Function ',\n",
       "  'content': 'Output QC properties By selecting this option, Petrel will produce properties useful for\\nQuality Checking the result of the stair stepping process. The\\nproperties will be stored in the Properties folder in the 3D grid.\\nIconize intermediate Produce additional points and meshes on the Input tab which help\\nresults demonstrate how the stair-stepping has sampled the structural\\nmodel and adjusted the horizons\\nUse multiple threads Allow use of multiple processors and cores when running\\nperformance-intensive parts of the algorithm\\nCollapse cells Eliminate thin cells above and below stair-step fault k-faces;\\ntruncated to less than higher numbers will result in more cells being eliminated.\\nxx percent of their\\nthickness\\nOutput QC properties\\nThe stair-step faulting process generates some properties on the resulting grid which can be used\\nto quickly identify potentially troublesome areas:'},\n",
       " {'header': 'Property Meaning ',\n",
       "  'content': 'Layer Marks the region of the grid that has been adjusted by the stair-stepping\\nadjustments process\\nInterpolation Where layering has been interpolated, this property corresponds to number\\ndistance of cells over which interpolation has occurred\\nReversal Indicates regions in the grid where some layers should have appeared\\nregions multiple times in the same column due to reverse (or near-reverse) faults\\nLayers Geological layer\\nCell z-range The z-size of the cell bounding box, useful for identifying cells which have\\nbeen skewed during stair-stepping.\\nIn addition, the option to \"Iconize intermediate results\" on the Expert tab also produces some\\nadditional results on the Input tree:'},\n",
       " {'header': 'Item Meaning ',\n",
       "  'content': 'Horizon XXX A point set showing where horizons and horizon-fault lines were sampled\\nsamples from the structural model, and which columns they were used in.\\nStair-step Triangle meshes showing the top and base horizon interpolations for a\\ninterpolated zone; these show how horizons have been extrapolated through the faults\\nhorizons of to guide layering of the zone in the vicinity of the fault.\\nzone XXX\\nIncorporating complex structure into a geocellular model\\nComplex structure often causes problems for traditional corner point geocellular models. This is\\nusually due to truncating faults warping / twisting cells making them unsuitable for input into a\\nreservoir simulator. Modelers usually omit problematic faults for this reason, which introduces\\nbias at early stages of the modeling process. These complex geometries can be approximated by\\nstair-stepping the grid in the faulted region.\\nThe option to add faults as stair-step has been added after the Layering process. Some or all of\\nthe faults can be stair-stepped, but it is important to understand the limitations of these kinds of\\ngrids.\\nIf a fully stair-step grid is required, then the best starting point is Utilities/Make simple grid.\\nSimply set the geometry here and then go to the Make Horizons process. Note that Make zones\\ncannot be used since the horizons in the grid must match the horizons in the structural model\\nwhen stair-step faults are being included.\\nThe process dialog will list the faults which have not yet been included in the grid.\\nFig 3. Left, Stair step faulting dialog window. Right, Resulting stair stepped grid displayed with\\ninput faults from structural framework for QC.\\nTutorials: Stair-step Faulting\\nUsing the Structural Model to construct Geocellular models\\nThere are three grid types which can be constructed from the Structural framework:\\n1. Normal Pillar Grid . This is the standard Petrel workflow where the fault faces are\\nrepresented by cell faces, ie, all faults are modeled by fault pillars. This is the best choice if\\nfaults can be reasonably modeled when: all data is on the correct side of the fault;when\\nfault segment boundaries can be used for contact definition;and when properties can be\\ncalculated on the faults.It is also a good grid for simulation.\\n2. Part Stair-step . In this grid major faults are modeled with pillars and stair-step faulting is\\nonly used where the geometry is too complex. Be aware that there are limitations with\\nstair-step faults.\\n3. Full Stair-step . This grid can handle most geometries and is the only choice in very thick\\nreservoirs with complex multiple truncations. Keep in mind the limitations of stair-step\\ngrids.'},\n",
       " {'header': 'A Normal Pillar Gridding Workflow ',\n",
       "  'content': '1. Fault model from structural framework: Convert all faults to pillar based faults.\\n2. Fault modeling (optional): Eventually optimize the pillar based fault model for pillar\\ngridding.\\n3. Pillar gridding: Tune the grid by incorporating all faults.\\n4. Make horizons: Use the horizons from the structural framework as input.\\n5. Make zones (optional)\\n6. Layering: Define the final cell size in the K-direction.\\nA partly stair stepped workflow\\n1. Fault model from structural framework: Select some of the faults in the structural\\nframework to be converted to pillar based faults.\\n2. Fault modeling (optional): Eventually optimize the pillar based fault model for pillar\\ngridding.\\n3. Pillar gridding: Tune the grid by incorporating the selected faults.\\n4. Make horizons: Use the horizons from the structural framework as input.\\n5. Layering: Define the final cell size in the K-direction.\\n6. Stair-step faulting: Select to use the faults from the structural framework which are not\\nselected in step 1 to guide the definition of stair stepping faults.\\nA fully stair stepped workflow\\n1. Make simple grid: Define a grid geometry without faults.\\n2. Make horizons: Use the horizons from the structural framework as input.\\n3. Layering: Define the final cell size in the K-direction.\\n4. Stair-step faulting: Select to use the faults from the structural framework to guide the\\ndefinition of stair stepping faults.\\n4.\\nFig. 1 Left, pillar based grid. Middle, partly stair stepped model where the structurally complex\\ngeometries are stair stepped and the not so complex geometries are kept pillar based. Right, a\\nfully stair stepped model.\\nStructural frameworks can be directly converted into a pillar-fault model. This process\\nautomatically limits the pillars to the chosen model interval and connects branches and crossings\\nbetween faults automatically. If complex fault truncations are included, the resultant pillar-fault\\nmodel will have pillars correctly placed for truncation but the user will have to manually make the\\ntruncation.\\nTutorials: Working with Time and Depth\\nIt is currently not possible to depth convert a structural model.\\nTwo workflows are suggested:\\nDepth convert the interpretation inputs and build a structural model in depth.\\nDepth convert the TWT grid.'},\n",
       " {'header': 'Edit 3D Grid ',\n",
       "  'content': 'The Edit 3D Grid step in Petrel allows the user to polish the 3D model. If there are flaws related\\nto the structural grid that could not be solved during the generation of the 3D grid structure, this\\nis where manual fixes can be made. The user should remember that manual edits are not easily\\ndocumented and this will make it difficult to reproduce the model.\\nEdited nodes can be locked before running Make Horizons again. Petrel will try to honor well tops\\nand locked nodes simultaneously, but locked nodes may conflict with well tops if they are in close\\nproximity.\\nThe process Edit 3D Grid allows for editing on the horizon nodes and the pillars. This is\\ndescribed later in this section.\\nUpdating the 3D grid\\nWhile the other structural modeling steps can be performed automatically, Fault Modeling is a\\nmanual step requiring decisions and interpretations from the user. When a 3D grid needs to be\\naltered, different actions apply depending on the type of the update.\\nHow to update when a new fault is introduced or an existing fault is\\nchanged\\nThis implies a fundamental change in the 3D grid and it is necessary to go back to the Fault\\nModeling process.\\n1. Change the Key Pillars to include the new fault or change existing Key Pillars to incorporate\\nthe change in the fault.\\n2. Run through the Pillar Gridding process and the processes for the vertical layering with the\\nsame settings as before.\\nHow to update when a seismic interpretation has produced a new top\\nreservoir horizon\\nIf the new interpretation does not lead to changes in the faulting, it can replace the existing\\ninterpretation in the Make Horizon process dialog (run Make Horizons with the new surface\\ninstead of the old). Run through the process steps for Make Zones and Layering with the same\\nsettings as before.\\nHow to update when a new well top is available\\n1. Reload the new well tops file or, use the Edit Well Points process to add the new well pick.\\n2. Insert the well top icon into the correct Input field in the Make Horizon process dialog and\\nrun Make Horizons.\\n3. Run through the process steps for Make Zones and Layering with the same settings as\\nbefore.\\nHow to update when an extra zone in the geological zonation is given\\n1. Open the Make zones process dialog and use the Tool bar icon to insert the new\\nzones.\\n2. Specify what the new input is and click OK.\\n3. Run through the process step for Layering with the same settings as before.\\nHow to redefine sub-zones (Layering)\\n1. Open the Layering process dialog and redefine the resolution and layout of the layers in\\nquestion.\\n2. Click OK to produce the new grid.\\nManual Edits of the 3D Grid\\nManual edits in Petrel are very powerful, but should be used with care as the data can be changed\\nextensively. However, manual edits are a very good tool which can compensate for poor or\\nindecisive input data, for example, a peak on the input data can be removed in one mouse click.\\nPetrel has a few tools for performing manual edits on the 3D grid. Note that these edits are NOT\\nreproducible and should be limited in a project. Editing is done directly in the 3D window on the\\ngrid. All elements of the 3D grid (horizons, faults, etc.) can be edited similarly to the editing of'},\n",
       " {'header': 'Key Pillars. ',\n",
       "  'content': 'Manual edits do not affect insertedlayers. Re-insert your layers after manual edits by running the\\nMake zones and Layering processes.\\nRemember that manual edits are powerful and very useful for correcting small errors in the\\ninput data or to correct interpretation of a model, however it is a time consuming task and can\\nintroduce new errors. Manual edits should always be kept at a minimum.\\nProcess dialog in Edit 3D Grid\\nIn the process dialog of the Edit 3D Grid process step, there are four tabs: Info, Fault Draw\\nStyle, Zones Draw Style, and Edit Draw Style. The draw style tabs contain settings for the\\ndisplay of various objects in the Display window.\\nThe Fault Draw Style tab is the same as the Style tab for Faults.\\nThe Zones Draw Style is the same as the Style tab for Edges\\nThe Edit Draw Style is the same as the Edit Draw Style tab for Edges and Faults.\\nSee Faults settings for details of these settings.'},\n",
       " {'header': 'Tools ',\n",
       "  'content': \"The following tools for manual edits on the 3D grid are:\\nMove Smooth- When this function is activated, all manual edits of the 3D grid with Select\\nHorizon Node will affect a number of nodes in a radius around the selected and edited node.\\nNumber of Smooth Nodes - Sets the radius of affected horizon nodes around the\\nselected node, when the Move Smooth function is activated. This radius will also affect Smooth\\nHorizon and Remove Peak On Horizon, but for these functions the radius is absolute and the\\nMove Smooth option doesn't have to be activated.\\nSmooth area - Option for automatic smoothing of a horizon within a user defined given\\nradius, set in Number of Smooth Nodes. The function will not smooth the selected node, which\\nwill have to be removed with the Remove Peak On Horizon option.\\nRemove Peak On Horizon - This tool will smooth the horizon within the selected radius,\\nincluding the horizon node you select. This is a good editing option for horizons with unwanted\\npeaks. The selected radius is set in Number of Smooth Nodes.\\nUndo - Removes the editing. The Undo option will remember all editing options unless the\\nprocess step is changed in the Process Diagram or if Petrel is closed.\\nRefresh Horizon View - This option will redraw the edited horizon with new color, grid and\\ncontour lines.\\nCollapse Horizon Node - This option will collapse two selected horizon nodes into one, i.e.\\nsetting the thickness of the zone to zero in the node. Two consecutive horizon nodes have to be\\nselected on a fault or the I- or J-intersection to be able to collapse the horizon nodes.\\nExpand Collapsed Horizon Node - This option will expand collapsed nodes back to two or\\nmore horizon nodes. This option will only work on horizon nodes that have been collapsed by the\\nMake Horizon or Make Zones processes or by the Collapse Horizon Node.\\nLock Horizon Node - This option will lock a horizon node at its current position in case of\\nrerunning the Make Horizon process*. This gives the possibility to edit on a horizon and save this\\nediting if the horizons are reintroduced in the 3D model. To distinguish locked nodes from other\\nnodes in the grid, they will be displayed with a brighter color.\\nUnlock Horizon Node - This will unlock a node that has previously been locked.\\nFree movement - A selected Shape Point or Key Pillar can be moved in all directions with no\\nrestrictions. Free movement is not available for horizon nodes, which has to be moved along the\\npillars in the grid.\\nMove along Tangent - A selected Horizon Node, Shape Point or Key Pillar can be moved along\\nits pillar tangent only.\\nSelect Horizon Node - Will select one or more horizon node(s) by clicking on a horizon or a\\nhorizon node, for manual edits.\\nSelect Shape Point - Will select one or more Shape Point(s) by clicking on faulted pillars for\\nedits.\\nSelect Pillar - Will select one or more faulted pillar(s) by clicking, for edits.\\nLock When Moving - While this toggle is depressed, all of the points edited will be locked.\\nVertical Pillar - Will set the selected faulted pillar(s) to vertical pillars.\\nLinear Pillar - Will set the selected faulted pillar(s) to linear pillars.\\nListric Pillar - Will set the selected faulted pillar(s) to listric pillars.\\nCurved Pillar - Will set the selected faulted pillar(s) to curved pillars.\\n* Note that locked nodes may move if the Make Horizon process is run again - well tops may\\ncause the locked nodes to move slightly. More information on this can be found in Settings tab\"},\n",
       " {'header': '(Make Horizon). Editing Horizons ',\n",
       "  'content': 'Editing of horizons in Petrel can be divided into three different approaches. The horizons can be\\nedited directly by selecting horizon nodes on the horizon and editing up and down. Each horizon\\nnode will be drawn in Petrel where the horizons intersect with faults, and if edits towards the\\nfaults are needed, it is recommended to edit the nodes directly intersecting between the horizon\\nand the fault. The main advantage with this approach is that more nodes can be selected and\\nedited together. By using the I- and J-intersections the same effect can be achieved between the\\nfaults.\\nUse shift to select all nodes between 2 selections when editing.'},\n",
       " {'header': 'Smoothing Horizon ',\n",
       "  'content': 'The Move Smooth option is a way of editing the horizons within a specified radius. After\\nspecifying the radius, move the horizon node in X, Y and/or Z-direction.\\nActivate the Lock When Moving option\\nActivate the Move Smooth icon and define the radius of grid cells. The number 3\\nis the number of cells away from the selected grid node that will be affected by the edition.\\nClick on the Select Horizon Node icon, and move nodes in the Display window.\\nThe concept is the same as for editing of Key Pillars.\\nMove smooth from one node with a radius of three.\\nHow to remove peaks on a Horizon\\nPeaks or spikes on horizons in the 3D grid can be removed with a simple click.\\nActivate the Lock When Moving option\\nChoose the Remove Peak On Horizon icon in the Function bar menu.\\nSet the Number of Smooth Nodes in the Tool bar menu. This will be the number of\\nnodes around the selected node that will be affected by the smoothing process.\\nClick on the peak on the horizon.\\nSmoothing of a Horizon\\nA horizon can be manually edited to be smooth, as explained in above. However, it is also\\npossible to use a more automatic approach to smooth a horizon. By using the Smooth Horizon\\noption in the Function bar the Horizon will be smoothed by calculating a smooth spleen curve\\non the horizon. What effect this operation has on the horizon depends on the Number of\\nSmooth Nodes set in the Tool bar menu. The larger this number is, the more\\nhorizontal the horizon will become. The node selected (clicked on) will not be edited.\\nThe Smooth Horizon option will not affect the horizon across faults.\\nActivate the Lock When Moving option\\nSet Smooth Horizon active\\nSelect the radius that should be affected by the operation in the Number of Smooth Nodes\\n.\\nClick on the horizon where smoothing is needed.\\nTo correct the selected node that has not been edited, select Remove Peak On Horizon\\n, reduce the Number of Smooth Nodes to 1-3, depending on how large it was\\nwhen using Smooth Horizon . Click on the node that wasn\\'t edited.\\nEdit of Horizon Nodes on Faults\\nAt this point of the process, the intersection between faults and horizon will be represented with\\nhorizon nodes on the fault planes. The different zones will have different colored horizon nodes,\\nwhile the footwall is represented with a solid line and the hanging wall is represented with a\\ndotted line.\\nIf the intersection between faults and the horizons needs to be edited, it is always recommended\\nto edit the horizon nodes directly on the fault plane first and then edit the horizon between faults.\\nWhen editing directly on the horizon nodes in the fault plane, it is possible to select more than one\\nnode at a time for edits. If Remove peak on horizon , Smooth horizon , or Move\\nsmooth are used, this will affect the horizon between the faults as well, and when using these\\nfunctions, the horizons that are to be edited should always be displayed to better control the edits\\nyou have made.\\nHow to correct wrapped around fault planes\\n\"Wrapped around faults\" are fault planes where the up-thrown and the down-thrown sides have\\nbeen mixed or wrongly defined. This can happen where the fault gap is small and the input data is\\ncoarse. Wrapped fault planes can be corrected by editing the horizon nodes on the fault plane,\\nlocking these nodes and rerunning the Make horizon process.\\n1. Activate the Lock when moving option\\n2. Edit the horizon nodes on the fault plane by using Select horizon node . To select more\\nthan one at a time, press the SHIFT key.\\n3. Select all the horizon nodes on the fault plane and lock the nodes with the Lock horizon\\nnode icon, the color of the horizon nodes will change to a lighter color.\\n4. Rerun the Make horizon process and specify an influence radius for the locked horizon\\nnodes in the Settings tab.\\n4.\\nNote that Well tops override locked horizon nodes in the Make horizon process.\\nUse of I- and J-intersections in manual edits\\nWhile editing on Horizons in the conventional way (by displaying the horizon), it is not possible to\\nselect more than one node at a time. Nor is it possible to see how the editing on one horizon\\naffects the other layers in the grid.\\nBy using the I- and J-intersections, it is possible to see the horizon nodes for all the horizons. This\\ngives a better understanding of the spatial relationship between the different horizons and a\\nbetter view to see how edits influence the other horizons. The intersections can also ensure that\\nthe thickness of a zone is kept across a fault.\\nUsing intersections can alter the XY shape of individual cells. All pillars in the 3D grid will be\\nrepresented on the intersections, like Key Pillars, if either Select Shape Point or Select\\nPillar is selected.\\nHow to edit the XY shape of cells in the grid\\nAll pillars can be edited just like Key Pillars in the Fault Modeling process step. By selecting one or\\nmore pillars, the type of the pillar can be changed, the whole pillar can be edited or single Shape\\nPoints can be edited.\\n1. Visualize the I- and/or J-intersection together with a horizon, displayed with grid lines.\\n2. Use either Select Shape Point or Select Pillar . By selecting one of these tools, all\\nvisualized pillars will be displayed as Key Pillars.\\n3. Select the pillar(s) or Shape Point(s) in the Display window and perform the needed edits.\\nHow to remove negative volumes by edits\\nNegative volume can be created in a Petrel grid, due to a poor fault model and/or insufficient\\ndirections and trends defined in the Pillar Gridding process. To remove negative volumes in a\\nPetrel grid, it is always recommended to go back to the Pillar Gridding or the Fault Modeling\\nprocess steps. However, it is also possible to remove negative volumes in the Edit 3D Grid process\\nby expanding or collapsing horizon nodes in the grid.\\n1. Calculate the Bulk Volume for the grid by using Geometrical Modeling, select\\nGeometrical and Bulk Volume.\\n2. Display only the cells with negative volume for the property. Use the limit filter on the\\nProperty folder and set the max value for the Bulk Volume to be zero, and click OK. Display\\n3.\\n2.\\nthe cells by checking the Bulk Volume in Petrel Explorer.\\n3. Together with the negative volumes, display faults and I- and J-intersections and other grid\\ndata that will help you recognize the area around cells with negative volume.\\n4. Move the I- and/or the J-intersection to the negative cell. Move the intersections to get an\\nimpression on where and why there is a negative cell present.\\n5. Activate the Lock When Moving option.\\nSeveral approaches can be done to remove the negative cell volume:\\n6. If the problem seems to be the vertical layering, select horizon nodes and try to expand\\nor collapse horizon nodes on the intersections to create different cell shapes. This can\\nonly be applied if zones of the grid are zero in the area, or if the zones are very thin.\\n7. If the problem seems to the XY-shape of the cells, select a pillar or a Shape Point on\\na pillar and alter the XY-shape of the cell.\\n8. After editing, recalculate the sub-zones in the grid and calculate a new Bulk Volume to\\ncheck if the edits have removed the cells with negative volume.\\nRemember that editing is an iterative process, and you might have to go back and forth a\\ncouple of times before the negative cells are removed.'},\n",
       " {'header': 'Editing Faults ',\n",
       "  'content': 'Fault planes in the 3D grid can be edited in this process step. All faulted pillars in the grid will be\\nrepresented as the Key pillars in the Fault modeling process step, and each faulted pillar can be\\nedited in the same way as in Fault modeling.\\nEditing on fault planes will alter the XY shape of the cells in the grid towards the fault. This type of\\nediting should be used carefully. The faulted pillar can only be edited to the cell boundaries, so it\\nwill not come in conflict with the neighboring pillars in the 3D grid.\\nIf a fault has been edited and the nodes locked, the Distance to fault setting must be set\\nto zero for that fault if the Make horizon process is rerun - otherwise the extrapolation towards\\nthe fault plane will override the locked nodes.\\nHow to edit fault planes\\nThe faulted pillars can be edited just like key pillars in the Fault modeling process step. By\\nselecting one or more pillars, the type of the faulted pillar can be changed, the whole pillar can be\\nedited, or single shape points can be edited.\\n1. Visualize the fault(s) you want to edit.\\n2. Use either Select Shape Point or Select Pillar . By selecting one of these tools, all\\nvisualized faulted pillars will be displayed as key pillars.\\nSelect the faulted pillar(s) or shape point(s) in the Display window and do the necessary edits.\\nQuality Control of grid edits\\nAfter automatic updates of the 3D grid or manual edits of the grid, it is important that the grid is\\nproperly quality controlled before the grid is used for further work or exported for simulation.\\nThe updated and/or edited grid needs to be inspected by using the I- and J-intersections together\\nwith the General Intersection. In addition, the different filters of the grid, fault filter, zone filter\\nand the segment filter can be used for quality control.\\nFor details on how to quality control the 3D grid see Quality Control of Make Horizons Process.\\nIf manual edits have been performed on the 3D grid the Make Zones and Layering processes\\nneeds to be re-run. It is not possible to edit the layers as they will follow the zones, and if these\\nhave been edited, the layers that are within the zones should be distributed again.\\nAfter performing manual edits, another important step is to quality check the grid again for\\nnegative volumes. This must be done after the Layering process has been re-run. For details on\\nhow to check for negative volume in the 3D grid, see Volume Quality Control.'},\n",
       " {'header': 'Make Local Grids ',\n",
       "  'content': 'The Make local grids process allows you to specify a locally enhanced grid definition, known as a\\nlocal grid refinement. This enables you to increase the model resolution near wells, around\\nsurfaces or inside a region of interest.\\nA simulation project can involve the use of several smaller models, such as cross-sections and\\nsingle well models. You can use these to examine the fine-scale performance of part of a field, for\\nexample, the performance in the vicinity of a well. Moving to a full field simulation model generally\\nmeans having to use a coarser simulation grid, and these fine-scale effects are lost in the process.\\nOne way of including these fine-scale effects in a full field simulation model is to refine the parts\\nof interest in the global grid by creating a set of local grids and refining the gridding within each\\nlocal grid in the set.\\nYou can create more than one set of local grids in a given global grid and associate one of these\\nsets in a Simulation case. By generating several cases using differing grid sets, you can compare\\nthe simulation effects of using different local grids and refinements.\\nThe Make local grids process is also available in the Workflow editor where its input parameters\\ncan be specified as expressions using variables.\\nDefining Local Grids using Sources\\nA local grid set in Petrel is defined in terms that are independent of the global grid on which it is\\nbased. Each local grid is defined in terms of a source, which can be a well, surface or a\\npolygon (or sets thereof). Sources must exist in the Input tab in order for you to create a local\\ngrid refinement based on it. For all the three source types, the local grid based on the source can\\nbe confined to a subset of zones or segments that are specified independently of the zone and\\nsegment display filters on the Model tab.\\nIf you modify the geometry of a global grid (e.g. change the layering) and this grid has local grids\\ndefined in it, you will have to rebuild the local grids associated with it. There is no dependency\\ncheck in Petrel to force you to do this.'},\n",
       " {'header': 'Host Cells Host Cell Set Generation - Polygons ',\n",
       "  'content': 'Petrel computes the vertical Z-projection of the polygon with the host grid and selects all the cells\\nin the uppermost layer whose centers lie within the polygon. The polygon must be closed. The\\ntop layer of the host grid might contain undefined cells, and so the first defined cell found in Z is\\nchosen. This set of cells is then projected down through the layers (K-index) to produce a cell set.\\nZone and segment filter settings from the dialog are applied so that the host cell set is confined to\\ncells within the selected zones and segments.\\nBecause the projection is made through K (cell index) and not in Z (vertical distance) the host\\ncells will follow the coordinate lines (pillars) of the host grid.\\nNote: polygons cannot be chosen as sources when gradual refinement methods are selected for\\ncreating the local grids.'},\n",
       " {'header': 'Host Cell Set Generation - Wells ',\n",
       "  'content': 'Petrel computes all the cells in the host grid that are intersected by the well. It then includes all of\\nthe cells whose centers lie within the Source influence distance from the well trace that are\\nconnected to the existing cells within the set. Zone and segment filter settings from the dialog are\\napplied so that the host cell set is confined to cells within the selected zones and segments.\\nIf the option Grid to well connections is switched on, the active source is limited to the parts of\\nthe well representing open connections to the global grid, such as perforations and open-hole\\nsections.'},\n",
       " {'header': 'Host Cell Set Generation - Surfaces ',\n",
       "  'content': 'Host cells around surfaces as local-grid sources are found by examining the distances between\\nthe cell-centers and the surface in a direction normal to the surface and around the edges. If the\\ndistance is less than the Source influence distance, the host cell is added to the set.\\nIn addition, you can specify only one side of a surface to be the active source for the local-grid\\ncreation by choosing either Above or Below in the process dialog. In the case of strictly vertical\\n(fault) surfaces, Above corresponds to the West and Below to the East.'},\n",
       " {'header': 'Simulation Issues - Host Cell Set Extensions ',\n",
       "  'content': 'When local grids are exported to the ECLIPSE simulators, they are decomposed into cuboid blocks\\n(in I,J,K). The algorithms described above, especially for well-based grids, can produce host cell\\nsets that generate many cuboids. The presence of too many cuboids can make simulators run\\nslower, and in some cases can cause a simulation to fail to converge.\\nYou can reduce the number of cuboids by extending a host cell set in any or all of the I, J or K\\ngrid directions. This will generate larger host cell sets, but fewer cuboids in their decompositions.\\nAlso, the enlarged sets may contain cells that are further away in distance from the well trace\\nthan you would like. You must choose a compromise between these issues that generates an\\nacceptable simulation.'},\n",
       " {'header': 'Host Cell Set Generation - Use Active Filter ',\n",
       "  'content': 'The host cell set produced by the above sources can be reduced according to the currently active\\nfilter. For example, if you want to focus on water coning, the filter can be used to force local grids\\nto appear only near fluid contacts. The active filter can depend on what is being displayed.\\nNote that although the state of the Use active filter flag is serialized, the set of filter cells is not.\\nWhen using this feature in a workflow with different grids, the set of filtered cells may be grid-\\ndependent, resulting in a different host cell set.\\nConflict Resolution Policies and Nested Local Grids\\nWhen creating a local grid set based on several sources, it is easy to specify a source influence\\ndistance which causes host cell sets to be generated that have intersections, i.e. a host cell may\\nbelong to more than one set. This is not acceptable for simulation purposes. Local grids can touch\\nbut may not intersect.\\nPetrel applies a resolution policy when this occurs. The policies are:\\nwell-well, surface-surface and polygon-polygon conflicts: assign common cells to the larger\\nof the two sets\\nwell-surface conflicts: assign common cells to the well set\\nwell-polygon conflicts: assign common cells to the well set\\nsurface-polygon conflicts: assign common cells to the surface set\\nconflicts between gradual-refinement levels around different sources: choose the level\\nresulting in a smoother refinement distribution\\nComplete containment of one set within another is regarded as unresolvable, and is reported as\\nan unresolvable conflict. If such a conflict occurs, you will not be able to generate local grids\\nbased on the current settings. You will have to change the settings (maybe remove an offending\\nsource) to remove the conflict in order to proceed.\\nGridding to Zones\\nThe option Grid separate zones causes Petrel to generate a separately definable grid for each\\nzone specified in the zone filter. So, with a single source and a host grid with several zones, you\\ncan: (a) generate a single grid with its refinement setting applied to a subset of zones OR (b)\\ngenerate several grids, one for each zone in the zone filter, each of which can have its own\\nrefinement settings.\\nHost cell generation and extension in I, J or K applies to each grid independently. This means that\\nthe union of the grids generated when Grid separate zones is selected is not always the same as\\nthe set generated when Grid separate zones is not selected.\\nNote: gradual refinement methods do not support the Grid separate zones option.'},\n",
       " {'header': 'Refinement Methods Cartesian Nx,Ny,Nz ',\n",
       "  'content': 'You specify the number of subdivisions required in each grid direction (Nx, Ny, Nz) and each\\nhost cell in the host cell set is sub-divided equally using linear interpolation of the host grid\\ncells. Horizons are not resampled at the higher resolution for the local grid. The geometry of\\nthe local grid depends only on the geometry of the host grid.'},\n",
       " {'header': 'Cartesian Dx,Dy,Dz ',\n",
       "  'content': 'You specify the maximum size of the subdivisions required in each grid direction (Dx, Dy,\\nDz). Each host cell in the host cell set is sub-divided equally using the closest value to that\\nrequested. For example, if the cell thickness in Z is 50 ft and Dz = 12 ft , then the calculated\\nNz will be 5, and the actual Dz will be 10 ft. Horizons are not resampled at the higher\\nresolution for the local grid. The geometry of the local grid depends only on the geometry of\\nthe host grid.'},\n",
       " {'header': 'Cartesian Gradual Nx,Ny,Nz ',\n",
       "  'content': 'Similar to the Cartesian Nx,Ny,Nz method except that Petrel gradually increases the\\nrefinement degree towards the local-grid source over a number of levels specified in Levels.\\nThe parameters Nx, Ny, Nz thus represent the target number of subdivisions (in each grid\\ndirection) within the highest-refinement level (i.e., closest to the source).'},\n",
       " {'header': 'Cartesian Gradual Dx,Dy,Dz ',\n",
       "  'content': 'Similar to the Cartesian Dx,Dy,Dz method except that Petrel gradually increases the\\nrefinement degree towards the local-grid source over a number of levels specified in Levels.\\nThe parameters Dx, Dy, Dz thus represent the target maximum size of subdivisions (in each\\ngrid direction) within the highest-refinement level (i.e., closest to the source).'},\n",
       " {'header': 'Gradual Refinement Methods ',\n",
       "  'content': 'Gradual refinement methods are applicable to wells and surfaces (as local-grid sources), i.e.\\nexcluding polygons, and they cannot be used together with the option Grid separate zones.\\nBoth Cartesian Gradual Nx,Ny,Nz and Cartesian Gradual Dx,Dy,Dz refinement method\\nattempts to partition the host cells found within the prescribed Source influence distance into a\\nnumber of contour levels specified by the integer Levels. The parameters Nx, Ny, Nz and Dx, Dy,\\nDz, respectively, represent the targets for the highest-refinement level closest to the source. The\\nrefinement graduation sequence is automatically set up using a power law in which the\\nexponential bases are either fractional or integer; The latter case is chosen by switching on the\\noption Integer bases. You should be aware, however, that by restricting the power law\\n(number_of_subdivisions = base ^ level) to integer bases only, the chances of exactly meeting\\nthe requested target (N\\'s or D\\'s) are much lower than when using fractional bases. As an\\nexample, consider the following two cases of applying the Cartesian Gradual Nx,Ny,Nz method\\nwith similar input data but obtaining very different results:\\n1. Levels = 3, Nx_requested = 15, Nx_obtained = 8\\n2. Levels = 3, Nx_requested = 16, Nx_obtained = 27\\nIf the Integer bases checkbox was turned off in the preceding example, both Nx_requested and\\nNx_obtained would be identical.\\nAnother discrepancy between the requested gradual refinement and the actually obtained one,\\nirrespective of the Integer bases checkbox status, may occur in one of the following three\\nsituations:\\n1. Too many requested Levels for the given Source influence distance and the global-grid\\n2.\\n1.\\ncell size near the source\\n2. Source influence distance too small with respect to the global-grid cell size near the\\nsource\\n3. Source influence distance too large with respect to the global-grid cell size near the\\nsource\\nIn the first two cases, Petrel cannot accommodate all the requested levels within the selected\\nhost-cell domain and therefore discards the exceeding number of high-refinement levels. In the\\nthird case, on the other hand, the selected host-cell domain is so large that some low-refinement\\nlevels have to be discarded.\\nNote: every gradual refinement level is represented (in the Local grids folder and its parent\\nLocal grid set) by a separate local-grid subject with the suffix [level] in its name, where level =\\n1, 2, ..., Levels (if all levels have been created).\\nAt certain conditions, parts of one level could come up missing between two neighboring levels,\\nresulting in a refinement-degree jump. Petrel prevents such cases by performing a final\\n\"smoothing step\" and re-assigning the affected host cells to the lower-refinement level. The only\\nsituation when the \"smoothing step\" is not carried out is a local grid around \"single-sided\\nsurfaces\" (option Above or Below).\\nBy default, the distribution of distances from the local-grid source to the outer edges of each\\ngradual-refinement level is linear. The option Logarithmic reduces the sizes of high-refinement\\nlevels towards the source by forcing a logarithmic distribution of such distances.\\nFigure 1. Gradually refined local grid around a well (Levels = 3, Nx = Ny = 8, Nz = 1)\\nRefinements and Touching Grids\\nGridding to zones can lead to grids that have adjacent K-layers. They are said to be \"vertically\\ntouching\". If you specify different Nx, Ny refinement settings (i.e. refinements in I, J) for vertically\\ntouching grids, you may generate many non-neighbor connections (NNCs) that can lead to\\ndifficulties in simulation.\\nLikewise, when a conflict is resolved by Petrel, grids that are adjacent (in I, J) will be generated.\\nThey are said to be \"areally touching\". If you specify different Nz refinement settings (i.e.\\nrefinements in K) for areally touching grids, you may generate many non-neighbor connections\\n(NNCs) that can lead to difficulties in simulation.\\nYou are allowed to generate grids under these conditions, but you will be warned when this\\nhappens by a message that appears next to the sources in question in the dialog source tree.\\nNaturally, the gradual refinement methods always produce such conflicts (between cells at the\\nlevel edges) and no warning is thus issued. The potentially larger number of NNCs in this case\\nmay be seen as a \"price for increased accuracy and stability of the model\"...'},\n",
       " {'header': 'Local Grid Coarsening ',\n",
       "  'content': 'The feature extends the Local Grid Refinement feature to support ECLIPSE style COARSEN\\nkeywords. The user interface and experience for generating Coarsened regions within the process\\nare very similar to that for generating Local Refinements. It operates by coarsening cells whose\\ncell centers lie inside or outside of a polygon source. Local Grid Coarsenings (LGCs) and Local Grid\\nRefinements can exist in the same Local Grid Set.\\nThe coarsening is performed in IJK space not XYZ, so nx*ny*nz cells are amalgamated into a\\nsingle cell. The distinction is most obvious over heavily thrown faults where the cells in the Kth\\nlayer on either side of the fault end up being amalgamated, even though they do not touch. There\\nis a user option to prevent coarsening across faults. In keeping with the ECLIPSE option (see the\\nLocal Grid Refinement and Coarsening section of the ECLIPSE Technical Description) Petrel sends\\nthe original fine model to the simulator together with the generated COARSEN keywords. The\\nsimulation results (which are only produced for the coarse model) are automatically expanded\\nback onto the fine grid for visualization).\\nThere may be many reasons why all of the proposed cells cannot be joined into a single\\nrepresentative one. For example some of them have no defined geometry, or they conflict with\\nother LGRs whose host cells take a higher priority. The resulting geometry of the amalgamation\\nmay look far from rectangular. This does NOT concern the simulator and does not imply that we\\nare using a new type of unstructured grid. The 3D view of the coarsened grid block is a\\nrepresentation only. The pore volume of the coarse block will be the sum of the individual cell\\npore volumes. The transmissibility between coarse blocks or from coarse to fine does NOT use the\\ncell face geometry of the coarse block, ECLIPSE performs a Transmissibility Upscaling of the fine\\nscale Transmissibilities calculated on the fine model.\\nCoarsen Outside without Active Filter\\nFigure 1. Grid coarsening without active filter\\nThe above grid was obtained using the following settings:'},\n",
       " {'header': 'Preserve Faults On Extend Host Cells On ',\n",
       "  'content': 'Preserve Wells (distance)'},\n",
       " {'header': 'Off Allow Smaller Cells On ', 'content': 'Allow 1x1 Areal cells'},\n",
       " {'header': 'Off ', 'content': 'Coarsen Outside of Polygon'},\n",
       " {'header': 'On ', 'content': '(nx, ny, nz)\\n(2,3,2)'},\n",
       " {'header': 'Grid Separate Zones Off Use Active Filter Off Feature Settings ',\n",
       "  'content': 'The above grid was obtained using the following settings:'},\n",
       " {'header': 'Preserve Faults On Extend Host Cells Off ',\n",
       "  'content': 'Preserve Wells (distance)'},\n",
       " {'header': 'Off Allow Smaller Cells Off ',\n",
       "  'content': 'Allow 1x1 Areal cells'},\n",
       " {'header': 'Off ', 'content': 'Coarsen Outside of Polygon'},\n",
       " {'header': 'On ', 'content': '(nx, ny, nz)\\n(2,3,2)'},\n",
       " {'header': 'Grid Separate Zones Off Use Active Filter On Feature Settings ',\n",
       "  'content': 'Coarsen outside with Extend Hosts\\nThe above grid was obtained using the following settings:'},\n",
       " {'header': 'Preserve Faults On Extend Host Cells On ',\n",
       "  'content': 'Preserve Wells (distance)'},\n",
       " {'header': 'Off Allow Smaller Cells Off ',\n",
       "  'content': 'Allow 1x1 Areal cells'},\n",
       " {'header': 'Off ', 'content': 'Coarsen Outside of Polygon'},\n",
       " {'header': 'On ', 'content': '(nx, ny, nz)\\n(2,3,2)'},\n",
       " {'header': 'Grid Separate Zones Off Use Active Filter On Feature Settings ',\n",
       "  'content': 'Coarsen outside with Allow Smaller\\nThe above grid was obtained using the following settings:'},\n",
       " {'header': 'Preserve Faults On Extend Host Cells On ',\n",
       "  'content': 'Preserve Wells (distance)'},\n",
       " {'header': 'Off Allow Smaller Cells On ', 'content': 'Allow 1x1 Areal cells'},\n",
       " {'header': 'Off ', 'content': 'Coarsen Outside of Polygon'},\n",
       " {'header': 'On ', 'content': '(nx, ny, nz)\\n(2,3,2)'},\n",
       " {'header': 'Grid Separate Zones Off Use Active Filter On Feature Settings ',\n",
       "  'content': 'Coarsen outside without faults\\nThe above grid was obtained using the following settings:'},\n",
       " {'header': 'Preserve Faults Off Extend Host Cells On ',\n",
       "  'content': 'Preserve Wells (distance)'},\n",
       " {'header': 'Off Allow Smaller Cells On ', 'content': 'Allow 1x1 Areal cells'},\n",
       " {'header': 'Off ', 'content': 'Coarsen Outside of Polygon'},\n",
       " {'header': 'On ', 'content': '(nx, ny, nz)\\n(5,3,2)'},\n",
       " {'header': 'Grid Separate Zones Off Use Active Filter On Feature Settings ',\n",
       "  'content': 'Coarsen outside with Selective LGRs\\nThe above grid was obtained using the following settings:'},\n",
       " {'header': 'Preserve Faults On Extend Host Cells On ',\n",
       "  'content': 'Preserve Wells (distance)'},\n",
       " {'header': 'On (300) Allow Smaller Cells On ',\n",
       "  'content': 'Allow 1x1 Areal cells'},\n",
       " {'header': 'Off ', 'content': 'Coarsen Outside of Polygon'},\n",
       " {'header': 'On ', 'content': '(nx, ny, nz)\\n(5,3,2)'},\n",
       " {'header': 'Grid Separate Zones Off Use Active Filter On Feature Settings ',\n",
       "  'content': 'Defaults Settings and Source Folders\\nWhen new sources are added to a set, they inherit default settings from their parents. A parent is\\na folder, or a source that has Grid separate zones set. The settings of a parent are applied to\\nall the children that have Use default option set. If you want to change the settings for any item\\nin the tree, you must unset Use default.\\nAll polygon sources are held in one folder. The folder is the parent of all polygon sources.\\nThe folder structure of the well and surface sources follows their corresponding tree structure in\\nthe Input tab.'},\n",
       " {'header': 'Local Grid Set Process Steps ',\n",
       "  'content': 'In Petrel you can create new grid sets or modify existing grid sets.\\nHow to create a new local grid set using the Cartesian\\nNx,Ny,Nz refinement method\\n1. In the Models tab select the model containing the wells, surfaces and polygons for which\\nyou want to create a local grid set.\\n2. In the Processes tab, open Structural modeling and select Make local grids. This will\\nopen the Make local grids dialog.\\n3. Select Create new local grid set.\\n4. Select sources, either wells, surfaces, or polygons from the Input tab. You can do this by\\nexpanding the appropriate section of the Wells folder or by finding surfaces or polygons\\nfrom the Input tab and checking the required subjects.\\n5. Click the Insert the source button . The selected wells, surfaces and polygons will be\\ninserted into the source list at the bottom of the dialog.\\n6. If you want to remove a source from the list, select it then click the Remove the source\\nbutton . The selected source will be removed from the list.\\n7. Select the Cartesian Nx,Ny,Nz refinement method. This is applied to the selected wells,\\nsurfaces or polygons.\\n8. Enter the division parameters for each axis in the Nx, Ny and Nz fields. The cells will be\\ndivided into grids using these numbers. For example, if you enter 3 in the Nx field, each\\ngrid cell will be divided into three equal portions in the X-direction.\\n9. Enter the Source influence distance value. The units for this value are determined by\\nthe project unit system. This value specifies the distance from the well or surface for which\\ncells will be refined using the local grid set.\\n10. If required, select specific Zone and Segment filters. You can click the All button for either\\nto apply filters of that type.\\n11. If you want to create separate grids for each zone in a sub-tree, select the Grid separate\\nzones checkbox. These per-zone grids can then be selected and refined separately from\\ntheir siblings.\\n12. The local grids can be restricted by selecting the Use active filter option. The local grids\\nwill then be reduced to the content being currently viewed.\\n13. Alternatively you can use the default settings for each source. If you switch Use default\\non, each well, surface or polygon takes its refinement settings from its parent folder. This,\\nfor example, makes it easy to create local grids for all wells.\\n14. Optionally click the Display host cells button to view the host cells for the local grid set\\nbefore the refinements are made to the parent grid.\\n15. Click the Apply button to apply the refinement to all sources and create the new local grid\\nset. Note that this may fail if the set is not consistent.\\n16. Resolve any inconsistencies and repeat as necessary.\\n17. Click the OK/Cancel button to close the Make local grids dialog. Note: clicking OK is the\\nsame as clicking Apply and Cancel.\\nHow to create a new local grid set using the Cartesian\\nGradual Dx,Dy,Dz refinement method\\n1.\\n2.\\n1. In the Models tab select the model containing the wells or surfaces for which you want to\\ncreate a local grid set.\\n2. In the Processes tab, open Structural modeling and select Make local grids. This will\\nopen the Make local grids dialog.\\n3. Select Create new local grid set.\\n4. Select sources, either wells or surfaces, from the Input tab. You can do this by expanding\\nthe appropriate section of the Wells folder or by finding surfaces from the Input tab and\\nchecking the required subjects.\\n5. Click the Insert the source button . The selected wells and surfaces will be inserted into\\nthe source list at the bottom of the dialog.\\n6. If you want to remove a source from the list, select it then click the Remove the source\\nbutton . The selected source will be removed from the list.\\n7. Select the Cartesian Gradual Dx,Dy,Dz refinement method. This is applied to the\\nselected wells or surfaces.\\n8. Enter the number of gradual refinement Levels and optionally choose Logarithmic\\ndistribution of their extents and/or force Integer bases of the graduation-sequence power\\nlaw.\\n9. Enter the target size-parameters for the highest-refinement level along each axis in the Dx,\\nDy and Dz fields. The cells in the level nearest to the source will be sub-divided equally\\nusing the closest value to that requested. For example, if the cell thickness in Z is 50 ft and\\nDz = 12 ft , then the calculated Nz will be 5, and the actual Dz will be 10 ft. Host cells in all\\nthe remaining lower-refinement levels will be sub-divided into gradually fewer and fewer\\nlocal cells according to the distance of the level from the local-grid source.\\n10. Enter the Source influence distance value. The units for this value are determined by\\nthe project unit system. This value specifies the distance from the well or surface to the\\nouter edge of the outermost gradual-refinement level.\\n11. If required, select specific Zone and Segment filters. You can click the All button for either\\nto apply filters of that type.\\n12. The local grids can be restricted by selecting the Use active filter option. The local grids\\nwill then be reduced to the content being currently viewed.\\n13. Alternatively you can use the default settings for each source. If you switch Use default\\non, each well or surface takes its refinement settings from its parent folder. This, for\\nexample, makes it easy to create local grids for all wells.\\n14. Optionally click the Display host cells button to view the host cells for the local grid set\\nbefore the refinements are made to the parent grid.\\n15. Click the Apply button to apply the refinement to all sources and create the new local grid\\nset. Note that this may fail if the set is not consistent.\\n16. Resolve any inconsistencies and repeat as necessary.\\n17. Click the OK/Cancel button to close the Make local grids dialog. Note: clicking OK is the\\nsame as clicking Apply and Cancel.\\nHow to modify refinements for local grid sets\\n1. In the Models tab select the model containing the wells, surfaces or polygons for which you\\nwant to modify a local grid set.\\n2. In the Processes tab, open Structural modeling and select Make local grids. This will\\nopen the Make local grids dialog.\\n3. Select Update existing and choose a set from the drop-down list. The wells, surfaces and\\npolygons appear in the source list at the bottom of the dialog. They may have different\\nrefinement methods associated with them. Select a polygon, well or surface to see the\\nassociated refinement.\\n4.\\n5.\\n4. In the source list, select the sources to which the new refinement will be applied.\\n5. Change the refinement settings, as required. The setting(s) will be applied to the selected\\nsources.\\n6. Optionally click the Display host cells button to view the host cells for the local grid set\\nbefore the refinements are made to the parent grid.\\n7. Click the Apply button to apply the refinement to all the selected wells, surfaces or\\npolygons and create the new local grid set. Note that this may fail if the set is not\\nconsistent.\\n8. Resolve any inconsistencies and repeat as necessary.\\n9. Click the OK/Cancel button to close the Make local grids dialog.\\nHow to delete or add local grids\\nComplete local grid sets can be deleted on the Models tree or in the Make local grids dialog\\nsource tree.\\nIndividual local grids can only be deleted using the Make local grids dialog source tree.\\nTo delete local grids and sets\\n1. Select Update existing and choose a set from the drop-down list. The wells, surfaces and\\npolygons appear in the source list at the bottom of the dialog.\\n2. Select the source(s) to be deleted then click the Remove the source button . The\\nselected source(s) will be removed from the source list.\\n3. Optionally press Display host cells button to see the new set.\\n4. Press Apply/OK to rebuild the set with the local grids deleted.\\nTo add local grids and sets\\n1. Select Update existing and choose a set from the drop-down list. The wells, surfaces and\\npolygons appear in the source list at the bottom of the dialog.\\n2. Select the new sources, either wells, surfaces or polygons, from the Input tab. You can do\\nthis by expanding the appropriate section of the Wells folder or by finding surfaces or\\npolygons from the Input tab and checking the required subjects.\\n3. Click the Insert the source button . The selected wells, surfaces and polygons will be\\ninserted into the source list at the bottom of the dialog.\\n4. Select the new source in the source list.\\n5. Select the refinement settings. The setting(s) will be applied to the source and the Source\\ntree gets updated.\\n6. Optionally click the Display host cells button to view the host cells for the local grid set\\nbefore the refinements are made to the parent grid.\\n7. Click the Apply button to apply the refinement to all sources and create the new local grid\\nset. Note that this may fail if the set is not consistent.\\n8. Resolve any inconsistencies and repeat as necessary.\\n9. Click the OK/Cancel button to close the Make local grids dialog. Note: clicking OK is the\\nsame as clicking Apply and Cancel.'},\n",
       " {'header': 'Make Local Grids Dialog Settings ',\n",
       "  'content': 'The options to define local grid sets for wells, surfaces and polygons are set in the Make local\\ngrids dialog. You must select the required model before you can define local grid sets using wells,\\nsurfaces and polygons. The following options are available:\\nCreate new local grid set\\nChoose this if you want to build a new local grid set.\\nUpdate existing set\\nChoose this if you want to modify a grid set. You can then choose the grid set from the drop-\\ndown list.\\nRefinement method\\nChoose the method you want to use to create the local grid from the parameters supplied.'},\n",
       " {'header': 'Levels ',\n",
       "  'content': 'Gradual refinement methods only: Specify the number of levels over which the local-grid\\nrefinement is gradually increased towards the source; Levels = 3 by default.'},\n",
       " {'header': 'Logarithmic ',\n",
       "  'content': \"Gradual refinement methods only: Force logarithmic rather than linear distribution of\\ndistances between the source and each level's outer edge; Off by default. See Figure 1 for a\\nschematic comparison.\\nFigure 1. Difference between linear (left) and logarithmic (right) distribution of gradual-\\nrefinement level extents.\\nInteger bases\\nGradual refinement methods only: Force integer rather than fractional bases of the power law\\nused internally to set up the refinement graduation sequence; Off by default. See also the\\ncaveats associated with this option.\"},\n",
       " {'header': 'Nx, Ny, Nz ',\n",
       "  'content': 'Enter the number of subdivisions which will be applied in the X, Y and Z directions to each cell\\nwithin the host-cell set when Cartesian (Gradual) Nx,Ny,Nz refinement method is selected.\\nThe default value is 3 for all, but you can enter any (reasonably high) positive value.'},\n",
       " {'header': 'Dx, Dy, Dz ',\n",
       "  'content': 'Enter the maximum subdivision sizes which will be applied in the X, Y and Z directions to each\\ncell within the host-cell set when Cartesian (Gradual) Dx,Dy,Dz refinement method is\\nselected. The fields are empty by default which corresponds to no subdivision in each\\nrespective direction; You have to specify at least one (reasonably small) positive value.\\nZone filter\\nYou can select the zones within the host grid to which the local grid will be confined. This\\nselection is also used when Grid separate zones is selected. Clicking the All button will\\nselect all zones. If you are NOT using Grid separate zones, then you can only select\\ncontiguous zones.\\nSegment filter\\nYou can select the segments within the host grid to which the local grid will be confined.\\nClicking the All button will select all segments.\\nGrid separate zones\\nNon-gradual refinement methods only: Select this if you want to create separate local grids\\nfor each zone in a sub-tree. These per-zone grids can then be selected and refined separately\\nfrom their siblings.\\nUse active filter\\nSelect this if you want to restrict the local grids to the host grid currently being displayed.\\nExtend host cells along\\nSelect these options (I,J,K) to extend the host-cell set in the chosen direction. The default is\\nalways to extend in K.\\nSource influence distance\\nEnter the distance from the selected well or surface within which all found host cells will be\\nrefined using the chosen method. The unit for this value is determined by the project unit\\nsystem. For Hydraulic Fractures the influence distance can be set to 0 with the result that\\nonly the inner Logarithmic LGR appears.\\nGrid to well connections\\nChoose this option for a selected well if you want to restrict the active source to open\\nwellgrid connections only (e.g., perforations and open-hole sections).\\nGrid to Hydraulic Fractures\\nChoose this option if you want to place a Logarithmically spaced LGR around any Hydraulic\\nFractures present in the well sources. The Logarithmic LGR will lie in a single I or J plane of\\ncells, with the LGR symmetrically placed about the intersection of the fracture with the well.\\nThe LGR extent will be longer than the fracture length since it extends to the edge of the host\\ncells. When this local grid is exported to the simulator using Define Simulation Case, property\\nmodifiers will be placed in the LGR cells within the fracture extent.\\nNote: When this option is on, the nodes in the source tree will expand to show the hydraulic\\nfractures attached to the wells. Only those fractures that are NOT modeled using the in-built\\ncorrelation will appear (controlled from the Fracture Properties tab on the Hydraulic Fracture\\nSettings panel).'},\n",
       " {'header': 'Above ',\n",
       "  'content': 'Choose this option for a selected surface if you want to restrict the active source to the top\\nside of the surface only. For a strictly vertical (fault) surface, Above corresponds to the West.'},\n",
       " {'header': 'Below ',\n",
       "  'content': 'Choose this option for a selected surface if you want to restrict the active source to the\\nbottom side of the surface only. For a strictly vertical (fault) surface, Below corresponds to\\nthe East.\\nDisplay host cells\\nClick this button to view the host cells for the local grid set before the refinements are made\\nto the parent grid.\\nUse default\\nSelect this to apply the default local grid options to all selected wells, surfaces and polygons.\\nThese settings are inherited from the parent. Any settings previously entered for those\\nparticular sources will be lost.\\nSource list\\nThis shows all the wells, surfaces and polygons to which local grid settings will be applied. You\\ncan add/remove new sources to/from this list using the buttons above the list.\\nYou can select one or more entries in this tree. When you change settings in the dialog (e.g.,\\nsource influence distance, refinement parameters Nx, Ny, Nz) they will be applied to the selected\\nsources in the tree.\\nIf you select a single source, its setting will be displayed in the controls above the tree.\\nItems for which Use default is switched on appear in pale grey.'},\n",
       " {'header': 'Local Grid Properties ',\n",
       "  'content': 'Local grid properties can be inherited from their host cell or set on the local grid. Inherited\\nproperties will display the values from their host cell; they will not be exported to the simulator,\\nas the simulator also inherits the values from the host cell. If any cells in the local grid have\\ndefined property values, none of the cells in the local grid will inherit from the host cell; in this\\nsituation, local cells with no defined value will display as undefined (grey). An example of this\\nwould be the Scale up well logs process: only the cells intersected by wells in the local grid\\nrefinement are populated. Some processes will use the values in the local grid properties while\\nothers will just use the values in the global grid; in particular, Facies and Petrophysical modeling\\nignore local property values because GSLIB (the standard library used for geostatistics) assumes\\nall cells are approximately the same size.\\nSimulation result properties are not inherited on local grids so will appear gray on any local grids\\nnot involved in the simulation run, however if manually copied within Petrel the simulation result\\nproperties lose their association with the simulation case and the local grid properties will inherit.\\nIn Petrel you can create or upscale properties to local grid sets in a number of ways.\\nHow to create a property using the Geometrical\\nmodeling\\n1. In the Processes tab, open Property modeling and select Geometrical modeling. This\\nwill open the Geometrical modeling dialog.\\n2. In the upper section, select Create new property.\\n3. Select the method (for example, Cell volume), the property template and the required fields\\nbased on the selected method.\\n4. Press Apply and the property will be calculated for the global grid and all local grid sets.\\nHow to create a property using the Property\\ncalculator\\n1. In the Models tab, right click on the Properties folder under the correct grid and select'},\n",
       " {'header': 'Calculator. ',\n",
       "  'content': '2. Visualize the local grid set(s) on which the calculation will be performed and hide Global\\ngrid.\\n3. Select the property (or type its name) and assign to it the requested algebraic expression.\\n4. Switch on the Use filter checkbox to apply only to cells of the selected local grid set(s).\\n5. Press Enter to perform the calculation.\\nExport local grids to a file\\nYou can export a grid model with or without a local grid set. Only one local grid set can be\\nexported at the same time. To export a set you need to make it active (bold), and it is irrelevant\\nif it is visible or not in a 2D or 3D window. In fact, you can display all local grid sets but only the\\nactive one will be exported.\\nIf you want to export a grid without a local grid set, just make sure none of the local sets are\\nactive.\\n1. In the Models tab, select the local grid set you would like to export so it becomes active\\n(bold).\\n2. Right click on the grid folder, and select export.\\n3. Select the format \"Generic ECLIPSE style (ASCII) grid geometry and properties\\n(*.GRDECL)\" and type the file name.\\n4. Select the properties you want to export. If you want to export the grid geometry only,\\nuncheck \"Include properties\". Press OK.\\n5. A window will appear asking for units conversion: you can press OK, or change the units as\\nneeded and then press OK.'},\n",
       " {'header': 'Make Contacts ',\n",
       "  'content': 'Petrel models complex oil and gas reservoirs, hence, the modeling of all types of contacts are\\nimportant in order to get a good representation and understanding of all the volumes in place.\\nThe goal of the Make contacts functionality is to facilitate the use of contacts inside a 3D grid.\\nAny type of contact can be set as Oil/Gas, Oil/Water, Oil up to, Gas down to, among others.\\nThese contacts can be constant depth levels as well as complex surfaces.\\nThe objectives are to visualize these contacts as they appear in 2D and 3D, but also to visualize\\nthem as fill colors and contour lines on modeled surfaces in 2D or 3D windows, as well as in map\\nwindows.\\nThe final goal of this module is to take into account these multiple contacts in the Volume\\nCalculation process to achieve accurate volumes.'},\n",
       " {'header': 'Make Contacts Dialog ',\n",
       "  'content': 'After having built a Petrel 3D grid, and before running volume calculation, the different contacts\\nshould be defined in the Make Contacts process . If you do not want to use any contact for\\nvolume calculation (e.g. to calculate only the bulk volumes of the model), you can go directly to\\nthe Volume Calculation process step.\\nSeveral sets of contacts can be defined for a model and each Contact Set can contain a number of\\ndifferent types of contacts. All Contact Sets will be stored in a folder called Fluid contacts in\\nthe Petrel Explorer Models tab. This folder is generated after the user has defined the first\\nContact Set and pressed apply/OK.\\nDifferent types of contacts can be defined, such as gas/oil, oil/water, oil up to, etc. and a\\ncorresponding name can be given to each of the defined contacts.\\nThe Contact Set can be created based on a constant depth value or a surface. If a surface is used\\nas input for the contact, it has to exist in the Input tab of the Petrel Explorer. Any type of surface\\ncan be used as input.\\nThe user also has the option of using the same contact for all zones and segments, different\\ncontacts for each segment and/or different contacts for each zone.\\nContacts can be copied out of the contact spreadsheet and into Excel, edited and pasted\\nback again.\\nHow to create a new contact set\\n1. Open the Make contacts process dialog\\n2. A default setting is available with two predefined contacts: Oil/Gas and Oil/Water.\\n3. Select the Contact Type in the pull-down menu\\n4. Change the name of the selected contact if desired.\\n5. If your contacts differ between each zone of the model, deselect the Same for all zones.\\n6. If your contact needs to be specified for each segment, deselect the Same for all\\nsegments.\\n7. Type a Z-value for the selected contact (remember that Petrel uses negative Z-values for\\ndepths below sea level). If the check box is selected, a surface must be dropped by\\nselecting a surface in the Petrel Explorer and clicking on the blue arrow.\\n8. Click OK and the Fluid Contacts folder, with the new set of contacts, will appear in the\\nPetrel Explorer Models tab below the segment filter.\\n8.\\nInput data for contacts\\nThe user has the option of using different contacts for each zone and segment. To use different\\ncontacts for each zone and/or segment, de-select the Same for all zones and/or Same for all\\nsegments. An input table will then appear where the user can enter the contacts as either a\\nconstant depth value or as a surface. If a surface is to be used, it has to be predefined and it\\nmust exist in Petrel Explorer.\\nTo use a constant value to define the contact, simply type the value in the cell in the table.\\nIn order to use a surface, first check the checkbox. A blue arrow pops up, allowing the user to\\ninsert a surface. Select the surface in Petrel Explorer and then click on the blue arrow to insert it\\ninto the table.\\nNote: By pressing the Zone or Segment top cell or name in the table, the entire row or\\ncolumn (respectively) will be filled with the first appearing value in that row or column.\\nHow to update / add / delete an existing contact set\\n1. Open the Make Contacts process dialog.\\n2. Select the contact you want to modify from the list, or use the Add new contact icon\\nto add a new General contact.\\n3. Select the General contact and specify the Type from the pull-down menu.\\n4. If your contact needs to be specified for each zone of the model, deselect the Same for all\\nzones.\\n5. If your contact needs to be specified for each segment, deselect the Same for all\\nsegments.\\n6. In the Table, modify the Z-value of the selected contact. If the check box is checked, a new\\nsurface must be entered by selecting a surface in the Petrel Explorer and clicking on the\\nblue arrow.\\n7. Click OK and the new set of contacts will appear in the Models tab below the segment filter.'},\n",
       " {'header': 'Visualizing Contact Sets ',\n",
       "  'content': 'Once the different contacts are defined by the Make Contacts process, the user has different\\noptions for visualizing these contacts in 2D, 3D or in map windows.\\nThese settings options are defined in the Settings window for the Fluid Contact , for the\\nContact Set and for each contact.\\nThe contacts can be visualized alone, and can be draped on horizons or visualized as a property\\ngrid. The contacts can also be shown on modeled horizons as contour lines.\\nVisualizing the contacts on surfaces in both 2D and 3D is illustrative for showing the extent of the\\noil/gas zones. Nice maps can be made in the Map Window and sent to the plotter.\\nHow to visualize the contacts alone\\nAfter setting all the values for each zone and/or each segment with Make Contacts, it can be\\ninteresting to visualize the results as surfaces in 3D. This could serve as a quality control of the\\ndata entered as input. Yyou can also visualize all the other types of data, such as your wells and\\nlogs simultaneously.\\n1. Open the Fluid Contact and the Contact Set (by pressing the plus sign in front of the\\nfolders).\\n2. Select one or all contacts for visualization.\\nHow to visualize the contacts on a surface\\nThe intersection of the contacts and the modeled horizons is a good tool for quality controlling\\nyour data and to understand the geological settings of your field.\\n1. Open the Fluid Contacts and the Contact Set folders.\\n2. Select one or all contacts for visualization.\\n3. Open the Horizons folder in the 3D grid and visualize one of them. Make sure that the\\nhorizons are part of the grid where the contact(s) are defined.\\nIn the settings window for the Fluid Contacts, toggle the option Show fill on horizons to drape\\nthe contacts on the horizon. Toggle the Show contact surfaces to also see the contacts as\\nsurfaces.\\nFor each contact, there is an option Show contact surface. This must be toggled off if you\\nonly want to show the contact draped over your surface. The same option can be found in the\\nFluid Contacts settings regarding all the contacts.\\nIf you want to display the contour line only, de-select the Show fill on horizon in the\\nSettings for all fluid contacts or for each individual contact.\\nHow to visualize contacts in a map window\\n1. Open a map window\\n2. Select one horizon from the 3D grid.\\n3. Toggle on the set of contacts to be visualized on top of this horizon\\nHow to visualize the contacts as properties in the 3D grid\\nThese operations allow the user to create a property where the cells are given a facies code\\naccording to their position related to the hydrocarbon contacts.\\n1.\\n2.\\n1. Right-click on one Contact Set.'},\n",
       " {'header': '2. Select Settings. ',\n",
       "  'content': \"3. In the Settings window, select the Operation tab.\\n4. Select the Code above highest contact, i.e. select the zone above the highest contact to\\nbe given a code.\\n5. Specify Code values in between each contact and below the lower contact, i.e. specify the\\nzone to be given a value.\\n6. Click OK and a new grid will be added inside the Properties folder.\\nSettings for contacts\\nThe settings are different depending on which level of the Fluid Contacts Folder you are in. I.e.\\nthe settings are different for the Fluid Contacts, the Contact Set and for the specific Contacts.\\nAnnotations (both name and contact depth) can be applied for each contact or for all contact sets\\nby selecting it from the Style tab. From the same tab, the user can choose to show lines only, if\\nthe purpose is to show the extent of the fluid zone.\\nSome settings are common at different levels, e.g. the Show contact surface option,\\nwhich is found both in the Fluid Contacts and for each contact's settings window. In these cases,\\nthe Fluid Contacts settings will override the setting for both Contact Sets and for each contact (if\\nchanged after the settings for the contacts and the Contact sets are defined).\\nHow to change the settings for all the Contacts Sets\\n1. Right-click on the Fluid Contacts Folder and select settings.\\n2. In the Style tab, the settings can be changed as follows: Show line, Show annotation, Fill\\ncolor in the oil/gas/water zones and more. If displaying only the line (no fill color) a contour\\nline will be drawn showing the extent of the fluid zones.\\nThe modifications done will apply on all the contacts in the folder.\\nHow to change the settings for one specific set of contacts\\n1. Open the settings of a Contact Set Folder (right-click on the contact set folder and\\nselect settings)\\n2. In the Style tab, change the desired settings. A pattern can be applied (only available in the\\nmap window).\\nThe modifications done will apply on all the contacts contained in the specific folder.\\nHow to change the settings for one contact\\n1. Open settings of a single contact.\\n2. In the Style tab, change to the preferred settings. A pattern can be applied only in a map\\nwindow. Modifications done will apply on this specific contact only.\"},\n",
       " {'header': 'Property Modeling ',\n",
       "  'content': \"Property modeling is the process of filling the cells of the grid with discrete (facies) or continuous\\n(petrophysics) properties. Petrel assumes that the layer geometry given to the grid follows the\\ngeological layering in the model area. Thus, are these processes dependant on the geometry of\\nthe existing grid. When interpolating between data points, Petrel will propagate property values\\nalong the grid layers.\\nProperty modeling in Petrel is split into three separate processes:\\nGeometrical modeling - No interpolation of input data is required. Properties are built\\nbased on the geometrical properties of the grid cells themselves, such as a cell volume,\\nangle, height, etc. Some algorithms also require input data, but this data is simply sampled\\ninto the grid (e.g. seismic).\\nFacies modeling - Interpolation or simulation of discrete data, for example, facies.\\nPetrophysical modeling - Interpolation or simulation of continuous data, for example,\\nporosity, permeability, and saturation.\\nIn addition there are other process steps which can be used when modeling properties:\\nScale up well logs - The process of sampling values from well logs or well log attributes\\ninto the grid, ready for use as input to facies modeling and petrophysical modeling.\\nData analysis - The process of preparing the input data (normally upscaled well logs) for\\nproperty modeling. It involves applying transformations on input data, identifying trends for\\ncontinuous data, vertical proportion, and probability for discrete data. It also involves\\ndefining variograms that describe the input for both cases. This is then used in the facies\\nand petrophysical modeling to ensure that the same trends appear in the result.\\nTrend modeling - This process allows you to produce a vertical proportion volume by\\nperforming a block kriging of the probabilities of each of the facies.\\nUser-defined object creation - The process enables you to model objects that are not\\nlimited in shape and can have an arbitrary 3D geometry defined by the user.\\nTraining image and pattern creation - A training image is an idealized and simplified\\nrepresentation of the reservoir geology. The information contained in the training image is\\nreorganized into conditional distribution information that is accessible by the simulation\\nalgorithm. The conditional distributions are stored in the form of a tree called a Multi-point\\nfacies pattern. A pattern means investigating the neighborhood relationship between the\\nfacies and writing it into a tree.\\nFault analysis - The process where you can generate fault transmissibility multipliers,\\neither directly or by modeling fault properties, providing grid permeabilities, and calculating\\nthe multiplier. These are then used as input to the simulation or simply as a visual\\nassessment of the sealing potential of faults.\\nTrain estimation model - This process gives you access to tools for Neural Network\\nanalysis, enabling you to create a classification or estimation model object.\\nGeneral information on Property modeling\\nThe objective of Property modeling is to distribute properties between the available wells so it\\nrealistically preserves the reservoir heterogeneity and matches the well data. The Data analysis\\nwill help to QC and interpret the data, to identify key geological features, and to prepare the input\\nfor Facies- and Petrophysical modeling.\\nThe input distribution of the data is honored during the modeling process, but there are often a\\nnumber of ways of interpreting the input data (for example, how much of the variation is due to\\ntrends and how much is 'random').\\nIf you imagine three points in a straight line with steadily ascending values, you may assume that\\nthis is a trend throughout your data. However, three points is a small amount, and it is possible\\nthat the data you sampled is much more varied and you randomly got the ascending values. If\\nyou sampled the data again, in the same areas, you might have the highest value in the middle or\\nat the opposite end. The difference is that if you assume that this is due to a trend when you\\ndistribute properties, they will have a smooth linear trend across the model. If you assume it is all\\nrandom, you will have random property values across the model.\\nIn the image below, the blue line shows that the apparent trend is that the data is random. As\\nillustrated by the red line, the data shows a real trend.\\nBasically, you identify trends in the Data analysis process and then use the Property modeling\\nprocesses to model the random variation away from that trend, that is, the deviation from the\\ntrends you have defined. It is important that you make a conscious decision on whether the trend\\nis real or not, ignoring it if you do not think it is genuine.\\nInstead of using your property values directly as input to the Property modeling process, the\\ntrend is accounted for by modeling the residual; that is, the difference between the property\\nvalues at each of the upscaled cells and the trend at that point. The residual is then added to the\\ntrend to give the model results. Petrel does this automatically when you use the Data analysis\\nprocess or insert 1D, 2D or 3D trends during the Petrophysical modeling process.\\nBefore we show you some practical examples of this, it is useful to look at the concept of\\nvariograms first.\\nUsing variograms in modeling\\nA variogram is a description of the variations in a property. It is based on the principle that two\\npoints close together are more likely to have similar values than points far away from each other.\\nThere are two main aspects to a variogram:\\n1. How similar are two values right next to each other (nugget)?\\n2. How far away do points have to be before they bear no relation to each other (range)?\\nIt is important to remember that the Property modeling processes are used to describe the\\nnatural (random) variation in a property. The variogram should describe this natural variation,\\nrather than the broad scale trends that you see in your data. Identify any regional trends in the\\nData analysis process before you start the variogram analysis (this is especially true when you\\nare using Sequential Gaussian simulation for modeling, which will introduce variation into your\\nproperty to honor the variogram).\\nDeterministic modeling\\nKriging is an estimation method. It estimates the distribution of the result at any single point;\\nhowever, it is deterministic because it returns the most likely result at that point (even when the\\nuncertainty is high).\\nIn the example below (Figure 1), the kriging estimation is based on five data points, four identical\\nones, and a high value in the middle. The first figure shows a property model with a high\\nvariogram range, the second has a much lower range. Due to the larger range in the first one, the\\nhigh value in the center increases the probability of having a high value at a greater distance from\\nthe center.\\nIn the second figure, a smaller range means that the best estimate becomes the mean (that is,\\nmaximum uncertainty) rather quickly as you move away from the known data points.\"},\n",
       " {'header': 'Figure 1 ',\n",
       "  'content': 'The range of a variogram can be diverse in different directions (and will often be very different in\\nthe vertical direction using vertical well log data as input). The Data analysis module allows you\\nto analyze your data in two directions; horizontally (these will be perpendicular to each other) and\\nvertically. All of this data can then be used in the Property modeling process.\\nIn the vertical direction, you often have continuous data along the well and can perform a\\nreasonable variogram analysis.\\nHorizontally, it is rare to have enough sample points to generate an ideal variogram, unless you\\nhave several lateral wells. Based on your knowledge of the area, estimate what kind of lateral\\nvariation you can expect and then use the variogram generation in the Data analysis process to\\ncheck that it fits with your data.\\nStochastic modeling\\nKriging will give you the value with the highest probability for each point. However, this will give\\nyou a smooth result and you cannot assume that this is the most likely distribution. It will reduce\\nhigh values and increase low values so that volumes calculated from kriged surfaces can have\\nsignificant errors, particularly when applying a cut off to differentiate pay from non-pay or in the\\nform of a contact for structure.\\nTo capture the variation you have identified in your data, using the variogram analysis, you need\\nto use a stochastic algorithm such as Sequential Gaussian simulation. This is essentially\\nsimilar to Kriging, but uses the variogram and the property distribution of the input data to add\\nadditional features to your property. Property models generated with the Sequential Gaussian\\nsimulation look more reasonable than those modeled using deterministic averaging methods and\\nthey honor the input distribution data more realistically.\\nThe disadvantage of this method is that it looks convincing and realistic even in areas far away\\nfrom the input data. The results should be viewed with great caution (do not drill high values) and\\nshould only be used if you are prepared to work with several realizations of the same model.\\nThe property models below (Figure 2 ) have the same input data and variograms as those above,\\nbut they are modeled using a Sequential Gaussian distribution. The random shapes are obviously\\ndifferent from the results of Kriging, but again you can see the influence of the variogram. A\\nlarger range (to the left) leads to larger areas of high and low values, and a low range results in\\nmuch more local variations. Note that in this case it is difficult to guess where the input data is,\\nbecause the model does not get artificial effects from the sample location. Conversely, several\\nrealizations with identical input data, but a different seed, would result in different models\\n(although the statistical distribution might be the same). This is especially true if you are working\\nwith sparse input data.'},\n",
       " {'header': 'Figure 2 ',\n",
       "  'content': 'Use of seeds in Stochastic modeling\\nIn stochastic modeling it is desirable to produce many similar outcomes with the same\\nparameters (except for a \"seed\" value explained below) so that statistical inferences from the set\\nof all outcomes can be made. Conclusions drawn from a single stochastic outcome can be\\nincorrect. For example, if one particular outcome shows that two wells are connected by a\\nchannel, it is incorrect to assume that the wells necessarily must be connected by a channel in the\\nreal reservoir. If, however, after running many realizations, 60% of them show two wells\\nconnected by a channel, if all other assumptions are correct, then it is reasonable to assume that\\nthere is a 60% chance that the wells are connected in reality.\\nOutcomes with the same parameters differ in details that the user does not control directly. These\\ndetails are determined by the algorithm based on a series of pseudorandom numbers (i.e.\\nnumbers that appear to be random but are actually generated by a deterministic method)\\ngenerated from one seed value. Stochastic modeling dialogs allow you to either set this seed\\nvalue or to have it set randomly by the program. Setting the seed to a given value will always\\ncause the algorithm to use the same sequence of pseudorandom numbers. When generating\\nmany outcomes in order to draw statistical inferences, you should allow the seed to be set\\nrandomly by the program (that is, uncheck the box beside the seed value(s)) in order to obtain\\nmany outcomes that are statistically similar, but differ in their details.\\nA stochastic outcome should only have to be reproduced if you wish to show the details of one run\\nor if you are attempting to analyze or debug a potential problem. To exactly reproduce the same\\nresults in two separate stochastic modeling runs, you must ensure the following:\\n1. You must be using the same version of Petrel in both runs. If you applied a patch or changed\\nversions of Petrel from the last run, you will no longer be able to reproduce the exact same\\noutput.\\n2. The seed value(s) used must be the same.\\n3. All other input (including all properties, surfaces, options, parameters, or settings that\\nintervene in the modeling) must be identical. It is not sufficient for the input to be equivalent (for\\nexample, in object modeling, requesting 10 bodies may be equivalent to requesting 5% facies of\\nthat body for a particular run); the input must be identical in both runs to obtain the same result.\\n4. The output of the first run should not be used as input for the second run if it changes during\\nthe run. For example, in object modeling, if an output facies property is used as input background\\nproperty for the next run, the results will not be the same.\\nIt is often not possible to reproduce a stochastic outcome exactly when changing to a different\\nversion of Petrel. However, correct usage of stochastic modeling methods should preclude this\\nneed.\\nWhy use trends in Property modeling\\nWhat is the point of defining a trend? When you perform petrophysical modeling, trends in the\\ninput data appear in the result. So, why do you need to identify them first? The figure (Figure 3 )\\nbelow shows a classic example where, due to ambiguities in the data, identifying a trend before\\nperforming Property modeling makes a big difference. The input data contains 5 points with a\\nlinear trend across one diagonal and 3 identical values across the other.'},\n",
       " {'header': 'Figure 3 ',\n",
       "  'content': 'The same data can be interpreted in several different ways and the resulting models will be quite\\ndifferent from eachother. The model can have similar values everywhere with some variation\\npicked up by the two anomalies. Alternatively, there could be a linear trend across the data.\\nModeling the two cases using Kriging, with a relatively small range, illustrates the difference these\\nconcepts make (Figure 4). The model to the left has no trends identified, while the model to the\\nright has a linear trend directly along three of the input data points.'},\n",
       " {'header': 'Figure 4 ',\n",
       "  'content': 'The first model shows that a constant value is the norm, while the second has the trend as a\\nbackground with the data points modeled as anomalies on that. If the trend had been perfect, the\\nproperty would have been completely smooth with no anomalies at the data points.\\nThis also applies when using a stochastic algorithm, although the differences are more difficult to\\nsee. Again, if the trend had been perfect, then the property on the right would have been\\ncompletely smooth with no anomalies anywhere (Figure 5).'},\n",
       " {'header': 'Figure 5 ',\n",
       "  'content': 'The impact on the model becomes much clearer when a larger range is used for the modeling'},\n",
       " {'header': '(Figure 6). Figure 6 ',\n",
       "  'content': 'By identifying the trend in the data and confirming that the trend is realistic (i.e. tying it to a\\nconceptual model), the interpolation of the data can be constrained and the resulting model is\\nmore likely to represent the real case. This is important because the trends need to be both\\nidentifiable in the data and real, meaning that they can be related to a conceptual model.\\nIf the data does not fit the identified trend, then the residual (the difference between the input\\ndata and the trend) will be large. When this is modeled and applied to the trend, the results are\\nusually erratic and are unlikely to fit the real case, however, they will still match the input data. It\\nis therefore important that you make sure the trend surface represents the property values you\\nexpect to see (i.e. a porosity trend surface should normally have values between 0 and 0.35).\\nWhy use Transformations in Property modeling\\nThe Sequential Gaussian simulation that Petrel uses in the Petreophysical modeling process\\nrequires the input data to have a mean of 0 and a standard deviation of 1. The algorithm\\ngenerates a property with a standard normal distribution. Consequently, if the input data is not\\nstandard normally distributed, then the results will not be coherent with the input.\\nTransformations are used to map the original distribution to a standard normal distribution prior\\nto Property modeling and also to identify patterns in the data. Once the modeling has been\\ncompleted, the mapping (or transformation) is reversed to ensure the results have the same\\ndistribution as the input. This is done automatically in Petrel, as long as the transformation has\\nbeen applied during Data analysis. If no transformation has been applied, then Petrel will\\nautomatically perform a Normal Score transformation prior to modeling (see standard\\ndistributions and normal score transformations).'},\n",
       " {'header': 'Which Modeling Algorithm? ',\n",
       "  'content': 'This section provides an overview of the different algorithms available in Petrel for Property\\nmodeling and the advantages and disadvantages of each of them. Also included are some basic\\nrecomendations for modeling petrophysical properties.\\nFor more information about the different algorithms available for Property modeling, see the\\nInterpolation Algorithms section.\\nDeterministic versus Stochastic\\nThe main division in the modeling algorithms available in Petrel is between Deterministic and\\nStochastic methods. Both types of algorithms are available in the Facies and Petrophysical\\nmodeling processes.\\nDeterministic algorithms will always give the same result with the same input data. These\\nalgorithms will generally run much quicker and are very transparent - it is easy to see why a\\nparticular cell has been given a particular value. The disadvantage is that models with little input\\ndata will automatically be smooth even though evidence and experience may suggest that this is\\nnot likely. Getting a good idea of the uncertainty of a model away from the input data points is\\noften difficult in such models.\\nStochastic algorithms use a random seed in addition to the input data, so while consecutive runs\\nwill give similar results with the same input data, the details of the result will be different.\\nStochastic algorithms such as Sequential Gaussian Simulation are more complex and therefore take\\nmuch longer to run, but they do honor more aspects of the input data, specifically the variability of\\nthe input data. This means that local highs and lows will appear in the results which are not steered\\nby the input data and whose location is purely an artifact of the random seed used. The result will\\nhave a distribution more typical of the real case, although the specific variation is unlikely to match.\\nThis can be useful, particularly when taking the model further to simulation as the variability of a\\nproperty is likely to be just as important as its average value. The disadvantage is that some\\nimportant aspects of the model can be random and it is important to perform a proper uncertainty\\nanalysis with several realizations of the same property model with different random seeds.\\nSee also Stochastic Modeling.\\nThe two models below were created using the same input data. The one to the left was built using\\nthe Kriging algorithm (deterministic) while the one to the right was built using the Sequential\\nGaussian algorithm (stochastic).\\nFacies Modeling algorithms\\nThe Stochastic algorithms include:'},\n",
       " {'header': 'Object Modeling ',\n",
       "  'content': 'Truncated Gaussian with trends\\nTruncated Gaussian simulation\\nSequential Indicator simulation\\nMulti-point facies simulation\\nThe only deterministic algorithm for Facies modeling is Indicator kriging .\\nOther algorithms available are Assign values , Neural net and User defined algorithm .\\nDetailed information Facies Modeling\\nPetrophysical Modeling algorithms\\nThe Stochastic algorithms include:\\nSequential Gaussian simulation\\nGaussian random function simulation\\nAlthough there are a number of options allowing the user to alter how they are done, such as using\\nbivariate transforms, conditioning via collocated co-kriging, locally varying mean and using trends\\nby pre/post processing.\\nThe Deterministic algorithms for Estimation include:\\nKriging interpolation'},\n",
       " {'header': 'Kriging ', 'content': 'Kriging by Gslib'},\n",
       " {'header': 'Functional Closest ', 'content': 'And for Interpolation :'},\n",
       " {'header': 'Moving Average ',\n",
       "  'content': 'Other algorithms available are Assign values , Neural net and User defined algorithm .\\nDetailed information Petrophysical Modeling'},\n",
       " {'header': 'Which Trends ',\n",
       "  'content': 'In many cases, the properties being modeled are likely to be related to one another, permeability\\nis often high in areas of high porosity, etc. In addition, certain properties may have much better\\ncontrol than others, like a porosity model built from logs in all the wells and a seismic attribute\\ncube, versus occasional measurements of permeability from core plugs. For this reason, it may be\\ndesirable to model fewer well controlled properties based on better controlled ones.\\nThere are generally four methods available in Petrel for doing this:\\nDeterministic trends - The trend is given in the same domain as the primary variable and\\nis subtracted from the input data before the interpolation is done on the residuals. After\\nmodeling the trend is reapplied.\\nLocally Varying Mean - A secondary property is used as a local mean for the simulation.\\nBoth the secondary property and the input data undergo a normal score transformation\\nbefore the local mean is subtracted and the modeling performed. The mean is then\\nreapplied before the result is back transformed. Primary and secondary variables can either\\nbe transformed separately or using the same transformation (in which case they should be\\nin the same domain).\\nCollocated Co-kriging - The secondary variable is supplied together with a correlation\\ncoefficient and the influence of the secondary variable is calculated based on this and the\\ndata in the area of each cell. In addition the correlation coefficient can be supplied as a\\nsurface or a property.\\nBivariate transform - Here the secondary variable is input as a cross plot against the\\nprimary variable. The scatter between the two points will be honored by the simulation.\\nIn general, the above list can be considered in order of the most deterministic methods\\n(Deterministic trends) to the @softest@ methods. Deterministic methods are often useful when\\nthere is plenty of data, while the softer methods are commonly used when data is scarce and\\nuncertainty high.'},\n",
       " {'header': 'Geometrical Modeling ',\n",
       "  'content': 'Geometrical modeling is the process where properties can be generated by using pre-defined\\nsystem variables, such as cell volume, seismic resampling, zone index, etc. Each cell will get a\\nnumerical value corresponding to the selected system variable. These properties can be important\\nin processes such as volume calculations and mathematical operations between petrophysical\\nproperties. Geometrical modeling is not restricted to simple geometrical properties, it also covers\\nmore complex property distributions such as:\\nRandom/Normal distribution\\nZones/segments\\nFaults/segments'},\n",
       " {'header': 'Seismic ',\n",
       "  'content': 'Connected volumes\\nWell index/region\\nGeometrical modeling process window\\nOpen Geometrical modeling under the Property modeling folder and select between:\\nCreate new\\nEdit existing\\nSelect the Method to use to generate the property. Next, choose a property template and input\\nany necessary settings.\\nClick Apply to run the process. The new property will be stored in the Property folder from the\\nselected 3D grid.\\nAvailable Methods for Geometrical Modeling\\nThe following methods are available for Geometrical Modeling and each method has its own\\nsettings:\\nRelated information'},\n",
       " {'header': 'Geobody Modeling ',\n",
       "  'content': 'Assign between surfaces and polygons\\nCells cut by surface\\nConstant value\\nConstant or surface in segment and zones\\nNormal distributed random values\\nUniform distributed random values\\nAbove contact\\nCell angle\\nCell height\\nAbsolute or relative depth\\nDistance to an object\\nCell inside out\\nSeismic resampling\\nCell volume'},\n",
       " {'header': 'Connected Volumes ',\n",
       "  'content': 'Fault and Segment index\\nSeismic geobody assignment\\nZone and Segment index'},\n",
       " {'header': 'Well Index ',\n",
       "  'content': 'Well region\\nAssign between surfaces and polygons\\nThis option generates a property model with discrete cell values taken from any combination of\\ninput surfaces and polygons. This option can be used to generate discrete property models within\\nsurface and polygon limits that do not conform to the layering scheme in the 3D model.\\nInput options:\\nTop Surface: All cells below surface are set to chosen value\\nBottom Surface: All cells above surface are set to chosen value\\nBoundary Polygon: All cells that have their cell center inside the polygon are set to\\nchosen value\\n1. Select Create new property.\\n2. Select the method: Assign between surfaces and polygons to generate the new\\nproperty.\\n3. Choose the Property template to use for the new property.\\n4. Assign a value inside the given boundaries (options are: Unchanged, Undefined and Value).\\n5. Assign a value outside the given boundaries (options are: Unchanged, Undefined and'},\n",
       " {'header': 'Value). ',\n",
       "  'content': '6. Click OK or Apply to run the process.\\nCells cut by surface\\nSample a surface into the 3D grid to generate a new property. A user-defined discrete value is\\ngiven where the input surface penetrates a cell.\\n1. Select Create new property.\\n2. Select the Method Cells cut by surface to generate the new property.\\n3. Choose the Property template to use for the new property.\\n4. Input the Surface\\n5. Assign a value to cells cut (options are: Unchanged, Undefined and Value).\\n6. Assign a value to other cells (options are: Unchanged, Undefined and Value).\\n7. Click OK or Apply to run the process.\\nConstant value\\nFor the constant value method, select a property template from the drop down list and specify the\\nvalue to assign the new property.\\nConstant or surface in segment and zones\\nThis creates a property with constant values or values assigned from a surface. Values can be\\ndefined individually for each zone or each segment, or each zone within each segment. Tick the\\nbox besides the input box to drop in a surface instead of using a constant value.\\nNormal distributed random values\\nThis will create a property with random values following a normal distribution. Select the template\\nof the property to generate and define the Mean value and the Standard deviation. All non-\\ngeometrical property templates are available for selection.\\nUniform distributed random values\\nThis will create a property where the cells get a random value between the user-defined\\nmaximum and minimum value, which has to be defined in the process dialog. All non-geometrical\\nproperty templates are available for selection.\\nAbove contact\\nChoose between height above a constant level or height above a contact defined in the 3D grid.\\nThe height can be calculated from the center of the cell or from the center of the part of the cell\\nabove the contact. Naturally, this second option will give higher values and is useful if contacts\\nare to be used to ignore the lower part of the cell, that is, in the Volume Calculation process.\\nCell angle\\nThis calculates the deviation (from 90degrees) of the angles in each cell (absolute values). Select\\ntype of angle and cell plane from which the angle is extracted. Angle types are:\\nApparent - use this to get a measure of the apparent cell angle\\nWorst - finds the largest angle deviation for every cell in the specified cell plane\\nBest - finds the smallest angle deviation for every cell in the specified cell plane\\nAverage - finds the average of the angle deviations for every cell in the specified cell plane\\nCell height\\nThis calculates the height of each cell in the 3D grid and there are three options:\\nTVT - Thickness of the cell, the vertical distance between the upper and the lower walls of the\\ncell.\\nTST - Thickness of the cell, measured perpendicular to the upper and the lower walls of the cell.\\nAlong pillars - Thickness of the cell along the pillars. This procedure should be used when the\\npillars are vertical or close to vertical, as this calculation is much faster compared with the\\ncalculation of TST and TVT.\\nCell width\\nThe Cell width method calculates the width of each cell in the 3D grid and there are two options:\\nAlong I - The width of the cell defined as the distance measured perpendicular on the I-direction\\nbetween the centers of the opposing cell faces.\\nAlong J - The width of the cell defined as the distance measured perpendicular on the J-direction\\nbetween the centers of the opposing cell faces.\\nAbsolute or relative depth\\nGenerates a new property relating to the absolute depth of the cell center, its distance from the\\nzone top or its distance from the zone base. The depth can be calculated using real coordinates or\\nsimbox coordinates (details of this process can be found in Visualize a property as a regular box),\\nand with depth as a positive number or as a negative number.\\nDistance to an object\\nThis generates a new property with cell values calculated as distance from a chosen object(s).\\nThere are three main options available: distance to the center of the upscaled cells, distance to\\nfaults and distance to other objects (input can be points, polygons/lines, wells or surfaces).\\nNote: When using surfaces the vertical distance from the mid-point of the cell to the surface will\\nbe calculated.\\nCell inside out\\nTo measure the quality of the simulation grid block geometry, Petrel uses a temporary fine grid of\\nmicrocells.\\nAssuming that the temporary microgrid cells are defined by trilinear mapping, Petrel calculates\\nthe Jacobian at the eight corners and at the center points of the microcells. You are able to\\nspecify the resolution of this micro grid by an integer, call it M, which is then used to construct an\\nM by M by M grid inside each simulation grid block. The total number of times that the Jacobian is\\nnegative is then reported. When the grid is good, the result is zero. In most cases, the values are\\nall, or almost all, zeros. Only when an inverted coordinate system has been used at the start will\\nthe larger number be the result. A grid is not good when the result is different in different grid\\nblocks. There is no known rigorous test for inside-out hexahedral with bilinear surfaces. See\\nKnupp, [Ref. 4], for a discussion. Larger values of M make the test increasingly rigorous.\\nEven if none of the cells are inside-out, many of them can be very distorted. This is to be\\nexpected, depending on the input data. The converse can happen, when a cell is flagged as\\ninside-out but does not appear to be so. In these cases, however, the Jacobian will still have\\nchanged sign, somewhere inside the grid block. If the total grid block volume is of the correct sign\\nthen this may not affect the ability of the simulator to solve the flow equations, however, we\\nrecommend that you investigate the causes of any inside-out cells. Inside-out cells occur because\\nthere is too much distortion in some of the input data, or one or more control lines are incorrectly\\nclassified as I-lines when they should be J-lines, and vice-versa.'},\n",
       " {'header': 'Reference ',\n",
       "  'content': 'Knupp, P. M. On the Invertibility of the Isoparametric Map [Ref. 21]\\nComputer Methods in Applied Mechanics and Engineering, 78, Page 313-329,1990.\\nSeismic resampling\\nBy sampling a seismic volume (raw seismic or attributes), you can create a seismic property into\\nthe 3D grid in time or depth according to the seismic domain. Select a seismic volume in the\\nInput pane by clicking on it and then clicking on the blue arrow in the process dialog. Details of\\nthis process can be found in Creating a Seismic Property .\\nCell volume\\nThis calculates the bulk volume of each cell in the 3D grid. More advanced volume calculations can\\nbe performed in the Volume calculation process step. Details are described in Volume'},\n",
       " {'header': 'Calculations. Geobody Modeling ',\n",
       "  'content': 'This will create a property with values sampled from voxels as defined by geobodies (or geoblobs)\\ncreated in the Geobody interpretation process. Only the discrete bodies property template is\\navailable for selection.\\nThis geometrical modeling method is not to be confused with the Seismic geobody assignment\\nmethod that uses output from the now retired pre-Petrel 2009.1 process Volume extraction.'},\n",
       " {'header': 'Connected Volumes ',\n",
       "  'content': 'Connected volumes can be calculated for a specified facies code and a specified facies model. The\\nlargest volume gets code 0, the second largest gets code 1, etc.\\nIf the Cross zone boundaries check box is not selected, the volumes inside each zone are\\nranked separately, that is, every zone gets a code 0 representing the largest volume in that zone.\\nBy using the Only for facies type option, a single facies code can be investigated. All other\\ncodes will be undefined.\\nFurther restrictions on the body connectivity can be set by selecting the Cross zone boundaries\\nand Cross faults check boxes. Only volumes that cross both a zone boundary and a fault will be\\ncounted if you select those two restrictions.\\nIf the Use filter is selected, the ranking will be performed only on the remaining volume. All\\nother data will be undefined.\\nLimit volumes generated - The number of bodies produced can be restricted to avoid dealing\\nwith an unmanageable list of indexes. The algorithm will create the volumes in this order; largest\\nfirst, until either the maximum number of volumes has been produced or the next volume is\\nsmaller than the specified limit.\\nSeeds - A single well, a folder of wells, or all of the wells in the project can seed the algorithm. It\\ncan return all of the volumes connected to the well or group of wells, or all of the volumes not\\nconnected to the wells. This can be used to give an indication of the volumes available to\\nproposed wells or identify the areas that new wells should target.\\nHow to calculate connected volumes\\n1. Double-click the Geometrical modeling process.\\n2. Select Create new property or overwrite an existing one.\\n3. Select Connected volumes both as method and property template.\\n4. Select which discrete property to analyze.\\n5. Select which discrete code to calculate connected volumes for. If not selected, all discrete\\ncodes will be ranked.\\n6. You can choose between these options; Cross zone boundaries, Cross faults, and Use\\nfilter.\\n7. Select to use Limit volumes generated by number or by volumes.'},\n",
       " {'header': '8. Click Apply. ',\n",
       "  'content': '9. A connected volume parameter will show up in the property folder.\\n10. Quality control the results by displaying the parameter in 3D and also try the filter.\\nFault and Segment index\\nFault index\\nThis option allows the user to create a discrete property where cells neighboring a fault are\\nassigned a value according to the adjacent fault.\\nNote that the discrete values are saved in 8-bits, which means that the total number of\\nvalues cannot exceed 256. One value is set to be undefined and the remaining values can be from\\n0-254.\\nFault and segment index\\nThis option allows you to create a discrete property of all cells neighboring a fault and combine it\\nwith segments so that different values on different sides of each fault can be filtered out using the\\nsegment filter.\\nThe index is found by starting at the first fault and iterating over the segments, then the next\\nuntil it reaches the last fault\\nNote that the discrete values are saved in-8 bits, which means that the total number of\\nvalues cannot exceed 256. One value is set to be undefined and the remaining values can be from\\n0-254.\\nLGR Index\\nLocal Grid Refinement index\\nThis method allows you to create a discrete property where cells are assigned a value according to\\ntheir local grid refinement.\\nSeismic geobody assignment\\nAlthough the Volume extraction process existing in pre-Petrel 2009.1 versions has been\\nremoved, the resulting extracted bodies can still be used to create properties in Geometrical\\nmodeling. Sample objects extracted from the seismic into a 3D grid as discrete properties. This\\nallows you to use the objects you have extracted in much the same way as you would use a facies\\nmodel. Filter on the property to perform functions on the areas of your model within these\\nobjects, Data Analysis, Volume Calculations, etc. The Algorithm first finds the center of each grid\\ncell, then checks to see whether that center falls inside the triangulated object.\\nChoose the seismic object to sample and the template and the values to be assigned inside and\\noutside the object. The figure below shows an object extracted from the seismic and sampled into\\nthe grid.\\nOnly geobodies extracted from seismic (using the pre-Petrel 2009.1 Volume extraction\\nprocess) will be accepted as input in Seismic geobody assignment.\\nZone and Segment index\\nSegment index\\nThis option allows the user to create a discrete property where cells are assigned a value\\naccording to their segment.\\nZone index\\nThis option allows the user to create a discrete property where cells are assigned a value\\naccording to their zone. Select between creating a property from:\\nmain zones - zones created by Make Horizons\\nall zones - all zones in the grid\\nall zones (in hierarchy) - as all zones but with the property template adjusted to give the\\ncorrect hierarchy\\nall layers - each k layer will get a single number\\nIt is possible to use an existing discrete property (that will be overwritten) or to create a new\\nproperty.\\nZone and segment index\\nThis option allows the user to create a discrete property where cells are assigned a value\\naccording to both their zone and their segment. Select between creating a property from main\\nzones, all zones or all zones (in hierarchy) and all layers. The index is found by starting at the\\nfirst zone and iterating over its segment, then the next until it reaches the last zone\\nNote that the discrete values are saved in 8 bits, which means that the total number of\\nvalues can only be 256. One value is set to be undefined and the remaining values can be from 0-\\n254.'},\n",
       " {'header': 'Well Index ',\n",
       "  'content': \"The Well Index property generates a property based on the wells penetrating the active 3D grid. A\\nsingle discrete value is assigned to all cells penetrated by each well. Cells not penetrated by wells\\nare set Undefined.\\nThe Well Index property is useful for evaluating property values linked to wells. The example\\nbelow shows a porosity vs. permeability crossplot for the cells penetrated by wells in the 3D grid.\\nSimple data analysis shows the 3rd dimension as the well ID property. The crossplot shows that\\nwell G03 has some anomalous permeability values.\\nWell region\\nThis option generates a new property that defines a region around the well (radius). A well folder\\ncan be selected or just visible wells displayed in a window. The well region can be delimited for:\\nConnected section only - includes only cells that are penetrated by the well, also\\nconnected and open at some time in the set of seed cells for the region. Otherwise, all the\\ncells that the well penetrates are included, regardless of whether they are connected to the\\nreservoir or not.\\nMerge laterals - if selected, one region index is assigned to a well and its laterals.\\nUnselected, each lateral will have an unique region index assigned to its region. But, if the\\nmain well of a lateral is not included in the wells selected, then the lateral will retain its own\\nregion number regardless of this option\\nRadius - defines the value for the well radius\\nOverlapping - can be truncated or merged. Merge will assign the same value to the cells in\\neither of the well's regions of influence for the merged wells. Truncating will assign a cell to\\nthe closest well in the region of influence.\\nScale up well logs\\nWhen modeling different properties, the modeled area is divided up by generating a 3D grid. Each\\ngrid cell has a single value for each property. As the grid cells often are much larger than the\\nsample density for well logs, well log data must be scaled up before it can be entered into the\\ngrid. This process is also called blocking of well logs.\\nThe user has some degree of control over how the grid values are chosen from the multiple\\nvalues that exist in the log. An upscaled property will have an U followed by its name in the\\nProperty folder.\\nThis process can also be used to sample attributes associated with well tops, zones, or point\\nobjects into the grid. This is one way to import data in the format X,Y,Z,P1,P2 into the 3D grid.\\nHow to scale up well logs\\n1. Activate the correct 3D grid.\\n2. Double-click the Scale up well logs icon in the Processes pane to open the process\\ndialog.\\n3. In the Scale up well logs tab, select the Create new property option.\\n4. Select the wells you want to use for the upscaling of the logs. The default selection is all\\nwells.\\n5. Select the log you want to use. This pull-down menu will show the log names available after\\nimport of the wells.\\n6. Choose Scale up settings under Settings tab. See Scale Up Well Logs Dialog for further\\ndetails.\\n7. Click OK.\\nA new property will be added to the bottom of the Properties folder list for the active 3D grid.\\nThis will have the same name and template as the well logs it was upscaled from. To change\\nthese, open the property's settings window and alter the name or template in the Info tab.\\nPrinciples of Scale up well logs\\nWhen upscaling well logs, Petrel will first find the 3D grid cells which the wells penetrate (see\\nFigure 1). For each grid cell, all of the log values that fall within the cell will be averaged according\\nto the selected algorithm to produce one log value for that cell.\\nFor discrete well logs (for example, facies or zone logs), the average method Most of is\\nrecommended. The upscaled value will then correspond to the value that is most represented in\\nthe log for that particular cell.\\nThe layout and the resolution of the 3D grid will control how many and which cells each well\\npenetrates. A dipping layering scheme, compared to a horizontal scheme, can dramatically alter\\nthe results from the Scale up of well logs process and the subsequent property modeling.\"},\n",
       " {'header': 'Figure 1 ',\n",
       "  'content': 'The result of the Scale up well logs process is placed as a property model icon in the\\nProperties folder for the 3D grid. It only holds values for the 3D grid cells which the wells have\\npenetrated (Figure 2). All other cells have an undefined value. Property modeling is then used\\nto assign values to all the other grid cells, based on the upscaled well logs and optional trend\\ndata.'},\n",
       " {'header': 'Figure 2 ',\n",
       "  'content': \"In summary, the Scale up well logs process assigns log values to the cells in the 3D grid that\\nare penetrated by the wells. The process is commonly used in post-process for the distribution of\\nproperty values between the wells.\\nScale up well logs dialog\\nScaled up well logs are held in the grid as properties, with only the upscaled cells having a defined\\nvalue.\\nFirst, you must choose between Create new property or Edit existing in the active grid. If an\\nexisting property is overwritten, the settings used to upscale that property originally will be the\\ndefault in the dialog. By toggling on the Show results in well section, all logs used in the\\nupscaling and the resulting properties will be displayed in a new well section window. The\\nupscaled properties can then be edited interactively see Properties in the well panel.\\nAny local grid defined in the global grid targeted by this process will have their cell-properties\\nupscaled accordingly. If the Use local grid filter check box is selected, only the local grid(s) will\\nbe used in the process.\\nYou can choose between using well logs as the input for upscaling or taking input from well top\\nattributes or points with attributes.\\nFig. 1 General settings in the Make property tab for the Scale up well logs process.\\nSettings tab (Scale up well logs)\\nSeveral settings can be applied to control the Scale up well logs process.\\nUse bias\\nTurn on this option to use a discrete property to control the upscaling process. For the upscaled\\nlog to be available, a discrete (facies) log must have been upscaled first. The reference of the raw\\nlog will appear in an upscaled form.\\nThis option is used to ensure that the upscaled values for a petrophysical property are appropriate\\nfor the facies property for the same cell. For example, if a cell has a channel facies after\\nupscaling, it should have a porosity value that is representative of channel facies within that cell.\\n1. Petrel will then check the facies code for each cell to be upscaled.\\n2. Find the corresponding well log for that facies property.\\n3. Compare the facies log with the property log to be upscaled.\\n4. Filter out the property values corresponding to the cells facies code.\\n5. Average those values to get the value for the upscaled cell.\\n4.\\n5.\\nThe results of this are shown in the figure below. The first column shows the facies property in the\\ngrid, the second the facies log, the third the raw log with the upscaling with no bias, and the\\nfourth shows upscaling with the bias (the blue points in the raw log were used for the average).\\nYou can see that upscaling with no bias option results in a general smoothing of property values.\\nFig. 2 Upscaled facies \\\\ Raw facies \\\\ Raw porosity \\\\ Upscaled porosity using bias.\\nScale up settings\\nDifferent methods are available to average the log values in the Scale up well logs process.\\nAverage method - controls the algorithm used for upscaling the log values. For detailed\\ninformation of the algorithms see Scale up settings ( Scale up well logs process)\\nTreat log - this option defines how the log values will be treated for the average in the\\ncells. Choose between lines and points as input. For detailed information see Treat log\\nMethod - defines which penetrated cells by the wells to upscale. For detailed information of\\nthe methods see Method\\nUse facies weighting - you can change the weight of a particular member of a discrete\\nlog; in the facies for example. Once this option is selected, the Weighted tab is enabled. For\\ndetailed information of the process see the Weighted tab (Scale up well logs)\\nMinimum number of points in a cell - you can specify that there should be a minimum\\nnumber of well log samples in a cell for it to be included in upscaling. For detailed\\ninformation see Minimum number of points in cell\\nWells - choose which wells should be used as input in the upscaling process. For detailed\\ninformation see Wells\\nUse saved search - this functionality allows to access wells based on specified search\\ncriteria. For detailed information see Saved searches\\nFig. 3 Settings tab for Scale up well logs process.\\nWeighted tab (Scale up well logs)\\nThe Weighted tab is enabled if you select the Use facies weighting check box. With this option\\nit is possible to change the weight of a particular facies, or to adjust the proportion of the\\nupscaled log to the raw log. You can specify the settings to apply for all zones or specify separate\\nsettings for each individual zone.\\nBy default, all of the facies will have a value of 1 on the Weighted table. Setting the same values\\nfor all facies gives the same result as using the 'Most of' algorithm. Increasing the weight of a\\nparticular facies means that less of that facies is required for it to be assigned to the upscaled cell.\\nThe weight values are relative, so they can be assigned as fractions. No method exists to\\ndetermine a weighted value. It is a process of trial and error, but comparing the histogram for the\\nupscaled facies to the raw logs can help to determine when a weight value is adequate.\\nFor example, if you scale up a facies log containing sand and shale using weight 1 (one) for both\\nfacies codes, as a result, you will get twice as much shale as sand. If you then want to increase\\nthe amount of sand, you must increase the weight for that facies code until you reach the desired\\nfraction between the sand and shale.\\nHow to use the Weighted tab\\n1. First, upscale the facies or discrete log as usual.\\n2. Select Update existing property and your upscaled discrete log as Input.\\n3. Turn on the option Use facies weighting and go to the Weighted tab.\\n4. If needed, select the Equal for all zones check box.\\n5. Open the Settings for the upscaled facies or discrete log.\\n6. Go to the Histogram tab and display both Upscaled cells and Well logs (the zone filter\\ncan also be used).\\n7. Set up the weight values for the particular facies you wish to change and click Apply.\\n8. Visualize the changes on the Histogram.\\n9. Try different weight values and click Apply until you get the desired result.\\n8.\\n9.\\nComparison of Facies\\nWell log and Upscaled cells without weighting.\\nFig. 4 On the left, applying weight to the different facies and, on the right, the resulting histogram\\ncomparing the Facies Well log and Upscaled cells that have been weighted.\\nSeed tab (Scale up well logs)\\nThe Seed tab is used by the Random pick - Average method. By selecting this method, the Seed\\ntab becomes activated. The seed number defines the start for the random number generation in\\nthe algorithms.\\nFig. 5 The Seed tab.\\nScale up Point attributes\\nPoints with attributes will be scaled up into the cells in which they occur. This option is useful for\\nproperties where no logs are available. A point data set with attributes can be imported or\\ngenerated and then upscaled. See also Importing Points Data\\nFor example, Velocity data (stacking velocities):\\n1. Import the data as Point with attributes. It will be saved in the Input pane. Display it\\nfor QC.\\n2. Expand the Point data set -> Attributes folder and make sure that the correct template\\nis selected for the attribute (in this case, Stacking velocity)\\n3. Operations/calculations can be performed to generate new attributes. For this particular\\ncase, select the Operation tab -> Seismic operations -> Dix conversion to generate\\nother attributes as interval or average velocities.\\n4. Select the correct 3D grid and open the Scale up well logs process\\n5. Select Create new property.\\n6. As the input, select Point attritbutes.\\n7. Select the Point data set and use the blue arrow to drop it into the process.\\n8. From the attribute list, select the attribute to be upscaled.\\n9. The new upscaled property will be stored under the 3D grid -> Property folder on the\\nModels pane. Display it for QC.\\nNote: It is important to review the vertical distance between points to perform the optimum\\nlayering for the 3D grid, and to get a good average for the cell value.\\nFig. 1 Example of Points with attributes (velocity data)\\nFig. 2 Scale up point attributes process and 3D displayed of the result.\\nScale up Welltop attributes\\nWell tops attributes will be scaled up into the cells in which they occur. Attributes can be sampled\\nfrom well logs, entered manually, imported with the well tops, or copied/pasted from another\\nspreadsheet . See also Attributes for well tops and zones\\n1. Import the Well tops. They will be stored in the Input pane. Display it for QC.\\n2. Expand the Well tops -> Attributes folder and make sure the correct template is\\nselected for the attribute.\\n3. Operations/calculations can be performed to generate new attributes. Right-click on the\\nWell tops -> Attributes folder and select the option Insert new attribute. For detailed\\ninformation on how to generate the attributes, see Calculating Well Top Attributes\\n4. Select the correct 3D grid and open the Scale up well logs process\\n5. Select Create new property.\\n6. As the input, select Welltop attributes.\\n7. Select the Well tops folder and use the blue arrow to drop it into the process.\\n8. From the attribute list, select the attribute to be upscaled.\\n9. The new upscaled property will be stored under the 3D grid -> Property folder. Display it\\nfor QC.\\n8.\\n9.\"},\n",
       " {'header': 'Fig. 3 ',\n",
       "  'content': 'Scale up settings ( Scale up well logs process)\\nAveraging methods\\nThe following methods for Scale up well logs are available:\\nArithmetic mean - Typically used for properties such as porosity, saturation, and\\nnet/gross because these are additive variables.\\nArithmetic mean weighted - Will produce a more correct arithmetic mean when input\\nvalues have variable interval within the resulting cell. This algorithm will be used when\\narithmetic mean is combined with the Treat log as lines option. Each sample will be\\nweighted according to the MD distance inside the cell.\\nHarmonic mean - Gives the effective vertical permeability if the reservoir is layered with\\nconstant permeability in each layer. The harmonic mean works well with log normal\\ndistributions. Used for permeability because it is sensitive to lower values. The method is\\nnot defined for negative values\\nHarmonic mean weighted - Will produce a more correct harmonic mean when input\\nvalues have variable presence within the resulting cell. This algorithm will be used when\\nharmonic mean is combined with the Treat log as lines option.\\nGeometric mean - Is normally a good estimate for permeability if it has no spatial\\ncorrelation and is log normally distributed. The geometric mean is sensitive to lower values,\\nwhich will have a greater influence of results. The method is not defined for negative values.\\nGeometric mean weighted - Will produce a more correct geometric mean when input\\nvalues have variable presence within the resulting cell. This algorithm will be used when\\ngeometric mean is combined with the Treat log as lines option\\nRMS (Root Mean Squared) - Will provide a strong bias towards high values\\nMost of - Will select the discrete value which is most represented in the log for each\\nparticular cell\\nFacies Weighted - Similar to Most of however the various facies will be multiplied by their\\nweighting factor prior to the assessment. The weighting factor is given on the weighting tab.\\nMedian - Will sort the input values and select the center value, e.g. if there are 7 input\\nvalues, these are sorted by magnitude and then entry number 4 in the sequence is\\nselected.\\nMinimum- Will pick the minimum value.\\nMaximum- Will pick the maximum value.\\nMid Point Pick - Will pick the log value where the well is halfway through the cell. This is\\nessentially a random choice and is therefore more likely to give a property with the same\\ndistribution of values as the original well log data.\\nRandom Pick - Picks a log point at random from anywhere within the cell. This random\\noption avoids the smoothing tendency of other methods and is, therefore, more likely to\\ngive a property with the same distribution of values as the original well log data.\\nDetails of these methods are given in Averaging Methods .\\nThe weighted options are selected by choosing the appropriate settings and selecting Treat log\\nas lines . Most of and Median options are only available for discrete logs.\\nFor Harmonic mean, only measurements with values greater than zero can be used.\\nGenerally speaking: RMS > Arithmetic > Geometric > Harmonic\\nTreat log\\nOption to treat the log as point or line data. See also Averaging Methods .\\nAs points : All sample values within each cell are used for averaging (without being weighted). If\\nno points are present in the cell, the cell will be undefined.\\nAs lines : Each sample value is weighted by a factor proportional to its interval. Sample values\\noutside the cell will be taken into account if the mid point between the sample and a sample inside\\n(or on the other side of) the cell is within the cell. Each sample will be weighted. The weighted\\nvalue of each point is given by the formula presented below. Only the part of l lying inside the cell'},\n",
       " {'header': 'I ',\n",
       "  'content': 'will be used to define the weight. If the sample interval is constant, \"as lines\" will be virtually\\nidentical to \"as points\".\\nFig. 1 Part of a horizontal well going through a cell. Five log values are present.\\nIn figure 1, l is the part of the length of the well trace that the log value of each point defines.'},\n",
       " {'header': 'I ',\n",
       "  'content': 'The total length of the cell is l .\\ntotal\\nThe value V , of each point involved is then:'},\n",
       " {'header': 'I ',\n",
       "  'content': 'where ni is the log value of the point. The resulting value of the cell is then calculated using the\\nvalues of each point involved and the average method selected.'},\n",
       " {'header': 'Method ',\n",
       "  'content': 'The input values from the raw logs to be used for averaging can be selected in different ways:\\nSimple - All cells penetrated by the well path will get a value. Even if just a tiny corner of a cell is\\npenetrated by the well path, it will get a value.\\nThrough cell - The well trajectory must go through two opposite cell walls (top and base -\\nopposite sidewalls) of a cell for the cell to be included.\\nNeighbor cell - This option will average log values from all cells immediately adjacent to the\\nupscaled cell and belonging to the same layer as the upscaled cell. Therefore, if there are three\\nadjacent cells along the well path which belong to the same layer, the first will get an average\\nvalue of the logs from cells 1 and 2, the second from cells 1, 2 and 3 and the third from logs\\nwithin cells 2 and 3.\\nMinimum number of points in cell\\nThis option allows the user to set a minimum number of well log samples in a cell for it to be\\nincluded in upscaling. e.g. if the minimum value was 3 and a cell has only 1 log value, the cell will\\nnot be upscaled. This avoids the risk that a single, atypical value may define the value of a cell\\n(which may then be used in petrophysical modeling to define a whole area).'},\n",
       " {'header': 'Wells ',\n",
       "  'content': 'Choose which of the wells should be used as input to the upscaling. Use the None and All buttons\\nto change the selection of all the wells.\\nA Use saved search option can be used for Wells , allowing users to access wells based on\\nspecified search criteria. The functionality helps to organize well data into different place holders\\nwithout duplicating data. The functionality is restricted to well data. Several types of search\\ncriteria can be applied, and each search can be used in isolation or in combination with other\\nsearches.\\nData analysis\\nData analysis is a process of quality controlling the data, exploring the data, and preparing\\ninputs for Facies and Petrophysical modeling. The Data analysis section of the Online Help is\\nsplit into two main sections:\\n1. Data analysis process - includes a detailed analysis of facies proportion and thickness,\\ndata transformation on continuous properties, as well as defining special variograms.\\n2. General Data analysis tools - includes using the Histogram and Function windows to\\ninspect the property distributions and the correlation between properties.\\nGeneral Information On Property Modeling contains a more general discussion on how the Data\\nanalysis process comes into play in the modeling process.\\nData analysis process\\nThe Data analysis process can be accessed from the Process diagram, Property modeling\\nfolder and allows the user to perform a detailed property analysis. Depending on whether a\\nproperty is discrete (e.g. facies) or continuous (e.g. porosity, permeability), different tools will\\nbe available within the Data analysis process window.\\nDiscrete data analysis for analyzing the facies proportion, facies thickness, calibration\\nbetween continuous properties (e.g. sampled seismic) and facies within each zone and also\\ncreate a variogram. The settings defined for discrete properties in the Data analysis process\\nwill be saved for the current property, and accessed directly during facies modeling.\\nContinuous data analysis for defining data transformations and to generate variograms.\\nData transformation enables the user to make the data stationary and standard normally\\ndistributed, which are requirements of many of the standard geostatistical algorithms.\\nSpatial trends in the data will be extracted from the data prior to property modeling to\\nensure stationarity, and these trends will be reapplied to the modeled property, ensuring\\ntheir preservation. Undiscovered trends in the data can invalidate data interpolation during\\nproperty modeling.\\nThese processes require the Data analysis process module.\\nData analysis General Settings\\nData analysis should usually be performed on each facies and each zone in order not to mix the\\nstatistics. Therefore, the user must first define the Property and Zone to be analyzed. If you\\nhave chosen a continuous property, you will also be given the choice to do Data analysis on each\\nFacies . When analyzing a discrete property, you will have the option to apply conditioning to\\nFacies (an existing discrete 3D model).\\nThe Leave settings unchanged (lock) icon must be deselected in order to change the\\nsettings in any of the tabs. The purpose is to preserve all settings in this process as default.\\nWithin the main settings in the Data analysis dialog, the user can also select if the analysis should\\nbe performed on: Use upscaled , Use logs or Use property .\\nData analysis is usually done on the upscaled logs. However, raw logs can be used if there are too\\nfew upscaled cells, and can be useful to inspect the raw data in order to quality control the log\\nupscaling process. Using the whole 3D property allows quality control on modeled properties, as\\nwell as the analysis of seismic data.\\nA filter, such as the segment filter or value filter can be applied. This is enabled by toggling on the\\nProperty filter icon . Note, when using the filter, all of the active filters will be applied. Hence,\\nyou can filter on segments, values and/or zones.\\nOther available tools are:\\nMove between zone/facies code setting panels - Show settings for first\\nzone/facies code, previous zone/facies code, next zone/facies code and last zone/facies code,\\nrespectively.\\nCopy settings from the selected zone(s) or facies code(s) - The action will copy all\\nsettings defined for the selected zone or facies code.\\nPaste settings for selected zone(s) or facies code(s) - Only available after using the\\ncopy option, click on the tab of another zone or facies code and then click on this icon. This will\\napply the settings of the copied zone/facies code to the currently selected zone/facies code.\\nPaste settings to all zones or facies code(s) - Only available after using the copy option.\\nThis will apply the settings of the copied zone or facies code to all other zones/facies codes.\\nReset settings of the selected zone or facies code to default - Will reset all the different\\nsettings of a zone or facies code to default values. A similar icon will be available in each sub\\nmenu to allow reset to default settings for selected settings.\\nReset settings of all zones to default - Will reset all the different settings for all the\\ndifferent zones in the project.\\nFor discrete properties:\\nAppend facies - Add new facies code to all editable curve lists.\\nRemove facies - Delete facies code to all editable curve lists.\\nThe Data analysis process dialog'},\n",
       " {'header': 'Discrete Properties ',\n",
       "  'content': 'Discrete properties are integer properties, such as facies, where the values fall into groups (either\\nsand or shale, etc.); as opposed to continuous properties where decimal values are possible (e.g.\\nporosity).\\nData analysis for discrete properties will most often be done on facies properties, but can also be\\nperformed on any type of discrete data.\\nAnalysis can be performed on all zones, each zone individually or using the filter on any\\ncombination of zones, or even areas of high/low permeability/porosity etc., different areas of the\\nproject (see Filter, for filter use). Analysis can also be a condition to an already existing facies\\nproperty.\\nThere are four main tabs in the discrete property analysis dialog:\\nProportion tab - Analyze the distribution of facies vertically through the model, edit this\\nfor use in Facies modeling.\\nThickness tab - Analyze the distribution in the thickness of facies bodies (only\\nvisualization).\\nProbability tab - Compare the facies to a continuous property (e.g. sampled seismic) and\\ndetermine the probability of correlation. This function is commonly used for the calibration\\nof seismic attributes against facies. It can convert a seismic attribute cube into a facies\\nprobability cube ready for use in Facies modeling\\\\Sequential Indicator Simulation.\\nVariogram tab - Generate a discrete variograms to describe the facies distribution (see'},\n",
       " {'header': 'Variogram Analysis (Data Analysis)). ',\n",
       "  'content': \"Proportion tab (Data analysis)\\nThe Proportion tab enables the user to assess and interactively edit curves that describe the\\nvertical distribution of the different facies based on model layers. The vertical probability\\ncurves can later be used as input to control the vertical distribution of facies codes in Facies\\nmodeling process.\\nThe tab consists of two data windows:\\nFacies proportions are displayed in the left window. This window displays the proportion\\nof facies in one zone or all zones, depending on the selection you have made in the general\\nsettings. Above this window, there is a table with facies and the user can select which facies\\nto display in the facies proportion window. All facies are selected as default. You can choose\\nto display the facies proportion in percent (%) or number of samples (N).\\nHistogram for the chosen facies and probability curves for all facies which can be\\nedited are displayed in the right window. The order of the facies will change automatically\\nso that the distribution of the chosen facies can be compared with its histogram.\\nChoose the facies to display in each window from the list box above the two data windows.\\nSettings for the Proportion tab (Data analysis)\\nAs default the proportion for each facies will be equal, but they can be edited directly by dragging\\nthe control points. In addition:\\nFit active/all curve(s) to a constant average - will create a constant distribution equal to\\nthe average probability for that facies.\\nFit active/all curve(s) to a linear regresion - will create a straight line trend\\napproximation of the actual facies distribution.\\nFit active/all curve(s) to a histogram - will create a distribution equal to the actual facies\\ndistribution.\\nApply to all - toggles between applying the above changes to all distributions (depressed), or\\nonly the active curve.\\nLock the selected curve - locks the active curve so that applying a distribution to 'all\\ndistributions' does not affect the locked facies.\\nSmooth active/all curve(s) - will smooth the distribution.\\nReset probability curves to original shape - will reset the distributions to original shape.\\nIt is also possible to move the data in the windows much the same as in a Petrel map window:\\nTo pan in the windows; hold the left mouse button and move the mouse.\\nTo zoom in the windows; hold the left mouse button and the Ctrl +Shift keys.\\nView all - will ensure all the data is visible and the data fills the window.\\nCopy to clipboard - will copy the window to the clipboard.\\nHow to edit the probability curve (Data analysis\\\\Proportion tab)\\n1. To edit a probability curve, the selected facies must be activated in the table above the\\nprobability window\\n2. Choose the facies curve to edit in the list of facies\\n3. Click on the points defining the curve and move them to change the probability. Using\\nShift will allow the editing of several points at once\\n4. The user has the option to fit the probability curve to a linear regression curve, to\\noriginal histogram or to a constant average value\\n5. The sum of the probabilities equals 1 . Hence, by editing the probability curve for the\\nactive facies, you will proportionally change the other facies probability curves (the facies\\nprobability always equals 1)\\n6. When you have finished editing on a selected facies probability curve, you have the option\\nto freeze it by locking the selected curve . If a curve is frozen, it will not be affected\\nwhen other facies probability curves are changed\\n7. After the definition of the probability curves, the settings must be applied. If you are\\nworking with the zones separately, you apply the settings for all zones at the same time\\nwhen pressing Apply\\n8. The edited facies probability curves can now be used in the Facies modeling\\nThickness tab (Data analysis)\\nThis tab enables you to analyze the thickness of facies bodies by means of a histogram.\\nThe main window in the tab is the histogram window. In the table on the left side, you can select\\nwhich facies to display.\\nStatistical characteristics, such as % (percentage of samples), Cell count (number of cells), N\\n(samples number), Minimum , Maximum , Mean and Std (standard deviation), attached to the\\nfacies codes are displayed above the window. The first three parameters on the left indicate the\\npercentage of samples, the number of cells or log samples and number of facies intervals done in\\nthe selected facies code(s) and the selected interval.\\nThese figures should be used to estimate the required thickness of bodies for use in the Object\\nmodeling algorithm in Facies modeling.\\nThe facies thickness shown in Data analysis represents the vertical facies thickness at the\\nwell locations. It may not represent the full thickness of the facies bodies if the well is not drilled\\nat the center of the body. The thickness input for object facies modeling requires the full thickness\\nof the facies bodies. Therefore, the facies thickness input in object facies modeling should often be\\nhigher than the statistic numbers in Data analysis.\\nSettings for the Thickness tab (Data analysis)\\nThe interval width for the histogram can be set by changing the Bin Interval .\\nThe number N and percentage of samples % in the selected interval and the selected facies are\\nshown in the top left area.\\nShow simbox hieght - Toggles between real and simbox view. In simbox view, the grid is\\ntransformed to regular grid cells with an average thickness. If simbox view is not selected, the\\ndata will be displayed with the true grid cells height (see Visualize a property as a regular box\\n(simbox view) ).\\nPercent button - For displaying the histogram data as percentage or samples number (Y-\\naxis).\\nView All - Adjusts the display to show all data.\\nCopy bitmap to clipboard - Can be used to make bitmaps of the data in the process.\\nAll - Displays all facies for the selected zone.\\nNone - Deselects all facies.\\nProbability tab (Data analysis)\\nIt is preferable to use all available information to help guide the facies modeling between the\\nwells.\\nWithin the Probability tab, you can analyze the relationship between facies and property values;\\ntypically seismic attributes that are sampled into the 3D grid (for example, an acoustic impedance\\ncube showing good correlation with the facies in the wells). Plots will show the probability of\\nfinding a particular facies at a particular acoustic impedance, and these can be used directly in\\nFacies modeling to generate a facies model based on the seismic (Fig. 1). The probabilities can\\nalso be interactively edited in order to fix anomalous data or test a conceptual model.\\nIt is important to be sure there is a link between the seismic data and the facies before you begin\\nthe analysis, particularly if the control data is sparse. It is easy to generate a property linked to\\nthe seismic data and this will often look reasonable even though it might be incorrect.\\nFig. 1 Probability tab settings, in the example is shown the probability curves of facies within\"},\n",
       " {'header': 'Acoustic Impedance. ',\n",
       "  'content': \"Settings for the Probability tab (Data analysis)\\nFrom the drop-down menu, select the Secondary property (seismic) to compare with the facies\\ndata. All of the continuous properties held in the current 3D grid will be available from this list.\\nSelect the facies whose probability you wish to edit from the list on the top right part of the\\nwindow. The order of the facies in the window will change so the active facies can be compared\\nwith its histogram.\\nThe number of classes the data is sorted into (for the histogram) is specified in the text box No\\nintervals .\\nBy default, the probability for each facies will be equal, but they can be edited directly by\\ndragging the blue control points. Clicking the line where no control point exists will create a new\\ncontrol point.\\nShow attribute histogram - toggles between showing and hiding a histogram of the chosen\\nattribute.\\nAttribute histogram in percent - toggles between showing number of samples or\\npercentage (left Y-axis).\\nFit active/all curve(s) to a constant average - will create a constant distribution equal to\\nthe average probability for that facies.\\nFit active/all curve(s) to a linera regression - will create a straight line trend\\napproximation of the actual facies distribution.\\nFit active/all curve(s) to histogram - will create a distribution equal to the actual facies\\ndistribution.\\nSmooth active/all curve(s) - will smooth the distribution.\\nApply to all - toggles between applying the above changes to all distributions (depressed), or\\nonly the active curve.\\nLock the selected curve - locks the active curve such that applying a distribution to\\n'all distributions' does not affect the locked facies.\\nReset probability curves to original shape - will reset the distributions to original shape.\\nIt is also possible to move the data in the windows much the same as in a Petrel map window:\\nTo pan in the windows; hold the left mouse button and move the mouse.\\nTo zoom in the windows; hold the left mouse button and the CTRL and SHIFT keys.\\nView all - will ensure all the data is visible and the data fills the window.\\nCopy bitmap to clipboard - will copy the window to the clipboard.\"},\n",
       " {'header': 'Continuous Properties ',\n",
       "  'content': 'Continuous properties are properties that can have decimal values, such as porosity and\\npermeability. Discrete properties, on the other, hand have integer values; for example, facies\\nproperties, where the \"value\" is either sand or shale represented by integers in Petrel (no decimal\\nvalues are possible).\\nThe Data analysis dialog on continuous properties includes two main tabs:\\n1. Transformations tab\\nViewing the data distribution as histograms, etc.\\nIdentifying trends within the data\\nMaking different data transformations such as Normal score, etc.\\nWhat is a Transformation?\\nA transformation is the preparation of a real data set into an internal data set that meets the\\nstatistical requirements given by a chosen algorithm (see Transformations available).\\nData transformation will make the data stationary and standard normally distributed before the\\nactual modeling process. Back-transformation will be automatically performed in the exact\\nreverse order of the modeling result to preserve the spatial trends and original data distribution in\\nthe final result property.\\nWhat is a Trend?\\nA trend is a permanent or continuous change of the mean value of a property in a 1D, 2D or 3D\\nmodel (see 1D Trend, 2D Trend and 3D Trend).\\nOnce trends have been identified, transformations can be used to extract them prior to\\nPetrophysical modeling. The Petrophysical modeling algorithm is then performed on the\\nresidual and after the modeling, the results will be back-transformed in a reversed order. This\\nensures that the same identified trends observed in the original data are also present in the\\nmodeled property.\\nSee Why use trends in property modeling and Why use transformations in property modeling for\\nmore details.\\nSee How to do Data Analysis on continuous variables? for detailed information in this process.\\n2. Variograms tab\\nDescribing the spatial variation of data by generating variograms (Horizontal and Vertical).\\nSee Variogram Analysis (Data Analysis)) for detailed information in this process.\\nNote that if you run through the Petrophysical modeling process without having gone\\nthrough the Data analysis process, the data will still be transformed by using the Normal Score\\ntransformation. By going through these steps in the Data analysis process, you can define the\\nentire transformation sequence interactively.\\nBackground on performing Transformations\\nThe two main objectives of the data transformation process are:\\n1.\\n2.\\n1. To remove spatial trends so that the data will be stationary, and\\n2. To transform the data into Standard normal distribution (with a mean of 0 and standard\\ndeviation of 1).\\nA stationary distribution is a basic requirement for input data to most geostatistical algorithms.\\nStandard normal distribution is a requirement of the Gslib Sequential Gaussian Simulation\\nalgorithm used for stochastic petrophysical simulation. The data must be transformed so that it\\nfits this criteria.\\nRemoving trends by identifying an appropriate transformation is an essential part of the Property\\nmodeling process. See Why use trends in property modeling and Why use transformations in\\nproperty modeling for more details.\\nTransformations are not commutative; that is, changing the order in which two\\ntransformations are applied will have a significant effect on the result. It is important to apply all\\nthe transformations in the right order. As guidance, the available transformations are listed in the\\norder they should be entered into the transformation sequence.\\nWhat can Transformations do for me?\\nData, such as porosity and permeability, will be distributed between the wells in Petrophysical\\nmodeling. The inputs are the well data and the modeler\\'s conceptual model of the geology. The\\nwell data must be considered together with the conceptual model, analyzed and possibly\\nmanipulated, in order to generate a 3D model that fits both the data and the conceptual model.\\nThe following are some examples:\\n1. Porosity shows a roughly normal distribution and a spatial trend (for example, decreasing\\ndown depositional gradient or vertically). Using transformations, this trend can be\\nidentified, removed for the purposes of property modeling and reapplied to the result of the\\nmodeling (this can be performed automatically in Petrel). The trend and the appropriate\\ndistribution will be preserved in the resulting model.\\n2. Data for the particular zone is sparse and perhaps not statistically valid, but supplementary\\ndata gives a lot of confidence in the conceptual model. You can control the modeling by\\nspecifying a porosity distribution that is normally distributed, with a specified mean and\\nstandard deviation (If you want to use a trend, the trend has to be specified before the\\ndistribution. In other words, you can only specify the distribution for the residual) to give a\\nmore realistic model than merely extrapolating from the available data.\\n3. When displaying the histogram of the porosity within clean sand, you might observe some\\nvery low porosity values that indicate that they are outliers. By using the Truncate\\nObservations transformation, these outliers can be truncated and not be considered in the\\nfinal realization.'},\n",
       " {'header': 'General Data Transformation Workflow ',\n",
       "  'content': \"1. Consolidate Zones and Facies. Data analysis will normally be performed on each zone and\\nfacies separately (as each will have different statistics). You will save time if you remove\\nany unnecessary zones and facies (for example, the non-reservoir zones and facies) before\\nyou begin the analysis.\\n2. Choose the appropriate Transformations. Select the required transformations, enter the\\nappropriate settings and click the button for a preview of the results. When all of the\\nrequired transformations have been selected, clicking Apply or OK will relate those\\ntransformations to the property. These can then be applied during Petrophysical\\nmodeling.\\n3. Generate a Variogram. It describes the normal local variation in the data and should be\\ngenerated from transformed data (that is, data with all regional trends removed and\\nstandard normally distributed).\\nA typical transformation sequence can look like the following:\\n1. Input Truncation, the user enters the min and max values to ensure that outliers in the\\ninput data are ignored.\\n2. Output Truncation, the user enters the min and max values for output to ensure that\\nextreme values outside the defined range will be truncated in the realization.\\n3. Trend transformations (1D trends in X, Y or Z directions, true view or simbox view, 2D\\ntrend and 3D trend), The user inspects for trends and identifies these before modeling.\\n4. Remove skewness (Cox-Box, logarithmic), Cox-Box is useful for skewed distributions\\n(typically permeability). Logarithmic is useful for log-normally distributed data.\\n5. Normal Score, ensures that the transformed data has a mean of 0 and a standard\\ndeviation of 1.\\nNormal score will force any type distribution into a standard normal distribution. It should\\nalways be the last transformation to use.\\nYou would not normally use all the transformations on one property. The most commonly used\\ntransformations are trends and normal score transformations.\\nTransformations are listed in the dialog box in the order that they should be applied.\\nTransformations tab (Data analysis)\\nThe dialog box for Data Transformations consists of two main windows and a histogram. The top\\nleft window shows a list of available Transformations, while the top right window holds a list of the\\ntransformations selected for the current zone and facies of the chosen property. The bottom left\\nwindow shows the histogram and the bottom right window shows the different settings for the\\napplied Transformation (Figure 1).\\nTransformations list window\\nUse the icons to add and to remove transformations from the list. Removing a\\ntransformation from the list will result in the loss of the settings for that transformation. You can\\ntemporarily avoid that by deactivating the transformation by clicking the button during the\\ndata analysis. Once deactivated, the transformation will appear grey and will not be applied to the\\ndata, although the settings will remain. Activate all transformations at once by clicking .\\nHistogram window\\nThe histogram shows the distribution of the chosen property before or after the chosen\\ntransformations have been performed. Directly above the histogram are a series of statistics\\nwindows showing the Intervals , Size (number of data points), Mean , Std (standard\\ndeviation), Maximum , and Minimum of the transformed data.\\nUse the button to toggle between showing percentages or sample numbers above of the Y-\\naxis.\\nIn the Show option the Input , Output , and Final (after the transformations are applied)\\ndistributions can be selected from the drop-down list.\\nFigure 1.- The dialog for Data Transformation.\\nSettings in the Transformations tab (Data analysis)\\nInsert - With the Insert a transformation icon the user can select a transformation and add it\\nto the list on the right.\\nRemove - Use this button to remove a selected transformation from list.\\nActivate/Deactivate selected transformations - Deactivate a transformation from the list\\nwithout removing it.\\nActivate all transformations - Activate all transformations from the list.\\nContext Tips - Move the mouse over the button to receive further information on the\\ncurrent transformation.\\nIntervals - Defines the number of bins the data is divided into for the histogram\\ndisplay.\\nStatistics window - Shows the mean and standard deviation of the transformed data, its\\nmaximum and minimum and the number of data points in the analysis.\\nPercent button - Toggle between percent and number of samples for the histogram.\\nShow - Histogram choice between input, output and final.\\nRefresh Histogram - Apply the settings of the current transformation.\\nCopy bitmap to clipboard - Can be used to make bitmaps of the data in the process.\\nTransformations available\\nThe Transformations available through the Data analysis process include:\\nInput Truncation - Truncate the input data.\\nOutput Truncation- Truncate the output data after Petrophysical modeling.\\nLogarithmic- Logarithmic transformation.\\nCox-Box- Removes skewness from the data.\\n1D Trend - Investigate linear trends.\\n2D Trend - Investigate aerial trends using a surface.\\n3D Trend - Investigate spatial trends using a property.\\nScale Shift - Shift the mean and scale the standard deviation of the data.\\nNormal Score Transformation - Transform the data to a standard normal (option to edit the\\ndata's distribution interactively).\"},\n",
       " {'header': 'Input Truncation ',\n",
       "  'content': 'The first transformation to be applied is usually Input truncation. This transformation will\\ntruncate the input distribution to get rid of data not to be represented in the final output. If your\\ninput data contains values that are outside the actual physical boundaries of the property, the\\ndata truncation can be used to remove these (Min and Max) values. The minimum and maximum\\nvalues can be set up as Absolute values or Relative in percent (%). You can also use Estimate\\nto extract the min and max value of the transformed data.\\nSpecify Min and Max, and what you want to do with the truncated values:\\nForce outside values to the boundary will include low values at the specified minimum\\nand vice versa (if many values are truncated, this will give large clusters of values at the\\nmaximum and minimum).\\nOutside values undefined will ignore values above or below the maximum and minimum\\nrespectively.\\nIn a porosity distribution representing a clean sand facies, you might observe outliers that\\nrepresent calcites. The calcites would show too low porosity values compared to the porosities in\\nthe rest of the clean sand. To exclude the porosity values that represent the calcites, use the\\nInput truncation and eliminate the values outside the desired range. The Outside values\\nundefined option should be used.\\nHow to use Input Truncation\\n1. Define the Minimum and the Maximum values of the input distribution.\\n2. Choose whether to Force outside values to the nearest bound or to set them to\\nundefined.\\n3. Click the Refresh histogram button.'},\n",
       " {'header': 'Output Truncation ',\n",
       "  'content': 'The Output truncation is the last step of the back-transformation of the data. Therefore, it has\\nno effect on the histogram within the data Transformation tab. The Output truncation will be\\nperformed on the output realization, that is, on the 3D property that will be created in property\\nmodeling. This transformation is applied to ensure that your realization does not get values\\noutside the desired range.\\nIf you are modeling porosity in clean sand you might expect porosity values in the range of 0.2 to\\n0.35. To make sure you do not create too low or too high values, use the Output truncation.\\nThe settings are the same as for Input truncation, see How to use Input Truncation.'},\n",
       " {'header': 'Logarithmic ',\n",
       "  'content': 'This method will simply apply a Logarithmic transformation to the data and has no input\\nrequirements. It is particularly useful for permeability and other log-normally distributed\\nparameters. Enter the transformation into the transformation sequence list. Click the icon to\\nsee the changes.\\nRemember that values < 0 cannot be used as input to this transformation, so values < 0 will\\nbe forced above 0.'},\n",
       " {'header': 'Cox-Box ',\n",
       "  'content': 'The Cox - Box transformation removes the skewness from the distribution. The factor Lambda\\nexpresses the degree of skewness and can be entered manually or estimated automatically.\\nClicking the Estimate button automatically estimates Lambda beginning in the range -16 to 16\\nand iterating down to an accuracy of 0.1 aimed at maximizing the likelihood function of a normal\\ndistribution.\\nIf Cox-Box transformation is applied, you will usually have to apply the Shift Scale\\ntransformation afterwards.\\nHow to use Cox-Box transformation\\n1. Enter Cox-Box into the transformation sequence.\\n2. Click the Estimate button to specify the Lambda factor.\\n3. Click the Refresh icon to see the effects of the transformation.\\n4. Adjust the value of Lambda manually, if necessary.'},\n",
       " {'header': '1D Trend ',\n",
       "  'content': 'In this transformation you can interactively define/generate a trend function (from the input\\ndata) by specifying a vector in space. However, trends must be used with care, if the correlation\\nis not good (typically at least 0.3-0.5) then it is probably too weak to be statistically valid.\\nThe vector is defined by specifying a dip and azimuth; if the trend is valid, then the data will\\ncollect along a straight line in the crossplot window. Petrel will automatically try to draw a\\nregression curve along the trend and annotate the crossplot window with the correlation factor'},\n",
       " {'header': '(Figure 1). ',\n",
       "  'content': 'Note that if you are going to properly model the petrophysical trend in different facies, you\\nwill have to set a 1D trend curve for each facies.\\nFigure 1.- The input for 1D Trend transformations.\\nSettings for 1D Trend Transformation\\nSet up the Trend direction\\nThere are a number of ways to set the trend direction:\\nEnter a dip (positive upwards) and azimuth directly\\nUse the , and icons to set the trend direction to one of the principle directions\\nUse the azimuth diagram and dip input to interactively adjust the azimuth and dip angle\\nChoose the appropriate coordinate system\\nIn the vertical direction, distances can be measured in 3 ways:\\nDistance in real space (default)\\nDistance from the top of the current zone\\nDistance from the base of the current zone\\nData in the crossplot window can be displayed in Real space or in Simbox view (it will\\ndisplay the data as though all of the cells in the model were rectangular and of the same\\ndimensions). See Visualize a property as a regular box (simbox view)\\nFitting a curve to the trend\\nPetrel will automatically try to fit a regression curve to any defined trend displayed as a blue\\nline in the crossplot window, and display the correlation factor in the plot window. If this trend\\nis applied without any editing, the mean of the data will not change. Similarly, when the trend is\\nremoved, all of the data will be centered along the horizontal line.\\nThe curve can also be edited manually. Clicking on control points on the line (blue squares) will\\nallow the user to edit those points, while clicking elsewhere in the crossplot window will create\\nnew points on the line. Pressing delete or when a control point is selected, (dark blue) will\\nremove that particular point from the line. As a default, the spline function toggle will be on\\nand the line will pass smoothly between points. With the toggle off, the line will be straight.\\nPress to revert to a best fit regression curve.'},\n",
       " {'header': 'Display ',\n",
       "  'content': 'Displaying a large number of points in the crossplot window can result in a slow redrawing of the\\nplot (particularly when displaying large properties). There is a setting defining the maximum\\nnumber of points displayed in the window. Points to be displayed can be chosen randomly or\\nas every Nth . The plot window can also be copied to the clip board as a bitmap by pressing .\\nTools for 1D Trend\\nX - direction - Sets the direction to east west (Azimuth 90degrees, Dip 0degrees).\\nY - direction. - Sets the direction to north south (Azimuth 0degrees, Dip 0degrees).\\nZ - direction - Sets the direction to vertical (Azimuth 0degrees, Dip 90degrees).\\nToggle Simbox View - Choose to measure trends relative to the edges of the grid cell.\\nReal view - Choose to measure trends in real space.\\nDistance to base of zone as z-coordinates - Use the distance to the zone base in the\\ntrend.\\nDistance to top of zone as z-coordinates - Use the distance to the zone top in the trend.\\nDelete - Delete a selected point in the trend function.\\nFit trend function to regression curve - Sets the function back to default.\\nSpline function - Enables the user to define a trend function.\\nFilter out every Nth point\\nFilter out points randomly\\nCopy bitmap to clipboard - Can be used to make bitmaps of the data in the process'},\n",
       " {'header': '2D Trend ',\n",
       "  'content': 'This transformation allows you to investigate 2D spatial trends in your data. You must first\\nprepare a 2D surface for the analysis store it under the Input tab on the Petrel pane, then simply\\ndrop it into the dialog. If the data matches the trend, then the points should congregate along the\\nblue line shown in the cross plot window (Figure 1).\\nFigure 1.- The input for 2D Trend transformation.\\nSettings for 2D Trend transformation\\nFitting a curve to the trend\\nAs a default, Petrel will not scale the trend at all. In effect, if the trend is to be used, for example,\\nporosity, you should ensure that the surface has values representing the expected porosity values\\nin the model (e.g. 0 - 0.3).\\nBy checking the Scale option, Petrel will scale the trend. This means that any surface can be used\\nto steer the property values. As an example, if you think that you are likely to have higher\\nporosity in the thicker areas of your aquifer, you could use an isochore as input as a porosity\\ntrend. By default, Petrel scales the trend linearly, Y= aX + b. Tthe values of a and b can be\\nentered manually or edited on the crossplot. Alternatively, choosing Scale with a general\\nfunction allows the user to add points to the trend line, using either a spline curve or a linear\\nfunction.\\nEditing the curve\\nThe curve can also be edited manually. Clicking on control points on the line (blue squares) will\\nallow the user to edit those points, while clicking elsewhere in the crossplot window will create\\nnew points on the line. Pressing delete or when a control point is selected (dark blue) will\\nremove that point from the line. As a default the spline function toggle will be on and the line\\nwill pass smoothly between points. With the toggle off, the line will be straight.\\nPressing will revert back to a best fit regression curve.'},\n",
       " {'header': 'Display ',\n",
       "  'content': 'Displaying a large number of points in the crossplot window can result in a slow redrawing of the\\nplot (particularly when displaying large properties). There is a setting defining the maximum\\nnumber of points displayed in the window. Points to be displayed can be chosen randomly or\\nas every Nth . The plot window can also be copied to the clipboard as a bitmap by pressing .\\nTools for 2D trend\\nDelete - Deletes a selected point in the trend function.\\nFit trend function to regression curve - Sets the function back to default.\\nSpline function - Enables the user to define a trend function.\\nFilter out every Nth point.\\nFilter out points randomly.\\nCopy bitmap to clipboard - Can be used to make bitmaps of the data in the process.'},\n",
       " {'header': '3D Trend ',\n",
       "  'content': 'The transformation allows you to fully investigate 3D spatial trends in the grid by comparing the\\ninput data with an existing property. You must first generate a property describing the 3D\\ntrend, and then select it from the drop down list on the dialog. If the data matches the trend,\\nthen the points should congregate along the blue line shown in the cross plot window (Figure 1).\\nTypically the users will want define 3D trends as:\\nAn existing property - of a different petrophysical parameters, i.e. use the trend from an\\nexisting porosity model to control permeability distribution (Figure 1)\\nAn inversion cube - use a seismic attribute cube to control how porosity data from the\\nwells is interpolated\\nA seismic derived petrophysical trend or a conceptual trend - a seismic derived\\nporosity trend, a fake smoothed deterministic porosity model to describe your porosity\\ntrend or a trend output from Object modeling (see Generating facies bodies with vertical\\nproperty trends)\\nFor the first two cases, it is recommended to use the property or seismic cube as a\\nsecondary property in Petrophysical modeling and NOT use them as a 3D trend.\\nFigure 1.- The input for 3D Trend transformation.\\nSettings for 3D Trend transformation\\nFitting a curve to the trend\\nBy default, Petrel will not scale the trend at all, so if the trend property is to be used for porosity,\\nyou should ensure that the property has values representing the expected porosity values in the\\nmodel (e.g. 0 - 0.3).\\nBy checking the Scale option, Petrel will scale the trend. This means that any 3D property can be\\nused to steer the property values. As an example, if you believe that you are likely to have higher\\nporosity in the thicker areas of your aquifer, you could use an isochore as input as a porosity\\ntrend. By default, Petrel scales the trend linearly, Y= aX + b. The values of a and b can be\\nentered manually or edited on the cross plot. Alternatively, choosing Scale with a general\\nfunction allows the user to add points to the trend line, using either a spline curve or a linear\\nfunction.\\nEditing the curve\\nThe curve can also be edited manually. Clicking on control points on the line (blue squares) will\\nallow the user to edit those points, while clicking elsewhere in the cross plot window will create\\nnew points on the line. Pressing delete or when a control point is selected (dark blue), will\\nremove that point from the line. By default the spline function toggle will be on and the line will\\npass smoothly between points. With the toggle off the line will be straight.\\nPressing will revert back to a best-fit regression curve.'},\n",
       " {'header': 'Display ',\n",
       "  'content': 'Displaying a large number of points in the cross plot window can result in a slow redrawing of the\\nplot (particularly when displaying large properties). There is a setting defining the maximum\\nnumber of points displayed in the window. Points to be displayed can be chosen randomly or\\nas every Nth . The plot window can also be copied to the clip board as a bitmap by pressing .\\nDuring Sequential Gaussian Simulation, local variation in the modeled property is controlled\\nby the variogram sill. In order to ensure that this local variation is not exaggerated, it should not\\nbe present in the trend property i.e. the trend property should be smooth.\\nTools for 3D Trend\\nDelete - Deletes a selected point in the trend function.\\nFit trend function to regression curve - Sets the function back to default.\\nSpline function - Enables the user to define a trend function.\\nFilter out every Nth point .\\nFilter out points randomly .\\nCopy bitmap to clipboard - Can be used to make bitmaps of the data in the process.'},\n",
       " {'header': 'Shift Scale ',\n",
       "  'content': \"The Shift scale transformation is used to shift and scale the data so that the mean is 0 and the\\nstandard deviation is 1 and should usually be applied after any spatial transformations (Cox-Box,\\nLogarithmic and Trend transformations). Unlike Normal Score, it will not change the shape of the\\ndistribution so the histogram should look like something close to a log normal distribution before\\napplying the transformation.\\nThe transformation will simply shift the data by its mean and scale it by it's standard deviation.\\nPress to have Petrel fetch these values automatically and edit them as desired. View\\nthe result by pressing the refresh icon .\\nHow to use Shift Scale Transformation\\n1. Inspect the histogram after all other transformations have been applied (remember to\\npress the Refresh Histogram button to see the effect of the transformations). If the mean\\nis different from 0, then use the Shift scale transformation\\n2. Include Shift scale in the transformations list\\n3. Press to get the mean and the standard deviations\\n4. Press the refresh icon and inspect the changes\"},\n",
       " {'header': 'Normal Score ',\n",
       "  'content': 'Normal score transformation will force any distribution to a standard normal distribution.\\nNormal distribution of data means that most of the samples in a set of data are close to the Mean\\nvalue, while relatively few samples tend to one extreme or the other. Normally distributed data\\nwill have something like a \"bell curve\" shape.\\nThis transformation should always be the last transformation performed on your data. In other\\nwords, after truncations of input data and removal of spatial trends (Figure1).\\nNormal score transformations should be used with caution, particularly if you have limited input\\ndata, as they will force the distribution of your property to exactly match the distribution of your\\ninput, i.e. both the position and the relative height of the histogram bars. If the input data is\\nlimited, then the histogram can be unrepresentative and will be matched exactly by the\\ndistribution of the property modeling result.\\nThis can be avoided by using a Shift scale, Cox-Box or Logarithmic transformations, or by defining\\nthe histogram curve manually.\\nFigure 1.- Normal score transformation settings window.\\nSettings for Normal score transformation\\nThere are two main options for Normal Score transformation:\\nUse values - This will base the transformation purely on your own data. Use it when you\\nhave a large number of data points with a reasonable spread (i.e. a smooth histogram)\\nDefine curve - This option will allow you to edit the curve for the transformation, i.e. allow\\nyou to make a model by using a different distribution from that in your input data. Use it\\nwhen the input data is sparse and the histogram is uneven.\\nIf many of the data points have the same value, spikes will occur in the histogram. Checking the\\nDespike option will ensure that you get a normal distribution even with many equal values.\\nThe Min and Max settings control how far the normal distribution should extend beyond the input\\ndata. Use the estimate button to get Petrel to estimate a reasonable value.\\nFor more information on what a normal score transformation does see Standard\\ndistributions and Normal Score transformations and What is Normal Score Transform (NST) or'},\n",
       " {'header': 'Gaussian Anamorphosis?. ',\n",
       "  'content': \"Settings for Normal score 'Define Curve'\\nWhen Define Curve is chosen, a new histogram window will appear showing the input data as a\\nhollow histogram and the transformation curve as a blue line (Figure 2).\\nThere are three options for defining the curve automatically:\\nWill exactly fit the curve to the input data at each of the histogram intervals\\nWill generate a flat line through the mean of the input data\\nWill fit the distribution curve to a normal distribution\\nWill generate a normal distribution with the mean and standard deviation specified in the\\ninput boxes, use Estimate to fetch the values from the input data\\nFigure 2.- Normal score transformation / Define curve settings.\\nOnce the curve is set, selecting the smooth curve icon will progressively smooth the points,\\nreduce peaks and fill troughs, etc.\\nThe curve can also be edited manually. Clicking on control points on the line (blue squares) will\\nallow the user to edit those points, while clicking elsewhere in the cross plot window will create\\nnew points on the line. Pressing delete or when a control point is selected (dark blue) will\\nremove that point from the line. The spline function toggle will switch between joining the\\npoints up with a straight line and joining them up with a smoothed curve.\\nSettings for the Plot window\\nThe intervals option will alter the number of intervals shown for the histogram, and consequently\\nthe number of control points generated when using the automatic curve setting options.\\nThe plot window can be panned by simply dragging with the mouse, and zoomed to show all the\\ndata by pressing .\\nUse to copy the Plot window to the clipboard.\"},\n",
       " {'header': 'Quality Control ',\n",
       "  'content': \"It is important to compare Petrophysical modeling results with the input data in the Data\\nanalysis process. There are some options:\\nCompare the 3D property distribution with the input distributions. Do they match?\\nIs the output distribution too wide? Try using a smaller standard deviation\\nIs the output distribution's mean too high/low? Try changing the shift factor in the Shift\\nscale transformation\\nDisplay the 3D property values in a crossplot with depth, and compare the trend before\\nmodeling and after modeling. Is the match acceptable? If you entered your own trend, does\\nthe output match the expected result?\\nIf Trend transformation has been applied or the input histogram has been manually edited,\\nthe output histogram will not match the input histogram since extra information has been added\\ninto the input histogram.\\nVariograms tab (Data analysis)\\nVariogram analysis in the Data analysis process is done under the Variograms tab (for discrete\\nand continuous properties). For more information about variograms and a description of the\\nterms used, see Background Information on Variograms and Exploratory Data Analysis .\\nThe property, zone and facies to be analyzed, as well as the data type (well logs, upscaled cells or\\nproperty) can be chosen in the same way for continuous and discrete properties. See General\"},\n",
       " {'header': 'Settings For Data Analysis . ',\n",
       "  'content': 'The Variograms tab is divided into two main sections:\\nResult from variogram analysis (the upper section): contains all the parameters\\ndescribing the variogram\\nMajor direction , Minor direction and Vertical direction tabs (the lower section): show\\nthe search settings for the variogram analysis, a location map of the sample points and a\\nplot of the variogram\\nAnother tab for discrete properties is available at the top of the tab:\\nFor facies to select the different facies codes\\nSame variogram for all the facies\\nResults from variogram analysis (Data\\nanalysis\\\\Variograms)\\nThe experimental variogram can be visualized in real or simbox mode . Toggle simbox on and\\noff by using Toggle simbox mode . By default, Simbox view will be on.\\nThe use of upscaled logs and simbox mode is recommended for horizontal analysis (Major and\\nMinor direction variograms), as it will ensure that only samples from equivalent geological layers\\nare compared. For detailed information of the simbox effect see Visualize a property as a regular\\nbox (simbox view) .\\nFor the vertical direction, what mode you use depends on what you plan to use the analyzed\\nresults for. If you are using the data analysis to decide the vertical resolution of your model, you\\nmay want to use the raw log data with the simbox mode turned off. If you analyze for modeling,\\nit is recommended to use the upscaled logs with the simbox mode on. Petrel will always use the\\nupscaled value together with simbox view when executing the modeling algorithms.\\nNote: There should not be too much of a discrepancy between the raw and upscaled data\\nvariogram ranges.\\nThe Orientation of the major axis (Major dir ) can be input manually or set interactively\\nthrough the location map using the Search cone on the major and minor direction tabs (see\\nLocation Map (Variogram Analysis) ). The Orientation of the minor axis (Minor dir ) is 90\\ndegrees to the major axis. The Dip of the major axis is input manually (see Variogram sampling\\norientations ).\\nThe Variogram type should be chosen here. The options are:'},\n",
       " {'header': 'Exponential Spherical Gaussian ',\n",
       "  'content': 'A diagram showing the shape of these variograms can be found on the tool tip to the right of the\\nlist box and they are described in more detail under Variogram models .\\nNote that when running the Gslib algorithm, the Gaussian variogram can be mathematically\\nunstable.\\nNugget and Ranges (major, minor and vertical) in each direction can be input manually or set\\ninteractively through the variogram window on each of the direction tabs (see Principle of\\nVariograms and How different parameters affect the Variograms and hence the results ) for a\\ndefinition od those parameters.\\nReset settings to default using the Reset variograms icon and Copy the variogram\\nparameters to the clipboard using .\\nThe Recalculate variograms automatically for each interaction in the dialog icon will\\npreserve the old behavior and is on by default. Every time a parameter that interferes in the\\nvariogram computation is changed, the sample variograms are updated. The Recompute\\nsample variograms icon is activated once the icon is turned off, meaning that the user\\ncan change any parameter in the interface and the sample variograms will only be updated after\\nthis icon is clicked.\\nDirection subtabs (Data analysis\\\\Variograms)\\nEach subtab is divided into three sections. The upper section defines the search settings for the\\nsampling , the lower left section has a window displaying a map of the data sampling points\\n(Search cone) and the lower right window shows the sample variogram and the variogram\\nmodel .\\nEach of the search settings can be input manually. The Lag Distance is automatically determined\\nfrom the Search radius and the Number of lags .\\nThe Band Width , Search Radius and Tolerance Angle can be edited interactively through the\\nlocation map (Search cone ). This is explained in Location Map (Variogram Analysis) . An\\nadditional setting, Thickness , is included allowing the user to vertically restrict the data\\nconsidered in the variogram.\\nSee Horizontal sample variograms for an explanation of the standard terms.\\nThe search distance must be greater than the expected range in the variogram model.\\nLocation Map (Data analysis\\\\Variograms\\\\Direction)\\nThe location map shows sample locations and the search frame for the current variogram\\ndirection. Zooming and panning are possible by clicking on the map in much the same way as for\\na standard map window in Petrel (left-click to pan and Ctrl + Shift + left-click to zoom). The\\nsearch frame will remain static allowing the search criteria to be compared with the sample points\\naround the project area.\\nPress to fit all the sample data into the window.\\nPress to copy the map to the clipboard.\\nThe search settings can be altered by clicking on one of the three blue control points on the\\nSearch cone (see Horizontal sample variograms ).The point furthest from the sample point\\n(the pointed end) controls the Search Radius , the center point allows editing of the\\norientation of the variogram (Major and Minor directions) and the innermost point allows\\nediting of the Bandwidth and Tolerance Angle .\\nIn the vertical direction , a well log is displayed with the search frame instead of the location\\nmap, for obvious reasons (see Vertical sample variogram ). The well on display can be selected\\nfrom the drop down list and zoomed and panned much the same as the location map. The only\\ndifference is that because the vertical variogram is always vertical, there is no control point to\\nchange the orientation of the variogram.\\nVariogram Plot (Data analysis\\\\Variograms\\\\Direction)\\nThe variogram plot has four elements:\\nHistogram - this shows the number of sample pairs in each Lag\\nSample Variogram - these are the grey points showing the semi-variance in each Lag\\nRegression curve - a best fit variogram model for the Sample Variogram (grey curve)\\nVariogram model - the current variogram model (blue curve)\\nThe Range and Nugget for the variogram model can be edited interactively by grabbing and\\nmoving the blue control points .\\nThe Sill for the variogram is fixed at 1 . If the sill appears to be different from 1, then\\nadditional transformations may be required before continuing with the variogram analysis.\\nSee What is a Variogram? What is Variography? for an explanation of the standard terms.\\nOther tools include:\\nShow No pairs histogram - will toggle the histogram on and off.\\nFit variogram to regression curve - will fit the Variogram model to the best fit.\\nCopy bitmap to clipboard - will copy the variogram to the clipboard.\\nView all - will scale all the data to fit into the window.\\nHow to create a variogram based on discrete data\\n1. Select the facies that you want to use to create a variogram\\n2. Edit the variogram settings interactively or manually (the settings are the same as for\\nthe continuous property variogram)\\n3. For a facies, each variogram pair has a weight of either 0 or 1 , depending on whether\\nthe head facies equals the selected facies or not\\nGeneral tools for data analysis\\nThere are two aspects of data analysis in Petrel. The Data analysis process provides a tool for\\nin-depth analysis of input data, transformation, and generation of variograms; see Data Analysis\\nProcess for more information. This section describes the general tools for Data analysis present\\nin Petrel and are mostly accessed through the Settings tab of a data object.\\nGeneral data analysis is divided into two parts:\\nDescriptive statistics: Options to describe/summarize data by plotting histograms and\\ncross plots\\nVariogram analysis: Options to create sample variograms and fit a model to be used as\\ninput to Kriging or Simulation\\nThe different types of data that can be used are:\\nWell logs\\nUpscaled well logs\\n3D property models\\n2D regular grids (surfaces)\\nPoint data sets\\nData analysis is often quite experimental and, thus, requires a high degree of user interaction for\\nexploring the data. In general, the output will be graphical in the form of plots that the user can\\nmanipulate. The result can be plotted or used in other processes. In particular, the variogram\\nconstruction can be used as input for Property modeling/simulation.\\nPlot windows for displaying statistical data\\nThe graphical output of the descriptive statistics and the variogram analysis can be displayed in\\ndifferent types of plot windows. Three types of plot windows are used:\\nHistogram window - For display of frequency distributions and cumulative distribution\\nfunctions (see Histogram viewport)\\nFunction window - For display of crossplots with linear regression functions, function\\ncurves, sample variograms and variogram models (see Function Viewport)\\nMap window - For display of variogram maps (see Map Viewport)\\nDescriptive statistics\\nData in Petrel can be presented graphically for statistical checks of imported or modeled data.\\nUnivariate, bivariate and multivariate statistical analysis (1, 2 or 3 variables) can be generated.\\nThe statistics can be represented graphically as:\\nHistograms with cumulative distribution functions (cdf)\\nCrossplots with two or three variables\\nThe data can be manipulated by using filters (property filter and segment/zone filters), applying\\ncut-offs to remove data, and using different scaling of the axis (i.e. log-scale). For crossplots, it is\\nalso possible to make a linear regression function and to edit functions manually.'},\n",
       " {'header': 'Functions ',\n",
       "  'content': 'Linear regression functions can be generated from a crossplot, digitized interactively, or imported\\ninto Petrel using the Function XY (ASCII) format. Once imported, they can be displayed and\\nedited in a Function viewport, and also used in the various calculators in Petrel to manipulate\\nvarious types of data.\\nSurfaces can also be used as 2D functions, see Using Functions and Surfaces in the Functions\\nCalculator for more information.\\nFunctions are placed in a Function tab in the Petrel pane and this folder will be automatically\\ngenerated when importing or generating the first function.\\nFor information about importing functions see Import Functions (Lookup curves).\\nFor the function window see Function viewport.\\nDisplay a function\\n1. Create a new function window by clicking on the New window button in the Tool bar,\\nand selecting New function window from the menu.\\n2. Toggle the function in the Petrel Explorer to be displayed.\\nEdit a function\\nManipulation of the function in the Function dialog box can be done in two ways:\\nEdit function points\\n1. Click on the icon Select and edit/add points in the Function bar.\\n2. To manipulate the points, drag the point to a new position.\\n3. To insert a new point in between points, click on the line. The new point can then be\\ndragged to a new position.\\n4. By default, Petrel uses a spline function to get a smooth line. To get straight lines between\\npoints, open the Settings dialog for the function and deselect the Use spline option in the\\nFunction tab.\\nEdit function line\\n1. Click on the Select and edit line in the Function bar.\\n2. To manipulate the line, drag the line to a new position.\\nNote that this mode only allows the points and lines to be manipulated parallel to the Y-axis.\\nGenerating a linear function\\nWhen generating a linear regression function, a dialog containing settings and statistics will\\nappear. Here, you can give the function a name, specify whether to overwrite the previously\\ngenerated function, and set the max and min of X-values for the function.\\nThe method used for generation of the linear regression function is the \"least squared method\".\\nThe dialog will also show statistics for the variables in the crossplot, such as:\\nMax and Min values for the variables in the crossplot\\nStandard deviation for the variables in the cross plot\\nCorrelation coefficient to summarize the relationship between the variables\\nCovariance to summarize the relationship between the variables\\nThe equation for the Linear function\\nHow to make a linear regression function\\n1. Click on the Make linear function from crossplot button in the Function bar\\n2. Look at statistics and select the settings in the Generate function and correlation\\nstatistics dialog. See Generating a linear function\\n3. Click OK to generate the function.\\n4. The function will be stored in an automatically generated (if not already existing) Function\\nfolder in the Input pane.\\nDistribution functions\\nNew distributions functions can be generated and edited from within the Histogram window.\\nThey are stored as functions and can then be used directly as an input histogram during\\nPetrophysical modeling. Options include:\\nFit line to active histogram - will interpolate a line through the displayed histogram\\nFit normal distribution to active histogram - will create a normal distribution with the\\nsame mean and standard deviation as the displayed histogram\\nFit distribution to the active histogram - will create a distribution which exactly fits the\\ndisplayed histogram\\nConstant - will create a constant distribution at a user defined value\\nNormal distribution - will create a normal distribution with user defined parameters\\nAfter clicking Run, the histogram will appear in a function folder in the Input pane and will\\nautomatically be displayed in the Histogram window.'},\n",
       " {'header': 'Editing Distribution Functions ',\n",
       "  'content': \"The Distribution functions can be edited within the Function tab of their Settings dialog or\\ndirectly in the Histogram window. The tools available in the Histogram window include:\\nSelect and Edit/add points - select and edit points individually\\nSelect and edit line - select and edit the distribution curve\\nNew Distribution Function - create a new distribution function\\nDelete - delete the selected points\\nSmooth - smooth the selected points\\nSpline - transform the function to a spline curve\\nIn percentage mode the curve will be readjusted after each edit such that the area under the\\ncurve never exceeds 100%.\\nChanging the curve to spline will also affect its distribution as the curve will be resampled prior to\\nproperty modeling.\\nPoints can also be edited in the Function tab on the distribution function's settings.\\nCrossplot objects\\nThe crossplot in Property modeling is used to describe a bivariate distribution. It can be\\nimported as two columns of data or created from any data plotted in a Function window.\\nTo generate a crossplot object from data plotted in the Crossplot window, click the Create raw\\ncrossplot button. The crossplot will appear on the Input pane and by default it will have 10\\nbins with an equal bin interval. These bins can be edited interactively using the Select line\\nbutton and moving the bins interactively in the Function viewport, or by regenerating them\\nthrough the Operations tab of the crossplot's Settings dialog.\\nOperations tab (Crossplot)\\nThe Operations tab allows you to set up and edit the crossplot bins. There are three methods for\\nregenerating the bins:\\nSpecify increment - Input a constant increment for the bin division\\nEqual increment - Create equal increments based on a specified number of intervals\\nEqual number of points - Create the defined number of intervals ensuring that each\\ncontains an equal number of points\\nBy default, minimum and maximums are taken as the limits of the data, however, these can also\\nbe specified.\\nClicking the Create intervals button will regenerate the bins (removing the existing bins).\\nIt is possible to resample a set of selected points. After the points have been selected, you have\\nto specify a mean value and a standard deviation value. The y-coordinate of the selected points\\nwill be normally distributed, but the x-coordinates will be unchanged as a result of the resampling\\nprocess. There is also an option to add points to a selected bin. First, you have to select the bin\\ninterval by clicking on the grey color area at the upper part of the bin. Then, you have to specify\\nthe mean value, standard deviation value, and the number of points to be added. These\\noperations are performed when you click on the Execute button.\\nSelecting points in the Crossplot\\nPoints in the crossplot can be selected individually, by drawing a box or by selecting individual\\nbins. Use the point select tool for all of these operations. Clicking on a point will select a single\\npoint. Clicking and dragging will draw a box with all of the points within the box selected, and\\nclicking in the white and grey boxes at the top of the viewport will select all of the points in the\\nbin (only displayed with the crossplot object plotted). Multiple selections of points can be made in\\nthe usual way by pressing SHIFT (all the bins between two selected points) and CTRL (additive\\nselection by any means).\\nOnce selected, the selected points can be deleted or displayed in the crossplot's histogram. See\\nUsing the Crossplot's histogram .\\nUsing the Crossplot's histogram\\nBy default, the crossplot histogram will show the distribution of all the points in the crossplot at\\nonce; however, using the button will restrict the display to only the selected points. See\\nSelecting points in the Crossplot for information about selecting points interactively. The\\nhistogram will change interactively as the selection of points changes or if a bin is selected as the\\nbin boundary is edited.\\nWhen comparing histograms for different crossplot bins it can be useful to fix the maximum,\\nminimum, and increment on the histogram so that the various plots are directly comparable.\\nVariogram tab (Object settings)\\nThe Variogram tab in the object settings of a property, surface or point data sets allows the\\ngeneration of variogram maps and sample variograms directly from the data. The variogram\\nmodel can then be used as input for deterministic Property modeling (Kriging), stochastic\\nProperty modeling using Gslib and in the Make/edit surface process (Kriging or using Gslib).\\nA more extensive variogram analysis tool is available through the Data analysis process; see\\nVariogram Analysis (Data Analysis). For more information on variograms and the terms used see\\nBackground Information on Variograms and Exploratory Data Analysis.\\nThe variogram analysis can be based upon:\\nWell log used in upscaling\\nUpscaled well log\"},\n",
       " {'header': 'Properties Surfaces ',\n",
       "  'content': 'Point data sets\\nTransform (Object Settings\\\\Variogram tab)\\nDue to the mathematical methods used in the variogram analysis, the variables sometimes have\\nto be manipulated to be able to generate good variogram maps or sample variograms. For\\nexample, when operating with differences between points close to zero and using the classic\\nmethod (squared difference), you can end up with extremely small values that will be treated as\\nzeros. The mix of both positive and negative values can also create problems due to the\\nmathematical method used.\\nTo avoid these problems some manipulations of the data (before and after calculation) can be\\ndone in the dialog for generation of variograms under the tab called transform, and these are:\\nStandardize: divides the result from the calculations with the variance. This operation\\ngives a more uniform result with values close to 1\\nScale: multiplies the data values with a constant value before the calculation\\nTranslate: adds a constant value to the data values before the calculation\\nWorkflow for Variogram Generation\\nThe generation of variogram models is an iterative process that can be quite time consuming.\\nA typical workflow can be described as follows:\\n1. Find the axis of anisotropy by use of variogram maps\\n2. Create sample variograms for the maximum and minimum directions\\n3. Create a vertical sample variogram\\n4. Match a variogram model to the sample variograms\\n5. Use the variogram model as input in the Property modeling\\nVariogram Map (Object Settings\\\\Variogram tab)\\nVariogram maps are useful in determining anisotropy, and if data is scarce, determining in which\\ndirection there is enough data to make a stable sample variogram. Variogram map is a contour\\nmap (2D plot) of the sample variogram surface. It is automatically given the template Variance.\\nThe generation of a useful \"nice looking\" variogram map is an iterative process where the settings\\n(lag range, number of lags and search distance in X- and Y-direction) have to be changed and the\\nresult displayed in a map window. See How to decide on the direction of variogram? for more\\ndetails.\\nHow to create a Variogram Map\\n1. Open the settings dialog for the data object, by double clicking on the name or clicking\\nwith the right mouse button on the name and selecting Settings from the pull-down menu.\\n2. Select the Variogram tab.\\n3. Select Variogram map under Generate.\\n4. Select variogram type (see Variogram Types).\\n5. If doing the analysis for properties select what to calculate the sample variogram for under\\nCalculate for.\\n6. Make the settings for transformation, horizontal search distance, vertical search\\ndistance, number of lags and Output (see Principle of Variograms)'},\n",
       " {'header': '7. Press Run. ',\n",
       "  'content': '8. The variogram map will be stored in a folder called Variograms in the Input/Model tab.\\nThe search distance must be greater than the expected range in the variogram model.\\nHow to display a Variogram Map\\n1. Open a Map window, by clicking on New window and selecting New Map Window\\nfrom the list\\n2. Toggle the variogram map in the Petrel Pane'},\n",
       " {'header': '3. Press View All ',\n",
       "  'content': '4. Fill the color table for the variogram map by highlighting the Variogram map in the Petrel\\nPane and clicking on the Adjust Color Table on Selected\\n5. Set the contour increment in the Style tab in the Settings dialog for the Variogram map\\nSample Variograms and Variogram Models\\nA sample variogram is a plot of separation distance against semi-variance for the data. The\\nvariogram model is an idealized version of this, mathematically described by the variogram\\nsettings. For more information on variograms, see Background Information on Variograms. It is\\ntherefore necessary to create a sample variogram in each of the required directions before\\ncreating a variogram model.\\nTo describe anisotropy, a variogram model can describe the data in three directions perpendicular\\nto each other, three sample variograms, one for each of the directions (maximum, minimum and\\nvertical), must be created. The range in each direction will vary but all other settings must remain\\nconstant.\\nThe variogram model can then be used as input in the Property modeling and Make/edit surfaces\\nprocesses, both for the deterministic modeling when using the Kriging method and for the\\nStochastic Simulation. When using the variogram in 2D, the vertical range is naturally not\\nrequired.\\nHow to create a Sample Variogram from the object settings tab\\n1. Open the Settings dialog for the data object\\n2. Select the Variogram tab\\n3. Select Sample variogram under Generate\\n4. Select Horizontally or Vertically\\n5. Select variogram type (see Variogram Types).\\n6. Make the settings for transformation, direction, horizontal search distance, vertical\\nsearch distance, number of lags and Output (see Principle of Variograms and Settings'},\n",
       " {'header': 'For Variogram Generation) 7. Press Run ',\n",
       "  'content': '8. The sample variogram will be stored in a folder called Variograms in the Input/Model\\ntab of the Petrel Pane\\nFor more information on sample variograms see Background Information on Variograms. A more\\nrigorous tool for generating variograms is available through the Data analysis process, see'},\n",
       " {'header': 'Variogram Analysis (Data Analysis). ',\n",
       "  'content': 'The search distance must be greater than the expected range in the variogram model.\\nHow to display a Sample Variogram\\n1. Open a Function window, by clicking on New window and selecting New Function\\nWindow from the list\\n2. Select the sample variogram in the Petrel Pane'},\n",
       " {'header': '3. Press View All ',\n",
       "  'content': 'How to generate a Variogram Model\\n1. Click on the Make Variogram for Sample Variogram or Create New Variogram\\nwhen having a Function window activated\\n2. Make the settings for function, sill, nugget and range in the Parameter dialog\\n3. Press OK\\n4. The variogram model will be stored in a folder called Variograms in the Input/Model tab\\nof the Petrel Pane\\nFor more information on sample variograms see Background Information on Variograms. A more\\nrigorous tool for generating variograms is available through the Data analysis process, see'},\n",
       " {'header': 'Variogram Analysis (Data Analysis). ',\n",
       "  'content': 'How to edit/fit a Variogram Model\\nThe manipulation of the variogram model to match the sample variogram can be performed in\\ntwo ways, either manually or by entering values for the parameters.\\nManual editing\\n1. Click on the icon Select and Edit/Add Points in the function bar\\n2. Select a point at the variogram model and drag it to a new position\\nA function and two points describe the variogram model. The first point describes the\\nnugget, and the second describes the sill and effective range. The function used can be\\nchanged in the Settings dialog for the variogram model.\\nParameter settings\\n1. Open the Settings dialog for the variogram model\\n2. Select the Settings tab\\n3. Make the settings for function, sill, nugget and range\\n4. Press Apply/OK\\nFor more information on sample variograms see Background Information on Variograms. A more\\nrigorous tool for generating variograms is available through the Data analysis process, see'},\n",
       " {'header': 'Variogram Analysis (Data Analysis). ',\n",
       "  'content': 'Settings for Variogram Generation\\nDifferent setting dialogs used in the variogram analysis can be reached from different places\\ndepending on the stage in the workflow.\\nGeneration of variogram map/sample variogram\\nThe dialog used for generation of variogram maps and sample variograms is placed as a tab\\ncalled Variogram in the Settings for the specific data object.\\nThe settings in the dialog are:\\nVariogram type - Selection of different mathematical methods to use for the calculations\\n(see Variogram Types)\\nGenerate - Selection between the generation of a variogram map or sample variogram.\\nFor generation of a sample variogram, there is an option for specifying to calculate\\nhorizontally or vertically. Different settings will be available in the tabs below depending on\\nthe selection\\nCalculate for - If calculating a variogram for properties, calculations can be made for the\\nwell log used in the upscaling, upscaled well log or the entire property model. There is also\\nan option to turn on/off the use of the property filter\\nHints - Tab with some information and hints for the variogram analysis\\nTransform - Tab for manipulation of the data values before or after calculation. For\\ninformation about transformations available under the object settings tab see\\nTransformation (Object Settings). More extensive options for data transformations are\\navailable through the Data analysis process see Transformations available\\nOrientation - Tab for specification of the orientation and tolerances for the data sampling.\\nBy selecting Isotropic the major and minor directions will use the same range. For\\ninformation about the terminology see Horizontal sample variograms\\nXY range - Tab for specification of number of lags and maximum search distance in the\\nXY-plane\\nZ range - Tab for specification of the maximum vertical search distance (only available for\\nproperty models)\\nOutput - Tab for specification of the output for a variogram map. The map can be\\nrepresented as a surface or as points\\nOverwrite last - This option will allow overwriting of the last generated variogram map or\\nsample variogram\\nRun - Will execute the calculation\\nGeneration of Variogram Model\\nVariogram models can be created in two ways when having a Function window activated.\\nIf a sample variogram is displayed, on the shortcut icon Make Variogram for Sample\\nVariogram will bring up a dialog with the settings for the variogram model. A variogram\\nmodel can also be created without a sample variogram by clicking on the shortcut icon Create\\nNew Variogram . The same dialog will pop up but Petrel does not have defaults for any\\nsettings.\\nInformation - Possibility to change the default name of the created variogram model\\nOverwrite last - This option will allow overwriting of the last generated variogram model\\nParameters for the Variogram - Specifications for variogram model type and its\\nparameters, Sill, Nugget and Range\\nGenerate the variogram - If clicking OK, the variogram model will be generated and\\nstored in the Variogram folder in the Input/Models tab of the Petrel Pane\\nSettings for Variogram Model\\nThe settings for a variogram model can be reached in the Settings dialog for the specific\\nvariogram model.\\nStyle tab\\nColors and symbols for the display can be set in the Style tab, and if an anisotropic model has\\nbeen created, the specification for which direction to show can be set here as well.\\nSettings tab\\nThe parameters and anisotropy of the variogram model are displayed here. The values can be\\nmanipulated by entering new values in the respective box. The values will be interactively\\nupdated if doing manual editing of the model in the Function window.\\nTrend modeling\\nThe Trend modeling algorithm allows you to produce a vertical proportion volume by doing a\\nblock kriging of the probabilities interpolation of each facies.\\nTrend modeling is an estimation modeling technique where the result is dependant upon:\\nUpscaled well log data\\nDefined variogram\\nTrends in 2D or 3D\\nVariogram and 3D Probability trend allow these settings to be taken from the Data\\nanalysis process.\\nThe result from Trend modeling process is stored in the Models pane -> 3D Grid ->\\nProperties folder in a subfolder called Probabilities (input property name).\\nFigure 1. Trend modeling example\\nMake model tab settings (Trend modeling)\\nThe general settings for Trend modeling are almost identical to the corresponding settings for\\nFacies modeling , which includes two main tabs: Make model and Hints . For detailed\\ninformation about the general settings in those tabs see Facies modeling General Settings .\\nOn the Make model tab it is possible to give a name for the new trend model by typing it in the\\nOutput name textbox.\\nOnce the Trend model process is unlocked , four sub-tabs are available (see Figure 2):\\n1. Facies tab\\n2. Block averaging tab\\n3. Expert tab\\n4. Hints tab\\n3.\\n4.\\nFigure 2. General settings in the Trend modeling process dialog\\nFacies tab (Trend modeling)\\nThe Facies tab lists the facies to be included in the model (Figure 3). By default, this will include\\nall the facies present in the upscaled cells at their fractions relative to the total number of\\nupscaled cells (that is, if half the upscaled cells are sand, the sand fraction will be 50%).\\nChoose the facies codes to be included in the trend model from the facies codes in the template.\\nThe order of the facies is not important for the trend result. The list on the left includes all the\\nfacies codes in the template used and the list on the right includes the facies in the trend model\\nprocess. Add facies to the list on the right using the button and they can be removed from the\\nmodel sequence using the button, they will then reappear in the list on the left hand side.\\nIn the facies template, rows/facies can be added and removed using the Append item in the\\ntable and Delete the last item in the table icons from the Settings window \\\\ Colors tab\\nfor that specific template. The new rows that are added will refer to the discrete logs defined in\\nthe template for the used property.\\nOther tools available are:\\nCopy selected facies settings - Will copy all settings defined for this specific facies.\\nPaste facies - Only available after selecting the copy option. Will apply the settings of the\\ncopied facies to another facies. Click on the tab of another facies and then click on this option.\\nReset settings of the selected facies to defaults - Will reset all the different settings of a\\nfacies to default values.\\nThe Facies tab has two sub-tabs, Variogram and Kriging mean . Variograms, fractions, and\\ntrends can be set for each facies individually.\\nThere is a check box where you can select to use the Same variogram for all facies . This will\\nmake the algorithm run faster. This option is off by default for properties which have not been\\nmodeled before. If the check box is selected and you change the variogram, the variogram will\\nchange for all of the facies (that is, it will not change when you change the facies selection).\\nFigure 3. Trend modeling process dialog\\nVariogram sub-tab for Facies\\nYou can define the variogram settings (see Figure 3), such as variogram model type (exponential\\nor spherical), nugget, and ranges.\\nDetails of the variogram and its settings can be found in Principle of Variograms .\\nTo use the variogram settings defined in the Data analysis process, click the Use the\\nvariograms made in the data analysis icon . When using the variogram settings from Data\\nanalysis , the options on this tab will be grayed out, any edits must be done through the Data\\nanalysis process.\\nThe directional trends within the reservoir (anisotropy) are defined by the following settings\\n(distance in true units):\\nMajor range - The maximum correlation length in the horizontal direction.\\nMinor range - The correlation length perpendicular to the major range.\\nVertical range - Vertical correlation length. Controls the amount of \"smearing\". The larger\\nthe distance, the more vertical smearing. The vertical influence range will never cross into\\nanother zone.\\nAzimuth - The rotation angle of the major range. The orientation is clock-wise from north.\\nDip - The dip (away from the vertical) of the vertical range. Remember, if the vertical\\nrange is much lower than the horizontal range, any deviation from zero will have a very\\nmarked effect.\\nObserve the change in the figure when changing the Orientation and the Ratio .\\nIf the major and the minor ranges are equal (isotropic), changing the azimuth will have no effect.\\nClicking will reset all of the settings on the tab to default.\\nKriging mean sub-tab for Facies\\nThe Trend modeling process is based on the Kriging algorithm, hence, the mean value must be\\ndefined. It can be either Global or Local mean .\\nReset to default settings - Will set the facies code percentages to undefined.\\nGlobal kriging mean - The global kriging mean can be selected here and is defined using\\nthe percentages for each facies either from the Upscaled cells , Well data or Manual by\\ntyping in a global mean value. The default value is the percent of those facies in the\\nupscaled well logs.\\nThe Global kriging mean can be also taken from Surface/property trend ,\\nspecified as a 2D/3D trend that defines the global mean and will be applied to the cells to be\\nmodeled. This option means that the mean of the 2D surface or 3D property used\\nimplicity gives the global mean . The surface or property can be included into the process\\nby checking on the Local kriging mean option and to drop the surface/property into the\\nbox using the blue button (see Figure 4 below). This option can not be used while clicking\\nthe button Use the Attribute probability curves made in the data analysis .\\nLocal kriging mean given by a surface/property - The kriging mean of the selected\\nfacies code can be made to vary locally using either a 2D surface or 3D property . Values in\\nthe data should range between 0 to 1. This option can be used in the followed cases:\\n1. When using an Ordinary kriging algorithm (to be selected in the Expert tab). The\\nmean is defined by the surface/property and it is not meaningful to enter a global\\nmean.\\n2. In conjunction with a Global kriging mean while using the Simple kriging\\nalgorithm (selected as default in the Expert tab).\\n2.\\nThe Local kriging mean option will be unavailable and unchangeable if you have clicked the\\nbutton to Use the Attribute probability curves made in the data analysis .\\nFigure 4. Kriging mean tab for Trend modeling process\\nNote: Read the Tips button for more information.\\nTrust global or local kriging m ean - By default, the total fraction will be scaled to 100%\\nand the maximum mean will also be scaled to 100%. Checking this option will disable that,\\nalthough the scaling must be done if these values go over 100%. The same thing is applied\\nfor the trends. Trends are normally in range between 0 (0%) to 1 (100%).\\nNote: read the Tips button for more information.\\nBlock averaging tab (Trend modeling)\\nBy selecting the Use block averaging option, the resulting probabilities will be averaged in a\\nblock, using the defined Block \\'radius\\' in the I,J & K directions.\\nThen the block size = (2*size_i+1, 2*size_j+1, 2*size_k+1).\\nReset to default settings - Will deselect the Use block averaging check box and the block\\nradius will be set to the default values (3,3,2).\\nFigure 5. Block averaging tab for Trend modeling process\\nExpert tab (Trend modeling)\\nOn the Expert tab , you can set the parameter settings controlling the GSLIB (G eostatistical S\\noftware LIB rary) algorithm. See Expert tab (Petrophysical modeling - Gaussian random function\\nsimulation) and Expert tab (Petrophysical modeling - Kriging and Kriging (Gslib)) for detailed\\ninformation about this tab.\\nFurther information related to these algorithms can be found in the GSLIB manual : GSLIB\\nGeostatistical Software Library and User\\'s Guide, 2nd Edition, 1998 by Clayton V. Deutsch, Andre\\nG. Journel or on the GSLIB website www.gslib.com (Support/Training section).\\nHint tab (Trend modeling)\\nThis tab contains general information regarding the Trend modeling process.\\nUser-defined Object Creation\\nUser defined object modeling allows the user to model objects that are not limited in shape to a\\npredetermined set of choices (such as box, ellipsoid, cylinder, etc.), but can have an\\narbitrary geometry defined by the user in three dimensions (channels, bars, splays, reefs,\\nconcretions, etc.). This capability is meant for creating training images for use in multi-point\\ngeostatistical modeling. Creating an object is the first step in user-defined object modeling. The\\nsecond step is using the object to populate a training image in a Facies Modeling run (see User-\\ndefined Objects in Object Modeling).\\nThe User-defined object creation process allows you to create new objects or edit existing\\nones. The purpose of this step is to define the shape of the object. Neither the final dimensions\\nnor the facies are defined at this stage. If the object is to have multiple facies, the shape of the\\nvolume occupied by each facies must defined and identified by an index. Each index is mapped\\ninto a facies later, in the Facies modeling process.\\nUser-defined objects can be of two types:\\nBoundary defined\\nwhich are determined by a set of 3 orthogonal 2D outlines and consist of a single facies\\nCell defined\\nwhich are determined by a three-dimensional set of cells, and may contain multiple facies.\\nSettings for User-defined Object Creation\\nTo start this process, select User-defined object creation under Property modeling in the\\nProcesses pane. This opens a dialog where you can create or edit a user-defined object:\\nThe upper part of the dialog contains the following controls:\\nCreate new  Edit existing\\nSpecifies whether to create a new object or edit an existing one. If no object exists, only the\\nfirst option is available. When creating a new object, its name may be specified. When editing\\nan existing object, it can be selected from the drop-down list.\\nBoundary def object (or Cell-defined object)\\nIndicates whether the object is a Boundary-defined or a Cell-defined object.\\nConvert to Cell or (Convert to Boundary if the object is already a cell-defined object)\\nWhile creating a Boundary defined type object, a Convert to Cell button is displayed which\\nconverts the object to a cell-defined object type. While creating a Cell defined type object, a\\nConvert to Boundary button is displayed which converts the object to a boundary-defined\\nobject type. Conversion almost always causes some loss of shape information. In particular,\\nconversion from a complex cell-defined object to a boundary-defined object may result in a\\nsignificant loss of the original shape, because cell-defined objects generally can reproduce\\nshapes better than boundary-defined objects. The default objects (a simple box, shown\\ninitially or when clicking the Reset button) can be converted back and forth without any loss\\nof information. In general, you should convert the object to the desired type early in the edit\\nprocess. However, sometimes it is desirable to start with a boundary-defined object (which is\\nfaster to edit), and then convert to a cell-defined object to add complexity and perhaps\\nmultiple facies indexes.'},\n",
       " {'header': 'Plan  Longitudinal  Transversal ',\n",
       "  'content': 'Specifies which of the three orthogonal 2D views is displayed. The J dimension (shown\\nvertically in the plan view) is the longitudinal or \"major\" axis of the body and is the reference\\nfor the bodys orientation when inserting the body in a model. When modeling, the minor\\nwidth is always the dimension of the body along the I axis, the major width (or length)\\nalong the J axis, and the thickness along the K axis, regardless of which dimension of the\\nbody is really the largest. The views of the body have no scales. Scaling is determined at the\\ntime of modeling.\\nResolution I, J and K\\nSpecifies the object\\'s resolution (number of cells or nodes along each axis). Boundary defined\\nobjects do not have a K resolution, because the vertical dimension is given by the outline.\\nOnly the resolution along the axes actually seen on the graph can be changed. To change a\\nresolution value that is grayed out (for example the vertical or K resolution when viewing a\\ncell-defined object in plan view), you must first change the section (plan, longitudinal, or\\ntransversal) and then change the resolution.'},\n",
       " {'header': 'Undo - Redo ',\n",
       "  'content': 'Undo or redo recent changes. Not all changes can be undone. Edits due to direct mouse clicks\\non the object and due to copying an object from a property can be undone. Resolution\\nchanges, conversions (between boundary-defined and cell-defined), resetting to defaults, and\\nopening a new object without saving the previous one can not be undone. If you save an\\nobject by clicking Apply, it is still possible to undo the latest changes (as long as they are\\nsimple edit actions) to return to a previous state of the object.\\nThe controls in the lower part of the dialog (except the Apply and OK buttons) depend on the\\ntype of object (boundary-defined or cell-defined) and are explained below for each type of object.'},\n",
       " {'header': 'Apply ', 'content': 'Saves the object.'},\n",
       " {'header': 'OK ',\n",
       "  'content': 'Saves the object and exits the dialog\\nAfter saving a user-defined object, it is stored in the Input tab, under a folder initially called\\nUser-defined objects.\\nBoundary-defined objects\\nBoundary-defined objects should be used when the geometry of the object is relatively simple and\\nthe object consists of a single facies. The main advantage of boundary-defined objects is that\\nthey can be created and edited quickly. Many geometric shapes (cylinders, ellipsoids, boxes,\\noxbow lakes, simple channel sections, and many user-defined variations of those shapes) can be\\nappropriately represented with boundary-defined objects.\\nA boundary-defined object is defined by outlines as seen in three perpendicular two-dimensional\\nviews:\\nA horizontal plan projection of the object.\\nA vertical longitudinal projection of the object.\\nA vertical transversal cross section through the object.\\nEach 2D view consists of two outlines (a top and a bottom outline for vertical views, and a\\nleft and a right outline for the plan view, shown in red and green in the figure above). Each\\noutline is defined by a set of amplitude values given at regularly spaced points (or \"nodes\") along\\nthe main axis of each 2D view. Each outline is a function along the main axis of the view. Thus,\\neach outline cannot intersect itself and cannot bend over itself because each point along the\\nmain axis can have only one amplitude. Additionally, each of the two outlines (top or left) cannot\\ncross the other in the same section (bottom or right), but curves can cross the main axis (that is,\\nhave positive and negative amplitude values).\\nWhen editing a boundary-defined object, the dialog shows one of the three 2D views and allows\\nthe user to edit each side of the outline independently. For example, a portion of a channel, can\\nbe represented by the following three sections (from left to right: plan, longitudinal, and\\ntransversal):\\nNote that the scales of each section need not match (that is, the channel in the cross section\\nappears to be much larger than the channel in plan- or longitudinal view). The sections are\\nautomatically rescaled and matched at the time of modeling.\\nIn boundary-defined objects, the resolution specifies the number of points (or nodes) used for\\neach outline in the current section. The plan and longitudinal views use the same number of\\npoints (along the J- or longitudinal axis of the body). The transversal view uses a set of points\\nalong the I axis of the body. Notice that there is no resolution to be specified along the K axis\\nbecause none of the outlines lies along that axis. The resolution pertains only to the number of\\npoints used in an outline. The position of the outline points across the axis is arbitrary, and can be\\nconsidered to have infinite resolution for practical purposes.\\nThe controls specific to boundary-defined objects are:\\nRight - Left (or Top - Bottom) . Specifies which of the two half outlines to draw. To draw or edit\\nthe outline, the user simply clicks on the graph. The graph automatically prevents crossing of the\\ntwo outlines.\\nDetailed description of boundary-defined object geometry\\nFor a better understanding on how the three 2D views define a unique 3D object, it is necessary\\nto point out that the plan- and longitudinal views are projections of the object on a vertical and a\\nhorizontal plane, respectively, whereas the transversal view is a cross section (not a projection)\\nthat is scaled vertically and horizontally according to the objects horizontal and vertical\\ndimensions specified by each of the two other projections.\\nTo conceptually reconstruct the object from the three views, consider the horizontal (plan) and\\nvertical (longitudinal) planes, and imagine infinitely many vertical (transversal) planes\\nperpendicular to the first two (all parallel to each other). At each transversal plane, the object has\\na width, height, and position determined by the longitudinal and plan projections. You can place\\nthe transversal section outline in each transversal plane and scale it (independently in the\\nhorizontal and vertical directions) so that the width and height of the body in the section exactly\\nmatch the width and height determined by the plan and longitudinal projections. Then, the set of\\nall scaled transversal sections will uniquely determine a three-dimensional body.\\nThus, it is important to note the following:\\nThe three views are independent from one another. Namely, you do not have to be\\nconcerned with matching any dimension of the body in the different sections. For example,\\nthe width as seen in plan (which varies along the length of the body) need not match the\\nwidth as seen in the transversal section (which will be scaled automatically). .\\nThe three views jointly determine one unique three-dimensional shape, but the converse is\\nnot true; not every 3D shape can be specified in this manner.\\nThe three views are not changeable: if you interchange the transversal section and the\\nlongitudinal section, you do not obtain the same body transposed. You may obtain a\\ndifferent geometry, because one of the views is a projection and the other is a scalable\\nsection. However, the plan and longitudinal views are changeable, in that if you interchange\\nthem, they define the same three dimensional geometry transposed (that is a mirror image\\nrotated 90 degrees).\\nCell-defined objects\\nCell-defined objects should be used when requiring arbitrary shapes that cannot be represented\\nby boundary-defined objects. Objects that might require a cell-defined representation include:\\nchannel pieces with sharply turning meanders, braided channels, objects with holes or cavities, or\\nother arbitrary or very complex shapes. They should also be used when the object requires more\\nthan one facies (however, keep in mind that through proper use of attachment rules, it is often\\npossible and even preferable to use several single-facies objects rather than one multifacies\\nobject). The main advantage of cell-defined objects is that their geometry can be completely\\narbitrary; they can even consist of multiple detached pieces.\\nIt is important to notice that there is no direct correspondence between cells in the object and\\ncells in the final model. The size (in number of cells) when defining the object can be smaller, the\\nsame, or larger than the size (in number of cells) that the object will occupy in the model. Of\\ncourse, if an object with very few cells (for example 3 x 3 x 2) is enlarged to occupy a large\\nnumber of cells in the model, it may have a box-like appearance. The object in the model will\\nhave a number of cells that will depend upon the size of the object as specified in the Geometry\\ntab of the Facies Modeling Process.\\nTo create a cell-defined object, you must first convert a boundary-defined object to a cell-defined\\nobject. The initial boundary-defined object may be the default object (a simple box), or it may\\nalready have been given an initial approximate shape (for example an ellipsoid) and then have\\nbeen converted to add detail and perhaps multiple facies.\\nTo edit a cell defined object, you must edit every cell in three dimensions. It is not sufficient to\\njust edit three perpendicular cross sections (as it is with boundary-defined objects). The dialog\\nallows you to navigate back and forth along the many parallel two dimensional views of the\\nobject.\\nAs an example, if you want to specify a simple cell-defined object (perhaps representing a very\\nshort portion of a channel), you would have to imagine the body embedded in a regular grid, and\\nthen edit that grid to represent the desired body. The process involves setting the desired\\nresolution (number of cells), and then navigating through the sections (using the K-layer control)\\nto set cells to the desired value (either \"erase\" which sets an undefined or background value, or\\n\"draw\" which sets a facies index) by clicking on them. For example, if you would like to draw a\\nchannel, select a plan view on a layer near the top of the grid, and draw a channel shaped body.\\nThen select the transversal view, and navigate through all the J-sections to draw every vertical\\ncross section, using as a reference the single row of cells near the top of the grid that was drawn\\nin the plan view. Now you can verify the shape of the object by selecting another view.\\nThis process is fast for small objects but may be tedious if the object contains a large number of\\ncells. It is also possible to use Petrels interactive facies modeling capability to draw an arbitrary\\nobject on any facies property and then copy the object into this dialog. Similarly, a cell-defined\\nobject can be copied into a property, then edited interactively and copied back.\\nThe resolution (number of cells) of the grid can be specified in the dialog (only the two dimensions\\nvisible in each 2D view can be changed, namely I and J for the plan view, J and K for the\\nlongitudinal view, and I and K for the transversal view). Notice that the grid is not a Petrel grid.\\nIt is a much simpler, non-dimensional, regular grid, in which all cells appear to be cubes (or\\nsquares in the 2D views). For cell-defined objects all three of the views are true cross sections\\n(not projections). So in addition to specifying which view is displayed (plan, longitudinal, or\\ntransversal) it is also necessary to specify which layer of cells is currently displayed using the\\nlayer control (labelled I-layer, J-layer, or K-layer).\\nThe figure below shows the dialog for editing a cell-defined object, in this case an irregular\\nellipsoid, with a \"core\" consisting of a different facies:\\nThe controls specific to cell-defined objects are:\\nK-layer or I-Section or J-Section\\nselection of layer or section to display, depending on view displayed.'},\n",
       " {'header': 'Erase - Draw ',\n",
       "  'content': 'specify whether to draw background or body cells. Drawing the background (Erase) draws\\nwith an undefined facies index value. When modeling, such cells preserve the original\\nbackground facies. However, when saving the body into a property by means of the Export\\nbutton (see below) these cells are copied to the property with an undefined value.\\nFacies index\\nSpecifies which index to use for drawing. Each index is translated into a different facies when\\nmodeling. Single-facies objects are those that use a single index (in addition to the\\nbackground). Multifacies object use more than one index. Index 0 is the default index (it is\\nnot the background value).\\nErase selected\\nErases all cells with the facies index currently selected in the Facies index control (reset to\\n\"undefined\").\\nErase all\\nErases all cells.\\nConvert all to 0\\nResets all defined cells to facies index 0, effectively converting any multi-facies object to a\\nsingle-facies object.'},\n",
       " {'header': 'Input Property ',\n",
       "  'content': 'Specifies the property from which the object will be copied when pressing the Pullbutton. The\\nproperty must be a facies property. To set it, first click on any facies property in the current\\nmodel, and then click on the blue arrow next to the Property label.'},\n",
       " {'header': 'Target Property ',\n",
       "  'content': 'Specifies the property to which the object will be copied when pressing the Pushbutton. The\\nproperty must be a facies property. To set it, first click on any facies property in the current\\nmodel, and then click on the blue arrow next to the Property label. A new property can be\\ncreated by pressing the Createbutton.'},\n",
       " {'header': 'Pull ',\n",
       "  'content': 'Copies a portion of the specified property into the object. The portion copied extends from the\\ncell specified by the origin and covers the current size of the object.'},\n",
       " {'header': 'Create ',\n",
       "  'content': 'Creates a new facies property for storing or retrieving the object using Pulland Push.'},\n",
       " {'header': 'Push ',\n",
       "  'content': 'Copies the object into the specified property. The lowest corner of the object (with I, J, K\\ncoordinates 1,1,1) will be copied into the property cell specified by the origin.'},\n",
       " {'header': 'Origin I J K ',\n",
       "  'content': 'Specifies the cell in the property from which or to which the object will be copied when\\npressing the Pull or Push button.\\nNote: when using the Pull and Push buttons, there is a one-to-one correspondence between cells\\nin the object and cells in the specified facies property).\\nSingle-facies vs multiple-facies cell-defined objects\\nTo create and edit a single-facies cell defined object, simply specify which cells in a regular grid\\nare body and which are background. It is convenient (but not mandatory) to use the cell index\\n\"0\" for single facies objects.\\nTo create and edit a multifacies user-defined object, simply use more than one index. Each index\\nwill be replaced by a different facies when the object is used in modeling. It is not convenient (and\\nusually unrealistic) to use more than about three or four facies indexes for a single object. While\\ngeological models can certainly contain more known facies, single objects (which have an\\nimmutable geometry of each facies except for scaling) are not very useful if they are very\\ncomplex. If you need more than three or four facies, it is likely that the objects can be\\ndecomposed into more than one object and rejoined with attachment rules. This ensures that the\\ngeometry will not be immutable, but will vary statistically according to the shape distributions\\nused for each body and their attachment rules.\\nTraining image and pattern creation\\nThe basic input for the Multi-point facies simulation algorithm is the Training image (TI )\\nand the Multi-point facies pattern . There are various methods you can use to make training\\nimages, such as object modeling or hand drawn models. The creation and the use of training\\nimages have been combined with the pattern creation into a process called Training image and\\npattern creation .\\nThe Make pattern process analyzes the Training image and produces a tree or pattern that\\nexplains the neighborhood relationship of the facies (event). Internally, for every event, a pdf (p\\nrior d istribution f unction) is recorded in the pattern.\\nThe result of the training image will be stored in a separate 3D grid (TI grid ) on the Models\\npane, and the result for the pattern process will be stored in a separate folder (Multi-point facies\\npattern folder) on the Input pane and will be used later by the Multi-point facies simulation in\\nthe Facies modeling process.\\nFor detailed information on the Multi-point facies simulation see Multi-point facies simulation\\n.\\nTraining image and pattern creation Settings\\nThe Training image and pattern creation process is found under Property modeling on the\\nProcesses pane. This process has two main tabs: the Make training image grid (Figure 1) and\\nMake pattern (Figure 5).\\nMake training image grid tab\\nThe first part of the process is to create a Training image (TI) . A training image is a facies\\nobject model with a minimum of two facies. For example, an existing object model that can be\\nedited by interactive facies modeling (hand made by using tools as the paintbrush).\\nThe main purpose of the training image is to show the relative position the facies have to each\\nother, with the goal to describe the facies relationship and not the geology (subsurface) in great\\ndetail. As is similar in Neural Networks, there is a risk of overtraining. For simple geological\\nsituations, it is sufficient to know the number of facies and their characteristics.\\nThe training image used in Multi-point statistics is similar to the variogram in Two-point statistics.\\nConsequently, the modeler must design the training image with care, in much the same way as\\nwhen we set up a search cone to explore a variogram.\\nGuidelines for preparing the Training image grid\\n1 . In the Make training image grid tab, you can choose either Create new or Edit existing\\nwhen designing the training image. In the latter case, the settings that were used when the\\nprocess was last run are shown in the dialog. If you want to create a new image from an existing\\none without overwriting the original, make a copy before you run the process.\\n2 . In theory, a training image can be any facies model. For practical reasons it is a good idea to\\nhave a separate model for the training images and for the easiest cases, this can be rectangular\\n. Then you can create an empty simple box model without any structure and zonation/layering by\\ndefining the following parameters:\\nNumber of cells (IJK) - Define the amount of cells in the different grid directions (I,J,K).\\nThe size of the training image grid is important. The training image grid does not have to be\\nas big as the grid where the final results will be produced (model grid). Rather, It is\\nrecommended to have a smaller training image grid than the model grid initially and to\\nwork with the scaling options later. The relationship of the facies will be measured in IJK\\nand not in XYZ. Smaller training grids lead to faster computing time. The critical issue is the\\nratio between the training grid and the model grid. There is no tool for calculating this, so\\nthe recommendation is to use a maximum of 30%, which should work efficiently. Tests have\\nshown that in I,J-directions, 50-200 cells, and in K-direction, 20 cells, can be sufficient in\\nmany cases.\\nCell size (XYZ) - Define the size of the cell in the X,Y and Z directions (be aware of the\\nProject unit system).\\nOrigin (XYZ) - The origin of the image grid can be set up as default (0,0,0) or with any\\nvalues you choose to assign. Generally, the training image grid can have any coordinates,\\nbut in some situations where the training image grid is \"far away\" from the real property,\\nparts of the model may disappear when moving one of these grids in a 2D/3D window.\\nTherefore it is recommended that the training image grid and the property model have\\ncoordinates which are close to each other.\\nFigure 1. Make training image grid process dialog.\\n3 . Once the grid cell parameters are defined, click on the Make grid button and\\na new 3D grid will be created. It will be stored in the Models pane and will contain a Property\\nfolder with an empty 3D property (Figure 2).\\nFigure 2. Training image grid generated under the Models pane.\\n4 . Use the Facies modeling button to show its process dialog. Then the Facies modeling\\nprocess will pop up with the Object modeling (stochastic) algorithm selected (Figure 3) and\\nthe training image can be generated as an object model. Additionally, the user defined objects\\ncan be modeled here as a fourth option in Object modeling (stochastic) algorithm (Figure 3).See\\nObject Modeling and User-defined Object Modeling for detailed information on those processes.\\nFigure 3. Facies modeling process dialog for the Training image. See in the Facies bodies tab to\\nthe right side, the four objects (icons) option to model.\\nGenerally, the training image should be as simple as possible. You should not create\\npatterns that are too detailed and with too many facies (>8). In most cases, between 3 to 6 main\\nfacies are sufficient.\\nAnother option to create a training image is by editing an existing facies model, using the painting\\ntools under the Facies Modeling function bar (see Interactive Facies Modeling ).\\nFigure 4. Example of training image (3D).\\nWhen preparing a training image, it is not necessary to explain every unknown detail. It is\\nmore important to show the principal characteristics; e.g. a 3 facies system (shale, channel and\\nlevee) and how they interact.\\nStationarity is also an issue in the Multi-point facies simulation modeling. If you expect to have\\nthe same geological situation everywhere in the field and in the model, one training image is\\nenough. If the situation is more complex, with different geological situations in different regions,\\nyou will have to produce as many training images as there are different regions.\\nMake pattern tab\\nIn the Make pattern tab, you can choose between Create new or Edit existing for your\\npattern. In the latter case, the settings that were used when the process was last run are shown\\nin the dialog. If you want to create a new pattern from an existing one without overwriting the\\noriginal, make a copy before you run the process.\\nFigure 5. Make pattern process dialog.\\nTraining image\\nThe Training image is the facies object model generated in the Make training image grid and\\nFacies modeling processes. Select it from the Models pane/Training image grid /Property\\nfolder and using the blue arrow, drop it into the process.\\nSearch mask\\nThe purpose of the Search mask section is to define a search area by using a geometrical\\nshape. It can be Ellipsoid or Rectangular (the last one is bigger).\\nThe Radius in Number of cells in IJK direction is comparable to the search radius in classical\\ngeostatistics and will be applied on the training image. The Effective radius (search radius) is\\nalso shown on the coarsest grid level in IJK domain.'},\n",
       " {'header': 'Advanced ',\n",
       "  'content': 'The advanced option allows the user to select how many multi-grids to work with. When\\nworking with multi-grids, the subgrid concept is automatically working in the background (see\\nnext section).\\nThere are two parameters that should be defined:\\nNumber of multi-grids - defines how many multigrids you want to work with.\\nMax number of informed nodes from current sub-grid - defines how many nodes\\nfrom the current sub-grid are used for simulation of a point. Nearby points are\\nautomatically used. Many points will generally give better results, but also tend to slow\\ndown the computation time. If you are not satisfied with the results, increasing the number\\nof cells used in the search mask (> 100 or up to ~10%) will help to improve them.\\nThe Multi-grid and Sub-grid concept\\nWorking with multi-grids and sub-grids makes the algorithm more efficient. The main goal of\\nmulti-grids is to describe both small and large scale structures as short and long variogram\\nranges in the 2 point geostatistics.\\nWhen creating a multi-point facies pattern the coarsest grid will be populated first and the finest\\ngrid last. In the coarsest grid every 2^(m-1) (m=number of multi-grids) cell will be addressed\\n(dark green cells in Multi-grid 4 in Figure 6). In the second coarsest grid, these cells work as\\nalready defined nodes like cells in a Gaussian simulation (now blue in Multi-grid 3). Using sub-\\ngrids means the cells sitting perfectly in the middle of the already defined cells will be populated\\nfirst (dark green), followed by the others in between (light green). This goes on until all cells are\\naddressed (Multi-grid 1 example in figure 6 below). The sub-grid concept is automatically\\nimplemented and works in the background.\\nWhen working (for example) with 4 multi-grids on the the coarsest grid level every 2^(4-1) = 8th\\ncell will be populated first (multi-grid 4). In multi-grid 3 every 2^(3-1) = 4th cell is simulated, but\\nthe centrally placed cells first and then followed by all others. In multi-grid 2, every second cell is\\nsimulated until finally every cell is done in the last step (multi-grid 1).'},\n",
       " {'header': 'Figure 6. Multigrids. ',\n",
       "  'content': 'How would this look in a real case scenario? In Figure 7 a training image (stacked\\nchannels/levees) is shown in 4 multi-grids. The size is 200 x 200 x 30 cells. The first image (multi-\\ngrid 1) shows a complete picture, but it needs a big search radius in the mask and therefore a\\nlarge pattern (tree and file). Multi-grid 2 is still a good representation of the facies association but\\nit needs a big search radius. In multi-grid 3 the facies are still visible and the search mask would\\nnot be too big. In Multi-grid 4 the ability to recognize stacked channels is lost. It would run very\\nfast but would give poor result.\\nFigure 7. Training image shown in multi-grids.\\nRelationship between Training image, Search mask and Multi-grid\\nIt is necessary to understand the relationship between all the settings. For example, when you set\\nup a 10x10x3 cell search in the Search mask and are working with 3 multi-grids , the search\\ncovers on the coarsest level:\\n2^(3-1) * 10 * 2 = 80 cells (horizontal)\\n2^(3-1) * 3 * 2 = 24 layers (vertical)\\nAt present, the Search mask cannot determine the optimal settings in the Search mask section\\nlike there is for the variogram modeling (range, sill, nugget, etc.). However, if you make the\\nassumption from the classical 2 point geostatistics that the search radius for variogram modeling\\nshould not be bigger than approximately 2/3 of the whole model extension, one conclusion can be\\nthat the training image should not be bigger than 120x120x36 cells. Or vice versa, if the training\\nimage has the dimension 200x200x30 cells and a Search mask using 3 multi-grids, then a\\nsufficient radius would be 17x17x3 cells. Working with bigger search radius will improve the image\\nslightly but will produce very large files.\\nThe result of Make multi-point facies pattern\\nWhen you are finished with the settings and press Apply, a pattern will be established. According\\nto the settings for any possible geometrical setup in every multi-grid, a pdf (prior density\\nfunction) will be calculated. Figure 8 is an example of how it works with just the nearest (one)\\nneighborhood in case of an elliptic search mask.'},\n",
       " {'header': 'Figure 8. ',\n",
       "  'content': 'In the figure above, it is probably sand (code 1) if the neighbor above and to the right is sand. In\\nthe training image, there are 7 events for this situation whereas 9 events show shale (code 0).\\nThe probability of having sand would be 7/16=0.44 or 44%.\\nWhat would happen if the training image shows a slightly bigger scale, for example, if the\\nsinuosity shows more than 1 cycle? It is likely that the probability will change towards 50%. This\\nexample shows why it is important to carefully prepare the training image. Practical tests have\\nshown that it is better to \"draw\" a minimum of 2 sinusoidal cycles when you work with a fluvial or\\na more general channel pattern.\\nTo continue this example, the tree for the 1 cell neighborhood has to calculate the pdf for all\\npossible events as shown in Figure 9 below.'},\n",
       " {'header': 'Figure 9. ',\n",
       "  'content': 'It now becomes obvious what happens when the search mask is not 2-dimensional with an\\nelliptical search radius of 1 cell, but 3-dimensional with a search mask of 17 x17 x 3 using 3\\nmultigrids. It is not recommended to work with extremely detailed training images on big grids\\nwhile applying a large search radius as this will make the CPU time longer.\\nAfterwards define all of the parameters to create or edit a multi-point facies pattern, click on the\\nMake pattern button .\\nThe result of the Make pattern process will be stored at the bottom of the Input pane and\\norganized in folders (see Figure 10). There is no data to visualize/display in the Petrel windows\\n(similar to the \"Neural net\" of Train estimation model). If you open the Settings of the selected\\nfacies pattern, you can check the Statistics . For the Multi-point facies simulation this output\\nwill be the main input. In this way, it works like the variogram parameter in classical geostatistics.\\nFigure 10. Multi-point facies pattern folder results stored in the Input pane.\\nOnce the multi-point facies pattern is generated, it can be tested by using the Test pattern\\nbutton . This option creates a multi-point facies property for testing using the\\ntraining image pattern in the Facies modeling/Multi-point facies simulation process automatically'},\n",
       " {'header': '(Figure 11). ',\n",
       "  'content': 'Figure 11. Test pattern property result.'},\n",
       " {'header': 'Facies Modeling ',\n",
       "  'content': 'Facies modeling is a means of distributing discrete data (e.g. facies) throughout the model grid.\\nIn Petrel Stochastic and Deterministic (estimation or interpolation ) methods are available for\\nmodeling the distribution of discrete properties in a reservoir.\\nNormally, you will have upscaled well logs with discrete properties in the model grid, and possibly\\ndefined trends within the reservoir, by analyzing this data in the Data analysis process. Whether a\\nproperty is discrete or not is defined by the property template it is attached to a discrete template\\n(see Templates for property models for more information). Filters and settings can be used to\\nmodel different parts of the grid separately (e.g. filter on values, index, zones, segments and local\\nmodel updated settings).\\nSee General information on Property modeling for more information on wthat to consider when\\nperfoming property modeling.\\nFacies modeling General Settings\\nAll operations for propagating facies properties throughout the grid are controlled from within the\\nFacies modeling dialog box. This process dialog includes two main tabs:\\n1. Make model\\nInput dialog for Facies modeling processes.'},\n",
       " {'header': '2. Hints ',\n",
       "  'content': 'Hints for using the interactive facies editing tools and the property player.\\nMake model tab\\nAt the top of the Make model tab are the basic settings for facies modeling:'},\n",
       " {'header': 'Overwrite ',\n",
       "  'content': 'This allows you to choose between modeling on an existing property with upscaled cells\\n(default), or generating a new property without using upscaled cells as input. For the last\\noption you have to select the correct discrete template and give a name to the new property.'},\n",
       " {'header': 'Existing Property ',\n",
       "  'content': 'Choose the property to perform the modeling on. If the property has upscaled cells, then\\nthese will be used as input to the modeling, only discrete properties will be listed here. The\\nStatus textbox will say whether the chosen facies is upscaled or not.'},\n",
       " {'header': 'Show Color Table ',\n",
       "  'content': 'Will open the color table tab in the Settings window for the active property.'},\n",
       " {'header': 'Show Discrete Statistics ',\n",
       "  'content': 'Will open the discrete statistics tab in the Settings window for the active property.\\nShow Data analysis dialog\\nWill open the Data analysis process dialog for the current property.\\nCommon tab\\nWill reveal the dialog for general settings for Facies modeling. For detailed information see\\nCommon tab.\\nZone settings tab\\nThis is the basic input dialog for modeling facies in Petrel. For detailed information see Zone\\nsettings button.\\nShow property Filter\\nWill pop up the property filter for the active grid. The filter will not be used for modeling\\nunless it is turned on under the common settings dialog.'},\n",
       " {'header': 'Seed ',\n",
       "  'content': 'Selects the seed for all stochastic algorithms used in the modeling (it deselects all local\\nseeds). When activated, all zones using stochastic modeling are given an irregular offset\\nseed.\\nBasic settings for the\\nFacies modeling process dialog\\nMake model settings (Facies modeling)\\nCommon tab\\nThe settings chosen in this button affect all of the zones in the model. The Reset button will\\nreset all settings in the Common tab to default.\\nIn the General section, if you select the Use filter check box, all filters that are active on the\\nFilter tab from the settings for the Property folder will be considered as well as the zone and\\nsegment filters. Take special care to check that the correct zones and segments are active.\\nThe check box Ensure that all cells get a value will find any cells that are undefined within the\\nmodel and give them an average value determined by values in surrounding cells.\\nThe Local model update section allows you to update a facies model in an area determined by a\\npolygon while keeping continuity with the neighboring cells that are not changed. It is a simple\\nway of filtering a region in which cells are going to be overwritten when the modeling processes\\nare run. The settings have two options:\\nOnly overwrite cells inside polygon - a closed polygon must be provided. It is arbitrary\\nand can optionally consist of several grouped polygons into one polygon object. When the\\nprocess is run, only cells inside the polygon wall will be modeled and all cells outside the\\npolygon wall remain unchanged.\\nPolygon lateral thickness - user defined lateral thickness; the higher the lateral\\nthickness, the more influence the previously modeled data will have when modeling the\\narea inside the polygon. The default value is 3 cells, it will be appropiate for most of the\\nalgorithms with the default settings.\\nIn the Realizations section, you can set up the Number of realizations. With multiple\\nrealizations, Petrel will use the same input parameters to assign a distribution multiple times.\\nAdditional distributions will be added as additional properties. In addition, you have the option to\\nOverwrite the previous set of realizations. You can also choose how to handle unchanged zones\\nin the new property models, whether to Copy them from the active property or to Leave it\\nunchanged.\\nCommon settings in the\\nFacies modeling process dialog\\nZone settings button\\nBy clicking on the Zones settings button, you can toggle between using the same settings for all\\nzones and describing settings for each zone individually. Here you can choose which algorithm to\\nuse when you are modeling. You can also choose the Together (As for the zone above) check\\nbox which will adopt the settings defined for the zone above. Furthermore, you can define\\nwhether to simulate/interpolate this zone separately or together with the zone above.\\nYou can do Facies modeling conditionally upon another facies model. Click on the Facies\\nbutton and select among the already existing facies models. For more information see Sequential\\nindicator simulation.\\nIn the Method for zone/facies option, you can select the algorithm you want to use for the\\nfacies modeling. Every algorithm has different settings and tabs that will appear once you have\\nselected one.\\nThere are many useful icons in the Zone settings dialog:\\nCopy settings from the selected zone\\nCopies all settings defined for the selected zone.\\nPaste settings to the selected zone\\nOnly available after using the copy option. Click on the tab of another zone and then click on\\nthis icon. Will apply the settings of the copied zone to the currently selected zone.\\nPaste settings to all zones\\nOnly available after using the copy option. Will apply the settings of the copied zone to all\\nother zones.\\nReset settings of the selected zone to default\\nResets all the different settings of a zone to default values. A similar icon is available in each\\nsub menu.\\nReset settings of all zones to default\\nResets all the different settings for all the different zones in the project.\\nLeave zone unchanged\\nWill lock the zone for modeling, use this option on all zones you do not want to work on to\\nmake the modeling run quickly. Press Shift while clicking this button to lock/unlock all the\\nzones at once.\\nUse the Variograms made in the data analysis\\nThis will fetch the variograms defined in the Data analysis process for use with the\\nSequential indicator simulation, Truncated Gaussian simulation and Indicator\\nkriging algorithms. It is possible to visualize the variogram parameters stored in Data\\nanalysis process once they have been edited and after the user turns on this button.\\nUse the Attribute Probability Curves made in the data analysis\\nThis will fetch the probability curve defined in the Data analysis process for use with the\\nSequential indicator simulation, Truncated Gaussian simulation and Multi-point\\nfacies simulation algorithms.\\nUse the Vertical Proportion Curves made in the data analysis\\nWill fetch the vertical proportion curve defined in the Data analysis process for use with the\\nSequential indicator simulation, Truncated Gaussian simulation, Object Modeling\\nand Multi-point facies simulation algorithms. When using Object modeling, this setting\\ncan be defined for each set of objects individually and is found on the Trends tab after the\\nobject is inserted.\\nSome examples of Zone settings in the Facies modeling process dialog'},\n",
       " {'header': 'Facies Modeling Methods ',\n",
       "  'content': 'This section describes the settings tabs for each of the Facies modeling algorithms.\\nIn Petrel 2010.1 the Facies modeling algorithms run in parallel, in two different ways: first\\nthrough reuse of the Kriging and Simulation algorithms and second by parallelization by zone or\\nrealization. The first method is used to parallelize parts of those algorithms which are based on\\nKriging and Simulation algorithms, such as, Adaptive channel. The second method is used for\\nthose algoritms which are Sequential by nature, such as, Sequential indicator simulation and\\nMulti-point facies simulation. The Truncated Gaussian algorithms have both types of\\nparallelization. Some exceptions as Fluvial channel and Object models were not parallelized.\\nThe Facies Modeling process involves eleven different facies modeling approaches:'},\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will combine header and content to make one string and store all of them as elements of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_list = []\n",
    "\n",
    "for section_dict in sections:\n",
    "    # Extract the 'header' and 'content' from the dictionary\n",
    "    header = section_dict['header']\n",
    "    content = section_dict['content']\n",
    "    \n",
    "    # Combine 'header' and 'content' with a newline in between\n",
    "    combined_string = f\"{header}\\n{content}\"\n",
    "    \n",
    "    # Append the combined string to your new list\n",
    "    sections_list.append(combined_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43417"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max = 0\n",
    "for section in sections_list:\n",
    "    if len(section)>max:\n",
    "        max = len(section)\n",
    "\n",
    "max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the text before embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script outlined below serves a crucial role in processing a list of text strings, specifically ensuring that none of the strings breach a predetermined character limit range, set here between 6,000 and 8,000 characters. This boundary is crucial when working with certain text processing APIs or systems that impose restrictions on the amount of text they can handle within a single operation.\n",
    "\n",
    "Here's a detailed breakdown of the script's operation:\n",
    "\n",
    "1. **Utility Function (`split_text_into_sentences`)**: Initially, the script employs a utility function that fragments the text into individual sentences using regular expressions to identify sentence terminators (like periods or question marks) while avoiding common false positives (such as abbreviations).\n",
    "\n",
    "2. **Main Processing Function (`process_strings`)**: The main logic resides in the `process_strings` function, which iterates through each string in the provided list. This function segments the text into sentences and dynamically aggregates them, ensuring each combined string respects the defined minimum and maximum character constraints.\n",
    "\n",
    "3. **Buffer Management for Text Aggregation**: A 'buffer' string temporarily holds the aggregated sentences. When the addition of a new sentence causes the buffer to approach the maximum limit, the function evaluates the buffer's length:\n",
    "\n",
    "   - If the buffer exceeds the minimum character threshold, it is appended to the final list of processed strings, emptied, and then initiated with the new sentence.\n",
    "   - If the buffer falls short of the minimum characters, the function continues to add sentences until it surpasses the minimum length, even if this means momentarily exceeding the maximum character limit. This ensures no processed string is below the acceptable length, accommodating scenarios where an original text string is too short.\n",
    "\n",
    "4. **Post-Processing and Edge Case Handling**: After iteratively processing each text string from the original list, the script addresses any residual content in the buffer. If this content surpasses the minimum character limit, it is added to the final list, ensuring valuable information isn't discarded.\n",
    "\n",
    "5. **Output Preparation**: The script concludes by returning a new list (`rearranged_strings`), consisting of the restructured text strings. Each entry in this list complies with the character restrictions, making them suitable for systems or APIs sensitive to text length.\n",
    "\n",
    "This approach ensures the integrity of the processed text, respecting logical content boundaries (like sentences) and maintaining the meaningful sequence of information, thereby readying the data for further text processing tasks within character-bound constraints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_text_into_sentences(text):\n",
    "    # This function splits text into a list of sentences.\n",
    "    sentence_endings = re.compile(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s')\n",
    "    sentences = sentence_endings.split(text)\n",
    "    return sentences\n",
    "\n",
    "def process_strings(strings, min_chars=6000, max_chars=8000):\n",
    "    \"\"\"\n",
    "    Process the list of strings, rearranging and splitting content so that each element adheres to character limits.\n",
    "\n",
    "    :param strings: List of strings.\n",
    "    :param min_chars: Minimum number of characters allowed in each section.\n",
    "    :param max_chars: Maximum number of characters allowed in each section.\n",
    "    :return: New list of strings, with content rearranged and split according to specified limits.\n",
    "    \"\"\"\n",
    "    processed_list = []\n",
    "    buffer = \"\" \n",
    "\n",
    "    for content in strings:\n",
    "        sentences = split_text_into_sentences(content)\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if not sentence:\n",
    "                continue\n",
    "\n",
    "            # If adding the new sentence doesn't exceed the maximum character limit, we add it to the buffer.\n",
    "            if len(buffer) + len(sentence) + 1 <= max_chars:  # +1 for space\n",
    "                buffer += (sentence + \" \")\n",
    "            else:\n",
    "\n",
    "                if len(buffer) >= min_chars:\n",
    "                    processed_list.append(buffer.strip())\n",
    "                    buffer = sentence + \" \"  # Start a new section with the current sentence\n",
    "                else:\n",
    "                    # If the current buffer is less than the minimum limit, we need special handling. \n",
    "                    # We will keep adding sentences to it until it exceeds min_chars, even if it means\n",
    "                    # going over the max_chars limit for this specific section.\n",
    "                    while len(buffer) < min_chars and sentences:\n",
    "                        buffer += (sentences.pop(0).strip() + \" \")  # Pop sentences and add them to the buffer\n",
    "                    processed_list.append(buffer.strip())\n",
    "                    buffer = \"\"  # Start fresh, as we've handled the 'too short' case by going over the limit\n",
    "                    \n",
    "                    if sentence:  # If current sentence wasn't added, initiate the buffer with it\n",
    "                        buffer = sentence + \" \"\n",
    "\n",
    "    # Handling the last part if it's above the minimum limit\n",
    "    if len(buffer) >= min_chars:\n",
    "        processed_list.append(buffer.strip())\n",
    "\n",
    "    return processed_list\n",
    "\n",
    "# Assuming 'original_strings' is your list of strings.\n",
    "rearranged_strings = process_strings(sections_list, 6000, 8000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding the document by chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0 to 4\n",
      "Processing batch 5 to 9\n",
      "Processing batch 10 to 14\n",
      "Processing batch 15 to 19\n",
      "Processing batch 20 to 24\n",
      "Processing batch 25 to 29\n",
      "Processing batch 30 to 34\n",
      "Processing batch 35 to 39\n",
      "Processing batch 40 to 44\n",
      "Processing batch 45 to 49\n",
      "Processing batch 50 to 54\n",
      "Processing batch 55 to 59\n",
      "Processing batch 60 to 64\n",
      "Processing batch 65 to 69\n",
      "Processing batch 70 to 74\n",
      "Processing batch 75 to 79\n",
      "Processing batch 80 to 84\n",
      "Processing batch 85 to 89\n",
      "Processing batch 90 to 94\n",
      "Processing batch 95 to 99\n",
      "Processing batch 100 to 104\n",
      "Processing batch 105 to 109\n",
      "Processing batch 110 to 114\n",
      "Processing batch 115 to 119\n",
      "Processing batch 120 to 124\n",
      "Processing batch 125 to 129\n",
      "Processing batch 130 to 134\n",
      "Processing batch 135 to 139\n",
      "Processing batch 140 to 144\n",
      "Processing batch 145 to 149\n",
      "Processing batch 150 to 154\n",
      "Processing batch 155 to 159\n",
      "Processing batch 160 to 164\n",
      "Processing batch 165 to 169\n",
      "Processing batch 170 to 174\n",
      "Processing batch 175 to 179\n",
      "Processing batch 180 to 184\n",
      "Processing batch 185 to 189\n",
      "Processing batch 190 to 194\n",
      "Processing batch 195 to 199\n",
      "Processing batch 200 to 204\n",
      "Processing batch 205 to 209\n",
      "Processing batch 210 to 214\n",
      "Processing batch 215 to 219\n",
      "Processing batch 220 to 224\n",
      "Processing batch 225 to 229\n",
      "Processing batch 230 to 234\n",
      "Processing batch 235 to 239\n",
      "Processing batch 240 to 244\n",
      "Processing batch 245 to 249\n",
      "Processing batch 250 to 254\n",
      "Processing batch 255 to 259\n",
      "Processing batch 260 to 264\n",
      "Processing batch 265 to 269\n",
      "Processing batch 270 to 274\n",
      "Processing batch 275 to 279\n",
      "Processing batch 280 to 284\n",
      "Processing batch 285 to 289\n",
      "Processing batch 290 to 294\n",
      "Processing batch 295 to 299\n",
      "Processing batch 300 to 304\n",
      "Processing batch 305 to 309\n",
      "Processing batch 310 to 314\n",
      "Processing batch 315 to 319\n",
      "Processing batch 320 to 324\n",
      "Processing batch 325 to 329\n",
      "Processing batch 330 to 334\n",
      "Processing batch 335 to 339\n",
      "Processing batch 340 to 344\n",
      "Processing batch 345 to 349\n",
      "Processing batch 350 to 354\n",
      "Processing batch 355 to 359\n",
      "Processing batch 360 to 364\n",
      "Processing batch 365 to 369\n",
      "Processing batch 370 to 374\n",
      "Processing batch 375 to 379\n",
      "Processing batch 380 to 384\n",
      "Processing batch 385 to 389\n",
      "Processing batch 390 to 394\n",
      "Processing batch 395 to 399\n",
      "Processing batch 400 to 404\n",
      "Processing batch 405 to 409\n",
      "Processing batch 410 to 414\n",
      "Processing batch 415 to 419\n",
      "Processing batch 420 to 424\n",
      "Processing batch 425 to 429\n",
      "Processing batch 430 to 434\n",
      "Processing batch 435 to 439\n",
      "Processing batch 440 to 444\n",
      "Processing batch 445 to 449\n",
      "Processing batch 450 to 454\n"
     ]
    }
   ],
   "source": [
    "# Configure your OpenAI API\n",
    "openai.api_key =  st.secrets['auth_key']\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # OpenAI's best embeddings as of Apr 2023\n",
    "\n",
    "# You might need to reduce this number if you still hit the token limit.\n",
    "# The actual value could be much smaller, depending on the average tokens per text in 'sections_list'.\n",
    "SAFE_BATCH_SIZE = 5  # Safely under the assumption of maximum tokens, considering the size of your texts\n",
    "\n",
    "embeddings = []\n",
    "batch_start_indices = range(0, len(rearranged_strings), SAFE_BATCH_SIZE)\n",
    "\n",
    "for batch_start in batch_start_indices:\n",
    "    batch_end = batch_start + SAFE_BATCH_SIZE\n",
    "    batch_texts = rearranged_strings[batch_start:batch_end]\n",
    "    \n",
    "    try:\n",
    "        print(f\"Processing batch {batch_start} to {batch_end-1}\")\n",
    "        response = openai.Embedding.create(\n",
    "            model=EMBEDDING_MODEL, \n",
    "            input=batch_texts\n",
    "        )\n",
    "        # Extract embeddings and extend the list\n",
    "        batch_embeddings = [data[\"embedding\"] for data in response[\"data\"]]\n",
    "        embeddings.extend(batch_embeddings)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {batch_start} to {batch_end-1}: {e}\")\n",
    "        continue  # Skip the problematic batch or handle the issue based on your project's requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a DataFrame (if all batches were successful, this should match the original list length)\n",
    "df = pd.DataFrame({\n",
    "    \"text\": rearranged_strings[:len(embeddings)],  # Safety measure to match the embeddings length\n",
    "    \"embedding\": embeddings\n",
    "})\n",
    "\n",
    "# Ensure you've captured all embeddings\n",
    "assert len(df) == len(rearranged_strings), \"Mismatch between number of texts and embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WWeellccoommee ttoo tthhee PPeettrreell** hhee...</td>\n",
       "      <td>[-0.02119479887187481, -0.006573337130248547, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benefits \\n3D surveys and thousands of 2D seis...</td>\n",
       "      <td>[-0.034185562282800674, -2.8231421310920268e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surface attribute library for rapid prospect i...</td>\n",
       "      <td>[-0.03658333048224449, 0.013583413325250149, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uses a standard layer cake approach for domain...</td>\n",
       "      <td>[-0.013447406701743603, 0.005238193087279797, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fault properties can then be visualized in the...</td>\n",
       "      <td>[-0.03174079954624176, -0.015956807881593704, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Appendix 5 - Well Connection Calculations \\nWh...</td>\n",
       "      <td>[-0.015207061544060707, -0.007961086928844452,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Network access is defined by two values: an IP...</td>\n",
       "      <td>[-0.0030754979234188795, 0.007947798818349838,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Observe how\\nthe Memory usage information in t...</td>\n",
       "      <td>[-0.009794695302844048, -0.01491154171526432, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>This name should be an existing name (see\\nPet...</td>\n",
       "      <td>[-0.02186855487525463, 0.006534830201417208, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>See section \"ID Strings\" for a list of possibl...</td>\n",
       "      <td>[-0.02286275289952755, 0.026704153046011925, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    WWeellccoommee ttoo tthhee PPeettrreell** hhee...   \n",
       "1    Benefits \\n3D surveys and thousands of 2D seis...   \n",
       "2    Surface attribute library for rapid prospect i...   \n",
       "3    Uses a standard layer cake approach for domain...   \n",
       "4    Fault properties can then be visualized in the...   \n",
       "..                                                 ...   \n",
       "446  Appendix 5 - Well Connection Calculations \\nWh...   \n",
       "447  Network access is defined by two values: an IP...   \n",
       "448  Observe how\\nthe Memory usage information in t...   \n",
       "449  This name should be an existing name (see\\nPet...   \n",
       "450  See section \"ID Strings\" for a list of possibl...   \n",
       "\n",
       "                                             embedding  \n",
       "0    [-0.02119479887187481, -0.006573337130248547, ...  \n",
       "1    [-0.034185562282800674, -2.8231421310920268e-0...  \n",
       "2    [-0.03658333048224449, 0.013583413325250149, 0...  \n",
       "3    [-0.013447406701743603, 0.005238193087279797, ...  \n",
       "4    [-0.03174079954624176, -0.015956807881593704, ...  \n",
       "..                                                 ...  \n",
       "446  [-0.015207061544060707, -0.007961086928844452,...  \n",
       "447  [-0.0030754979234188795, 0.007947798818349838,...  \n",
       "448  [-0.009794695302844048, -0.01491154171526432, ...  \n",
       "449  [-0.02186855487525463, 0.006534830201417208, -...  \n",
       "450  [-0.02286275289952755, 0.026704153046011925, 0...  \n",
       "\n",
       "[451 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store document chunks and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('petrel_manual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "petrobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
